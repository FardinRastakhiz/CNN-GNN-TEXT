{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-16T02:25:06.224658Z",
     "iopub.status.busy": "2025-06-16T02:25:06.224500Z",
     "iopub.status.idle": "2025-06-16T02:25:08.306558Z",
     "shell.execute_reply": "2025-06-16T02:25:08.305896Z",
     "shell.execute_reply.started": "2025-06-16T02:25:06.224643Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk import pos_tag\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T02:25:10.622763Z",
     "iopub.status.busy": "2025-06-16T02:25:10.622356Z",
     "iopub.status.idle": "2025-06-16T02:25:10.627896Z",
     "shell.execute_reply": "2025-06-16T02:25:10.627132Z",
     "shell.execute_reply.started": "2025-06-16T02:25:10.622736Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "stem = PorterStemmer()\n",
    "\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-zA-Z0-9]',' ',text)\n",
    "    text = text.split()\n",
    "    text = [ i for i in text if i not in stopwords.words('english')]\n",
    "    text = [stem.stem(i) for i in text]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T02:25:10.628952Z",
     "iopub.status.busy": "2025-06-16T02:25:10.628653Z",
     "iopub.status.idle": "2025-06-16T02:31:45.476813Z",
     "shell.execute_reply": "2025-06-16T02:31:45.476183Z",
     "shell.execute_reply.started": "2025-06-16T02:25:10.628930Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(r'data\\TextClassification\\AGNews\\train.csv', header=None)\n",
    "# df_train.columns=['Class Index', 'Title', 'Description']\n",
    "# df_test = pd.read_csv(r'data\\TextClassification\\AGNews\\test.csv', header=None)\n",
    "# df_test.columns=['Class Index', 'Title', 'Description']\n",
    "# df_train['News'] = df_train['Title']+\" \"+df_train['Description']\n",
    "# df_test['News'] = df_test['Title']+\" \"+df_test['Description']\n",
    "\n",
    "# df_train['clean'] = df_train['News'].apply(clean)\n",
    "# df_train.to_csv(r\"data\\TextClassification\\AGNews\\train-clean.csv\")\n",
    "\n",
    "# df_test['clean'] = df_test['News'].apply(clean)\n",
    "# df_test.to_csv(r\"data\\TextClassification\\AGNews\\test-clean.csv\")\n",
    "\n",
    "df_train = pd.read_csv(r\"data\\TextClassification\\AGNews\\train-clean.csv\")\n",
    "df_test = pd.read_csv(r\"data\\TextClassification\\AGNews\\test-clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T02:25:09.293554Z",
     "iopub.status.busy": "2025-06-16T02:25:09.293333Z",
     "iopub.status.idle": "2025-06-16T02:25:09.298660Z",
     "shell.execute_reply": "2025-06-16T02:25:09.297905Z",
     "shell.execute_reply.started": "2025-06-16T02:25:09.293537Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T02:25:09.218008Z",
     "iopub.status.busy": "2025-06-16T02:25:09.217702Z",
     "iopub.status.idle": "2025-06-16T02:25:09.290546Z",
     "shell.execute_reply": "2025-06-16T02:25:09.289757Z",
     "shell.execute_reply.started": "2025-06-16T02:25:09.217982Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Unnamed: 0   120000 non-null  int64 \n",
      " 1   Class Index  120000 non-null  int64 \n",
      " 2   Title        120000 non-null  object\n",
      " 3   Description  120000 non-null  object\n",
      " 4   News         120000 non-null  object\n",
      " 5   clean        120000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T02:25:09.299791Z",
     "iopub.status.busy": "2025-06-16T02:25:09.299520Z",
     "iopub.status.idle": "2025-06-16T02:25:09.316806Z",
     "shell.execute_reply": "2025-06-16T02:25:09.316070Z",
     "shell.execute_reply.started": "2025-06-16T02:25:09.299766Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Index\n",
       "3    30000\n",
       "4    30000\n",
       "2    30000\n",
       "1    30000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Class Index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T02:31:59.600977Z",
     "iopub.status.busy": "2025-06-16T02:31:59.600548Z",
     "iopub.status.idle": "2025-06-16T02:31:59.793318Z",
     "shell.execute_reply": "2025-06-16T02:31:59.792751Z",
     "shell.execute_reply.started": "2025-06-16T02:31:59.600960Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_len1 = df_train['clean'].map(lambda x: len(x.split())).max()\n",
    "sent_len2 = df_test['clean'].map(lambda x: len(x.split())).max()\n",
    "sent_len = max(sent_len1, sent_len2)\n",
    "sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Articles\\CGNet\\venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.tensor([tokenizer(doc, padding='max_length', truncation=True, max_length=sent_len).input_ids for doc in df_train['clean']])\n",
    "train_label = torch.tensor([label - 1 for label in df_train['Class Index']])\n",
    "train_dataset = TensorDataset(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.tensor([tokenizer(doc, padding='max_length', truncation=True, max_length=sent_len).input_ids for doc in df_test['clean']])\n",
    "test_label = torch.tensor([label - 1 for label in df_test['Class Index']])\n",
    "test_dataset = TensorDataset(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class GRUTextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes):\n",
    "        super(GRUTextClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.bigru1 = nn.GRU(embed_dim, 128, batch_first=True, bidirectional=True)\n",
    "        self.bigru2 = nn.GRU(128*2, 64, batch_first=True, bidirectional=True)\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Linear(64*2, 256)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        self.out = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)                         # [B, L] -> [B, L, E]\n",
    "        x, _ = self.bigru1(x)                          # [B, L, 2*128]\n",
    "        x, _ = self.bigru2(x)                          # [B, L, 2*64]\n",
    "        x = x.permute(0, 2, 1)                         # [B, 2*64, L]\n",
    "        x = self.global_max_pool(x).squeeze(-1)        # [B, 2*64]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example values (adjust as needed)\n",
    "vocabulary_size = tokenizer.vocab_size\n",
    "embed_size = 256\n",
    "max_len = sent_len\n",
    "num_classes = 4\n",
    "num_epochs = 20\n",
    "lr = 0.0012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 33262532\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = GRUTextClassifier(vocabulary_size, embed_size, num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "\n",
    "num_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'number of parameters: {num_total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Embedding is treated as a zero-op.\n",
      "Warning: module Dropout is treated as a zero-op.\n",
      "Warning: module GRUTextClassifier is treated as a zero-op.\n",
      "Warning! No positional inputs found for a module, assuming batch size is 1.\n",
      "GRUTextClassifier(\n",
      "  494.53 k, 1.487% Params, 60.13 MMac, 99.969% MACs, \n",
      "  (embedding): Embedding(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 128000, 256)\n",
      "  (bigru1): GRU(296.45 k, 0.891% Params, 42.35 MMac, 70.411% MACs, 256, 128, batch_first=True, bidirectional=True)\n",
      "  (bigru2): GRU(123.65 k, 0.372% Params, 17.69 MMac, 29.404% MACs, 256, 64, batch_first=True, bidirectional=True)\n",
      "  (global_max_pool): AdaptiveMaxPool1d(0, 0.000% Params, 18.18 KMac, 0.030% MACs, output_size=1)\n",
      "  (fc1): Linear(33.02 k, 0.099% Params, 33.02 KMac, 0.055% MACs, in_features=128, out_features=256, bias=True)\n",
      "  (dropout1): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.25, inplace=False)\n",
      "  (fc2): Linear(32.9 k, 0.099% Params, 32.9 KMac, 0.055% MACs, in_features=256, out_features=128, bias=True)\n",
      "  (dropout2): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.25, inplace=False)\n",
      "  (fc3): Linear(8.26 k, 0.025% Params, 8.26 KMac, 0.014% MACs, in_features=128, out_features=64, bias=True)\n",
      "  (dropout3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.25, inplace=False)\n",
      "  (out): Linear(260, 0.001% Params, 260.0 Mac, 0.000% MACs, in_features=64, out_features=4, bias=True)\n",
      ")\n",
      "MACs: 60146564, Params: 33262532\n"
     ]
    }
   ],
   "source": [
    "def input_constructor(input_res):\n",
    "    # input_res is (batch_size, sent_len)\n",
    "    return {'x': torch.ones(input_res, dtype=torch.long)}\n",
    "\n",
    "macs, params = get_model_complexity_info(\n",
    "    model, \n",
    "    (1, sent_len), \n",
    "    as_strings=False, \n",
    "    backend='pytorch', \n",
    "    print_per_layer_stat=True, \n",
    "    verbose=True,\n",
    "    input_constructor=input_constructor\n",
    ")\n",
    "print(f\"MACs: {macs}, Params: {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:14<00:00, 32.37it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 65.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 231.4989, Val Loss: 8.8333, Val Acc: 0.8982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:13<00:00, 35.85it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 72.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Loss: 125.6758, Val Loss: 8.3877, Val Acc: 0.8984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:12<00:00, 36.17it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 74.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Loss: 101.5442, Val Loss: 7.7483, Val Acc: 0.9080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:12<00:00, 36.15it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 71.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Loss: 83.6554, Val Loss: 7.9473, Val Acc: 0.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:12<00:00, 36.52it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 70.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Loss: 69.4139, Val Loss: 8.2513, Val Acc: 0.9102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:13<00:00, 34.21it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 48.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Loss: 56.0850, Val Loss: 9.1144, Val Acc: 0.9099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:14<00:00, 33.17it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 67.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Loss: 44.5056, Val Loss: 9.6988, Val Acc: 0.9133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:13<00:00, 34.21it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 65.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Loss: 36.0154, Val Loss: 10.5812, Val Acc: 0.9103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:13<00:00, 34.63it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 65.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Loss: 29.7368, Val Loss: 10.9907, Val Acc: 0.9098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:14<00:00, 31.86it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 55.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Loss: 25.5902, Val Loss: 12.5474, Val Acc: 0.9084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:14<00:00, 32.07it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 66.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Loss: 21.6882, Val Loss: 12.7420, Val Acc: 0.9080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:14<00:00, 32.17it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 38.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Loss: 19.3233, Val Loss: 12.7352, Val Acc: 0.9077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:14<00:00, 32.73it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 63.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Loss: 18.2203, Val Loss: 13.0892, Val Acc: 0.9098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:13<00:00, 35.77it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 74.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Loss: 17.4841, Val Loss: 13.3803, Val Acc: 0.9124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:14<00:00, 33.15it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 49.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Loss: 16.1766, Val Loss: 13.0035, Val Acc: 0.9129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:23<00:00, 19.66it/s]\n",
      "100%|██████████| 29/29 [00:01<00:00, 24.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Loss: 14.4031, Val Loss: 14.6887, Val Acc: 0.9054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:24<00:00, 18.76it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 45.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Loss: 15.1299, Val Loss: 14.8473, Val Acc: 0.9102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:25<00:00, 18.60it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 48.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Loss: 14.8119, Val Loss: 13.1010, Val Acc: 0.9134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:23<00:00, 19.57it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 41.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Loss: 13.5512, Val Loss: 14.9606, Val Acc: 0.9119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:23<00:00, 19.67it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 46.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Loss: 13.7057, Val Loss: 13.4410, Val Acc: 0.9153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.00001)\n",
    "# Training Loop\n",
    "model = model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in tqdm(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)                     # [B, num_classes]\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in tqdm(test_dataloader):\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            v_loss = loss_fn(val_outputs, val_labels)\n",
    "            val_loss += v_loss.item()\n",
    "            preds = val_outputs.argmax(dim=1)\n",
    "            correct += (preds == val_labels).sum().item()\n",
    "            total += val_labels.size(0)\n",
    "    val_acc = correct / total if total > 0 else 0\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader, num_classes):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1) if len(y_true.shape)>1 else y_true\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 42.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9223    0.9133    0.9178      1858\n",
      "           1     0.9645    0.9661    0.9653      1858\n",
      "           2     0.8908    0.8778    0.8843      1850\n",
      "           3     0.8837    0.9037    0.8936      1858\n",
      "\n",
      "    accuracy                         0.9153      7424\n",
      "   macro avg     0.9153    0.9152    0.9152      7424\n",
      "weighted avg     0.9154    0.9153    0.9153      7424\n",
      "\n",
      "confusion matrix:\n",
      " tensor([[1697,   36,   74,   51],\n",
      "        [  30, 1795,   14,   19],\n",
      "        [  60,   15, 1624,  151],\n",
      "        [  53,   15,  111, 1679]])\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(model, test_dataloader, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 612351,
     "sourceId": 1095715,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
