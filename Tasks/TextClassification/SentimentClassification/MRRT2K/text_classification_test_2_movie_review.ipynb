{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification Using Proposed CNN-GNN on MR Polarity dataset + Token Sentiment Injection + Dataset Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Results:\n",
    "| metric | fold 1 | fold 2 | fold 3 | fold 4 | fold 5 | fold 6 | fold 7 | fold 8 | fold 9 | fold 10 | Average |\n",
    "|:---|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| f1-score | 86.34 | 88.94 | 87.79 | 88.76 | 89.85 | 83.47 | 88.00 | 82.21 | 84.58 | 84.52 | 86.45 |\n",
    "| accuracy | 86.50 | 89.00 | 88.00 | 88.50 | 90.00 | 84.00 | 88.00 | 82.50 | 84.50 | 84.50 | 86.55 |\n",
    "| precision | 86.21 | 89.00 | 87.79 | 88.86 | 89.85 | 83.60 | 88.00 | 82.86 | 84.67 | 84.70 | 8655 |\n",
    "| recall | 86.47 | 88.88 | 87.79 | 88.65 | 89.85 | 83.35 | 88.00 | 81.57 | 84.50 | 84.33 | 86.34 |\n",
    "| loss | 0.5797 | 0.4209 | 0.4578 | 0.5229 | 0.4363 | 0.5536 | 0.5129 | 0.7152 | 0.7316 | 0.6490 | 0.5580 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch_scatter import scatter_max, scatter_mean, scatter_sum, scatter_std\n",
    "import torchmetrics\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from copy import copy\n",
    "import spacy\n",
    "from umap import UMAP\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import PyPDF2\n",
    "from bs4 import BeautifulSoup\n",
    "# import textract\n",
    "import json\n",
    "import gzip\n",
    "import re\n",
    "import collections\n",
    "import csv\n",
    "import string\n",
    "import textwrap\n",
    "import random\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "771064"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'data\\reduced_embeddings\\spacy_lg_reduced_embeddings.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "nlp = spacy.load('en_core_web_lg', disable=['tok2vec','tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
    "t_tokenizer = TweetTokenizer()\n",
    "nlp.max_length = len(' '.join(list(nlp.vocab.strings)))+1\n",
    "all_vocab_doc = nlp(' '.join(list(nlp.vocab.strings)))\n",
    "all_vocab_str = [f'{t}' for t in all_vocab_doc]\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "embeddings = (embeddings - torch.min(embeddings)) / (torch.max(embeddings)-torch.min(embeddings))\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))\n",
    "token_vocab_dict['<n>'] = token_vocab_dict['newline']\n",
    "len(token_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "771064"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'data\\reduced_embeddings\\spacy_polarities_subjectivities.npy', 'rb') as f:\n",
    "    polarities_subjectivities= np.load(f)\n",
    "polarities_subjectivities = torch.from_numpy(polarities_subjectivities)\n",
    "polarity_vocab_dict = dict(zip(all_vocab_str, polarities_subjectivities))\n",
    "polarity_vocab_dict['<n>'] = torch.tensor([0.0, 0.0])\n",
    "len(token_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 50\n",
    "folder_path = r'data\\TextClassification\\review_polarity'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_path):\n",
    "    pos_path = os.path.join(dataset_path, 'pos')\n",
    "    neg_path = os.path.join(dataset_path, 'neg')\n",
    "    pos_names = os.listdir(pos_path)\n",
    "    neg_names = os.listdir(neg_path)\n",
    "    df = []\n",
    "    for pname in pos_names:\n",
    "        file_path = os.path.join(pos_path, pname)\n",
    "        with open(file_path, 'rt', encoding='utf8') as f:\n",
    "            df.append([1, f.read()])\n",
    "    \n",
    "    for nname in neg_names:\n",
    "        file_path = os.path.join(neg_path, nname)\n",
    "        with open(file_path, 'rt', encoding='utf8') as f:\n",
    "            df.append([0, f.read()])\n",
    "    df = pd.DataFrame(data=df, columns=['label', 'text'])\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_ratio = 1.0\n",
    "df = load_dataset(r'data\\TextClassification\\review_polarity')\n",
    "# df.text = df.text.apply(lambda d: d[:50])\n",
    "df.dropna(inplace=True)\n",
    "df = df.iloc[:int(keep_ratio*df.shape[0])]\n",
    "target_classes = [\"Negative\", \"Positive\"]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = df.label.unique()\n",
    "class_id = {target_classes[i]:i for i in class_list}\n",
    "id_class = {i:target_classes[i] for i in class_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set = set()\n",
    "for doc in df.text.values:\n",
    "    char_set.update(set(' '.join(t_tokenizer.tokenize(doc))))\n",
    "len(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' '\n",
    "all_chars = set(''.join(char_set).join(allowed_chars))\n",
    "vocab_dict = {c:i for i, c in enumerate(all_chars)}\n",
    "if '\\x01' not in vocab_dict:\n",
    "    vocab_dict['\\x01'] = len(vocab_dict)\n",
    "char_Set = set(vocab_dict.keys())\n",
    "num_embedding = len(vocab_dict)\n",
    "vocab_dict_rev = dict(zip(list(vocab_dict.values()), list(vocab_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldCharacterandTokenLevelDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, num_classes, char_dict, token_dict, sentiment_dict, tokenizer, shuffle=True, batch_size=128, k_folds=10, fold_idx=0) -> None:\n",
    "        super().__init__()\n",
    "        self.fold_idx = fold_idx\n",
    "        kf = KFold(k_folds, shuffle=True, random_state=42)\n",
    "        self.k_folds = list(kf.split(np.arange(len(y))))\n",
    "        self.k_folds = [(np.array(f[0], dtype=np.longlong), np.array(f[1], dtype=np.longlong)) for f in self.k_folds]\n",
    "        \n",
    "        if batch_size > len(y)//k_folds:\n",
    "            batch_size = len(y)//k_folds\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        if len(y) % batch_size*k_folds != 0:\n",
    "            \n",
    "            self.shortage = ((len(y) // (batch_size*k_folds))+1)*(batch_size*k_folds) - len(y)\n",
    "            print(f\"!!!! This amount of data added: {self.shortage}, change batch size or k-fold to reduce it!\")\n",
    "            empty_labels = [i%2 for i in range(self.shortage)]\n",
    "            empty_strings = [id_class[l] for l in empty_labels]\n",
    "            y = np.concatenate([y, empty_labels])\n",
    "            X = np.concatenate([X, empty_strings])\n",
    "        \n",
    "        y = torch.from_numpy(y)\n",
    "        self.shuffle = shuffle\n",
    "        self.y = torch.nn.functional.one_hot(y, num_classes=num_classes).float()\n",
    "        self.X = X\n",
    "        self.char_dict = char_dict\n",
    "        self.char_Set = set(char_dict.keys())\n",
    "        self.vocab_size = len(self.char_dict)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_dict = token_dict\n",
    "        self.sentiment_dict = sentiment_dict\n",
    "        self.max_token_count = 0\n",
    "        \n",
    "        self.all_data = []\n",
    "        self.token_lengths = []\n",
    "        self.token_embeddign_ids = []\n",
    "        \n",
    "        self.sum_a = 0\n",
    "        \n",
    "        for doc in tqdm(self.X):\n",
    "            # tokens = self.tokenizer(''.join(c for c in doc if c in self.char_Set))\n",
    "            # tokens = [t.text for t in tokens]\n",
    "            tokens = self.tokenizer(doc)\n",
    "            if len(tokens) == 0:\n",
    "                tokens = ['empty']\n",
    "                            \n",
    "            token_lengths = [len(t) for t in tokens]\n",
    "            tokens.append('\\x01')\n",
    "            \n",
    "            token_lengths.append(len(tokens[-1])-1)\n",
    "            token_lengths = torch.from_numpy(np.array(token_lengths, dtype=np.longlong))+1\n",
    "            token_embs = [self.token_dict[t] if t in self.token_dict else torch.zeros((64, ), dtype=torch.float32) for t in tokens]\n",
    "            token_sentiments = [self.sentiment_dict[t] if t in self.sentiment_dict else (0.0, 0.0) for t in tokens]\n",
    "            token_embs = torch.from_numpy(np.array(token_embs, dtype=np.float32))\n",
    "            token_sentiments = torch.from_numpy(np.array(token_sentiments, dtype=np.float32))\n",
    "            doc = ' '.join(tokens)\n",
    "            characters = torch.from_numpy(np.array([self.char_dict[t] for t in doc], dtype=np.longlong))\n",
    "            token_positions = torch.arange(len(token_lengths), dtype=torch.long)\n",
    "            token_indices = torch.repeat_interleave(token_positions, token_lengths)\n",
    "            num_tokens = len(token_lengths)\n",
    "            if num_tokens > self.max_token_count:\n",
    "                self.max_token_count = num_tokens\n",
    "            g_data = Data(x=characters,\n",
    "                            token_positions=token_positions,\n",
    "                            character_length = len(characters),\n",
    "                            num_tokens = num_tokens,\n",
    "                            token_indices=token_indices,\n",
    "                            token_lengths=token_lengths,\n",
    "                            token_embeddings=token_embs,\n",
    "                            token_sentiments=token_sentiments)\n",
    "            self.all_data.append(g_data)\n",
    "            \n",
    "        self.all_data = Batch.from_data_list(self.all_data)\n",
    "        self.update_split(self.fold_idx)\n",
    "        \n",
    "    def update_split(self, fold_idx):\n",
    "        self.active_fold = self.k_folds[fold_idx]\n",
    "        \n",
    "        self.train_y = self.y[self.active_fold[0]]\n",
    "        self.test_y = self.y[self.active_fold[1]]\n",
    "        \n",
    "        self.all_train_data = self.all_data[self.active_fold[0]]\n",
    "        self.all_test_data = self.all_data[self.active_fold[1]]\n",
    "        self.train()\n",
    "        \n",
    "    def train(self):\n",
    "        self.update_sections(self.train_y, self.all_train_data)\n",
    "        self.is_train=True\n",
    "        \n",
    "    def eval(self):\n",
    "        self.update_sections(self.test_y, self.all_test_data)\n",
    "        self.is_train=False\n",
    "        \n",
    "    def update_sections(self, y, all_data):\n",
    "        \n",
    "        self.num_sections = len(y) // batch_size\n",
    "        self.x_lengths = np.array([all_data[i].character_length[0] for i in range(len(all_data))])\n",
    "        self.x_len_args = np.argsort(self.x_lengths)[::-1]\n",
    "        \n",
    "        self.section_ranges = np.linspace(0, len(self.x_len_args), self.num_sections+1)\n",
    "        self.section_ranges = [(int(self.section_ranges[i-1]), int(self.section_ranges[i])) for i in range(1, len(self.section_ranges))]\n",
    "\n",
    "        self.position_j = 0\n",
    "        self.section_i = 0\n",
    "        self.epoch = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "        self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        return self.sections, self.section_size, self.x_len_args, self.x_lengths, self.num_sections\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        index = self.get_section_index()\n",
    "        if self.is_train:\n",
    "            return self.all_train_data[index], self.train_y[index]\n",
    "        else:\n",
    "            return self.all_test_data[index], self.test_y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def get_section_index(self):\n",
    "        target_index = self.sections[self.section_i, self.position_j]\n",
    "        \n",
    "        self.position_j = (self.position_j + 1) % self.section_size\n",
    "        if self.position_j == 0:\n",
    "            self.section_i = (self.section_i + 1) % self.num_sections\n",
    "            if self.shuffle and self.section_i == 0:\n",
    "                self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        return target_index    \n",
    "\n",
    "    def reset_params(self):\n",
    "        self.section_i = 0\n",
    "        self.position_j = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "    def split_into_k_groups(self, len_sorted_args, lengths:np.array, k):\n",
    "        if self.shuffle and self.epoch > 0:\n",
    "            randomize_sections = np.concatenate([np.random.choice(np.arange(r[0], r[1]), size=r[1]-r[0], replace=False) for r in self.section_ranges])\n",
    "            len_sorted_args = len_sorted_args[randomize_sections]\n",
    "        \n",
    "        nums = lengths[len_sorted_args]\n",
    "        groups_size = len(len_sorted_args) // k\n",
    "        \n",
    "        groups = [[] for _ in range(k)]\n",
    "        group_sums = np.zeros(k, dtype=int)\n",
    "        group_sizes = np.zeros(k, dtype=int)\n",
    "        \n",
    "        for i, num in enumerate(nums):\n",
    "            candidate_indices = np.where(group_sizes<groups_size)[0]\n",
    "            min_group_idx = candidate_indices[np.argmin(group_sums[candidate_indices])]\n",
    "            groups[min_group_idx].append(len_sorted_args[i])\n",
    "            group_sums[min_group_idx] += num\n",
    "            group_sizes[min_group_idx] += 1\n",
    "        self.epoch += 1\n",
    "        \n",
    "        groups = np.array(groups)\n",
    "        group_sums_argsort = np.argsort(group_sums)[::-1]\n",
    "        groups = groups[group_sums_argsort]\n",
    "                \n",
    "        return np.array(groups), groups_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTestDatasetWrapper(Dataset):\n",
    "    \n",
    "    def __init__(self, target_dataset, is_train=True) -> None:\n",
    "        super().__init__()\n",
    "        self.dataset = target_dataset\n",
    "        self.is_train = is_train\n",
    "    \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.is_train:\n",
    "            if not self.dataset.is_train:\n",
    "                self.dataset.train()\n",
    "            return self.dataset[index]\n",
    "        else:\n",
    "            if self.dataset.is_train:\n",
    "                self.dataset.eval()\n",
    "            return self.dataset[index]\n",
    "    \n",
    "    def set_active_fold(self, fold_idx):\n",
    "        self.dataset.update_split(fold_idx)\n",
    "    \n",
    "    def reset_params(self):\n",
    "        self.dataset.reset_params()\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return len(self.dataset.train_y)\n",
    "        else:\n",
    "            return len(self.dataset.test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CharacterandTokenLevelDataLoader(DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        follow_batch: List[str] | None = None,\n",
    "        exclude_keys: List[str] | None = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CharacterandTokenLevelDataLoader, self).__init__(\n",
    "            dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        base_iterator = super(CharacterandTokenLevelDataLoader, self).__iter__()\n",
    "        for batch in base_iterator:\n",
    "            cumsum_vals = torch.cumsum(batch[0].num_tokens, dim=0).roll(1)\n",
    "            cumsum_vals[0] = 0\n",
    "            additions = torch.repeat_interleave(cumsum_vals, batch[0].character_length)\n",
    "            batch[0].cumulative_token_indices = batch[0].token_indices + additions\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_tokenizer(doc):\n",
    "    tokens = t_tokenizer.tokenize(doc)\n",
    "    tokens = nlp(' '.join(tokens))\n",
    "    tokens = [t.text for t in tokens]\n",
    "    return tokens\n",
    "\n",
    "def nlp_tokenizer(doc):\n",
    "    tokens = nlp(doc)\n",
    "    tokens = [t.text for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2000 [00:00<01:45, 18.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:09<00:00, 28.96it/s]\n"
     ]
    }
   ],
   "source": [
    "main_dataset = KFoldCharacterandTokenLevelDataset(df.text.values, df.label.values, len(class_id), vocab_dict, token_vocab_dict, polarity_vocab_dict, nlp_tokenizer, batch_size=batch_size)\n",
    "batch_size = main_dataset.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainTestDatasetWrapper(main_dataset, True)\n",
    "test_dataset = TrainTestDatasetWrapper(main_dataset, False)\n",
    "train_dataset.set_active_fold(0)\n",
    "test_dataset.set_active_fold(0)\n",
    "# max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=False)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2869\n",
      "1860\n"
     ]
    }
   ],
   "source": [
    "train_lengths = np.array([train_dataset[i][0].num_tokens for i in range(len(train_dataset))])\n",
    "test_lengths = np.array([test_dataset[i][0].num_tokens for i in range(len(test_dataset))])\n",
    "print(np.max(train_lengths))\n",
    "print(np.max(test_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[4848], token_positions=[906], character_length=[1], num_tokens=[1], token_indices=[4848], token_lengths=[906], token_embeddings=[906, 64], token_sentiments=[906, 2]),\n",
       " tensor([0., 1.]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                                                    1\n",
       "text     no , i did not read the novel by thomas hardy ...\n",
       "Name: 1738, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[np.argwhere(['hardy' in c and 'obscure' in c for c in  df.text.values]).squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 i 'm guessing -- and from the available evidence , it 's not a great guess -- that burn hollywood burn began life as an insider satire of hollywood excess , stupidity , ego and power - mongering . \n",
      " if so , the film that ended up on the screen ranks as one of the most spectacularly ironic unintentional jokes in film history . \n",
      " it has already been well - documented that the original title , an alan smithee film , became a problem when miserable test screenings forced re - cuts against the will of director arthur hiller , prompting hiller himself to opt for the directors ' guild - mandated pseudonym of alan smithee . \n",
      " that left a film satire in the hands of writer joe eszterhas , as humorless a hack as ever put finger to word processor . \n",
      " and you could just smell the disaster brewing . \n",
      " if you 're unfortunate enough to sit through burn hollywood burn , you 'll still be smelling that disaster long after the lights come up . \n",
      " ostensibly , it 's a pseudo - documentary account of a director named alan smithee ( eric idle ) who loses control of a big - budget action film called trio starring sylvester stallone , whoopi goldberg and jackie chan ( all of whom appear as themselves ) . \n",
      " when the only recourse available to him is abandoning the project to be called \" an alan smithee film \" -- which , of course , it already is -- smithee steals the negative of the film and threatens to destroy it . \n",
      " among the parties interviewed are the film 's producer james edmunds ( ryan o'neal ) and studio boss jerry glover ( richard jeni ) , who spend virtually the entire film narrating the story while painfully unfunny things go on around them . \n",
      " it 's bad enough that burn hollywood burn has -- literally -- not a single laugh for its entire , blissfully brief 84 minutes . \n",
      " what makes it even worse is eszterhas ' insistence upon telling every bad joke not once , but twice or even three times . \n",
      " michael ovitz references , showgirls references , oral sex references , whoopi goldberg / ted danson references -- all show up multiple times with all the subtlety that is eszterhas ' stock - in - trade . \n",
      " the reduncancy even manages to turn actively offensive with some frequency , notably with the hilarious use of the word \" feminist \" as an identifying caption for every single female character in the film . \n",
      " by the time coolio and chuck d show up as black independent film - makers the brothers brothers ( cleverly identified as \" bad a-- \" and \" badder a-- \" , among other unprintable things ) , you may be ready to walk out of the theater with your coat over your head to avoid being identified . \n",
      " those documentary captions , for all their leaden obviousness , allow the best insight into what 's so hideously wrong with burn hollywood burn . \n",
      " not content to stick any hollywood type with only one jab from his rapier wit , eszterhas fills the screen with bullet points every time a new character appears . \n",
      " the producer is a \" liar \" who \" slept in the white house ; \" the media are \" maggots \" and \" leeches \" working for publications like \" the new york slimes \" and \" newsleak \" ( with the camera zooming in on the altered title to make sure you do n't miss the joke ) . \n",
      " it does n't even matter that eszterhas tags \" penile implant \" after his own name when he makes a cameo , because it seems like such a desperate attempt to feign self - deprecation . \n",
      " this is a petulant schoolboy 's idea of satire -- pictures of hollywood insiders to which eszterhas has taken a pen to draw little moustaches and black out the teeth . \n",
      " the last stomach - churning straw comes when burn hollywood burn closes with out - takes over the closing credits , the kind that show the audience how much fun everyone was having making the film that just sucked an hour and a half of your life away . \n",
      " perhaps it was just a final , desperate attempt by eszterhas to convince himself there was some purpose behind the film , or to convince everyone involved that a few blown lines warranted threatening to blow their whole career . \n",
      " pity everyone involved with this excessive , ego - driven \" satire \" of excess and ego . \n",
      " it 's too bad that only directors can remove their names from noxious material like this . \n",
      " otherwise , you might have seen credits for burn hollywood burn overflowing with alan smithees . \n",
      " \u0001\n",
      "1 clue is an unfairly ignored comedy , very similar to 1976 's murder by death . \n",
      " this big screen version of the classic board game ( what 's next . . . \n",
      " chutes and ladders : the motion picture ? ) is filled with slapstick antics and silly dialogue . \n",
      " the plot , for what it 's worth , has all the characters from the game ( in this case , the names from the game are used as aliases ) meeting in an isolated mansion to confront mr . boddy ( lee ving ) , the man who 's been blackmailing them all . \n",
      " when he turns up dead , everyone ( including the audience ) must figure out whodunnit . . . \n",
      " and in what room , and with what object . \n",
      " while not as witty as neil simon 's murder by death , clue definitely has it moments . \n",
      " it has so many moments in fact that i use a lot of the lines from the film when i 'm joking around with my friends . \n",
      " to this day , whenever someone says the phrase \" well , to make a long story short \" i have the follow up phrase \" too late \" ready to go . \n",
      " the cast ( all very good comedic talents ) play well off one another , while the late madeline kahn ( as the dark and sultry mrs . white ) sometimes steals the film away from the rest . \n",
      " and colleen camp , as the french maid yvette , displays some of her natural talents as well . \n",
      " clue is available on dvd from paramount home video . \n",
      " it includes the film in its original theatrical aspect ratio of 1 . 85 : 1 ( and is enhanced for 16x9 televisions ) and features the original theatrical trailer . \n",
      " a french language audio track is also available . \n",
      " the trailer holds up well considering most previews from that time do not , and it even includes a scene not in the film itself ( a scene that should have been in the film , as it 's a good joke ) . \n",
      " also , the trailer is scored to the music from airplane ! , which was an interesting choice . \n",
      " when clue played in theaters , it ran with the gimmick of three different endings . \n",
      " if you wanted to see all three , you had to go to the movies three separate times . \n",
      " so when the film was released on home video , rather than releasing three separate videos , all three endings were included on one tape . . . \n",
      " the first two endings being \" what if ? \" \n",
      " endings and the third ending being the actual ending . \n",
      " now for the dvd release you get two choices . \n",
      " you can watch the film as it was presented on home video or you can select to watch it with one of the three endings randomly chosen for you . \n",
      "  ( note : there 's an easter egg hidden in the disc pertaining to this . \n",
      " after watching the film with a randomly selected ending , when you return to the menu screen you will be able to highlight the large magnifying glass and select it . \n",
      " when you do , a secret menu opens , allowing you to watch any of the three endings by themselves . ) \n",
      " now while i applaud the effort of paramount here , as they clearly tried to do something special with the disc , it just does n't work well . \n",
      " first , why not give the viewer the choice of what ending we want to watch ? \n",
      " maybe someone like myself who 's seen the movie hundreds of times would like to sit down and show it to someone with the second ending only . \n",
      " i 'm no technical dvd expert , but i ca n't imagine that being too hard to accomplish . \n",
      " secondly , the delay between when the film itself ends and one of the endings begins is too long and too obvious , thereby becoming a distraction right when you definitely do n't need a distraction . \n",
      " finally , the back of the dvd case states \" and now , with this special dvd version , you can see all 3 surprise endings \" . \n",
      " i have no idea why they would word it that way , since that 's not a special feature in the slightest . \n",
      " the video has been out for fifteen years now ( good lord , has it been that long ? ) and it 's played on television with all three endings all the time . \n",
      " these are merely minor complaints however , seeing that i 've watched the home video version hundreds of times and have no problem watching the film as such on the dvd . \n",
      " the picture and sound are wonderfully improved over my worn out vhs copy , and i 'm thrilled that paramount agrees with me that clue is a film worthy of being preserved on this great digital format . \n",
      " [ pg ] \n",
      " \u0001\n",
      "1 in my review of there 's something about mary , i said something to the effect of \" laughter is n't everything . \" \n",
      " i now need to make a brief addendum to my postulate : laughter is n't everything , unless i 'm watching a jim abrahams film . \n",
      " see , spoofs are easy with me . \n",
      " i love movies , and i love movies that make fun of movies that i love . \n",
      " sometimes i 'm the only one in the theater laughing . \n",
      " sometimes i laugh so hard that i embarass myself because my laugh is so high - pitched in comparison to my speaking voice ( it cuts right through everyone else 's laughter ) . \n",
      " sometimes i laugh so much that my cheekbones are sore by the end of the film . \n",
      " abraham 's latest film , mafia ! , induced this kind of hysteria upon me . \n",
      " it 's gotten some mediocre reviews , but , hey , i 'm the guy who laughs at everything . \n",
      " there may be a lot of jokes that flop in this film , but there are far more that work , and i laughed so frequently that the failed jokes usually occurred as i was recovering from the previous bout of giddy madness . \n",
      " i enjoy films like this because not one second of it is serious or thought - provoking . \n",
      " most lighweight films that pose as comedies try to do other things , like develop characters , shape stories , and other such nonsense . \n",
      " mafia ! \n",
      " has no pretentions about characters or story , and it exists for no other reason than to make people laugh . \n",
      " the film begins on the perfect high note , with a mockery of the opening of casino . \n",
      " our hero ( jay mohr ) is seen walking from a casino and getting into his car , which subsequently explodes and sends him flying through the air against a backdrop of flowing fire . \n",
      " to describe the story of mafia ! \n",
      " is absurd and pointless , but i will mention that it basically follows the framework of the godfather films , with a lot of casino references inserted throughout . \n",
      " along the way , the parodies seem arbitrary , and rarely victimize mob films : pictures like the english patient , forrest gump , and jaws undergo severe and hilarious bashing . \n",
      " movies like this rely on just a few things , but the most important element is direction . \n",
      " abrahams has been down this path many times before ( hot shots ! , top secret ! , airplane ! , and any other film with an exclamation point in the title ) , and so i hold most of the success of mafia ! \n",
      " to his experience . \n",
      " he takes just the right attitude in each scene , and manages to wring at least a bit laughter out of even the most oddly placed references ( one inexplicable moment seems like it wants to make fun of titanic , but it never develops ) . \n",
      " the actors are all energetic , which helps a lot with the tone of the film . \n",
      " mohr ( suicide kings , paulie ) , who is quickly becoming one of my favorite actors , is so good here . \n",
      " he looks like he 's having so much fun that he 's containing his laughter in every scene ( watch his face in the sequence by the swimming pool ) . \n",
      " he 's probably the only performer in the cast who manages to urge laughter without the help of the material . \n",
      " lloyd bridges does a decent imitation of brando 's godfather , while pamela gidley is dead - on in a full - blown mockery of sharon stone . \n",
      " the hard thing about writing reviews for comedies is that i 'm supposed to give examples of things and be specific . \n",
      " unfortunately , i was so constantly blindsided by laughter during mafia ! \n",
      " that i ca n't remember a lot of what made me laugh . \n",
      " but that 's a good sign : mafia ! \n",
      " is so funny that i was n't even given time to apply any of the scenes to memory . \n",
      " i laughed so hard that it shut off my brain . \n",
      " i know that does n't sound particularly complimentary , but when watching a dumb comedy like this , the first thing i want to do is shut off my brain . \n",
      " finally , a film that does this for me . \n",
      " \u0001\n",
      "0 an american werewolf in paris is a failed attempt to recapture the humor and horror of john landis ' 1981 feature , an american werewolf in london . \n",
      " where the original had comedy , the sequel has the kind of revolting silliness that can be found in tv sit - coms . \n",
      " where the first installment had chills , this one has sequences that are inappropriately , unintentionally funny . \n",
      " in short , while an american werewolf in london has become something of a minor classic in its genre , the woeful an american werewolf in paris seems destined for late nights on cinemax ( it even has the necessary gratuitous nudity ) . \n",
      " the film opens with a trio of daredevil americans -- andy ( tom everett scott ) , brad ( vince vieluf ) , and chris ( phil buckman ) -- sneaking up to the top of the eiffel tower to drink wine and do a little bungee jumping . \n",
      " soon they have company in the person of serafine ( julie delpy ) , who has decided to end it all . \n",
      " she jumps , but andy , with a bungee cord attached , goes after her , and manages to save her ( at the price of a major headache ) . \n",
      " serafine disappears , but a smitten andy seeks her out . \n",
      " however , once he learns his would - be girlfriend 's dark secret , he wishes he had n't . \n",
      " she 's a werewolf , cursed to change into a hideous beast when the moon is full , and , to make matters worse , he has suffered a nasty bite himself . \n",
      " actress julie delpy is far too good for this movie . \n",
      " she imbues serafine with spirit , spunk , and humanity , which gives us an emotional stake in the character 's fate . \n",
      " this is n't necessarily a good thing , since it prevents us from relaxing and enjoying an american werewolf in paris as a completely mindless , campy entertainment experience . \n",
      " delpy 's injection of class into an otherwise classless production raises the specter of what this film could have been with a better script and a better cast surrounding her . \n",
      " delpy 's previous credits include such memorable ventures as krzysztof kieslowski 's white and richard linklater 's before sunrise . \n",
      " she was radiant , charismatic , and effective in both . \n",
      " given the nature and level of the material she has to work with here , she gets as close as possible to those adjectives . \n",
      " it could be argued that delpy is the only reason to see an american werewolf in paris , but even her most devoted fans should consider giving this one a miss . \n",
      " and if your primary objective is catching a glimpse of her in the buff , check out either killing zoe or the passion of beatrice -- those movies have intelligible plots in addition to breasts . \n",
      " the rest of the cast acts at a level considerably below that of delpy -- which is to say , they give performances appropriate for the screenplay . \n",
      " tom everett scott ( that thing you do ) plays the lead like he 's in a made - for - tv movie . \n",
      " it would be kind to call him bland . \n",
      " actors vince vieluf and phil buckman , as andy 's friends , are no more impressive . \n",
      " julie bowen ( happy gilmore ) is suitably fetching as werewolf meat . \n",
      " and respected french actor thierry lhermitte has a brief turn as another monster meal . \n",
      " on the technical side , it 's all bad news . \n",
      " the computer - generated werewolves look painfully unreal . \n",
      " the creatures would probably have been more believable had they been men in wolf suits . \n",
      " repeated use is made of the \" werewolf cam \" , an infrared wolf 's point - of - view approach that 's interesting the first couple of times it 's employed , then becomes tedious . \n",
      " and the soundtrack includes some alternative grunge rock tunes that clash violently with the on - screen action they 're matched to . \n",
      " director anthony waller , who displayed a confident , edgy style in mute witness , stumbles with this material , never being able to make the comedy and horror elements gel . \n",
      " as a result , we get the worst werewolf sequel since the howling ii : your sister is a werewolf . \n",
      "  ( i will give waller credit for killing off a dog , though -- something that 's rarely seen in movies these days . ) an american werewolf in paris is marginally entertaining in a \" bad movie \" sort of way , but that 's a dubious distinction . \n",
      " ultimately , it 's an unfortunate effort , for , while it is n't unbearable to sit through , it is n't a howl , either . \n",
      " \u0001\n",
      "0 my first press screening of 1998 and already i 've gotten a prime candidate for my worst ten of the year list . \n",
      " what an auspicious beginning ! \n",
      " welcome to the dog days of winter when the only film openings of merit are those oscar contenders that the studios opened in late december in new york and l . a . and which are just now beginning to appear elsewhere . \n",
      " firestorm , the directorial debut of dances with wolves 's academy award winning cinematographer dean semler , is the first of the new year 's crop of movies . \n",
      " as our story opens , the movie pretentiously informs us that of the tens of thousands of firefighters only 400 are \" smokejumpers . \" \n",
      " we then cut to a plane load of smoke jumping cowboys and one cowgirl , where one of the gung - ho guys is taking a romance quiz from \" cosmopolitan . \" \n",
      " having the time of their lives , they then jump into the middle of a burning forest . \n",
      " when , even in the beginning , the director ca n't get the small parts right , you can sense the movie is in trouble . \n",
      " with the noisy fire roaring all about them and with the trapped people huddled near their gasoline - filled cars , smokejumper monica ( christianne hirt ) tells them to get away from their soon - to - explode vehicles . \n",
      " not bothering to shout nor even get close to them , she announces her warning without raising her voice much or approaching the people . \n",
      " miraculously , they manage to hear her and move away . \n",
      " in a movie that specializes in cheap shots , the camera locates the proverbial young girl trapped in a nearby burning building . \n",
      " as it does throughout , overly dramatic cinematographer stephen f . windon from the postman uses extremely fast zooms right down to the endangered girl 's face . \n",
      " our show 's two heroes , the crew 's chief , wynt perkins , played laconically by scott glenn , and his second - in - command , jesse graves , played by howie long in a weak attempt to be the next steven seagal , enter the burning house looking for the little girl . \n",
      " in a panic they have difficulty in locating her before they are engulfed in flames . \n",
      " the manipulative script has her hidden in her own dollhouse . \n",
      " this mawkish show cuts back to monica , who has a life - or - death decision to make . \n",
      " the chopper with the fire - retardant chemicals has only enough to save one group . \n",
      " will it be the large group near the cars or the helpless little girl and monica 's two firefighting buddies ? \n",
      " she has only seconds to decide who will be saved . \n",
      " yes , she goes for the majority , but , miracle of miracles , the other three come out alive anyway . \n",
      " not content with a traditional firefighting story , chris soth 's screenplay attempts to jazz it up by having william forsythe from palookaville play a vicious killer named randy earl shaye who sets a forest fire so that he can join the crew to put it out and then escape . \n",
      "  ( \" hoods in the woods , \" is what the \" ground - pounders \" yell out when the convicts are bused in to help them fight the fire . ) \n",
      " along the way , shaye picks up an ornithologist hostage played by suzy amis , who turns out to have been trained in warrior ways by her father , who was a marine drill instructor . \n",
      " most of the highly predictable movie is a long chase in which poor howie long is given one ridiculous stunt after another to look silly performing . \n",
      " he flings a chain saw backwards over his head while riding a speeding motorcycle so that the saw can hit the windshield of the pursuing truck . \n",
      " arguably the low point is when he escapes from a locked burning building by riding a motorcycle conveniently parked inside . \n",
      " using a ramp , he shoots straight out of the top of the building 's attic , and when he hits the ground , he just rides off in a cloud of dust . \n",
      " when the film is n't using some stock footage of actual forest fires , the simulated ones look hokey . \n",
      " editor jack hofstra cheapens the action even more by his use of burning flames in scene transitions . \n",
      " the ending , with its sick twists , manages to be even worse than the rest of the movie . \n",
      " perhaps the best that can be said for the picture is the faint praise i heard afterwards in the lobby , \" it 's not as bad as some of the television sitcoms . \" \n",
      " firestorm runs mercifully just 1 : 29 . \n",
      " it is rated r for violence and language and would be acceptable for teenagers . \n",
      " \u0001\n"
     ]
    }
   ],
   "source": [
    " \n",
    "for i in range(15,20):\n",
    "    char_ids = X[i].x\n",
    "    text_for_ids = ''.join([vocab_dict_rev[ci.item()] for ci in char_ids])\n",
    "    print(torch.argmax(y[i]).item(), text_for_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[194874], token_positions=[40215], character_length=[50], num_tokens=[50], token_indices=[194874], token_lengths=[40215], token_embeddings=[40215, 64], token_sentiments=[40215, 2], batch=[194874], ptr=[51], cumulative_token_indices=[194874])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset.reset_params()\n",
    "# test_dataset.position_j = 0\n",
    "# for X, y in test_dataloader:\n",
    "#     print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv\n",
    "\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, *args, **kwargs):\n",
    "        super(GCNN, self).__init__(*args, **kwargs)\n",
    "        # self.hidden_dim = hidden_dim\n",
    "        self.gnn = GATv2Conv(hidden_dim, hidden_dim//8, heads=4)\n",
    "        # self.gnn = SimpleConv(aggr='mean')\n",
    "        self.conv = nn.Conv1d(hidden_dim, hidden_dim//2, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        # self.out_fc = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim//2)\n",
    "        # self.bn2 = nn.BatchNorm1d(hidden_dim//2)\n",
    "        # self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        # self.bn4 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, graph, total_token_count, return_attention_weights = False):\n",
    "        x1, edge_weights = self.gnn(x, graph.edge_index, return_attention_weights=return_attention_weights) \n",
    "        # x2 = F.relu(self.bn2(self.conv(x.T).T))\n",
    "        x2 = F.relu(self.conv(x.T).T)\n",
    "        # x3 =  F.leaky_relu_(self.fc(x1[total_token_count:]))\n",
    "        # x3 =  F.leaky_relu_(self.bn3(self.fc(x1[total_token_count:])))\n",
    "        x1 = F.leaky_relu_(self.bn1(x1))\n",
    "        # x1 = F.leaky_relu_(x1)\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        # x = torch.cat([x, x3], dim=0)\n",
    "        # x = self.bn4(x)\n",
    "        return x, edge_weights #F.leaky_relu_(self.bn4(self.out_fc(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(1, 0), dtype=torch.int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(2, 2, 2).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp = [1, 4, 5]\n",
    "lp = lp if lp is None else torch.tensor(lp)\n",
    "ls = lp if lp is not None else torch.arange(10)\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, to_undirected\n",
    "\n",
    "class GenGraph(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, virtual_nodes, lattice_step, lattice_pattern=None, *args, **kwargs):\n",
    "        super(GenGraph, self).__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.lattice_step = lattice_step\n",
    "        self.lp = lattice_pattern if lattice_pattern is None else torch.tensor(lattice_pattern)\n",
    "        self.virtual_node_embeddings = nn.Embedding(self.virtual_nodes, hidden_dim)\n",
    "        \n",
    "    def gen_graph(self, x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2, seed=-1):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance, seed)\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        edge_index = torch.empty((2, base_numel + v_n_e_counts*2), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "            \n",
    "        if self.virtual_nodes > 0:\n",
    "            virtual_nodes_range = torch.arange(self.virtual_nodes, device=x.device).view(1, -1)\n",
    "            virtual_nodes_ids = torch.repeat_interleave(virtual_nodes_range, len(token_counts), dim=0)\n",
    "            v_n_idx = (virtual_nodes_ids + torch.arange(0, len(token_counts)*self.virtual_nodes, self.virtual_nodes, device=x.device).view(-1, 1) + total_token_coutns )\n",
    "            virtual_edge_ids = torch.repeat_interleave(v_n_idx.view(-1), token_counts.view(-1, 1).expand(len(token_counts), self.virtual_nodes).reshape(-1), dim=0).view(1, -1)\n",
    "            \n",
    "            embs = self.virtual_node_embeddings(virtual_nodes_ids.T).view(-1, self.hidden_dim)\n",
    "            x_extended = torch.cat([x, embs], dim=0)\n",
    "            x_index = torch.arange(total_token_coutns, device=x.device).repeat(self.virtual_nodes).view(1, -1)\n",
    "            edge_index[:, base_numel:base_numel+v_n_e_counts] = torch.cat([x_index, virtual_edge_ids], dim=0)\n",
    "            edge_index[:, base_numel+v_n_e_counts:] = torch.cat([virtual_edge_ids, x_index], dim=0)\n",
    "            x = x_extended\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "        \n",
    "    def re_gen_graph(self, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2, seed=-1):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance, seed)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "        # for i in range(base.shape[1]):\n",
    "        #     edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "            \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "    \n",
    "    def replace_unimportant_edges(self, edge_weights, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2, seed=-1):\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        if v_n_e_counts>0:\n",
    "            important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        else:\n",
    "            important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "\n",
    "        important_indices = torch.arange(total_token_coutns, dtype=torch.int64, device=x.device) + important_indices*total_token_coutns\n",
    "        important_indices = important_indices.view(-1)\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance, seed)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "        new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_index[:, important_indices]\n",
    "        if(self.virtual_nodes>0):\n",
    "            new_edge_index[:, -2*v_n_e_counts:] = edge_index[:, -2*v_n_e_counts:]\n",
    "            \n",
    "        # for i in range(base.shape[1]):\n",
    "        #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "         \n",
    "    def calculate_graph(self, x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance, seed=-1):\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    "        tc_extended = torch.repeat_interleave(token_counts, token_counts, dim=0).view(-1,1)\n",
    "        tc_lower_bound = torch.empty((len(token_counts)+1), dtype=torch.long, device=x.device) #torch.cuda.IntTensor(len(token_counts)+1) #\n",
    "        tc_lower_bound[0] = 0\n",
    "        tc_lower_bound[1:] = torch.cumsum(token_counts, dim=0)\n",
    "        tc_lower_bound_extended = torch.repeat_interleave(tc_lower_bound[:-1], token_counts, dim=0).view(-1,1)\n",
    "        tc_range = torch.arange(tc_lower_bound[-1], device=x.device).view(-1,1)\n",
    "        # torch.arange(tc_lower_bound[-1], dtype=torch.int32, device=x.device).view(-1,1)\n",
    "        random_ints = torch.randint(0, 2*total_token_counts, (total_token_counts, random_edges), device=x.device) # torch.cuda.IntTensor(len(token_lengths), random_edges).random_()\n",
    "        lattice = self.lp.to(x.device) if self.lp is not None else torch.arange(lattice_start_distance, max(lattice_start_distance, self.lattice_step*lattice_edges+1), self.lattice_step, device=x.device).view(1, -1)\n",
    "        \n",
    "\n",
    "        # exponentials = torch.pow(2, torch.arange(1, self.exp_edges+1, device=x.device)).view(1, -1)\n",
    "        tc_local_range = tc_range - tc_lower_bound_extended\n",
    "        random_links = (((random_ints % (tc_extended - 1))+1 + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        lattice_links = ((lattice + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        # base = torch.cat([base1, base2], dim=1)\n",
    "        tc_range = tc_range.view(1,-1)\n",
    "        return random_links, lattice_links, tc_range\n",
    "    \n",
    "    def fill_lattice_and_random_edges(self, edge_index, random_links, lattice_links, tc_range):\n",
    "        for i in range(0, lattice_links.shape[1]*2, 2):\n",
    "            edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]] = torch.cat([lattice_links[:,i//2].view(1,-1), tc_range], dim=0)\n",
    "            edge_index[:, (i+1)*lattice_links.shape[0]:(i+2)*lattice_links.shape[0]] = edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]][[1, 0]]\n",
    "            \n",
    "        for i in range(random_links.shape[1]):\n",
    "            j = i + lattice_links.shape[1]*2\n",
    "            edge_index[:, j*random_links.shape[0]:(j+1)*random_links.shape[0]] = torch.cat([random_links[:,i].view(1,-1), tc_range], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.convert import to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 DataBatch(x=[1018], edge_index=[2, 20360], batch=[1018], ptr=[2])\n"
     ]
    }
   ],
   "source": [
    "# for j in range(100):\n",
    "j=0\n",
    "graph_generator = GenGraph(64, 0, 2)\n",
    "i = torch.tensor([j], dtype=torch.long)\n",
    "sub_X = Batch.from_data_list(X[i])\n",
    "graph = graph_generator.gen_graph(sub_X.token_lengths, len(sub_X.token_lengths), sub_X.num_tokens, 4, 8, lattice_start_distance=2, seed=46)\n",
    "nx_graph = to_networkx(graph)\n",
    "print(j, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'node degrees: {nx.degree(nx_graph)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "community: 0.019597104624140108\n",
      "diameter: 4\n",
      "average clustering: 0.45049013861544585\n",
      "average shortest path: 2.940289151226787\n"
     ]
    }
   ],
   "source": [
    "# print(f'average degree: {nx.average_node_connectivity(nx_graph)}')\n",
    "print(f'community: {nx.density(nx_graph)}')\n",
    "print(f'diameter: {nx.diameter(nx_graph)}')\n",
    "print(f'average clustering: {nx.average_clustering(nx_graph)}')\n",
    "print(f'average shortest path: {nx.average_shortest_path_length(nx_graph)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "community: 0.013001286793590664\n",
      "diameter: 5\n",
      "average clustering: 0.4483840287835902\n",
      "average shortest path: 3.1244923960266533\n"
     ]
    }
   ],
   "source": [
    "# print(f'average degree: {nx.average_node_connectivity(nx_graph)}')\n",
    "print(f'community: {nx.density(nx_graph)}')\n",
    "print(f'diameter: {nx.diameter(nx_graph)}')\n",
    "print(f'average clustering: {nx.average_clustering(nx_graph)}')\n",
    "print(f'average shortest path: {nx.average_shortest_path_length(nx_graph)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw_circular(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(6, device=X.x.device)[:2].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import PairNorm\n",
    "class CNN_for_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embedding, pos_emb_size=8192, embedding_dim=64, hidden_dim=64, dropout=0.3, num_out_features=4, seed=-1, random_edges=4, lattice_edges=10, virtual_nodes=1, lattice_step=2, lattice_start_distance=2, lattice_pattern=None, inject_embedding_dim=64, graph_gen_Seeds=[], num_gnn_layers=2, *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text, self).__init__(*args, **kwargs)\n",
    "        self.pos_emb_size = pos_emb_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        self.graph_gen_Seeds = torch.from_numpy(np.array(graph_gen_Seeds))\n",
    "        self.num_gnn_layers = num_gnn_layers\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    " \n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.positional_encoding = nn.Embedding(pos_emb_size, embedding_dim)\n",
    "        self.positional_encoding.weight = self.create_positional_encoding()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(2*hidden_dim + 2, hidden_dim, kernel_size=3, padding=1)\n",
    "               \n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.gcnn2s = []\n",
    "        for i in range(1, self.num_gnn_layers):\n",
    "            self.gcnn2s.append(GCNN(hidden_dim + inject_embedding_dim))\n",
    "        self.gcnn2s = nn.ModuleList(self.gcnn2s) \n",
    "        \n",
    "        self.pair_norms = []\n",
    "        for i in range(1, self.num_gnn_layers):\n",
    "            self.pair_norms.append(PairNorm())\n",
    "        self.pair_norms = nn.ModuleList(self.pair_norms) \n",
    "        \n",
    "        self.graph_generator = GenGraph(hidden_dim, virtual_nodes, lattice_step, lattice_pattern=lattice_pattern)\n",
    "        \n",
    "        k = 32\n",
    "        self.fc0 =  nn.Linear(hidden_dim , hidden_dim + inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim + inject_embedding_dim , hidden_dim * k)\n",
    "        self.fc2 = nn.Linear(hidden_dim * (2+virtual_nodes) * k , 32)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, num_out_features)\n",
    "        self.max_length = 0\n",
    "    \n",
    "    def forward(self, g_data):\n",
    "        # self.max_length = max(self.max_length, len(g_data.x))\n",
    "        if len(g_data.x) > self.max_length:\n",
    "            self.max_length = len(g_data.x)\n",
    "            self.graph_gen_Seeds = self.graph_gen_Seeds.to(g_data.x.device)\n",
    "            print(self.max_length)\n",
    "        graph_seeds = (-1, -1) if len(self.graph_gen_Seeds) < 2 else self.graph_gen_Seeds[torch.randperm(len(self.graph_gen_Seeds), device=g_data.x.device)[:2]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = self.embedding(g_data.x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.T\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x1 = scatter_max(x, g_data.cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, g_data.cumulative_token_indices, dim=1)\n",
    "\n",
    "        x = torch.cat([x1, x2, g_data.token_sentiments.T], dim=0)\n",
    "        x = F.relu(self.conv3(x)).T\n",
    "        x = x + self.positional_encoding(g_data.token_positions)\n",
    "\n",
    "        if self.num_gnn_layers>0:\n",
    "            rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "            graph = self.graph_generator.gen_graph(x, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance, seed=graph_seeds[0])\n",
    "            rand_edges = rand_edges-1\n",
    "            lattice_edges = lattice_edges-1\n",
    "            \n",
    "            x, edge_weights = self.gcnn1(graph.x, graph, len(g_data.token_lengths), return_attention_weights = True)\n",
    "            edge_weights = edge_weights[1][:graph.edge_index.shape[1], 0]\n",
    "            x = torch.cat([x, g_data.token_embeddings], dim=1)\n",
    "        \n",
    "        for i in range(1, self.num_gnn_layers):\n",
    "            self.pair_norms[i-1](x)\n",
    "            graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, graph.edge_index, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, p_keep=2, lattice_start_distance=self.lattice_start_distance+1, seed=graph_seeds[1])\n",
    "                \n",
    "            # x1 = F.relu(self.fc0(graph.x[g_data.token_embeddings.shape[0]:]))\n",
    "            # x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "            x, edge_weights = self.gcnn2s[i-1](x, graph, len(g_data.token_lengths), return_attention_weights = (i < self.num_gnn_layers-1))\n",
    "            edge_weights = edge_weights[1][:graph.edge_index.shape[1], 0]\n",
    "\n",
    "        x = F.elu_(self.fc1(x))\n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(g_data.num_tokens), device=x.device), g_data.num_tokens)\n",
    "        x1 = scatter_max(x[:len(g_data.token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(g_data.token_lengths)], doc_token_index, dim=0)\n",
    "        vn_embs = x[len(g_data.token_lengths):]\n",
    "        x_for_cat = [x1, x2]\n",
    "        x_for_cat.extend([vn_embs[i*x1.shape[0]:(i+1)*x1.shape[0]] for i in range(self.virtual_nodes)])\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "    def create_positional_encoding(self):\n",
    "        position = torch.arange(self.pos_emb_size).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.hidden_dim, 2) * (-math.log(10000.0) / self.hidden_dim))\n",
    "        pe = torch.zeros(self.pos_emb_size, self.hidden_dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return torch.nn.Parameter(pe, requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=64, embedding_dim=64, pos_emb_size=3072, dropout=0.2, num_out_features=len(class_id), seed=911, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2, num_gnn_layers=4, graph_gen_Seeds=[2,5,6,7]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_torch_model.graph_gen_Seeds.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = classifier_torch_model(X.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CnnGnnClassifierLightningModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        num_classes,\n",
    "        optimizer=None,\n",
    "        loss_func=None,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=64,\n",
    "        lr_scheduler=None,\n",
    "        user_lr_scheduler=False,\n",
    "        min_lr=0.0,\n",
    "    ):\n",
    "        super(CnnGnnClassifierLightningModel, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.min_lr = min_lr\n",
    "        # self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        self.optimizer = self._get_optimizer(optimizer)\n",
    "        self.lr_scheduler = (\n",
    "            self._get_lr_scheduler(lr_scheduler) if user_lr_scheduler else None\n",
    "        )\n",
    "        self.loss_func = loss_func\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)\n",
    "\n",
    "    def on_train_epoch_start(self) -> None:\n",
    "        param_groups = next(iter(self.optimizer.param_groups))\n",
    "        if \"lr\" in param_groups and param_groups[\"lr\"] is not None:\n",
    "            current_learning_rate = float(param_groups[\"lr\"])\n",
    "            self.log(\n",
    "                \"lr\",\n",
    "                current_learning_rate,\n",
    "                batch_size=self.batch_size,\n",
    "                on_epoch=True,\n",
    "                on_step=False,\n",
    "            )\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.train()\n",
    "        y_out = self(X)\n",
    "\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.train_losses.append(loss.detach().item())\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        self.train_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        y_out = self(X)\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.val_losses.append(loss.detach().item())\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.val_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.lr_scheduler is None:\n",
    "            return self.optimizer\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": self.lr_scheduler,\n",
    "                \"monitor\": \"train_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def update_learning_rate(self, learning_rate: float):\n",
    "        self.learning_rate = learning_rate\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g[\"lr\"] = learning_rate\n",
    "\n",
    "    def _get_optimizer(self, optimizer):\n",
    "        return (\n",
    "            optimizer\n",
    "            if optimizer is not None\n",
    "            else torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        )\n",
    "\n",
    "    def _get_lr_scheduler(self, lr_scheduler):\n",
    "        return (\n",
    "            lr_scheduler\n",
    "            if lr_scheduler is not None\n",
    "            else torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer, patience=5, factor=0.5, mode=\"min\", min_lr=self.min_lr\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 128\n",
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "label_size = 1\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import Logger, CSVLogger\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from typing import List\n",
    "from pytorch_lightning.core.saving import save_hparams_to_yaml\n",
    "\n",
    "class ModelManager(ABC):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 max_epochs = 100,\n",
    "                 ckpt_path: str|None=None,\n",
    "                 accumulate_grad_batches=1):\n",
    "        self.torch_model = torch_model\n",
    "        self.lightning_model = lightning_model\n",
    "        self.log_dir = log_dir\n",
    "        self.log_name = log_name\n",
    "        self.model_save_dir = model_save_dir\n",
    "        self.device = device\n",
    "        self.accelerator = 'cpu' if self.device=='cpu' else 'gpu'\n",
    "        self.max_epochs = max_epochs\n",
    "        self.ckpt_path = ckpt_path\n",
    "\n",
    "        self.logger = self._create_logger()\n",
    "        self.callbacks = self._create_callbacks()\n",
    "        self.trainer: L.Trainer = self._create_trainer(accumulate_grad_batches)\n",
    "        self.tuner = Tuner(self.trainer)\n",
    "        self.tuning_result = None\n",
    "\n",
    "    def tune(self, data_manager=None, train_dataloaders=None, val_dataloaders=None, datamodule=None, draw_result=True, min_lr=0.0000001, max_lr=0.1):\n",
    "        self.tuning_result = self.tuner.lr_find(self.lightning_model, datamodule=data_manager, train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders, min_lr=min_lr,max_lr=max_lr, num_training=150)\n",
    "        if draw_result:\n",
    "            fig = self.tuning_result.plot(suggest=True)\n",
    "            fig.show()\n",
    "        self.update_learning_rate(self.tuning_result.suggestion())\n",
    "        return self.tuning_result.suggestion()\n",
    "    \n",
    "    def update_learning_rate(self, lr):\n",
    "        self.lightning_model.update_learning_rate(lr)\n",
    "\n",
    "    def fit(self, train_dataloaders=None, val_dataloaders=None, datamodule=None, max_epochs = -1, ckpt_path=None):\n",
    "        if ckpt_path is not None and ckpt_path != '':\n",
    "            self.ckpt_path = ckpt_path\n",
    "        if max_epochs>0:\n",
    "            self.trainer.fit_loop.max_epochs = max_epochs\n",
    "            # self.max_epochs = max_epochs\n",
    "            # self.trainer = self._create_trainer()\n",
    "        self.trainer.fit(self.lightning_model,\n",
    "                         datamodule=datamodule,\n",
    "                         train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders,\n",
    "                         ckpt_path = self.ckpt_path\n",
    "                         )\n",
    "\n",
    "    def validate(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.validate(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def predict(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.predict(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def _create_trainer(self, accumulate_grad_batches) -> L.Trainer:\n",
    "        return L.Trainer(\n",
    "            callbacks=self.callbacks,\n",
    "            max_epochs=self.max_epochs,\n",
    "            accelerator=self.accelerator,\n",
    "            logger=self.logger,\n",
    "            num_sanity_val_steps=0,\n",
    "            default_root_dir=self.model_save_dir,\n",
    "            accumulate_grad_batches=accumulate_grad_batches\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        pass\n",
    "\n",
    "    def _create_logger(self) -> Logger:\n",
    "        return CSVLogger(save_dir=self.log_dir, name=self.log_name)\n",
    "\n",
    "    @abstractmethod\n",
    "    def draw_summary(self, dataloader):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def plot_csv_logger(self, loss_names, eval_names):\n",
    "        pass\n",
    "    \n",
    "    def save_hyper_parameters(self):\n",
    "        mhparams = {\n",
    "            'start_lr': 0.045,\n",
    "            'ckpt_lrs' :  {51: 0.002, 65: 0.00058},\n",
    "            'last_lr' : 0.0003,\n",
    "            'ac_loss_factor': 0.0002,\n",
    "            'weight_decay': 0.0012\n",
    "        }\n",
    "        save_hparams_to_yaml(config_yaml=r'logs\\hetero_model_17_AG\\version_12\\hparams.yaml',\n",
    "                     hparams=mhparams)\n",
    "        \n",
    "    # def find_best_settings(data_manager,\n",
    "    #                        lrs: List[float]=[0.001], dropouts: List[float]=[0.2], \n",
    "    #                        weight_decays: List[float]=[0.00055], emb_factors: List[float]=[0.1], \n",
    "    #                        batch_sizes: List[int]=[128], log_name='find_best_settings'):\n",
    "    #     for lr in lrs:\n",
    "    #         for dropout in dropouts:\n",
    "    #             for wd in weight_decays:\n",
    "    #                 for emb_factor in emb_factors:\n",
    "    #                     for bs in batch_sizes:\n",
    "    #                         data_manager.update_batch_size(bs)\n",
    "    #                         torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 128, dropout=dropout)\n",
    "    #                         lightning_model = HeteroBinaryLightningModel(torch_model,\n",
    "    #                                         torch.optim.Adam(torch_model.parameters(), lr=lr, weight_decay=wd),\n",
    "    #                                             loss_func=HeteroLoss1(exception_keys='word', enc_factor=emb_factor),\n",
    "    #                                             learning_rate=lr,\n",
    "    #                                             batch_size=bs,\n",
    "    #                                             user_lr_scheduler=True\n",
    "    #                                             ).to(device)\n",
    "    #                         model_manager = ClassifierModelManager(torch_model, lightning_model, log_name=log_name, device=device, num_train_epoch=10)\n",
    "    #                         model_manager.fit(datamodule=data_manager)\n",
    "    #                         model_manager.save_plot_csv_logger(name_prepend=f'{lr}_{dropout}_{wd}_{emb_factor}_{bs}', loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "import torch\n",
    "# from scripts.managers.ModelManager import ModelManager\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from torch_geometric.nn import summary\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from os import path\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "class ClassifierModelManager(ModelManager):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 num_train_epoch = 100,\n",
    "                 accumulate_grad_batches=1):\n",
    "        super(ClassifierModelManager, self).__init__(torch_model, lightning_model, model_save_dir, log_dir, log_name, device, num_train_epoch, accumulate_grad_batches=accumulate_grad_batches)\n",
    "\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        return [\n",
    "            ModelCheckpoint(save_top_k=2, mode='max', monitor='val_acc', save_last=True),\n",
    "            # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "        ]\n",
    "\n",
    "    def draw_summary(self, dataloader):\n",
    "        X, y = next(iter(dataloader))\n",
    "        print(summary(self.torch_model, X.to(self.device)))\n",
    "\n",
    "    def plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    def save_plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc'], name_prepend: str=\"\"):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        \n",
    "        loss_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_loss_metric.png')\n",
    "        plt.savefig(loss_png)\n",
    "        \n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        \n",
    "        acc_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_acc_metric.png')\n",
    "        plt.savefig(acc_png)\n",
    "        \n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate(self, eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.lightning_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        # if(give_hinge_loss):\n",
    "        #     print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')\n",
    "                \n",
    "    def evaluate_best_models(self, lightning_type: L.LightningModule, eval_dataloader,\n",
    "                             give_confusion_matrix: bool=True, \n",
    "                             give_report: bool=True, \n",
    "                             give_f1_score: bool=False, \n",
    "                             give_accuracy_score: bool=False, \n",
    "                             give_precision_score: bool=False, \n",
    "                             give_recall_score: bool=False, \n",
    "                             give_hinge_loss: bool=False,\n",
    "                             multi_class: bool=False, **kwargs):\n",
    "        self.lightning_model = lightning_type.load_from_checkpoint(rf'{self.trainer.checkpoint_callback.best_model_path}', map_location=None, hparams_file=None, strict=True, **kwargs).eval()\n",
    "        self.save_evaluation(eval_dataloader, 'best_model', give_confusion_matrix, give_report,\n",
    "                             give_f1_score, give_accuracy_score, give_precision_score, give_recall_score, give_hinge_loss, multi_class)\n",
    "            \n",
    "    def save_evaluation(self, eval_dataloader, name_prepend: str='',\n",
    "                    give_confusion_matrix: bool=True, \n",
    "                    give_report: bool=True, \n",
    "                    give_f1_score: bool=False, \n",
    "                    give_accuracy_score: bool=False, \n",
    "                    give_precision_score: bool=False, \n",
    "                    give_recall_score: bool=False, \n",
    "                    give_hinge_loss: bool=False,\n",
    "                    multi_class: bool=False\n",
    "                    ):\n",
    "            \n",
    "            test_metrics_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_test_metrics.txt')\n",
    "            \n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            self.lightning_model.eval()\n",
    "            self.lightning_model.model.eval()\n",
    "            self.torch_model.eval()\n",
    "            self.trainer.model.eval()\n",
    "            for X, y in eval_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    y_p = self.lightning_model(X.to(self.device))\n",
    "                if type(y_p) is tuple:\n",
    "                    y_p = y_p[0]\n",
    "                \n",
    "                if multi_class:\n",
    "                    y_pred.append(y_p.detach().to(y.device))\n",
    "                    y_true.append(y)\n",
    "                else:\n",
    "                    y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "                    y_true.append(y.to(torch.int32))\n",
    "                    \n",
    "            y_true = torch.concat(y_true)\n",
    "            y_pred = torch.concat(y_pred)\n",
    "            print(y_true.shape)\n",
    "            print(y_pred.shape)\n",
    "            if multi_class:\n",
    "                y_true_num = torch.argmax(y_true, dim=1)\n",
    "                y_pred_num = torch.argmax(y_pred, dim=1)\n",
    "            else:\n",
    "                y_true_num = y_true\n",
    "                y_pred_num = y_pred\n",
    "                \n",
    "            print(y_true_num.shape)\n",
    "            print(y_pred_num.shape)\n",
    "            with open(test_metrics_path, 'at+') as f:\n",
    "                if(give_confusion_matrix):\n",
    "                    print(f'confusion_matrix: \\n{confusion_matrix(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_report):\n",
    "                    print(classification_report(y_true_num, y_pred_num), file=f)\n",
    "                if(give_f1_score):\n",
    "                    if multi_class:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_accuracy_score):\n",
    "                    print(f'accuracy_score: {accuracy_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_precision_score):\n",
    "                    if multi_class:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_recall_score):\n",
    "                    if multi_class:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num)}', file=f)\n",
    "                # if(give_hinge_loss):\n",
    "                #     print(f'hinge_loss: {hinge_loss(y_true_num, y_pred)}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "def train_model(epochs=30, dropout=0.2, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True, graph_gen_seeds=[], lattice_pattern=None):\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=4096, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=8, lattice_step=2, lattice_pattern=lattice_pattern, virtual_nodes=0, lattice_start_distance=2, graph_gen_Seeds=graph_gen_seeds, num_gnn_layers=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 40, 45,50,55],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name='CNN-GNN18_mr2k_seeds',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    train_dataset.reset_params()\n",
    "    train_dataset.position_j = 0\n",
    "    test_dataset.reset_params()\n",
    "    test_dataset.position_j = 0\n",
    "    \n",
    "    # train_dataset.section_i = 0\n",
    "    # train_dataset.each_section_i = np.zeros((train_dataset.num_sections, ), dtype=int)\n",
    "    # test_dataset.section_i = 0\n",
    "    # test_dataset.each_section_i = np.zeros((test_dataset.num_sections, ), dtype=int)\n",
    "    \n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.torch_model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(CnnGnnClassifierLightningModel, test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.set_active_fold(3)\n",
    "# test_dataset.set_active_fold(3)\n",
    "# # max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "# train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=False)\n",
    "# test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)\n",
    "# # for i in [43, 48, 51, 57, 62]:\n",
    "# #     for j in [48, 51, 57, 62, 43]:\n",
    "# for grnd in [np.arange(1000)]:\n",
    "#     for i in range(3):\n",
    "#         train_model(30, 0.2, 0.000012, 0.0032, amsgrad=False, fused=True, graph_gen_seeds=grnd)\n",
    "#         time.sleep(30)\n",
    "#         torch.cuda.empty_cache()\n",
    "#         import gc\n",
    "#         gc.collect()\n",
    "#         time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    train_dataset.set_active_fold(i)\n",
    "    test_dataset.set_active_fold(i)\n",
    "    # max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "    train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=False)\n",
    "    test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)\n",
    "    for j in range(3):\n",
    "        model_manager = train_model(70, 0.2, 0.000012, 0.0032)\n",
    "        time.sleep(60)\n",
    "        torch.cuda.empty_cache()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                                                    0\n",
       "text     susan granger's review of \" america's sweethea...\n",
       "Name: 1251, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df.iloc[test_dataset.dataset.k_folds[9][1]]\n",
    "test_df.iloc[np.argwhere(['susan' in c and 'orchestrate' in c for c in  test_df.text.values]).squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = model_manager.trainer.model.model.eval()\n",
    "y_pred = t_model(X.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0016,  0.1605], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(y_pred, dim=1).shape\n",
    "y_pred[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_pred, t_model, model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 susan granger 's review of \" america 's sweethearts \" ( columbia / sony ) \n",
      " what a waste of a talented cast ! \n",
      " billy crystal and co - writer peter tolan have concocted a sly , provocative premise and , as the opening credits roll , it 's obvious that they 're attempting an old - fashioned romantic comedy . \n",
      " the story involves a veteran publicist ( billy crystal ) who is summoned to orchestrate a press junket in las vegas when an arrogant director ( christopher walken ) holds a megabuck movie hostage in his editing room , refusing to show it to anyone . \n",
      " he figures that by giving the journalists juicy hints of a possible reconciliation between the film 's once - married - but - now - estranged stars , gwen and eddie ( catherine zeta - jones , john cusack ) , they 'll be so distracted that they wo n't remember they did n't see the movie or it was n't what they expected . \n",
      "  ( and crystal thought of this long before a sony exec concocted the phony critic / david manning quote scandal ! ) \n",
      " for help , he turns to gwen 's personal assistant / sister ( julia roberts ) . \n",
      " but the laughs are few and far - between . \n",
      " crystal 's glib , cynical flack is n't wickedly funny enough with a few amusing one - liners . \n",
      " after six months under the care of a depak chopra - like guru ( alan arkin ) , cusack 's character 's too emotionally fragile , lacking the necessary charisma . \n",
      " zeta - jones 's vain , narcissistic diva is undeveloped and one - dimensional . \n",
      " only hank azaria , as zeta - jones 's much - macho spanish lover , and stanley tucci , as a studio exec , and roberts manage to whip up any farcical froth . \n",
      " basically , we do n't like these ego - driven , stereotypical characters , let alone root for them to unwind their romantic entanglements , and joe roth 's direction is predictable , formulaic and telegraphic . \n",
      " on the granger movie gauge of 1 to 10 , \" america 's sweethearts \" is a contrived , shallow 4 . as a screwball satire , it 's strictly superficial . \n",
      " \u0001\n"
     ]
    }
   ],
   "source": [
    " \n",
    "for i in range(49,50):\n",
    "    char_ids = X[i].x\n",
    "    text_for_ids = ''.join([vocab_dict_rev[ci.item()] for ci in char_ids])\n",
    "    print(torch.argmax(y[i]).item(), text_for_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2):\n",
    "#     time.sleep(30)\n",
    "#     torch.cuda.empty_cache()\n",
    "#     import gc\n",
    "#     gc.collect()\n",
    "#     train_model(60, 0.2, 0.000012, 0.0032, amsgrad=False, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(10, 0.2, 0.000012, 0.0032, amsgrad=False, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     train_model(60, 0.2, 0.000012, 0.0032, amsgrad=False, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(5):\n",
    "#     train_model(60, 0.2, 0.000012, 0.0032, amsgrad=False, fused=True)\n",
    "#     time.sleep(30)\n",
    "#     torch.cuda.empty_cache()\n",
    "#     import gc\n",
    "#     gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sp1 in [True, False]:\n",
    "    for sp2 in [True, False]:\n",
    "        for sp3 in [True, False]:\n",
    "            for i in range(3):\n",
    "                train_model(30, 0.2, 0.000012, 0.0032, amsgrad=False, fused=True, use_token_polarity=[sp1, sp2, sp3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2):\n",
    "#     train_model(70, 0.2, 0.000012, 0.0032, amsgrad=False, fused=True)\n",
    "#     time.sleep(60)\n",
    "#     torch.cuda.empty_cache()\n",
    "#     import gc\n",
    "#     gc.collect()\n",
    "#     time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     train_model(40, 0.2, 0.000012, 0.0032, amsgrad=False, fused=False)\n",
    "#     time.sleep(60)\n",
    "#     torch.cuda.empty_cache()\n",
    "#     import gc\n",
    "#     gc.collect()\n",
    "#     time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from os import path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_results(execution_number=0, base_path='logs/CNN-GNN15_imdb_sentiments/'):\n",
    "    base_path = path.join(base_path, rf'version_{execution_number}')\n",
    "    best_ckpts = [f for f in os.listdir(path.join(base_path, 'checkpoints'))][:2]\n",
    "    best_epochs = [int(re.search(r'\\d+', ckpt).group()) for ckpt in best_ckpts ]\n",
    "    \n",
    "    metrics = pd.read_csv(path.join(base_path, 'metrics.csv'))\n",
    "\n",
    "    aggregation_metrics = []\n",
    "    agg_col = 'epoch'\n",
    "    for i, dfg in metrics.groupby(agg_col):\n",
    "        agg = dict(dfg.mean())\n",
    "        agg[agg_col] = i\n",
    "        aggregation_metrics.append(agg)\n",
    "    df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "    \n",
    "    print(f\"{df_metrics['val_acc_epoch'][best_epochs]}\")\n",
    "    print(f\"{df_metrics['val_loss_epoch'][best_epochs]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31    0.875\n",
      "68    0.855\n",
      "Name: val_acc_epoch, dtype: float64\n",
      "31    0.579714\n",
      "68    0.675249\n",
      "Name: val_loss_epoch, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_best_results(2, 'logs/CNN-GNN18_mr2k_seeds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{0:68, 1:39, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoints = {'49': r'logs\\CNN-GNN15_imdb_sentiments\\version_49\\checkpoints\\epoch=42-step=4214.ckpt', \n",
    "          '50': r'logs\\CNN-GNN15_imdb_sentiments\\version_50\\checkpoints\\epoch=30-step=3038.ckpt',\n",
    "          '59': r'logs\\CNN-GNN15_imdb_sentiments\\version_59\\checkpoints\\epoch=42-step=4816.ckptt',\n",
    "          '60': r'logs\\CNN-GNN15_imdb_sentiments\\version_60\\checkpoints\\epoch=25-step=2912.ckpt',\n",
    "          '61': r'logs\\CNN-GNN15_imdb_sentiments\\version_61\\checkpoints\\epoch=51-step=5824.ckpt'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their Result: </br>\n",
    "{'losses': 0.31136547923088076, </br>\n",
    " 'accuracies': 0.9054926658163265, </br>\n",
    " 'precisions': 0.9056822870000001, </br>\n",
    " 'recalls': 0.9054926640000002, </br>\n",
    " 'f1_scores': 0.9055874557407388}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    0.90504\n",
      "30    0.90492\n",
      "Name: val_acc_epoch, dtype: float64\n",
      "18    0.252355\n",
      "30    0.317930\n",
      "Name: val_loss_epoch, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_best_results(27, 'logs/CNN-GNN14_imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_float_numbers(line_str):\n",
    "    line_str = str.split(line_str, sep=\":\")[-1]\n",
    "    all_floats = re.findall(r\"[-+]?(?:\\d*\\.*\\d+)\", line_str)\n",
    "    all_floats = np.array([float(fs) for fs in all_floats])\n",
    "    return all_floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_results(execution_number=0, base_path='logs/CNN-GNN15_imdb_sentiments/'):\n",
    "    base_path = os.path.join(base_path, rf'version_{execution_number}')\n",
    "    \n",
    "    best_ckpts = [f for f in os.listdir(path.join(base_path, 'checkpoints'))][:2]\n",
    "    best_epochs = [int(re.search(r'\\d+', ckpt).group()) for ckpt in best_ckpts ]\n",
    "    \n",
    "    metrics = pd.read_csv(path.join(base_path, 'metrics.csv'))\n",
    "\n",
    "    aggregation_metrics = []\n",
    "    agg_col = 'epoch'\n",
    "    for i, dfg in metrics.groupby(agg_col):\n",
    "        agg = dict(dfg.mean())\n",
    "        agg[agg_col] = i\n",
    "        aggregation_metrics.append(agg)\n",
    "    df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "    \n",
    "    max_acc_idx = df_metrics['val_acc_epoch'][best_epochs].argmax()\n",
    "    # print(max_acc_idx)\n",
    "    # print(f\"{df_metrics['val_acc_epoch'][best_epochs]}\")\n",
    "    # print(f\"{df_metrics['val_loss_epoch'][best_epochs]}\")\n",
    "    \n",
    "    \n",
    "    with open(path.join(base_path, 'best_model_test_metrics.txt'), 'rt') as f:\n",
    "        all_lines = f.readlines()\n",
    "\n",
    "    accuracy = np.mean(get_float_numbers(all_lines[13]))\n",
    "    # print(f\"accuracy: {accuracy}\")\n",
    "    precision = np.mean(get_float_numbers(all_lines[14]))\n",
    "    # print(f\"precision: {precision}\")\n",
    "    recall = np.mean(get_float_numbers(all_lines[15]))\n",
    "    # print(f\"recall: {recall}\")\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    # print(f\"f1_score: {f1_score}\")\n",
    "    loss = df_metrics['val_loss_epoch'][best_epochs[max_acc_idx]]\n",
    "    # print(f\"loss: {loss}\")\n",
    "    return loss, accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(execution_numbers, base_path='logs/CNN-GNN15_imdb_sentiments/'):\n",
    "    losses, accuracies, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "    for i in execution_numbers:\n",
    "        loss, accuracy, precision, recall, f1_score = get_best_results(i, base_path)\n",
    "        losses.append(loss)\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1_score)\n",
    "    losses, accuracies, precisions, recalls, f1_scores = np.mean(losses),  np.mean(accuracies),  np.mean(precisions),  np.mean(recalls),  np.mean(f1_scores)\n",
    "    return {'losses': losses, 'accuracies':accuracies, 'precisions':precisions, 'recalls':recalls, 'f1_scores':f1_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'losses': 0.6764065225919088,\n",
       " 'accuracies': 0.8383333333333333,\n",
       " 'precisions': 0.8417081249999999,\n",
       " 'recalls': 0.8322483316666668,\n",
       " 'f1_scores': 0.8368639588036478}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean([0, 1, 2], base_path='logs/CNN-GNN18_mr2k_seeds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_max(execution_numbers, base_path='logs/CNN-GNN15_imdb_sentiments/'):\n",
    "    losses, accuracies, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "    for i in execution_numbers:\n",
    "        loss, accuracy, precision, recall, f1_score = get_best_results(i, base_path)\n",
    "        losses.append(loss)\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1_score)\n",
    "    losses, accuracies, precisions, recalls, f1_scores = np.min(losses),  np.max(accuracies),  np.max(precisions),  np.max(recalls),  np.max(f1_scores)\n",
    "    return {'losses': losses, 'accuracies':accuracies, 'precisions':precisions, 'recalls':recalls, 'f1_scores':f1_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'losses': 0.6489618420600891,\n",
       " 'accuracies': 0.845,\n",
       " 'precisions': 0.846998685,\n",
       " 'recalls': 0.843349355,\n",
       " 'f1_scores': 0.845170080690126}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_max([27, 28, 29], base_path='logs/CNN-GNN18_mr2k_seeds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Results:\n",
    "| metric | fold 1 | fold 2 | fold 3 | fold 4 | fold 5 | fold 6 | fold 7 | fold 8 | fold 9 | fold 10 | Average |\n",
    "|:---|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| f1-score | 86.34 | 88.94 | 87.79 | 88.76 | 89.85 | 83.47 | 88.00 | 82.21 | 84.58 | 84.52 | 86.45 |\n",
    "| accuracy | 86.50 | 89.00 | 88.00 | 88.50 | 90.00 | 84.00 | 88.00 | 82.50 | 84.50 | 84.50 | 86.55 |\n",
    "| precision | 86.21 | 89.00 | 87.79 | 88.86 | 89.85 | 83.60 | 88.00 | 82.86 | 84.67 | 84.70 | 8655 |\n",
    "| recall | 86.47 | 88.88 | 87.79 | 88.65 | 89.85 | 83.35 | 88.00 | 81.57 | 84.50 | 84.33 | 86.34 |\n",
    "| loss | 0.5797 | 0.4209 | 0.4578 | 0.5229 | 0.4363 | 0.5536 | 0.5129 | 0.7152 | 0.7316 | 0.6490 | 0.5580 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55799"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array([0.5797, 0.4209, 0.4578, 0.5229, 0.4363, 0.5536, 0.5129, 0.7152, 0.7316, 0.6490]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    si_all = {'0': r'logs\\CNN-GNN15_imdb_sentiments\\version_0\\checkpoints\\epoch=15-step=3136.ckpt', \n",
    "            #'0': r'logs\\CNN-GNN15_imdb_sentiments\\version_0\\checkpoints\\epoch=23-step=4704.ckpt',\n",
    "            '1': r'logs\\CNN-GNN15_imdb_sentiments\\version_1\\checkpoints\\epoch=20-step=4116.ckpt',\n",
    "            '2': r'logs\\CNN-GNN15_imdb_sentiments\\version_2\\checkpoints\\epoch=16-step=3332.ckpt'}\n",
    "\n",
    "    si_p1_p2 = {'3': r'logs\\CNN-GNN15_imdb_sentiments\\version_3\\checkpoints\\epoch=15-step=3136.ckpt',\n",
    "                # '4': r'logs\\CNN-GNN15_imdb_sentiments\\version_4\\checkpoints\\epoch=25-step=5096.ckpt',\n",
    "                '4': r'logs\\CNN-GNN15_imdb_sentiments\\version_4\\checkpoints\\epoch=27-step=5488.ckpt',\n",
    "                '5': r'logs\\CNN-GNN15_imdb_sentiments\\version_5\\checkpoints\\epoch=27-step=5488.ckpt',\n",
    "                # '5': r'logs\\CNN-GNN15_imdb_sentiments\\version_5\\checkpoints\\epoch=18-step=3724.ckpt'\n",
    "                }\n",
    "\n",
    "    si_p1_p3 = {'6': r'logs\\CNN-GNN15_imdb_sentiments\\version_6\\checkpoints\\epoch=25-step=5096.ckpt',\n",
    "                '7': r'logs\\CNN-GNN15_imdb_sentiments\\version_7\\checkpoints\\epoch=28-step=5684.ckpt',\n",
    "                '8': r'logs\\CNN-GNN15_imdb_sentiments\\version_8\\checkpoints\\epoch=20-step=4116.ckpt',\n",
    "                '8': r'logs\\CNN-GNN15_imdb_sentiments\\version_8\\checkpoints\\epoch=22-step=4508.ckpt'\n",
    "                }\n",
    "\n",
    "    si_p1 = {'9': r'logs\\CNN-GNN15_imdb_sentiments\\version_9\\checkpoints\\epoch=25-step=5096.ckpt',\n",
    "            '10': r'logs\\CNN-GNN15_imdb_sentiments\\version_10\\checkpoints\\epoch=15-step=3136.ckpt',\n",
    "            '11': r'logs\\CNN-GNN15_imdb_sentiments\\version_11\\checkpoints\\epoch=21-step=4312.ckpt'}\n",
    "\n",
    "    si_p2_p3 = {'12': r'logs\\CNN-GNN15_imdb_sentiments\\version_12\\checkpoints\\epoch=27-step=5488.ckpt',\n",
    "                '13': r'logs\\CNN-GNN15_imdb_sentiments\\version_13\\checkpoints\\epoch=27-step=5488.ckpt',\n",
    "                '14': r'logs\\CNN-GNN15_imdb_sentiments\\version_14\\checkpoints\\epoch=20-step=4116.ckpt'}\n",
    "\n",
    "    si_p2 = {'15': r'logs\\CNN-GNN15_imdb_sentiments\\version_15\\checkpoints\\epoch=21-step=4312.ckpt',\n",
    "            '16': r'logs\\CNN-GNN15_imdb_sentiments\\version_16\\checkpoints\\epoch=21-step=4312.ckpt',\n",
    "            '17': r'logs\\CNN-GNN15_imdb_sentiments\\version_17\\checkpoints\\epoch=19-step=3920.ckpt'}\n",
    "\n",
    "    si_p3 = {'18': r'logs\\CNN-GNN15_imdb_sentiments\\version_18\\checkpoints\\epoch=14-step=2940.ckpt',\n",
    "            '19': r'logs\\CNN-GNN15_imdb_sentiments\\version_19\\checkpoints\\epoch=16-step=3332.ckpt',\n",
    "            '20': r'logs\\CNN-GNN15_imdb_sentiments\\version_20\\checkpoints\\epoch=15-step=3136.ckpt'}\n",
    "\n",
    "    si_none = {'24': r'logs\\CNN-GNN15_imdb_sentiments\\version_24\\checkpoints\\epoch=24-step=4900.ckpt',\n",
    "           '25': r'logs\\CNN-GNN15_imdb_sentiments\\version_25\\checkpoints\\epoch=20-step=4116.ckpt',\n",
    "           '26': r'logs\\CNN-GNN15_imdb_sentiments\\version_26\\checkpoints\\epoch=25-step=5096.ckpt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_types = {'si_all': [True, True, True], 'si_p1_p2':[True, True, False], 'si_p1_p3':[True, False, True], 'si_p1':[True, False, False], 'si_p2_p3':[False, True, True], 'si_p2':[False, True, False], 'si_p3':[False, False, True], 'si_none':[False, False, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    }
   ],
   "source": [
    "classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=3072, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2, use_token_polarity=si_types['si_all'])\n",
    "classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(si_all['2'], model=classifier_torch_model, num_classes=len(class_id)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpt = torch.load(si_all['2'], map_location=lambda storage, loc: storage)\n",
    "model_state_dict = classifier_torch_model.state_dict()\n",
    "for k in checkpt['state_dict']:\n",
    "    if k[6:] in model_state_dict:\n",
    "        model_state_dict[k[6:]] = checkpt['state_dict'][k]\n",
    "    else:\n",
    "        print(f\"Error: it doesn't have the key: {k[6:]}\")\n",
    "classifier_torch_model.load_state_dict(model_state_dict)\n",
    "classifier_torch_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(r\"logs\\CNN-GNN15_imdb_sentiments\\version_0\\checkpoints\\epoch=15-step=3136.ckpt\", map_location=None, hparams_file=None, strict=True, model=classifier_torch_model, num_classes=len(class_id)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "    seed=911\n",
    "\n",
    "    for k in si_all:    \n",
    "        classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=3072, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2, use_token_polarity=si_types['si_all'])\n",
    "        \n",
    "        checkpt = torch.load(si_all[k], map_location=lambda storage, loc: storage)\n",
    "        model_state_dict = classifier_torch_model.state_dict()\n",
    "        for k in checkpt['state_dict']:\n",
    "            if k[6:] in model_state_dict:\n",
    "                model_state_dict[k[6:]] = checkpt['state_dict'][k]\n",
    "            else:\n",
    "                print(f\"Error: it doesn't have the key: {k[6:]}\")\n",
    "        classifier_torch_model.load_state_dict(model_state_dict)\n",
    "        classifier_torch_model.to(device)\n",
    "        classifier_torch_model.eval()\n",
    "        \n",
    "        # classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(si_all[k], map_location=None, hparams_file=None, strict=True, model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "        mean_infer_acc = []\n",
    "        mean_infer_f1 = []\n",
    "        mean_infer_prec = []\n",
    "        mean_infer_rec = []\n",
    "        for i in range(5):\n",
    "            all_ys = []\n",
    "            all_y_preds = []\n",
    "            for X, y in test_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    y_pred = classifier_torch_model(X.to(device))\n",
    "                all_ys.append(torch.argmax(y,dim=1))\n",
    "                all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "            all_ys = torch.concat(all_ys)\n",
    "            all_y_preds = torch.concat(all_y_preds)\n",
    "            \n",
    "            cm = confusion_matrix(all_ys, all_y_preds)\n",
    "            \n",
    "            accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "            precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
    "            recall = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "            f1_score = (2*precision*recall)/(precision + recall)\n",
    "            \n",
    "            mean_infer_acc.append(accuracy)\n",
    "            mean_infer_f1.append(f1_score)\n",
    "            mean_infer_prec.append(precision)\n",
    "            mean_infer_rec.append(recall)\n",
    "        mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "        mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "        mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "        mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "        \n",
    "        print(f'accuracy {k}: {mean_infer_acc}')\n",
    "        print(f'f1 {k}: {mean_infer_f1}')\n",
    "        print(f'prec {k}: {mean_infer_prec}')\n",
    "        print(f'rec {k}: {mean_infer_rec}')\n",
    "        total_accuracy.append(mean_infer_acc)\n",
    "        total_f1.append(mean_infer_f1)\n",
    "        total_prec.append(mean_infer_prec)\n",
    "        total_rec.append(mean_infer_rec)\n",
    "\n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoints = {'0': r'logs\\CNN-GNN14_imdb\\version_0\\checkpoints\\epoch=21-step=4312.ckpt',\n",
    "                    '1': r'logs\\CNN-GNN14_imdb\\version_1\\checkpoints\\epoch=16-step=3332.ckpt',\n",
    "                    '2': r'logs\\CNN-GNN14_imdb\\version_2\\checkpoints\\epoch=15-step=3136.ckpt',\n",
    "                    '3': r'logs\\CNN-GNN14_imdb\\version_3\\checkpoints\\epoch=21-step=4312.ckpt',\n",
    "                    '4': r'logs\\CNN-GNN14_imdb\\version_4\\checkpoints\\epoch=21-step=4312.ckpt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "\n",
    "\n",
    "    for k in best_checkpoints:\n",
    "        classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=3072, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "        classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(best_checkpoints[k], model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "        mean_infer_acc = []\n",
    "        mean_infer_f1 = []\n",
    "        mean_infer_prec = []\n",
    "        mean_infer_rec = []\n",
    "        for i in range(5):\n",
    "            all_ys = []\n",
    "            all_y_preds = []\n",
    "            for X, y in test_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    y_pred = classfier_lightning_model(X.to(device))\n",
    "                all_ys.append(torch.argmax(y,dim=1))\n",
    "                all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "            all_ys = torch.concat(all_ys)\n",
    "            all_y_preds = torch.concat(all_y_preds)\n",
    "            \n",
    "            cm = confusion_matrix(all_ys, all_y_preds)\n",
    "            \n",
    "            accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "            precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
    "            recall = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "            f1_score = (2*precision*recall)/(precision + recall)\n",
    "            \n",
    "            mean_infer_acc.append(accuracy)\n",
    "            mean_infer_f1.append(f1_score)\n",
    "            mean_infer_prec.append(precision)\n",
    "            mean_infer_rec.append(recall)\n",
    "        mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "        mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "        mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "        mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "        \n",
    "        print(f'accuracy {k}: {mean_infer_acc}')\n",
    "        print(f'f1 {k}: {mean_infer_f1}')\n",
    "        print(f'prec {k}: {mean_infer_prec}')\n",
    "        print(f'rec {k}: {mean_infer_rec}')\n",
    "        total_accuracy.append(mean_infer_acc)\n",
    "        total_f1.append(mean_infer_f1)\n",
    "        total_prec.append(mean_infer_prec)\n",
    "        total_rec.append(mean_infer_rec)\n",
    "\n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-GNN14_imdb\n",
    "# fused on:\n",
    "best_checkpoints_fused_on = {'18': r'logs\\CNN-GNN14_imdb\\version_18\\checkpoints\\epoch=23-step=4704.ckpt',\n",
    "                             '19': r'logs\\CNN-GNN14_imdb\\version_19\\checkpoints\\epoch=21-step=4312.ckpt',\n",
    "                             '20': r'logs\\CNN-GNN14_imdb\\version_20\\checkpoints\\epoch=30-step=6076.ckpt',\n",
    "                             '21': r'logs\\CNN-GNN14_imdb\\version_21\\checkpoints\\epoch=21-step=4312.ckpt',\n",
    "                             '22': r'logs\\CNN-GNN14_imdb\\version_22\\checkpoints\\epoch=25-step=5096.ckpt',\n",
    "                             }\n",
    "\n",
    "# fused on:\n",
    "best_checkpoints_fused_off = {'23': r'logs\\CNN-GNN14_imdb\\version_23\\checkpoints\\epoch=21-step=4312.ckpt',\n",
    "                              '24': r'logs\\CNN-GNN14_imdb\\version_24\\checkpoints\\epoch=34-step=6860.ckpt',\n",
    "                              '25': r'logs\\CNN-GNN14_imdb\\version_25\\checkpoints\\epoch=34-step=6860.ckpt',\n",
    "                              '26': r'logs\\CNN-GNN14_imdb\\version_26\\checkpoints\\epoch=32-step=6468.ckpt',\n",
    "                              '27': r'logs\\CNN-GNN14_imdb\\version_27\\checkpoints\\epoch=18-step=3724.ckpt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'losses': 0.2982066869735718,\n",
       " 'accuracies': 0.903208,\n",
       " 'precisions': 0.9034025120000001,\n",
       " 'recalls': 0.903208,\n",
       " 'f1_scores': 0.9033052366785561}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean([23, 24, 25, 26, 27], 'logs/CNN-GNN14_imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'losses': 0.3015179574489594,\n",
       " 'accuracies': 0.9037200000000001,\n",
       " 'precisions': 0.9037939429999999,\n",
       " 'recalls': 0.9037200000000001,\n",
       " 'f1_scores': 0.9037569696843178}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean([18, 19, 20, 21, 22], 'logs/CNN-GNN14_imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_checkpoints_fused_on' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\Form&ColorIntelligence\\notebooks\\Task1_X_3\\text_classification\\text_classification_test_2_movie_review.ipynb Cell 66\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_2_movie_review.ipynb#Y120sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m total_prec \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_2_movie_review.ipynb#Y120sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m total_rec \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_2_movie_review.ipynb#Y120sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m best_checkpoints_fused_on:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_2_movie_review.ipynb#Y120sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     classifier_torch_model \u001b[39m=\u001b[39m CNN_for_Text(num_embedding\u001b[39m=\u001b[39mnum_embedding, hidden_dim\u001b[39m=\u001b[39mhidden_dim, embedding_dim\u001b[39m=\u001b[39membedding_dim, pos_emb_size\u001b[39m=\u001b[39m\u001b[39m3072\u001b[39m, dropout\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, num_out_features\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(class_id), seed\u001b[39m=\u001b[39mseed, random_edges\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, lattice_edges\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, lattice_step\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, virtual_nodes\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, lattice_start_distance\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_2_movie_review.ipynb#Y120sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     checkpt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(best_checkpoints_fused_on[k], map_location\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m storage, loc: storage)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_checkpoints_fused_on' is not defined"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "\n",
    "    for k in best_checkpoints_fused_on:\n",
    "        classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=3072, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "        \n",
    "        checkpt = torch.load(best_checkpoints_fused_on[k], map_location=lambda storage, loc: storage)\n",
    "        model_state_dict = classifier_torch_model.state_dict()\n",
    "        for k in checkpt['state_dict']:\n",
    "            if k[6:] in model_state_dict:\n",
    "                model_state_dict[k[6:]] = checkpt['state_dict'][k]\n",
    "            else:\n",
    "                print(f\"Error: it doesn't have the key: {k[6:]}\")\n",
    "        classifier_torch_model.load_state_dict(model_state_dict)\n",
    "        classifier_torch_model.to(device)\n",
    "        classifier_torch_model.eval()\n",
    "        \n",
    "        \n",
    "        # classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "        # classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(best_checkpoints_fused_on[k], model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "        mean_infer_acc = []\n",
    "        mean_infer_f1 = []\n",
    "        mean_infer_prec = []\n",
    "        mean_infer_rec = []\n",
    "        for i in range(5):\n",
    "            all_ys = []\n",
    "            all_y_preds = []\n",
    "            for X, y in test_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    y_pred = classfier_lightning_model(X.to(device))\n",
    "                all_ys.append(torch.argmax(y,dim=1))\n",
    "                all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "            all_ys = torch.concat(all_ys)\n",
    "            all_y_preds = torch.concat(all_y_preds)\n",
    "            \n",
    "            cm = confusion_matrix(all_ys, all_y_preds)\n",
    "            \n",
    "            accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "            precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
    "            recall = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "            f1_score = (2*precision*recall)/(precision + recall)\n",
    "            \n",
    "            mean_infer_acc.append(accuracy)\n",
    "            mean_infer_f1.append(f1_score)\n",
    "            mean_infer_prec.append(precision)\n",
    "            mean_infer_rec.append(recall)\n",
    "        mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "        mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "        mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "        mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "        \n",
    "        print(f'accuracy {k}: {mean_infer_acc}')\n",
    "        print(f'f1 {k}: {mean_infer_f1}')\n",
    "        print(f'prec {k}: {mean_infer_prec}')\n",
    "        print(f'rec {k}: {mean_infer_rec}')\n",
    "        total_accuracy.append(mean_infer_acc)\n",
    "        total_f1.append(mean_infer_f1)\n",
    "        total_prec.append(mean_infer_prec)\n",
    "        total_rec.append(mean_infer_rec)\n",
    "\n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = r'logs\\CNN-GNN14_imdb\\version_35\\checkpoints\\epoch=29-step=5880.ckpt'\n",
    "classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=3072, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(best_checkpoint, model=classifier_torch_model, num_classes=len(class_id)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ys = []\n",
    "all_y_preds = []\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        y_pred = classfier_lightning_model(X.to(device))\n",
    "    all_ys.append(torch.argmax(y,dim=1))\n",
    "    all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "all_ys = torch.concat(all_ys)\n",
    "all_y_preds = torch.concat(all_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_answers = torch.where(all_ys!=all_y_preds)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Negative', 1: 'Positive'}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_vocab_dict['monument']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: Negative\n",
      "predict:  Positive\n",
      "Great music, but ain't these people PATHETIC?!? A true period piece of The Trippy Sixties, and it left me depressed. The director paints the wrong side of the jetset life and it stings as a hornets nest. If the culture of the time led people to do these things, it appears to me that it was all a journey of no discovery, only despair. I tried, really tried, to like this film, but these people aren't anywhere on my page. Yes, it would be nice to see the world, go away for awhile, but I always plan to come BACK. Drugs aren't the cause of these characters' downfalls, it's their lousy attitudes  these guys passionately drink their cup of poison. They cheapen their lives, and in the end, cheapen the journey that is life. Has romance ever been so dark?<br /><br />Cheers: Interesting scenery. Wonderful soundtrack by Pink Floyd.<br /><br />Caveats: Dated. Drugs. Depressing. Thoroughly unlikable characters; they aren't flower children.<br /><br />Only for the curious, since most packages swoon The Pink Floyd connection. ( Rare Floyd tracks many will have never heard before, as FM ain't what it was. )<br /><br />Rating: Two Stars.\n"
     ]
    }
   ],
   "source": [
    "target = wrong_answers[10]\n",
    "print(f'original: {id_class[all_ys[target].item()]}')\n",
    "print(f'predict:  {id_class[all_y_preds[target].item()]}')\n",
    "print(test_df.text.values[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_tokenizer.tokenize(test_df.text.values[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_tokenizer.tokenize(test_df.text.values[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [t for t in nlp(test_df.text.values[target])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[1638], token_positions=[324], character_length=1638, num_tokens=324, token_indices=[1638], token_lengths=[324], token_embeddings=[324, 64], token_sentiments=[324, 2]),\n",
       " tensor([0., 1.]))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[wrong_answers[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5690, 0.4279, 0.4346, 0.4461, 0.3818, 0.4812, 0.4366, 0.4414, 0.4344,\n",
       "        0.4238, 0.4482, 0.4549, 0.4248, 0.4391, 0.4586, 0.4327, 0.4505, 0.4512,\n",
       "        0.4434, 0.4419, 0.4308, 0.4346, 0.4399, 0.4611, 0.4297, 0.4528, 0.4385,\n",
       "        0.4429, 0.4572, 0.4548, 0.4501, 0.4404, 0.4428, 0.4398, 0.4401, 0.4505,\n",
       "        0.4367, 0.4604, 0.4323, 0.4415, 0.4319, 0.4389, 0.4170, 0.4280, 0.4440,\n",
       "        0.4366, 0.4440, 0.4463, 0.4444, 0.4423, 0.4420, 0.4493, 0.4414, 0.4523,\n",
       "        0.4494, 0.4485, 0.4456, 0.4471, 0.4572, 0.3837, 0.4540, 0.4410, 0.4355,\n",
       "        0.4449])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token_vocab_dict['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2380])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_answers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.flop_counter import FlopCounterMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module                          FLOP    % Total\n",
      "------------------------  ----------  ---------\n",
      "CNN_for_Text              45366.445M    100.00%\n",
      " - aten.convolution       21007.046M     46.31%\n",
      " - aten.addmm             24359.399M     53.69%\n",
      " CNN_for_Text.conv1        8175.821M     18.02%\n",
      "  - aten.convolution       8175.821M     18.02%\n",
      " CNN_for_Text.conv2        8175.821M     18.02%\n",
      "  - aten.convolution       8175.821M     18.02%\n",
      " CNN_for_Text.conv3        2086.906M      4.60%\n",
      "  - aten.convolution       2086.906M      4.60%\n",
      " CNN_for_Text.gcnn1         856.166M      1.89%\n",
      "  - aten.addmm              342.467M      0.75%\n",
      "  - aten.convolution        513.700M      1.13%\n",
      " CNN_for_Text.sentiment2    695.635M      1.53%\n",
      "  - aten.addmm              695.635M      1.53%\n",
      " CNN_for_Text.fc0             0.000M      0.00%\n",
      "  - aten.addmm                0.000M      0.00%\n",
      " CNN_for_Text.gcnn2        3424.666M      7.55%\n",
      "  - aten.addmm             1369.866M      3.02%\n",
      "  - aten.convolution       2054.799M      4.53%\n",
      " CNN_for_Text.fc1         21917.860M     48.31%\n",
      "  - aten.addmm            21917.860M     48.31%\n",
      " CNN_for_Text.fc2            33.554M      0.07%\n",
      "  - aten.addmm               33.554M      0.07%\n",
      " CNN_for_Text.fc_out          0.016M      0.00%\n",
      "  - aten.addmm                0.016M      0.00%\n"
     ]
    }
   ],
   "source": [
    "classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=3072, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2, use_token_polarity=[True, False, True]).to(device)\n",
    "classifier_torch_model.eval()\n",
    "flopt_counter = FlopCounterMode(classifier_torch_model)\n",
    "with flopt_counter:\n",
    "    classifier_torch_model(X.to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
