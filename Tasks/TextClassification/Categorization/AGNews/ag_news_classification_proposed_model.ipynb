{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Using Proposed CNN-GNN on AG-News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Results:\n",
    "| metric | test 1 | test 2 | test 3 | test 4 | test 5 | Average |\n",
    "|:---|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| f1-score | 92.47 | 92.69 | 92.72 | 92.69 | 92.54 | 92.62 |\n",
    "| accuracy | 92.44 | 92.68 | 92.72 | 92.71 | 92.53 | 92.61 |\n",
    "| precision | 92.49 | 92.70 | 92.71 | 92.68 | 92.55 | 92.62 |\n",
    "| recall | 92.44 | 92.69 | 92.73 | 92.70 | 92.53 | 92.62 |\n",
    "| loss | 0.1100 | 0.1057 | 0.1078 | 0.1070 | 0.1074 | 0.1076 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch_scatter import scatter_max, scatter_mean, scatter_sum, scatter_std\n",
    "import torchmetrics\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from copy import copy\n",
    "import spacy\n",
    "from umap import UMAP\n",
    "\n",
    "import os\n",
    "import PyPDF2\n",
    "from bs4 import BeautifulSoup\n",
    "# import textract\n",
    "import json\n",
    "import gzip\n",
    "import re\n",
    "import collections\n",
    "import csv\n",
    "import string\n",
    "import textwrap\n",
    "import random\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 1024\n",
    "folder_path = r'data\\TextClassification\\AGNews'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "771064"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'data\\reduced_embeddings\\spacy_lg_reduced_embeddings.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "nlp = spacy.load('en_core_web_lg', disable=['tok2vec','tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
    "t_tokenizer = TweetTokenizer()\n",
    "nlp.max_length = len(' '.join(list(nlp.vocab.strings)))+1\n",
    "all_vocab_doc = nlp(' '.join(list(nlp.vocab.strings)))\n",
    "all_vocab_str = [f'{t}' for t in all_vocab_doc]\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "embeddings = (embeddings - torch.min(embeddings)) / (torch.max(embeddings)-torch.min(embeddings))\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))\n",
    "token_vocab_dict['<n>'] = token_vocab_dict['newline']\n",
    "len(token_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(r'data\\TextClassification\\AGNews\\test.csv', header=None)\n",
    "test_df['Topic'] = test_df[0] - 1\n",
    "test_df['Content'] = test_df[1] + test_df[2]\n",
    "train_df = pd.read_csv(r'data\\TextClassification\\AGNews\\train.csv', header=None)\n",
    "train_df['Topic'] = train_df[0] - 1\n",
    "train_df['Content'] = train_df[1] + train_df[2]\n",
    "ag_classes = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = df.Topic.unique()\n",
    "class_id = {ag_classes[i]:i for i in class_list}\n",
    "id_class = {i:ag_classes[i] for i in class_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' '\n",
    "all_chars = set(allowed_chars)\n",
    "vocab_dict = {c:i for i, c in enumerate(allowed_chars)}\n",
    "if '\\x01' not in vocab_dict:\n",
    "    vocab_dict['\\x01'] = len(vocab_dict)\n",
    "char_Set = set(vocab_dict.keys())\n",
    "num_embedding = len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterandTokenLevelCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, num_classes, char_dict, token_dict, tokenizer) -> None:\n",
    "        super().__init__()\n",
    "        # y = y[indices].values\n",
    "        # y = torch.from_numpy(np.array([class_id[c] for c in y], dtype=np.longlong))\n",
    "        y = torch.from_numpy(y)\n",
    "        self.y = torch.nn.functional.one_hot(y, num_classes=num_classes).float()\n",
    "        \n",
    "        self.char_dict = char_dict\n",
    "        self.char_Set = set(char_dict.keys())\n",
    "        self.vocab_size = len(self.char_dict)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_dict = token_dict\n",
    "        self.max_token_count = 0\n",
    "        \n",
    "        self.all_data = []\n",
    "        \n",
    "        self.token_lengths = []\n",
    "        \n",
    "        self.token_embeddign_ids = []\n",
    "        for doc in X:\n",
    "            tokens = self.tokenizer(''.join(c for c in doc if c in self.char_Set))\n",
    "            if len(tokens) == 0:\n",
    "                tokens = ['empty']\n",
    "                            \n",
    "            token_lengths = [len(t) for t in tokens]\n",
    "            tokens.append('\\x01')\n",
    "            \n",
    "            token_lengths.append(len(tokens[-1])-1)\n",
    "            token_lengths = torch.from_numpy(np.array(token_lengths, dtype=np.longlong))+1\n",
    "            token_embs = [self.token_dict[t] if t in self.token_dict else torch.zeros((64, ), dtype=torch.float32) for t in tokens]\n",
    "            token_embs = torch.from_numpy(np.array(token_embs, dtype=np.float32))\n",
    "            doc = ' '.join(tokens)\n",
    "            characters = torch.from_numpy(np.array([self.char_dict[t] for t in doc], dtype=np.longlong))\n",
    "            token_positions = torch.arange(len(token_lengths), dtype=torch.long)\n",
    "            token_indices = torch.repeat_interleave(token_positions, token_lengths)\n",
    "            num_tokens = len(token_lengths)\n",
    "            if num_tokens > self.max_token_count:\n",
    "                self.max_token_count = num_tokens\n",
    "            g_data = Data(x=characters,\n",
    "                            token_positions=token_positions,\n",
    "                            character_length = len(characters),\n",
    "                            num_tokens = num_tokens,\n",
    "                            token_indices=token_indices,\n",
    "                            token_lengths=token_lengths,\n",
    "                            token_embeddings=token_embs)\n",
    "            self.all_data.append(g_data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.all_data[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CharacterandTokenLevelDataLoader(DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        follow_batch: List[str] | None = None,\n",
    "        exclude_keys: List[str] | None = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CharacterandTokenLevelDataLoader, self).__init__(\n",
    "            dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        base_iterator = super(CharacterandTokenLevelDataLoader, self).__iter__()\n",
    "        for batch in base_iterator:\n",
    "            cumsum_vals = torch.cumsum(batch[0].num_tokens, dim=0).roll(1)\n",
    "            cumsum_vals[0] = 0\n",
    "            additions = torch.repeat_interleave(cumsum_vals, batch[0].character_length)\n",
    "            batch[0].cumulative_token_indices = batch[0].token_indices + additions\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CharacterandTokenLevelCustomDataset(train_df.Content.values, train_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, t_tokenizer.tokenize)\n",
    "test_dataset = CharacterandTokenLevelCustomDataset(test_df.Content.values, test_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, t_tokenizer.tokenize)\n",
    "max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv\n",
    "\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, *args, **kwargs):\n",
    "        super(GCNN, self).__init__(*args, **kwargs)\n",
    "        # self.hidden_dim = hidden_dim\n",
    "        self.gnn = GATv2Conv(hidden_dim, hidden_dim//8, heads=4)\n",
    "        # self.gnn = SimpleConv(aggr='mean')\n",
    "        self.conv = nn.Conv1d(hidden_dim, hidden_dim//2, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        # self.out_fc = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim//2)\n",
    "        # self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        # self.bn4 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, graph, total_token_count, return_attention_weights = False):\n",
    "        x1, edge_weights = self.gnn(x, graph.edge_index, return_attention_weights=return_attention_weights) \n",
    "        x2 = F.relu(self.conv(x[:total_token_count].T).T)#self.bn2(self.conv(x[:total_token_count].T).T))\n",
    "        x3 =  F.leaky_relu_(self.bn3(self.fc(x1[total_token_count:])))\n",
    "        x1 = F.leaky_relu_(self.bn1(x1[:total_token_count]))\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = torch.cat([x, x3], dim=0)\n",
    "        # x = self.bn4(x)\n",
    "        return x, edge_weights #F.leaky_relu_(self.bn4(self.out_fc(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, to_undirected\n",
    "\n",
    "class GenGraph(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, virtual_nodes, lattice_step, *args, **kwargs):\n",
    "        super(GenGraph, self).__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.lattice_step = lattice_step\n",
    "        self.virtual_node_embeddings = nn.Embedding(self.virtual_nodes, hidden_dim)\n",
    "        \n",
    "    def gen_graph(self, x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        edge_index = torch.empty((2, base_numel + v_n_e_counts*2), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "            \n",
    "        if self.virtual_nodes > 0:\n",
    "            virtual_nodes_range = torch.arange(self.virtual_nodes, device=x.device).view(1, -1)\n",
    "            virtual_nodes_ids = torch.repeat_interleave(virtual_nodes_range, len(token_counts), dim=0)\n",
    "            v_n_idx = (virtual_nodes_ids + torch.arange(0, len(token_counts)*self.virtual_nodes, self.virtual_nodes, device=x.device).view(-1, 1) + total_token_coutns )\n",
    "            virtual_edge_ids = torch.repeat_interleave(v_n_idx.view(-1), token_counts.view(-1, 1).expand(len(token_counts), self.virtual_nodes).reshape(-1), dim=0).view(1, -1)\n",
    "            \n",
    "            embs = self.virtual_node_embeddings(virtual_nodes_ids.T).view(-1, self.hidden_dim)\n",
    "            x_extended = torch.cat([x, embs], dim=0)\n",
    "            x_index = torch.arange(total_token_coutns, device=x.device).repeat(self.virtual_nodes).view(1, -1)\n",
    "            edge_index[:, base_numel:base_numel+v_n_e_counts] = torch.cat([x_index, virtual_edge_ids], dim=0)\n",
    "            edge_index[:, base_numel+v_n_e_counts:] = torch.cat([virtual_edge_ids, x_index], dim=0)\n",
    "            x = x_extended\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "        \n",
    "    def re_gen_graph(self, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "        # for i in range(base.shape[1]):\n",
    "        #     edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "            \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "    \n",
    "    def replace_unimportant_edges(self, edge_weights, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2):\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        if v_n_e_counts>0:\n",
    "            important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        else:\n",
    "            important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "\n",
    "        important_indices = torch.arange(total_token_coutns, dtype=torch.int64, device=x.device) + important_indices*total_token_coutns\n",
    "        important_indices = important_indices.view(-1)\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "        new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_index[:, important_indices]\n",
    "        if(self.virtual_nodes>0):\n",
    "            new_edge_index[:, -2*v_n_e_counts:] = edge_index[:, -2*v_n_e_counts:]\n",
    "            \n",
    "        # for i in range(base.shape[1]):\n",
    "        #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "         \n",
    "    def calculate_graph(self, x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance):\n",
    "        tc_extended = torch.repeat_interleave(token_counts, token_counts, dim=0).view(-1,1)\n",
    "        tc_lower_bound = torch.empty((len(token_counts)+1), dtype=torch.long, device=x.device) #torch.cuda.IntTensor(len(token_counts)+1) #\n",
    "        tc_lower_bound[0] = 0\n",
    "        tc_lower_bound[1:] = torch.cumsum(token_counts, dim=0)\n",
    "        tc_lower_bound_extended = torch.repeat_interleave(tc_lower_bound[:-1], token_counts, dim=0).view(-1,1)\n",
    "        tc_range = torch.arange(tc_lower_bound[-1], device=x.device).view(-1,1)\n",
    "        # torch.arange(tc_lower_bound[-1], dtype=torch.int32, device=x.device).view(-1,1)\n",
    "        random_ints = torch.randint(0, 2*total_token_coutns, (total_token_coutns, random_edges), device=x.device) # torch.cuda.IntTensor(len(token_lengths), random_edges).random_()\n",
    "        lattice = torch.arange(lattice_start_distance, self.lattice_step*lattice_edges+1, self.lattice_step, device=x.device).view(1, -1)\n",
    "\n",
    "        # exponentials = torch.pow(2, torch.arange(1, self.exp_edges+1, device=x.device)).view(1, -1)\n",
    "        tc_local_range = tc_range - tc_lower_bound_extended\n",
    "        random_links = (((random_ints % (tc_extended - 1))+1 + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        lattice_links = ((lattice + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        # base = torch.cat([base1, base2], dim=1)\n",
    "        tc_range = tc_range.view(1,-1)\n",
    "        return random_links, lattice_links, tc_range\n",
    "    \n",
    "    def fill_lattice_and_random_edges(self, edge_index, random_links, lattice_links, tc_range):\n",
    "        for i in range(0, lattice_links.shape[1]*2, 2):\n",
    "            edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]] = torch.cat([lattice_links[:,i//2].view(1,-1), tc_range], dim=0)\n",
    "            edge_index[:, (i+1)*lattice_links.shape[0]:(i+2)*lattice_links.shape[0]] = edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]][[1, 0]]\n",
    "            \n",
    "        for i in range(random_links.shape[1]):\n",
    "            j = i + lattice_links.shape[1]*2\n",
    "            edge_index[:, j*random_links.shape[0]:(j+1)*random_links.shape[0]] = torch.cat([random_links[:,i].view(1,-1), tc_range], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv, summary\n",
    "\n",
    "class CNN_for_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embedding, pos_emb_size=8192, embedding_dim=64, hidden_dim=64, dropout=0.3, num_out_features=4, seed=-1, random_edges=4, lattice_edges=10, virtual_nodes=1, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64,  *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text, self).__init__(*args, **kwargs)\n",
    "        self.pos_emb_size = pos_emb_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    " \n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.positional_encoding = nn.Embedding(pos_emb_size, embedding_dim)\n",
    "        self.positional_encoding.weight = self.create_positional_encoding()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(2*hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.gcnn2 = GCNN(hidden_dim + inject_embedding_dim)\n",
    "        self.graph_generator = GenGraph(hidden_dim, virtual_nodes, lattice_step)\n",
    "        \n",
    "        k = 8\n",
    "        self.fc0 =  nn.Linear(hidden_dim , hidden_dim + inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim + inject_embedding_dim , hidden_dim * k)\n",
    "        self.fc2 = nn.Linear(hidden_dim * (2+virtual_nodes) * k , 32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, num_out_features)\n",
    "    \n",
    "    \n",
    "    def forward(self, g_data):\n",
    "\n",
    "        x = self.embedding(g_data.x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.T\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x1 = scatter_max(x, g_data.cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, g_data.cumulative_token_indices, dim=1)\n",
    "\n",
    "        x = torch.cat([x1, x2], dim=0)\n",
    "\n",
    "        x = F.relu(self.conv3(x)).T\n",
    "        \n",
    "        x = x + self.positional_encoding(g_data.token_positions)\n",
    "\n",
    "        rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "        graph = self.graph_generator.gen_graph(x, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "        rand_edges = rand_edges-1\n",
    "        lattice_edges = lattice_edges-1\n",
    "        \n",
    "        x, edge_weights = self.gcnn1(graph.x, graph, len(g_data.token_lengths), return_attention_weights = True)\n",
    "        edge_weights = edge_weights[1][:graph.edge_index.shape[1], 0]\n",
    "        \n",
    "        graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, graph.edge_index, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        \n",
    "        x = torch.cat([graph.x[:g_data.token_embeddings.shape[0]], g_data.token_embeddings], dim=1)\n",
    "        x1 = F.relu(self.fc0(graph.x[g_data.token_embeddings.shape[0]:]))\n",
    "        x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "        x, edge_weights = self.gcnn2(x, graph, len(g_data.token_lengths))\n",
    "\n",
    "        x = F.elu_(self.fc1(x))\n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(g_data.num_tokens), device=x.device), g_data.num_tokens)\n",
    "        x1 = scatter_max(x[:len(g_data.token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(g_data.token_lengths)], doc_token_index, dim=0)\n",
    "        vn_embs = x[len(g_data.token_lengths):]\n",
    "        x_for_cat = [x1, x2]\n",
    "        x_for_cat.extend([vn_embs[i*x1.shape[0]:(i+1)*x1.shape[0]] for i in range(self.virtual_nodes)])\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        \n",
    "        x = F.elu_(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def create_positional_encoding(self):\n",
    "        position = torch.arange(self.pos_emb_size).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.hidden_dim, 2) * (-math.log(10000.0) / self.hidden_dim))\n",
    "        pe = torch.zeros(self.pos_emb_size, self.hidden_dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return torch.nn.Parameter(pe, requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CnnGnnClassifierLightningModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        num_classes,\n",
    "        optimizer=None,\n",
    "        loss_func=None,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=64,\n",
    "        lr_scheduler=None,\n",
    "        user_lr_scheduler=False,\n",
    "        min_lr=0.0,\n",
    "    ):\n",
    "        super(CnnGnnClassifierLightningModel, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.min_lr = min_lr\n",
    "        # self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        self.optimizer = self._get_optimizer(optimizer)\n",
    "        self.lr_scheduler = (\n",
    "            self._get_lr_scheduler(lr_scheduler) if user_lr_scheduler else None\n",
    "        )\n",
    "        self.loss_func = loss_func\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)\n",
    "\n",
    "    def on_train_epoch_start(self) -> None:\n",
    "        param_groups = next(iter(self.optimizer.param_groups))\n",
    "        if \"lr\" in param_groups and param_groups[\"lr\"] is not None:\n",
    "            current_learning_rate = float(param_groups[\"lr\"])\n",
    "            self.log(\n",
    "                \"lr\",\n",
    "                current_learning_rate,\n",
    "                batch_size=self.batch_size,\n",
    "                on_epoch=True,\n",
    "                on_step=False,\n",
    "            )\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.train()\n",
    "        y_out = self(X)\n",
    "\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.train_losses.append(loss.detach().item())\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        self.train_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        y_out = self(X)\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.val_losses.append(loss.detach().item())\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.val_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.lr_scheduler is None:\n",
    "            return self.optimizer\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": self.lr_scheduler,\n",
    "                \"monitor\": \"train_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def update_learning_rate(self, learning_rate: float):\n",
    "        self.learning_rate = learning_rate\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g[\"lr\"] = learning_rate\n",
    "\n",
    "    def _get_optimizer(self, optimizer):\n",
    "        return (\n",
    "            optimizer\n",
    "            if optimizer is not None\n",
    "            else torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        )\n",
    "\n",
    "    def _get_lr_scheduler(self, lr_scheduler):\n",
    "        return (\n",
    "            lr_scheduler\n",
    "            if lr_scheduler is not None\n",
    "            else torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer, patience=5, factor=0.5, mode=\"min\", min_lr=self.min_lr\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 128\n",
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "label_size = 1\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import Logger, CSVLogger\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from typing import List\n",
    "from pytorch_lightning.core.saving import save_hparams_to_yaml\n",
    "\n",
    "class ModelManager(ABC):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 max_epochs = 100,\n",
    "                 ckpt_path: str|None=None,\n",
    "                 accumulate_grad_batches=1):\n",
    "        self.torch_model = torch_model\n",
    "        self.lightning_model = lightning_model\n",
    "        self.log_dir = log_dir\n",
    "        self.log_name = log_name\n",
    "        self.model_save_dir = model_save_dir\n",
    "        self.device = device\n",
    "        self.accelerator = 'cpu' if self.device=='cpu' else 'gpu'\n",
    "        self.max_epochs = max_epochs\n",
    "        self.ckpt_path = ckpt_path\n",
    "\n",
    "        self.logger = self._create_logger()\n",
    "        self.callbacks = self._create_callbacks()\n",
    "        self.trainer: L.Trainer = self._create_trainer(accumulate_grad_batches)\n",
    "        self.tuner = Tuner(self.trainer)\n",
    "        self.tuning_result = None\n",
    "\n",
    "    def tune(self, data_manager=None, train_dataloaders=None, val_dataloaders=None, datamodule=None, draw_result=True, min_lr=0.0000001, max_lr=0.1):\n",
    "        self.tuning_result = self.tuner.lr_find(self.lightning_model, datamodule=data_manager, train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders, min_lr=min_lr,max_lr=max_lr, num_training=150)\n",
    "        if draw_result:\n",
    "            fig = self.tuning_result.plot(suggest=True)\n",
    "            fig.show()\n",
    "        self.update_learning_rate(self.tuning_result.suggestion())\n",
    "        return self.tuning_result.suggestion()\n",
    "    \n",
    "    def update_learning_rate(self, lr):\n",
    "        self.lightning_model.update_learning_rate(lr)\n",
    "\n",
    "    def fit(self, train_dataloaders=None, val_dataloaders=None, datamodule=None, max_epochs = -1, ckpt_path=None):\n",
    "        if ckpt_path is not None and ckpt_path != '':\n",
    "            self.ckpt_path = ckpt_path\n",
    "        if max_epochs>0:\n",
    "            self.trainer.fit_loop.max_epochs = max_epochs\n",
    "            # self.max_epochs = max_epochs\n",
    "            # self.trainer = self._create_trainer()\n",
    "        self.trainer.fit(self.lightning_model,\n",
    "                         datamodule=datamodule,\n",
    "                         train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders,\n",
    "                         ckpt_path = self.ckpt_path\n",
    "                         )\n",
    "\n",
    "    def validate(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.validate(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def predict(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.predict(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def _create_trainer(self, accumulate_grad_batches) -> L.Trainer:\n",
    "        return L.Trainer(\n",
    "            callbacks=self.callbacks,\n",
    "            max_epochs=self.max_epochs,\n",
    "            accelerator=self.accelerator,\n",
    "            logger=self.logger,\n",
    "            num_sanity_val_steps=0,\n",
    "            default_root_dir=self.model_save_dir,\n",
    "            accumulate_grad_batches=accumulate_grad_batches\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        pass\n",
    "\n",
    "    def _create_logger(self) -> Logger:\n",
    "        return CSVLogger(save_dir=self.log_dir, name=self.log_name)\n",
    "\n",
    "    @abstractmethod\n",
    "    def draw_summary(self, dataloader):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def plot_csv_logger(self, loss_names, eval_names):\n",
    "        pass\n",
    "    \n",
    "    def save_hyper_parameters(self):\n",
    "        mhparams = {\n",
    "            'start_lr': 0.045,\n",
    "            'ckpt_lrs' :  {51: 0.002, 65: 0.00058},\n",
    "            'last_lr' : 0.0003,\n",
    "            'ac_loss_factor': 0.0002,\n",
    "            'weight_decay': 0.0012\n",
    "        }\n",
    "        save_hparams_to_yaml(config_yaml=r'logs\\hetero_model_17_AG\\version_12\\hparams.yaml',\n",
    "                     hparams=mhparams)\n",
    "        \n",
    "    # def find_best_settings(data_manager,\n",
    "    #                        lrs: List[float]=[0.001], dropouts: List[float]=[0.2], \n",
    "    #                        weight_decays: List[float]=[0.00055], emb_factors: List[float]=[0.1], \n",
    "    #                        batch_sizes: List[int]=[128], log_name='find_best_settings'):\n",
    "    #     for lr in lrs:\n",
    "    #         for dropout in dropouts:\n",
    "    #             for wd in weight_decays:\n",
    "    #                 for emb_factor in emb_factors:\n",
    "    #                     for bs in batch_sizes:\n",
    "    #                         data_manager.update_batch_size(bs)\n",
    "    #                         torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 128, dropout=dropout)\n",
    "    #                         lightning_model = HeteroBinaryLightningModel(torch_model,\n",
    "    #                                         torch.optim.Adam(torch_model.parameters(), lr=lr, weight_decay=wd),\n",
    "    #                                             loss_func=HeteroLoss1(exception_keys='word', enc_factor=emb_factor),\n",
    "    #                                             learning_rate=lr,\n",
    "    #                                             batch_size=bs,\n",
    "    #                                             user_lr_scheduler=True\n",
    "    #                                             ).to(device)\n",
    "    #                         model_manager = ClassifierModelManager(torch_model, lightning_model, log_name=log_name, device=device, num_train_epoch=10)\n",
    "    #                         model_manager.fit(datamodule=data_manager)\n",
    "    #                         model_manager.save_plot_csv_logger(name_prepend=f'{lr}_{dropout}_{wd}_{emb_factor}_{bs}', loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "import torch\n",
    "# from scripts.managers.ModelManager import ModelManager\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from torch_geometric.nn import summary\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from os import path\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "class ClassifierModelManager(ModelManager):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 num_train_epoch = 100,\n",
    "                 accumulate_grad_batches=1):\n",
    "        super(ClassifierModelManager, self).__init__(torch_model, lightning_model, model_save_dir, log_dir, log_name, device, num_train_epoch, accumulate_grad_batches=accumulate_grad_batches)\n",
    "\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        return [\n",
    "            ModelCheckpoint(save_top_k=2, mode='max', monitor='val_acc', save_last=True),\n",
    "            # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "        ]\n",
    "\n",
    "    def draw_summary(self, dataloader):\n",
    "        X, y = next(iter(dataloader))\n",
    "        print(summary(self.torch_model, X.to(self.device)))\n",
    "\n",
    "    def plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    def save_plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc'], name_prepend: str=\"\"):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        \n",
    "        loss_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_loss_metric.png')\n",
    "        plt.savefig(loss_png)\n",
    "        \n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        \n",
    "        acc_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_acc_metric.png')\n",
    "        plt.savefig(acc_png)\n",
    "        \n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate(self, eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.lightning_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        if(give_hinge_loss):\n",
    "            print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')\n",
    "                \n",
    "    def evaluate_best_models(self, lightning_type: L.LightningModule, eval_dataloader,\n",
    "                             give_confusion_matrix: bool=True, \n",
    "                             give_report: bool=True, \n",
    "                             give_f1_score: bool=False, \n",
    "                             give_accuracy_score: bool=False, \n",
    "                             give_precision_score: bool=False, \n",
    "                             give_recall_score: bool=False, \n",
    "                             give_hinge_loss: bool=False,\n",
    "                             multi_class: bool=False, **kwargs):\n",
    "        self.lightning_model = lightning_type.load_from_checkpoint(rf'{self.trainer.checkpoint_callback.best_model_path}', map_location=None, hparams_file=None, strict=True, **kwargs).eval()\n",
    "        self.save_evaluation(eval_dataloader, 'best_model', give_confusion_matrix, give_report,\n",
    "                             give_f1_score, give_accuracy_score, give_precision_score, give_recall_score, give_hinge_loss, multi_class)\n",
    "            \n",
    "    def save_evaluation(self, eval_dataloader, name_prepend: str='',\n",
    "                    give_confusion_matrix: bool=True, \n",
    "                    give_report: bool=True, \n",
    "                    give_f1_score: bool=False, \n",
    "                    give_accuracy_score: bool=False, \n",
    "                    give_precision_score: bool=False, \n",
    "                    give_recall_score: bool=False, \n",
    "                    give_hinge_loss: bool=False,\n",
    "                    multi_class: bool=False\n",
    "                    ):\n",
    "            \n",
    "            test_metrics_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_test_metrics.txt')\n",
    "            \n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            self.lightning_model.eval()\n",
    "            self.lightning_model.model.eval()\n",
    "            self.torch_model.eval()\n",
    "            self.trainer.model.eval()\n",
    "            for X, y in eval_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    y_p = self.lightning_model(X.to(self.device))\n",
    "                if type(y_p) is tuple:\n",
    "                    y_p = y_p[0]\n",
    "                \n",
    "                if multi_class:\n",
    "                    y_pred.append(y_p.detach().to(y.device))\n",
    "                    y_true.append(y)\n",
    "                else:\n",
    "                    y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "                    y_true.append(y.to(torch.int32))\n",
    "                    \n",
    "            y_true = torch.concat(y_true)\n",
    "            y_pred = torch.concat(y_pred)\n",
    "            print(y_true.shape)\n",
    "            print(y_pred.shape)\n",
    "            if multi_class:\n",
    "                y_true_num = torch.argmax(y_true, dim=1)\n",
    "                y_pred_num = torch.argmax(y_pred, dim=1)\n",
    "            else:\n",
    "                y_true_num = y_true\n",
    "                y_pred_num = y_pred\n",
    "                \n",
    "            print(y_true_num.shape)\n",
    "            print(y_pred_num.shape)\n",
    "            with open(test_metrics_path, 'at+') as f:\n",
    "                if(give_confusion_matrix):\n",
    "                    print(f'confusion_matrix: \\n{confusion_matrix(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_report):\n",
    "                    print(classification_report(y_true_num, y_pred_num), file=f)\n",
    "                if(give_f1_score):\n",
    "                    if multi_class:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_accuracy_score):\n",
    "                    print(f'accuracy_score: {accuracy_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_precision_score):\n",
    "                    if multi_class:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_recall_score):\n",
    "                    if multi_class:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_hinge_loss):\n",
    "                    print(f'hinge_loss: {hinge_loss(y_true_num, y_pred)}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "def train_model(epochs=30, dropout=0.2, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True):\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 38, 40,45,50],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name='CNN-GNN13_large_models',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.torch_model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(CnnGnnClassifierLightningModel, test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6711"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | CNN_for_Text       | 778 K  | train\n",
      "1 | loss_func | BCEWithLogitsLoss  | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "254 K     Trainable params\n",
      "524 K     Non-trainable params\n",
      "778 K     Total params\n",
      "3.114     Total estimated model params size (MB)\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032c9e91d08745908632c3a399964c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecf4707d10c49e49b46b500508f45b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae213a88b7d4a49815610abc287c84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d48257f32874b85bb7dcf43234d1694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ffc2fbb08246d59f754770df62ce0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f202cb83cb2c411db30afc4a28d765a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e9b3a7081e457cb456fc367aa0fb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b752b17d57455fbbe2f0bd6831321f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef588de797d4b44a0a6eec11e3f1329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf5a27d890b4773a62cfc0504ca7c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b1503060754a6e9e3ed80270b20114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d294d19f674245948e89154990da1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764486eccfe9467c8e72b3cdc3ddb6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23487a4d96ef4a13a336c83bdbc4cf09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554cbc79b9d24abfaa873162b8c6304a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f877ea610f864e14b4f3278bb56822ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017afd4b378d462e8ff30ecc8006b026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3a887df14c4364b652c587685e989d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d417f7031d164ab2bcea6b0a6b7107e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6b373972ea422b91b5d90c5ac69d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b71a1a40614f9fab10bbc4692be7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7b9f17d33e46b88edec72f9a673aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f305e32ea40405b974efcbaa0154926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d07acaa6f24f7484bbd35645faa530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2117c237e470452597097b12b7f20895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40788de1176441ec8da559b42779a6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b88b4fd2cc4d9897fac4ff6b2e95e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bad1f94dfbb4dfcaa31b727c72b62b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cc9b71ec7f4357a638c8f88c5455f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8a6f5b24b0409d9ee4fb086be53dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3503773af0724892a5db7ef64e64855f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536e96db32c644efa8a110f8faab50ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968d69b8cd014e39a0a6542df22b4260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f754d3576f154e558a1c743e873913ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0a2681a9fc425ca6e3c84b6faafbe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdde816962d4e17a20ab514b8493616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fe3f2a9c6644d2bd2c2da36af6bb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1877729e34b24c10953e04a49f0690fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2a1cae6bfc48cfb4eafeb5b8567b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f9ee894e164d95ab02ed2dae78f137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af9087375c64cfabcf5a3666ce77876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c9a3c57b3f4d62942de43206b9d634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baea17e7b03742699863fc946ff40166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11b812272574be4add507fde9479554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5b983118584e1db75d02a7581e58d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74ad5f109f2491eb33bf325ef81a309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b50599fe30c42508f1498fac29f7dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7503f692a3454cab91987c33e2fc618e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277a388128cd473391ed999cfc78d68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819f1f7538e74c41990b3c4a3a929351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cf00c493d74dc7b13af83b330d5bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c5be2c8b3347fa8ec70038f516309e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0a48da1fb149eabc31690c43ba9d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacccfc3b4694eb8a84568d6b9fdf918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ee259c46c04cadb262a7174dfb1bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb4beb5f4c34d68a1474ca908ea73a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5e5e16ac7a46d5baf1686d31dabf8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2860781c1a5549b1bf51eaf71d8c6c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f5797a589f4d78888c017be4e4c6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a60c1ba4f24cb6a1b0510a90e23ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d782d4046b62444b9478e3e9b532e8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797528e363d34db2872d2ff07609b070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2c6d3058ec442b991a8dadf42eb89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c797e36892914a19a5244fc126d3c88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c41a54dc174fe0a693484ee7b5fad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569804fd325b4660bbe863631f4f9f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bfbc2ae7fc4b879a3b537614139881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9f4beb9faf41ba89c750959352fa93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c42f5cb4e844a77bc3c330dcaf6b84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa9b73cdaf740409349e645cecdd716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a40dcd20a594b5789fac5132e81656c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=70` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7168, 4])\n",
      "torch.Size([7168, 4])\n",
      "torch.Size([7168])\n",
      "torch.Size([7168])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9317    0.9358    0.9337      1792\n",
      "           1     0.9729    0.9767    0.9748      1802\n",
      "           2     0.9024    0.8781    0.8901      1789\n",
      "           3     0.8938    0.9104    0.9020      1785\n",
      "\n",
      "    accuracy                         0.9254      7168\n",
      "   macro avg     0.9252    0.9253    0.9252      7168\n",
      "weighted avg     0.9253    0.9254    0.9253      7168\n",
      "\n",
      "confusion matrix:\n",
      " tensor([[1677,   17,   59,   39],\n",
      "        [  19, 1760,   13,   10],\n",
      "        [  54,   20, 1571,  144],\n",
      "        [  50,   12,   98, 1625]])\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7168, 4])\n",
      "torch.Size([7168, 4])\n",
      "torch.Size([7168])\n",
      "torch.Size([7168])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_manager = train_model(70, 0.2, 0.000012, 0.0032, amsgrad=False, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/CNN-GNN13_large_models\\\\version_4\\\\checkpoints\\\\epoch=69-step=8190.ckpt'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_manager.trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoints = {\n",
    "    # '1': r'logs\\CNN-GNN13_large_models\\version_1\\checkpoints\\epoch=58-step=6903.ckpt',\n",
    "    # '2': r'logs\\CNN-GNN13_large_models\\version_2\\checkpoints\\epoch=65-step=7722.ckpt',\n",
    "    # '3': r'logs\\CNN-GNN13_large_models\\version_3\\checkpoints\\epoch=66-step=7839.ckpt',\n",
    "    '4': r'logs\\CNN-GNN13_large_models\\version_4\\checkpoints\\epoch=69-step=8190.ckpt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "def train_model(epochs=30, dropout=0.2, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True):\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 38, 40,45,50],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name='CNN-GNN13_large_models',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.torch_model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(CnnGnnClassifierLightningModel, test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=len(class_id))\n",
    "f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=len(class_id))\n",
    "precision = torchmetrics.Precision(task=\"multiclass\", num_classes=len(class_id))\n",
    "recall = torchmetrics.Recall(task=\"multiclass\", num_classes=len(class_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs\\CNN-GNN13_large_models\\version_4\\checkpoints\\epoch=69-step=8190.ckpt\n",
      "accuracy 4: 0.9252511160714285\n",
      "f1 4: 0.92525756036205\n",
      "prec 4: 0.9252797829293058\n",
      "rec 4: 0.9252353396775783\n",
      "total_accuracy: 0.9252511160714285\n",
      "total_f1: 0.92525756036205\n",
      "total_prec: 0.9252797829293058\n",
      "total_rec: 0.9252353396775783\n"
     ]
    }
   ],
   "source": [
    "total_accuracy = []\n",
    "total_f1 = []\n",
    "total_prec = []\n",
    "total_rec = []\n",
    "\n",
    "for k in best_checkpoints:\n",
    "    print(best_checkpoints[k])\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(best_checkpoints[k], model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "    mean_infer_acc = []\n",
    "    mean_infer_f1 = []\n",
    "    mean_infer_prec = []\n",
    "    mean_infer_rec = []\n",
    "    for i in range(5):\n",
    "        all_ys = []\n",
    "        all_y_preds = []\n",
    "        for X, y in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                y_pred = classfier_lightning_model(X.to(device))\n",
    "            all_ys.append(torch.argmax(y,dim=1))\n",
    "            all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "        all_ys = torch.concat(all_ys)\n",
    "        all_y_preds = torch.concat(all_y_preds)\n",
    "        \n",
    "        cm = confusion_matrix(all_ys, all_y_preds)\n",
    "        \n",
    "        accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "        precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
    "        recall = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "        f1_score = (2*precision*recall)/(precision + recall)\n",
    "        \n",
    "        mean_infer_acc.append(accuracy)\n",
    "        mean_infer_f1.append(f1_score)\n",
    "        mean_infer_prec.append(precision)\n",
    "        mean_infer_rec.append(recall)\n",
    "    mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "    mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "    mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "    mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "    \n",
    "    print(f'accuracy {k}: {mean_infer_acc}')\n",
    "    print(f'f1 {k}: {mean_infer_f1}')\n",
    "    print(f'prec {k}: {mean_infer_prec}')\n",
    "    print(f'rec {k}: {mean_infer_rec}')\n",
    "    total_accuracy.append(mean_infer_acc)\n",
    "    total_f1.append(mean_infer_f1)\n",
    "    total_prec.append(mean_infer_prec)\n",
    "    total_rec.append(mean_infer_rec)\n",
    "\n",
    "total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "total_prec = torch.mean(torch.tensor(total_prec))\n",
    "total_rec = torch.mean(torch.tensor(total_rec))\n",
    "print(f'total_accuracy: {total_accuracy}')\n",
    "print(f'total_f1: {total_f1}')\n",
    "print(f'total_prec: {total_prec}')\n",
    "print(f'total_rec: {total_rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1682   23   68   37]\n",
      " [  14 1744   14   12]\n",
      " [  29   15 1630  118]\n",
      " [  47   14  124 1597]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(all_ys, all_y_preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1810, 1784, 1792, 1782], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(cm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9281606301071419"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.diag(cm))/ np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9281529017857143"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.diag(cm))/ np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9282)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(all_ys, all_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9282)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(all_ys, all_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNGNNClassifier_FromPretrained:\n",
    "    \n",
    "    def __init__(self, num_embedding, hidden_dim, embedding_dim, num_classes, pos_emb_size=8192,  dropout=0.2, device='cpu'):\n",
    "        self.device = device;\n",
    "        self.num_classes = num_classes\n",
    "        self.classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=pos_emb_size, dropout=dropout, num_out_features=num_classes, seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "        self.classfier_lightning_model = None\n",
    "        \n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.precision = torchmetrics.Precision(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.recall = torchmetrics.Recall(task=\"multiclass\", num_classes=num_classes)\n",
    "        \n",
    "    \n",
    "    def load_inference_model(self, checkpoint_path):\n",
    "        # checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "        self.classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(checkpoint_path, model=self.classifier_torch_model, num_classes=self.num_classes).to(self.device).eval()\n",
    "        \n",
    "    # def load_train_model(self, checkpoint_path):\n",
    "    #     optimizer = torch.optim.AdamW(self.classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    #     # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    #     lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 38, 40,45,50],gamma=0.5, verbose=False)\n",
    "    #     loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    #     classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "    #                                                         num_classes=len(class_id),\n",
    "    #                                                 learning_rate=lr,\n",
    "    #                                                 batch_size=batch_size,\n",
    "    #                                                 optimizer=optimizer,\n",
    "    #                                                 loss_func=loss_func,\n",
    "    #                                                 lr_scheduler=lr_scheduler,\n",
    "    #                                                 user_lr_scheduler=True\n",
    "    #                                                 ).to(device)\n",
    "    \n",
    "    def evaluate(self, eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        \n",
    "        \n",
    "        all_ys = []\n",
    "        all_y_preds = []\n",
    "        for X, y in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                y_pred = classfier_lightning_model(X.to(device))\n",
    "            all_ys.append(torch.argmax(y,dim=1))\n",
    "            all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "        all_ys = torch.concat(all_ys)\n",
    "        all_y_preds = torch.concat(all_y_preds)\n",
    "        accuracy = accuracy(all_ys, all_y_preds).item()\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.lightning_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        if(give_hinge_loss):\n",
    "            print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in best_checkpoints:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
