{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Using Proposed CNN-GNN on AG-News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Results:\n",
    "| metric | test 1 | test 2 | test 3 | test 4 | test 5 | Average |\n",
    "|:---|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| f1-score | 92.47 | 92.69 | 92.72 | 92.69 | 92.54 | 92.62 |\n",
    "| accuracy | 92.44 | 92.68 | 92.72 | 92.71 | 92.53 | 92.61 |\n",
    "| precision | 92.49 | 92.70 | 92.71 | 92.68 | 92.55 | 92.62 |\n",
    "| recall | 92.44 | 92.69 | 92.73 | 92.70 | 92.53 | 92.62 |\n",
    "| loss | 0.1100 | 0.1057 | 0.1078 | 0.1070 | 0.1074 | 0.1076 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "# from transformers import BertTokenizer\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "# import time\n",
    "# import matplotlib.pyplot as plt\n",
    "# import random\n",
    "from torch_scatter import scatter_max, scatter_mean, scatter_sum, scatter_std\n",
    "import torchmetrics\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "# from torch_geometric.loader import DataLoader\n",
    "from copy import copy\n",
    "import spacy\n",
    "# from umap import UMAP\n",
    "\n",
    "# import os\n",
    "# import PyPDF2\n",
    "# from bs4 import BeautifulSoup\n",
    "# import textract\n",
    "# import json\n",
    "# import gzip\n",
    "# import re\n",
    "# import collections\n",
    "# import csv\n",
    "import string\n",
    "# import textwrap\n",
    "import random\n",
    "# import itertools\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 224\n",
    "folder_path = r'data\\TextClassification\\AGNews'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508709"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'Data\\ReducedEmbeddings\\spacy_lg_reduced_embeddings.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "nlp = spacy.load('en_core_web_lg', disable=['tok2vec','tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
    "t_tokenizer = TweetTokenizer()\n",
    "nlp.max_length = len(' '.join(list(nlp.vocab.strings)))+1\n",
    "all_vocab_doc = nlp(' '.join(list(nlp.vocab.strings)))\n",
    "all_vocab_str = [f'{t}' for t in all_vocab_doc]\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "embeddings = (embeddings - torch.min(embeddings)) / (torch.max(embeddings)-torch.min(embeddings))\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))\n",
    "token_vocab_dict['<n>'] = token_vocab_dict['newline']\n",
    "len(token_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(r'data\\TextClassification\\AGNews\\test.csv', header=None)\n",
    "test_df['Topic'] = test_df[0] - 1\n",
    "test_df['Content'] = test_df[1] + test_df[2]\n",
    "train_df = pd.read_csv(r'data\\TextClassification\\AGNews\\train.csv', header=None)\n",
    "train_df['Topic'] = train_df[0] - 1\n",
    "train_df['Content'] = train_df[1] + train_df[2]\n",
    "ag_classes = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = df.Topic.unique()\n",
    "class_id = {ag_classes[i]:i for i in class_list}\n",
    "id_class = {i:ag_classes[i] for i in class_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' '\n",
    "all_chars = set(allowed_chars)\n",
    "vocab_dict = {c:i for i, c in enumerate(allowed_chars)}\n",
    "if '\\x01' not in vocab_dict:\n",
    "    vocab_dict['\\x01'] = len(vocab_dict)\n",
    "char_Set = set(vocab_dict.keys())\n",
    "num_embedding = len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterandTokenLevelCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, num_classes, char_dict, token_dict, tokenizer) -> None:\n",
    "        super().__init__()\n",
    "        # y = y[indices].values\n",
    "        # y = torch.from_numpy(np.array([class_id[c] for c in y], dtype=np.longlong))\n",
    "        y = torch.from_numpy(y)\n",
    "        self.y = torch.nn.functional.one_hot(y, num_classes=num_classes).float()\n",
    "        \n",
    "        self.char_dict = char_dict\n",
    "        self.char_Set = set(char_dict.keys())\n",
    "        self.vocab_size = len(self.char_dict)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_dict = token_dict\n",
    "        self.max_token_count = 0\n",
    "        \n",
    "        self.all_data = []\n",
    "        \n",
    "        self.token_lengths = []\n",
    "        \n",
    "        self.token_embeddign_ids = []\n",
    "        for doc in X:\n",
    "            tokens = self.tokenizer(''.join(c for c in doc if c in self.char_Set))\n",
    "            if len(tokens) == 0:\n",
    "                tokens = ['empty']\n",
    "                            \n",
    "            token_lengths = [len(t) for t in tokens]\n",
    "            tokens.append('\\x01')\n",
    "            \n",
    "            token_lengths.append(len(tokens[-1])-1)\n",
    "            token_lengths = torch.from_numpy(np.array(token_lengths, dtype=np.longlong))+1\n",
    "            token_embs = [self.token_dict[t] if t in self.token_dict else torch.zeros((64, ), dtype=torch.float32) for t in tokens]\n",
    "            token_embs = torch.from_numpy(np.array(token_embs, dtype=np.float32))\n",
    "            doc = ' '.join(tokens)\n",
    "            characters = torch.from_numpy(np.array([self.char_dict[t] for t in doc], dtype=np.longlong))\n",
    "            token_positions = torch.arange(len(token_lengths), dtype=torch.long)\n",
    "            token_indices = torch.repeat_interleave(token_positions, token_lengths)\n",
    "            num_tokens = len(token_lengths)\n",
    "            if num_tokens > self.max_token_count:\n",
    "                self.max_token_count = num_tokens\n",
    "            g_data = Data(x=characters,\n",
    "                            token_positions=token_positions,\n",
    "                            character_length = len(characters),\n",
    "                            num_tokens = num_tokens,\n",
    "                            token_indices=token_indices,\n",
    "                            token_lengths=token_lengths,\n",
    "                            token_embeddings=token_embs)\n",
    "            self.all_data.append(g_data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.all_data[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CharacterandTokenLevelDataLoader(DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        follow_batch: List[str] | None = None,\n",
    "        exclude_keys: List[str] | None = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CharacterandTokenLevelDataLoader, self).__init__(\n",
    "            dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        base_iterator = super(CharacterandTokenLevelDataLoader, self).__iter__()\n",
    "        for batch in base_iterator:\n",
    "            cumsum_vals = torch.cumsum(batch[0].num_tokens, dim=0).roll(1)\n",
    "            cumsum_vals[0] = 0\n",
    "            additions = torch.repeat_interleave(cumsum_vals, batch[0].character_length)\n",
    "            batch[0].cumulative_token_indices = batch[0].token_indices + additions\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CharacterandTokenLevelCustomDataset(train_df.Content.values, train_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, t_tokenizer.tokenize)\n",
    "test_dataset = CharacterandTokenLevelCustomDataset(test_df.Content.values, test_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, t_tokenizer.tokenize)\n",
    "max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[53736], token_positions=[9632], character_length=[224], num_tokens=[224], token_indices=[53736], token_lengths=[9632], token_embeddings=[9632, 64], batch=[53736], ptr=[225], cumulative_token_indices=[53736])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv\n",
    "\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, *args, **kwargs):\n",
    "        super(GCNN, self).__init__(*args, **kwargs)\n",
    "        # self.hidden_dim = hidden_dim\n",
    "        self.gnn = GATv2Conv(hidden_dim, hidden_dim//8, heads=4)\n",
    "        # self.gnn = SimpleConv(aggr='mean')\n",
    "        self.conv = nn.Conv1d(hidden_dim, hidden_dim//2, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        # self.out_fc = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim//2)\n",
    "        # self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        # self.bn4 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, graph, total_token_count, return_attention_weights = False):\n",
    "        x1, edge_weights = self.gnn(x, graph.edge_index, return_attention_weights=return_attention_weights) \n",
    "        x2 = F.relu(self.conv(x[:total_token_count].T).T)#self.bn2(self.conv(x[:total_token_count].T).T))\n",
    "        x3 =  F.leaky_relu_(self.bn3(self.fc(x1[total_token_count:])))\n",
    "        x1 = F.leaky_relu_(self.bn1(x1[:total_token_count]))\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = torch.cat([x, x3], dim=0)\n",
    "        # x = self.bn4(x)\n",
    "        return x, edge_weights #F.leaky_relu_(self.bn4(self.out_fc(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, to_undirected\n",
    "\n",
    "class GenGraph(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, virtual_nodes, lattice_step, *args, **kwargs):\n",
    "        super(GenGraph, self).__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.lattice_step = lattice_step\n",
    "        self.virtual_node_embeddings = nn.Embedding(self.virtual_nodes, hidden_dim)\n",
    "        \n",
    "    def gen_graph(self, x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        edge_index = torch.empty((2, base_numel + v_n_e_counts*2), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "            \n",
    "        if self.virtual_nodes > 0:\n",
    "            virtual_nodes_range = torch.arange(self.virtual_nodes, device=x.device).view(1, -1)\n",
    "            virtual_nodes_ids = torch.repeat_interleave(virtual_nodes_range, len(token_counts), dim=0)\n",
    "            v_n_idx = (virtual_nodes_ids + torch.arange(0, len(token_counts)*self.virtual_nodes, self.virtual_nodes, device=x.device).view(-1, 1) + total_token_coutns )\n",
    "            virtual_edge_ids = torch.repeat_interleave(v_n_idx.view(-1), token_counts.view(-1, 1).expand(len(token_counts), self.virtual_nodes).reshape(-1), dim=0).view(1, -1)\n",
    "            \n",
    "            embs = self.virtual_node_embeddings(virtual_nodes_ids.T).view(-1, self.hidden_dim)\n",
    "            x_extended = torch.cat([x, embs], dim=0)\n",
    "            x_index = torch.arange(total_token_coutns, device=x.device).repeat(self.virtual_nodes).view(1, -1)\n",
    "            edge_index[:, base_numel:base_numel+v_n_e_counts] = torch.cat([x_index, virtual_edge_ids], dim=0)\n",
    "            edge_index[:, base_numel+v_n_e_counts:] = torch.cat([virtual_edge_ids, x_index], dim=0)\n",
    "            x = x_extended\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "        \n",
    "    def re_gen_graph(self, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "        # for i in range(base.shape[1]):\n",
    "        #     edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "            \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "    \n",
    "    def replace_unimportant_edges(self, edge_weights, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2):\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        if v_n_e_counts>0:\n",
    "            important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        else:\n",
    "            important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "\n",
    "        important_indices = torch.arange(total_token_coutns, dtype=torch.int64, device=x.device) + important_indices*total_token_coutns\n",
    "        important_indices = important_indices.view(-1)\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "        new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_index[:, important_indices]\n",
    "        if(self.virtual_nodes>0):\n",
    "            new_edge_index[:, -2*v_n_e_counts:] = edge_index[:, -2*v_n_e_counts:]\n",
    "            \n",
    "        # for i in range(base.shape[1]):\n",
    "        #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "         \n",
    "    def calculate_graph(self, x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance):\n",
    "        tc_extended = torch.repeat_interleave(token_counts, token_counts, dim=0).view(-1,1)\n",
    "        tc_lower_bound = torch.empty((len(token_counts)+1), dtype=torch.long, device=x.device) #torch.cuda.IntTensor(len(token_counts)+1) #\n",
    "        tc_lower_bound[0] = 0\n",
    "        tc_lower_bound[1:] = torch.cumsum(token_counts, dim=0)\n",
    "        tc_lower_bound_extended = torch.repeat_interleave(tc_lower_bound[:-1], token_counts, dim=0).view(-1,1)\n",
    "        tc_range = torch.arange(tc_lower_bound[-1], device=x.device).view(-1,1)\n",
    "        # torch.arange(tc_lower_bound[-1], dtype=torch.int32, device=x.device).view(-1,1)\n",
    "        random_ints = torch.randint(0, 2*total_token_coutns, (total_token_coutns, random_edges), device=x.device) # torch.cuda.IntTensor(len(token_lengths), random_edges).random_()\n",
    "        lattice = torch.arange(lattice_start_distance, self.lattice_step*lattice_edges+1, self.lattice_step, device=x.device).view(1, -1)\n",
    "\n",
    "        # exponentials = torch.pow(2, torch.arange(1, self.exp_edges+1, device=x.device)).view(1, -1)\n",
    "        tc_local_range = tc_range - tc_lower_bound_extended\n",
    "        random_links = (((random_ints % (tc_extended - 1))+1 + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        lattice_links = ((lattice + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        # base = torch.cat([base1, base2], dim=1)\n",
    "        tc_range = tc_range.view(1,-1)\n",
    "        return random_links, lattice_links, tc_range\n",
    "    \n",
    "    def fill_lattice_and_random_edges(self, edge_index, random_links, lattice_links, tc_range):\n",
    "        for i in range(0, lattice_links.shape[1]*2, 2):\n",
    "            edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]] = torch.cat([lattice_links[:,i//2].view(1,-1), tc_range], dim=0)\n",
    "            edge_index[:, (i+1)*lattice_links.shape[0]:(i+2)*lattice_links.shape[0]] = edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]][[1, 0]]\n",
    "            \n",
    "        for i in range(random_links.shape[1]):\n",
    "            j = i + lattice_links.shape[1]*2\n",
    "            edge_index[:, j*random_links.shape[0]:(j+1)*random_links.shape[0]] = torch.cat([random_links[:,i].view(1,-1), tc_range], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv, summary\n",
    "\n",
    "class CNN_for_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embedding, pos_emb_size=8192, embedding_dim=64, hidden_dim=64, dropout=0.3, num_out_features=4, seed=-1, random_edges=4, lattice_edges=10, virtual_nodes=1, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64,  *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text, self).__init__(*args, **kwargs)\n",
    "        self.pos_emb_size = pos_emb_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    " \n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.positional_encoding = nn.Embedding(pos_emb_size, embedding_dim)\n",
    "        self.positional_encoding.weight = self.create_positional_encoding()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(2*hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.gcnn2 = GCNN(hidden_dim + inject_embedding_dim)\n",
    "        self.graph_generator = GenGraph(hidden_dim, virtual_nodes, lattice_step)\n",
    "        \n",
    "        k = 8\n",
    "        self.fc0 =  nn.Linear(hidden_dim , hidden_dim + inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim + inject_embedding_dim , hidden_dim * k)\n",
    "        self.fc2 = nn.Linear(hidden_dim * (2+virtual_nodes) * k , 32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, num_out_features)\n",
    "    \n",
    "    \n",
    "    def forward(self, g_data):\n",
    "\n",
    "        x = self.embedding(g_data.x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.T\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x1 = scatter_max(x, g_data.cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, g_data.cumulative_token_indices, dim=1)\n",
    "\n",
    "        x = torch.cat([x1, x2], dim=0)\n",
    "\n",
    "        x = F.relu(self.conv3(x)).T\n",
    "        \n",
    "        x = x + self.positional_encoding(g_data.token_positions)\n",
    "\n",
    "        rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "        graph = self.graph_generator.gen_graph(x, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "        rand_edges = rand_edges-1\n",
    "        lattice_edges = lattice_edges-1\n",
    "        \n",
    "        x, edge_weights = self.gcnn1(graph.x, graph, len(g_data.token_lengths), return_attention_weights = True)\n",
    "        edge_weights = edge_weights[1][:graph.edge_index.shape[1], 0]\n",
    "        \n",
    "        graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, graph.edge_index, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        \n",
    "        x = torch.cat([graph.x[:g_data.token_embeddings.shape[0]], g_data.token_embeddings], dim=1)\n",
    "        x1 = F.relu(self.fc0(graph.x[g_data.token_embeddings.shape[0]:]))\n",
    "        x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "        x, edge_weights = self.gcnn2(x, graph, len(g_data.token_lengths))\n",
    "\n",
    "        x = F.elu_(self.fc1(x))\n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(g_data.num_tokens), device=x.device), g_data.num_tokens)\n",
    "        x1 = scatter_max(x[:len(g_data.token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(g_data.token_lengths)], doc_token_index, dim=0)\n",
    "        vn_embs = x[len(g_data.token_lengths):]\n",
    "        x_for_cat = [x1, x2]\n",
    "        x_for_cat.extend([vn_embs[i*x1.shape[0]:(i+1)*x1.shape[0]] for i in range(self.virtual_nodes)])\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        \n",
    "        x = F.elu_(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def create_positional_encoding(self):\n",
    "        position = torch.arange(self.pos_emb_size).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.hidden_dim, 2) * (-math.log(10000.0) / self.hidden_dim))\n",
    "        pe = torch.zeros(self.pos_emb_size, self.hidden_dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return torch.nn.Parameter(pe, requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.flop_counter import FlopCounterMode\n",
    "\n",
    "# classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=64, embedding_dim=64, pos_emb_size=8192, dropout=0.4, num_out_features=len(class_id), seed=911, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "# flopt_counter = FlopCounterMode()\n",
    "# with flopt_counter:\n",
    "#     classifier_torch_model(X.x, torch.zeros((2, 0)), X.token_subsampling_probabilities, X.token_indices, X.token_sentiments, X.token_lengths, X.num_tokens, X.character_length, X.token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.flop_counter import FlopCounterMode\n",
    "\n",
    "# classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=128, embedding_dim=128, pos_emb_size=8192, dropout=0.4, num_out_features=len(class_id), seed=911, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "# flopt_counter = FlopCounterMode()\n",
    "# with flopt_counter:\n",
    "#     classifier_torch_model(X.x, torch.zeros((2, 0)), X.token_subsampling_probabilities, X.token_indices, X.token_sentiments, X.token_lengths, X.num_tokens, X.character_length, X.token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CnnGnnClassifierLightningModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        num_classes,\n",
    "        optimizer=None,\n",
    "        loss_func=None,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=64,\n",
    "        lr_scheduler=None,\n",
    "        user_lr_scheduler=False,\n",
    "        min_lr=0.0,\n",
    "    ):\n",
    "        super(CnnGnnClassifierLightningModel, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.min_lr = min_lr\n",
    "        # self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        self.optimizer = self._get_optimizer(optimizer)\n",
    "        self.lr_scheduler = (\n",
    "            self._get_lr_scheduler(lr_scheduler) if user_lr_scheduler else None\n",
    "        )\n",
    "        self.loss_func = loss_func\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)\n",
    "\n",
    "    def on_train_epoch_start(self) -> None:\n",
    "        param_groups = next(iter(self.optimizer.param_groups))\n",
    "        if \"lr\" in param_groups and param_groups[\"lr\"] is not None:\n",
    "            current_learning_rate = float(param_groups[\"lr\"])\n",
    "            self.log(\n",
    "                \"lr\",\n",
    "                current_learning_rate,\n",
    "                batch_size=self.batch_size,\n",
    "                on_epoch=True,\n",
    "                on_step=False,\n",
    "            )\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.train()\n",
    "        y_out = self(X)\n",
    "\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.train_losses.append(loss.detach().item())\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        self.train_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        y_out = self(X)\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.val_losses.append(loss.detach().item())\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.val_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.lr_scheduler is None:\n",
    "            return self.optimizer\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": self.lr_scheduler,\n",
    "                \"monitor\": \"train_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def update_learning_rate(self, learning_rate: float):\n",
    "        self.learning_rate = learning_rate\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g[\"lr\"] = learning_rate\n",
    "\n",
    "    def _get_optimizer(self, optimizer):\n",
    "        return (\n",
    "            optimizer\n",
    "            if optimizer is not None\n",
    "            else torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        )\n",
    "\n",
    "    def _get_lr_scheduler(self, lr_scheduler):\n",
    "        return (\n",
    "            lr_scheduler\n",
    "            if lr_scheduler is not None\n",
    "            else torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer, patience=5, factor=0.5, mode=\"min\", min_lr=self.min_lr\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 128\n",
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "label_size = 1\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import Logger, CSVLogger\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from typing import List\n",
    "from pytorch_lightning.core.saving import save_hparams_to_yaml\n",
    "\n",
    "class ModelManager(ABC):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 max_epochs = 100,\n",
    "                 ckpt_path: str|None=None,\n",
    "                 accumulate_grad_batches=1):\n",
    "        self.torch_model = torch_model\n",
    "        self.lightning_model = lightning_model\n",
    "        self.log_dir = log_dir\n",
    "        self.log_name = log_name\n",
    "        self.model_save_dir = model_save_dir\n",
    "        self.device = device\n",
    "        self.accelerator = 'cpu' if self.device=='cpu' else 'gpu'\n",
    "        self.max_epochs = max_epochs\n",
    "        self.ckpt_path = ckpt_path\n",
    "\n",
    "        self.logger = self._create_logger()\n",
    "        self.callbacks = self._create_callbacks()\n",
    "        self.trainer: L.Trainer = self._create_trainer(accumulate_grad_batches)\n",
    "        self.tuner = Tuner(self.trainer)\n",
    "        self.tuning_result = None\n",
    "\n",
    "    def tune(self, data_manager=None, train_dataloaders=None, val_dataloaders=None, datamodule=None, draw_result=True, min_lr=0.0000001, max_lr=0.1):\n",
    "        self.tuning_result = self.tuner.lr_find(self.lightning_model, datamodule=data_manager, train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders, min_lr=min_lr,max_lr=max_lr, num_training=150)\n",
    "        if draw_result:\n",
    "            fig = self.tuning_result.plot(suggest=True)\n",
    "            fig.show()\n",
    "        self.update_learning_rate(self.tuning_result.suggestion())\n",
    "        return self.tuning_result.suggestion()\n",
    "    \n",
    "    def update_learning_rate(self, lr):\n",
    "        self.lightning_model.update_learning_rate(lr)\n",
    "\n",
    "    def fit(self, train_dataloaders=None, val_dataloaders=None, datamodule=None, max_epochs = -1, ckpt_path=None):\n",
    "        if ckpt_path is not None and ckpt_path != '':\n",
    "            self.ckpt_path = ckpt_path\n",
    "        if max_epochs>0:\n",
    "            self.trainer.fit_loop.max_epochs = max_epochs\n",
    "            # self.max_epochs = max_epochs\n",
    "            # self.trainer = self._create_trainer()\n",
    "        self.trainer.fit(self.lightning_model,\n",
    "                         datamodule=datamodule,\n",
    "                         train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders,\n",
    "                         ckpt_path = self.ckpt_path\n",
    "                         )\n",
    "\n",
    "    def validate(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.validate(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def predict(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.predict(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def _create_trainer(self, accumulate_grad_batches) -> L.Trainer:\n",
    "        return L.Trainer(\n",
    "            callbacks=self.callbacks,\n",
    "            max_epochs=self.max_epochs,\n",
    "            accelerator=self.accelerator,\n",
    "            logger=self.logger,\n",
    "            num_sanity_val_steps=0,\n",
    "            default_root_dir=self.model_save_dir,\n",
    "            accumulate_grad_batches=accumulate_grad_batches\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        pass\n",
    "\n",
    "    def _create_logger(self) -> Logger:\n",
    "        return CSVLogger(save_dir=self.log_dir, name=self.log_name)\n",
    "\n",
    "    @abstractmethod\n",
    "    def draw_summary(self, dataloader):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def plot_csv_logger(self, loss_names, eval_names):\n",
    "        pass\n",
    "    \n",
    "    def save_hyper_parameters(self):\n",
    "        mhparams = {\n",
    "            'start_lr': 0.045,\n",
    "            'ckpt_lrs' :  {51: 0.002, 65: 0.00058},\n",
    "            'last_lr' : 0.0003,\n",
    "            'ac_loss_factor': 0.0002,\n",
    "            'weight_decay': 0.0012\n",
    "        }\n",
    "        save_hparams_to_yaml(config_yaml=r'logs\\hetero_model_17_AG\\version_12\\hparams.yaml',\n",
    "                     hparams=mhparams)\n",
    "        \n",
    "    # def find_best_settings(data_manager,\n",
    "    #                        lrs: List[float]=[0.001], dropouts: List[float]=[0.2], \n",
    "    #                        weight_decays: List[float]=[0.00055], emb_factors: List[float]=[0.1], \n",
    "    #                        batch_sizes: List[int]=[128], log_name='find_best_settings'):\n",
    "    #     for lr in lrs:\n",
    "    #         for dropout in dropouts:\n",
    "    #             for wd in weight_decays:\n",
    "    #                 for emb_factor in emb_factors:\n",
    "    #                     for bs in batch_sizes:\n",
    "    #                         data_manager.update_batch_size(bs)\n",
    "    #                         torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 128, dropout=dropout)\n",
    "    #                         lightning_model = HeteroBinaryLightningModel(torch_model,\n",
    "    #                                         torch.optim.Adam(torch_model.parameters(), lr=lr, weight_decay=wd),\n",
    "    #                                             loss_func=HeteroLoss1(exception_keys='word', enc_factor=emb_factor),\n",
    "    #                                             learning_rate=lr,\n",
    "    #                                             batch_size=bs,\n",
    "    #                                             user_lr_scheduler=True\n",
    "    #                                             ).to(device)\n",
    "    #                         model_manager = ClassifierModelManager(torch_model, lightning_model, log_name=log_name, device=device, num_train_epoch=10)\n",
    "    #                         model_manager.fit(datamodule=data_manager)\n",
    "    #                         model_manager.save_plot_csv_logger(name_prepend=f'{lr}_{dropout}_{wd}_{emb_factor}_{bs}', loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "# from scripts.managers.ModelManager import ModelManager\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from torch_geometric.nn import summary\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from os import path\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "class ClassifierModelManager(ModelManager):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 num_train_epoch = 100,\n",
    "                 accumulate_grad_batches=1):\n",
    "        super(ClassifierModelManager, self).__init__(torch_model, lightning_model, model_save_dir, log_dir, log_name, device, num_train_epoch, accumulate_grad_batches=accumulate_grad_batches)\n",
    "\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        return [\n",
    "            ModelCheckpoint(save_top_k=2, mode='max', monitor='val_acc', save_last=True),\n",
    "            # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "        ]\n",
    "\n",
    "    def draw_summary(self, dataloader):\n",
    "        X, y = next(iter(dataloader))\n",
    "        print(summary(self.torch_model, X.to(self.device)))\n",
    "\n",
    "    def plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    def save_plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc'], name_prepend: str=\"\"):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        \n",
    "        loss_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_loss_metric.png')\n",
    "        plt.savefig(loss_png)\n",
    "        \n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        \n",
    "        acc_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_acc_metric.png')\n",
    "        plt.savefig(acc_png)\n",
    "        \n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate(self, eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.lightning_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        if(give_hinge_loss):\n",
    "            print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')\n",
    "                \n",
    "    def evaluate_best_models(self, lightning_type: L.LightningModule, eval_dataloader,\n",
    "                             give_confusion_matrix: bool=True, \n",
    "                             give_report: bool=True, \n",
    "                             give_f1_score: bool=False, \n",
    "                             give_accuracy_score: bool=False, \n",
    "                             give_precision_score: bool=False, \n",
    "                             give_recall_score: bool=False, \n",
    "                             give_hinge_loss: bool=False,\n",
    "                             multi_class: bool=False, **kwargs):\n",
    "        self.lightning_model = lightning_type.load_from_checkpoint(rf'{self.trainer.checkpoint_callback.best_model_path}', map_location=None, hparams_file=None, strict=True, **kwargs).eval()\n",
    "        self.save_evaluation(eval_dataloader, 'best_model', give_confusion_matrix, give_report,\n",
    "                             give_f1_score, give_accuracy_score, give_precision_score, give_recall_score, give_hinge_loss, multi_class)\n",
    "            \n",
    "    def save_evaluation(self, eval_dataloader, name_prepend: str='',\n",
    "                    give_confusion_matrix: bool=True, \n",
    "                    give_report: bool=True, \n",
    "                    give_f1_score: bool=False, \n",
    "                    give_accuracy_score: bool=False, \n",
    "                    give_precision_score: bool=False, \n",
    "                    give_recall_score: bool=False, \n",
    "                    give_hinge_loss: bool=False,\n",
    "                    multi_class: bool=False\n",
    "                    ):\n",
    "            \n",
    "            test_metrics_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_test_metrics.txt')\n",
    "            \n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            self.lightning_model.eval()\n",
    "            self.lightning_model.model.eval()\n",
    "            self.torch_model.eval()\n",
    "            self.trainer.model.eval()\n",
    "            for X, y in eval_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    y_p = self.lightning_model(X.to(self.device))\n",
    "                if type(y_p) is tuple:\n",
    "                    y_p = y_p[0]\n",
    "                \n",
    "                if multi_class:\n",
    "                    y_pred.append(y_p.detach().to(y.device))\n",
    "                    y_true.append(y)\n",
    "                else:\n",
    "                    y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "                    y_true.append(y.to(torch.int32))\n",
    "                    \n",
    "            y_true = torch.concat(y_true)\n",
    "            y_pred = torch.concat(y_pred)\n",
    "            print(y_true.shape)\n",
    "            print(y_pred.shape)\n",
    "            if multi_class:\n",
    "                y_true_num = torch.argmax(y_true, dim=1)\n",
    "                y_pred_num = torch.argmax(y_pred, dim=1)\n",
    "            else:\n",
    "                y_true_num = y_true\n",
    "                y_pred_num = y_pred\n",
    "                \n",
    "            print(y_true_num.shape)\n",
    "            print(y_pred_num.shape)\n",
    "            with open(test_metrics_path, 'at+') as f:\n",
    "                if(give_confusion_matrix):\n",
    "                    print(f'confusion_matrix: \\n{confusion_matrix(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_report):\n",
    "                    print(classification_report(y_true_num, y_pred_num), file=f)\n",
    "                if(give_f1_score):\n",
    "                    if multi_class:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_accuracy_score):\n",
    "                    print(f'accuracy_score: {accuracy_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_precision_score):\n",
    "                    if multi_class:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_recall_score):\n",
    "                    if multi_class:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_hinge_loss):\n",
    "                    print(f'hinge_loss: {hinge_loss(y_true_num, y_pred)}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "def train_model(epochs=30, dropout=0.2, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True):\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 38, 40,45,50],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name='CNN-GNN13_large_models',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.torch_model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(CnnGnnClassifierLightningModel, test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Articles\\CGNet\\venv\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "f:\\Articles\\CGNet\\venv\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | CNN_for_Text       | 778 K  | train\n",
      "1 | loss_func | BCEWithLogitsLoss  | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "254 K     Trainable params\n",
      "524 K     Non-trainable params\n",
      "778 K     Total params\n",
      "3.114     Total estimated model params size (MB)\n",
      "37        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "f:\\Articles\\CGNet\\venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "f:\\Articles\\CGNet\\venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "f:\\Articles\\CGNet\\venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716fc0ba8e184a40835c03c4f8959e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754cda503f9443ad886b9dfcfd41242c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24f28e06a534812988abd070a3993d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5781cb516a9d43a2859ffc3a687980ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cd998e58ba4d12b4e3a4b06248e6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907001ae75204e198d633d914e4aae0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89feec01d724d5095652f93ebecb6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080d85bdb1714b7490cc9d4ca63cc09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acee64f590724c5c8d6e7f57c2c6a524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67cf064b2394e599b206c0c0c29d863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90020fe02215454aa24e1bf6ea8476ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6324e05c5a4d40a809caae11fdb03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc19b15817d40a29bd23ee3fb32492f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1db0fe208c40689475d579965f3593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2bc2ac32164de8a8016d7b2763e333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb7986e99d04f8a9424dea786b8a19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f1c836d03344f58655829ecc98c90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccc46b53e9b4f7c96e9a9086d24ad4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babfccb05b2845e2aa3b4afbe6fefb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c28d6560b34c7a8b897c69188c58cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686b2d5ccb1049c0ab6c15b1770be4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe1091c8d114414b41d2c29f67179e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7be5559c8ea4f329cae1df27ad56757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd8247115e94a7196a126532ca22b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7abd5b8c59147b9a4db8cb1b771d1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcc3c5ced9349d683ee10c5e5a660da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732ff4de312a42ae8a49b2c3634f2215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c2660f043943e8a0aa655db5fd7f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef671c9ccc146289abd917cea2a4273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68962074702c4ad6959b20d54c2d929b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8069a53453a4459fbccb5a72f92dab41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c48c599374438d9ce6c85773de83db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2970eb40b344fc87faec25cbf13f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0737596bdeac4cb5b71c19d5f6cc734c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b985f565ab94154928f5882a5189c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c229877f0c1e4efa9f1ddd5cc262ee8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51a1867fc604149a6703fdcf05f8e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5b935a1dda49ad8da060a93160497c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963321859f4549308616e3d99af59370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b429d0c26c945f2aa66c4c60f65e6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b397eba6d27443094b79c87c3a73ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f31144c1954b55bb5ab651bfc64ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e957a2f3e94a32b2b077e0ad638d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6487ba8297c24b4f9f5df38faf97c0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc8ba6a2a764affb73de360a746ee14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e61e83c54ca4e65a0dc1abb856deb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac799184ccc4b4d86d300bb3922afec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1742206c88724e23a5a1bd5136483ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e53031e96da4b818ddb27b59bdeaa47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6442ad448464b53a55cc2bf78f7a84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a557b81edeec4bc0b00b487af84c67de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d200e54fc04e13a5942f84d5822acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a038c0338c642b48f768ce924e16ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40577833091f4956a98ce52d753a31a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437ebce250bf460891609a5073e087a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48f3cb3cc75453183e2373102720af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469d8cf4f8464c569e7064a39be21b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6207b842a594b73ad1ac09bbc7f4880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c933589dbb8b484486dcbbde4c7bc487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb047c9822846d393ca29b917ad924f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d8ca85a4ca47eeacfe06dd27918e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7528b10d8fb49dab6a1a65e84512df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9b744ffc9b4034bd58c84072dc993e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1367874ec4a404ca9a45884f7a57f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738032e84d4e4b54ae9fd96cdcb15fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd64c15c847b4a5cb97f49dcb2e36721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193751d7892c4095a10db6f37f446209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e11f882aec7499c8c0fc6015c9f5099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa2e2a0e0ed44c7bdaca4dbb48b75c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6130346e69d454fa988633b2fc8c9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f315809bcc491f814dd6d451e2b839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=70` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7392, 4])\n",
      "torch.Size([7392, 4])\n",
      "torch.Size([7392])\n",
      "torch.Size([7392])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 33/33 [00:02<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9382    0.9305    0.9344      1843\n",
      "           1     0.9732    0.9758    0.9745      1859\n",
      "           2     0.8991    0.8870    0.8930      1849\n",
      "           3     0.8918    0.9087    0.9002      1841\n",
      "\n",
      "    accuracy                         0.9256      7392\n",
      "   macro avg     0.9256    0.9255    0.9255      7392\n",
      "weighted avg     0.9257    0.9256    0.9256      7392\n",
      "\n",
      "confusion matrix:\n",
      " tensor([[1715,   19,   61,   48],\n",
      "        [  21, 1814,   15,    9],\n",
      "        [  47,   16, 1640,  146],\n",
      "        [  45,   15,  108, 1673]])\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Articles\\CGNet\\venv\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "f:\\Articles\\CGNet\\venv\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7392, 4])\n",
      "torch.Size([7392, 4])\n",
      "torch.Size([7392])\n",
      "torch.Size([7392])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_manager = train_model(70, 0.2, 0.000012, 0.0032, amsgrad=False, fused=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification report:  <br/>\n",
    "               precision    recall  f1-score   support <br/>\n",
    "\n",
    "           0     0.9317    0.9358    0.9337      1792\n",
    "           1     0.9729    0.9767    0.9748      1802\n",
    "           2     0.9024    0.8781    0.8901      1789\n",
    "           3     0.8938    0.9104    0.9020      1785\n",
    "\n",
    "     accuracy     -         -         0.9254      7168 \n",
    "    macro_avg     0.9252    0.9253    0.9252      7168 <br/>\n",
    "    weighted_avg  0.9253    0.9254    0.9253      7168 <br/>\n",
    "\n",
    "confusion matrix: <br/>\n",
    " tensor([[1677,   17,   59,   39], <br/>\n",
    "        [  19, 1760,   13,   10], <br/>\n",
    "        [  54,   20, 1571,  144], <br/>\n",
    "        [  50,   12,   98, 1625]]) <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/CNN-GNN13_large_models\\\\version_4\\\\checkpoints\\\\epoch=69-step=8190.ckpt'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_manager.trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoints = {\n",
    "    # '1': r'logs\\CNN-GNN13_large_models\\version_1\\checkpoints\\epoch=58-step=6903.ckpt',\n",
    "    # '2': r'logs\\CNN-GNN13_large_models\\version_2\\checkpoints\\epoch=65-step=7722.ckpt',\n",
    "    # '3': r'logs\\CNN-GNN13_large_models\\version_3\\checkpoints\\epoch=66-step=7839.ckpt',\n",
    "    '4': r'logs\\CNN-GNN13_large_models\\version_4\\checkpoints\\epoch=69-step=8190.ckpt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "def train_model(epochs=30, dropout=0.2, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True):\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 38, 40,45,50],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name='CNN-GNN13_large_models',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.torch_model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(CnnGnnClassifierLightningModel, test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=len(class_id))\n",
    "f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=len(class_id))\n",
    "precision = torchmetrics.Precision(task=\"multiclass\", num_classes=len(class_id))\n",
    "recall = torchmetrics.Recall(task=\"multiclass\", num_classes=len(class_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs\\CNN-GNN13_large_models\\version_4\\checkpoints\\epoch=69-step=8190.ckpt\n",
      "accuracy 4: 0.9252511160714285\n",
      "f1 4: 0.92525756036205\n",
      "prec 4: 0.9252797829293058\n",
      "rec 4: 0.9252353396775783\n",
      "total_accuracy: 0.9252511160714285\n",
      "total_f1: 0.92525756036205\n",
      "total_prec: 0.9252797829293058\n",
      "total_rec: 0.9252353396775783\n"
     ]
    }
   ],
   "source": [
    "total_accuracy = []\n",
    "total_f1 = []\n",
    "total_prec = []\n",
    "total_rec = []\n",
    "\n",
    "for k in best_checkpoints:\n",
    "    print(best_checkpoints[k])\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(best_checkpoints[k], model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "    mean_infer_acc = []\n",
    "    mean_infer_f1 = []\n",
    "    mean_infer_prec = []\n",
    "    mean_infer_rec = []\n",
    "    for i in range(5):\n",
    "        all_ys = []\n",
    "        all_y_preds = []\n",
    "        for X, y in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                y_pred = classfier_lightning_model(X.to(device))\n",
    "            all_ys.append(torch.argmax(y,dim=1))\n",
    "            all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "        all_ys = torch.concat(all_ys)\n",
    "        all_y_preds = torch.concat(all_y_preds)\n",
    "        \n",
    "        cm = confusion_matrix(all_ys, all_y_preds)\n",
    "        \n",
    "        accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "        precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
    "        recall = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "        f1_score = (2*precision*recall)/(precision + recall)\n",
    "        \n",
    "        mean_infer_acc.append(accuracy)\n",
    "        mean_infer_f1.append(f1_score)\n",
    "        mean_infer_prec.append(precision)\n",
    "        mean_infer_rec.append(recall)\n",
    "    mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "    mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "    mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "    mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "    \n",
    "    print(f'accuracy {k}: {mean_infer_acc}')\n",
    "    print(f'f1 {k}: {mean_infer_f1}')\n",
    "    print(f'prec {k}: {mean_infer_prec}')\n",
    "    print(f'rec {k}: {mean_infer_rec}')\n",
    "    total_accuracy.append(mean_infer_acc)\n",
    "    total_f1.append(mean_infer_f1)\n",
    "    total_prec.append(mean_infer_prec)\n",
    "    total_rec.append(mean_infer_rec)\n",
    "\n",
    "total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "total_prec = torch.mean(torch.tensor(total_prec))\n",
    "total_rec = torch.mean(torch.tensor(total_rec))\n",
    "print(f'total_accuracy: {total_accuracy}')\n",
    "print(f'total_f1: {total_f1}')\n",
    "print(f'total_prec: {total_prec}')\n",
    "print(f'total_rec: {total_rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1682   23   68   37]\n",
      " [  14 1744   14   12]\n",
      " [  29   15 1630  118]\n",
      " [  47   14  124 1597]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(all_ys, all_y_preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1810, 1784, 1792, 1782], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(cm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9281606301071419"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.diag(cm))/ np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9281529017857143"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.diag(cm))/ np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9282)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(all_ys, all_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9282)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(all_ys, all_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNGNNClassifier_FromPretrained:\n",
    "    \n",
    "    def __init__(self, num_embedding, hidden_dim, embedding_dim, num_classes, pos_emb_size=8192,  dropout=0.2, device='cpu'):\n",
    "        self.device = device;\n",
    "        self.num_classes = num_classes\n",
    "        self.classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=pos_emb_size, dropout=dropout, num_out_features=num_classes, seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "        self.classfier_lightning_model = None\n",
    "        \n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.precision = torchmetrics.Precision(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.recall = torchmetrics.Recall(task=\"multiclass\", num_classes=num_classes)\n",
    "        \n",
    "    \n",
    "    def load_inference_model(self, checkpoint_path):\n",
    "        # checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "        self.classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(checkpoint_path, model=self.classifier_torch_model, num_classes=self.num_classes).to(self.device).eval()\n",
    "        \n",
    "    # def load_train_model(self, checkpoint_path):\n",
    "    #     optimizer = torch.optim.AdamW(self.classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    #     # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    #     lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 38, 40,45,50],gamma=0.5, verbose=False)\n",
    "    #     loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    #     classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "    #                                                         num_classes=len(class_id),\n",
    "    #                                                 learning_rate=lr,\n",
    "    #                                                 batch_size=batch_size,\n",
    "    #                                                 optimizer=optimizer,\n",
    "    #                                                 loss_func=loss_func,\n",
    "    #                                                 lr_scheduler=lr_scheduler,\n",
    "    #                                                 user_lr_scheduler=True\n",
    "    #                                                 ).to(device)\n",
    "    \n",
    "    def evaluate(self, eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        \n",
    "        \n",
    "        all_ys = []\n",
    "        all_y_preds = []\n",
    "        for X, y in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                y_pred = classfier_lightning_model(X.to(device))\n",
    "            all_ys.append(torch.argmax(y,dim=1))\n",
    "            all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "        all_ys = torch.concat(all_ys)\n",
    "        all_y_preds = torch.concat(all_y_preds)\n",
    "        accuracy = accuracy(all_ys, all_y_preds).item()\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.lightning_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        if(give_hinge_loss):\n",
    "            print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in best_checkpoints:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
