{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification Using Proposed CNN-GNN on IMDB binary dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Results:\n",
    "| metric | test 1 | test 2 | test 3 | test 4 | test 5 | Average |\n",
    "|:---|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| f1-score | 9039 | 9041 | 9015 | 9051 | 9050 | 9039 |\n",
    "| accuracy | 9038 | 9040 | 9015 | 9051 | 9042 | 9037 |\n",
    "| precision | 9040 | 9041 | 9015 | 9051 | 9058 | 9041 |\n",
    "| recall | 9038 | 9040 | 9015 | 9051 | 9042 | 9037 |\n",
    "| loss | 0.2738 | 0.2721 | 0.2597 | 0.2865 | 0.2947 | 0.2774 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch_scatter import scatter_max, scatter_mean, scatter_sum, scatter_std\n",
    "import torchmetrics\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from copy import copy\n",
    "import spacy\n",
    "from umap import UMAP\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import PyPDF2\n",
    "from bs4 import BeautifulSoup\n",
    "# import textract\n",
    "import json\n",
    "import gzip\n",
    "import re\n",
    "import collections\n",
    "import csv\n",
    "import string\n",
    "import textwrap\n",
    "import random\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\reduced_embeddings\\\\spacy_lg_reduced_embeddings.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\CGNet\\FindBestModel\\FindBestStepImplementation\\text_classification_test_1_imdb_optimizer_step_implementatio.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/FindBestStepImplementation/text_classification_test_1_imdb_optimizer_step_implementatio.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mreduced_embeddings\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mspacy_lg_reduced_embeddings.npy\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/FindBestStepImplementation/text_classification_test_1_imdb_optimizer_step_implementatio.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     embeddings \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/FindBestStepImplementation/text_classification_test_1_imdb_optimizer_step_implementatio.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39men_core_web_lg\u001b[39m\u001b[39m'\u001b[39m, disable\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtok2vec\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtagger\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mparser\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mattribute_ruler\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlemmatizer\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mner\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\reduced_embeddings\\\\spacy_lg_reduced_embeddings.npy'"
     ]
    }
   ],
   "source": [
    "with open(r'data\\reduced_embeddings\\spacy_lg_reduced_embeddings.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "nlp = spacy.load('en_core_web_lg', disable=['tok2vec','tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
    "t_tokenizer = TweetTokenizer()\n",
    "nlp.max_length = len(' '.join(list(nlp.vocab.strings)))+1\n",
    "all_vocab_doc = nlp(' '.join(list(nlp.vocab.strings)))\n",
    "all_vocab_str = [f'{t}' for t in all_vocab_doc]\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "embeddings = (embeddings - torch.min(embeddings)) / (torch.max(embeddings)-torch.min(embeddings))\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))\n",
    "token_vocab_dict['<n>'] = token_vocab_dict['newline']\n",
    "len(token_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 128\n",
    "folder_path = r'data\\TextClassification\\IMDB'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'data\\TextClassification\\IMDB\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I have seen this movie twice and it's theme is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I happened to catch this on community TV a few...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  I have seen this movie twice and it's theme is...\n",
       "1      1  I happened to catch this on community TV a few..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_ratio = 1.0\n",
    "test_df = pd.read_csv(r'data\\TextClassification\\IMDB\\test.csv')\n",
    "test_df['Topic'] = test_df['label']\n",
    "test_df['Content'] = test_df['text']\n",
    "test_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df = test_df.iloc[:int(keep_ratio*test_df.shape[0])]\n",
    "train_df = pd.read_csv(r'data\\TextClassification\\IMDB\\train.csv')\n",
    "train_df['Topic'] = train_df['label']\n",
    "train_df['Content'] = train_df['text']\n",
    "train_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df = train_df.iloc[:int(keep_ratio*train_df.shape[0])]\n",
    "sst_classes = [\"Negative\", \"Positive\"]\n",
    "df = pd.concat([train_df, test_df])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2901"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = np.array([len(t_tokenizer.tokenize(doc)) for doc in df['Content'].values])\n",
    "np.max(lengths)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = df.Topic.unique()\n",
    "class_id = {sst_classes[i]:i for i in class_list}\n",
    "id_class = {i:sst_classes[i] for i in class_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = set()\n",
    "for doc in df.Content.values:\n",
    "    char_set.update(set(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' '\n",
    "all_chars = set(allowed_chars).update(char_set)\n",
    "vocab_dict = {c:i for i, c in enumerate(allowed_chars)}\n",
    "if '\\x01' not in vocab_dict:\n",
    "    vocab_dict['\\x01'] = len(vocab_dict)\n",
    "char_Set = set(vocab_dict.keys())\n",
    "num_embedding = len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterandTokenLevelCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, num_classes, char_dict, token_dict, tokenizer) -> None:\n",
    "        super().__init__()\n",
    "        # y = y[indices].values\n",
    "        # y = torch.from_numpy(np.array([class_id[c] for c in y], dtype=np.longlong))\n",
    "        y = torch.from_numpy(y)\n",
    "        self.y = torch.nn.functional.one_hot(y, num_classes=num_classes).float()\n",
    "        \n",
    "        self.char_dict = char_dict\n",
    "        self.char_Set = set(char_dict.keys())\n",
    "        self.vocab_size = len(self.char_dict)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_dict = token_dict\n",
    "        self.max_token_count = 0\n",
    "        \n",
    "        self.all_data = []\n",
    "        \n",
    "        self.token_lengths = []\n",
    "        \n",
    "        self.token_embeddign_ids = []\n",
    "        for doc in tqdm(X):\n",
    "            tokens = self.tokenizer(''.join(c for c in doc if c in self.char_Set))\n",
    "            tokens = [t.text for t in tokens]\n",
    "            if len(tokens) == 0:\n",
    "                tokens = ['empty']\n",
    "                            \n",
    "            token_lengths = [len(t) for t in tokens]\n",
    "            tokens.append('\\x01')\n",
    "            \n",
    "            token_lengths.append(len(tokens[-1])-1)\n",
    "            token_lengths = torch.from_numpy(np.array(token_lengths, dtype=np.longlong))+1\n",
    "            token_embs = [self.token_dict[t] if t in self.token_dict else torch.zeros((64, ), dtype=torch.float32) for t in tokens]\n",
    "            token_embs = torch.from_numpy(np.array(token_embs, dtype=np.float32))\n",
    "            doc = ' '.join(tokens)\n",
    "            characters = torch.from_numpy(np.array([self.char_dict[t] for t in doc], dtype=np.longlong))\n",
    "            token_positions = torch.arange(len(token_lengths), dtype=torch.long)\n",
    "            token_indices = torch.repeat_interleave(token_positions, token_lengths)\n",
    "            num_tokens = len(token_lengths)\n",
    "            if num_tokens > self.max_token_count:\n",
    "                self.max_token_count = num_tokens\n",
    "            g_data = Data(x=characters,\n",
    "                            token_positions=token_positions,\n",
    "                            character_length = len(characters),\n",
    "                            num_tokens = num_tokens,\n",
    "                            token_indices=token_indices,\n",
    "                            token_lengths=token_lengths,\n",
    "                            token_embeddings=token_embs)\n",
    "            self.all_data.append(g_data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.all_data[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CharacterandTokenLevelDataLoader(DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        follow_batch: List[str] | None = None,\n",
    "        exclude_keys: List[str] | None = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CharacterandTokenLevelDataLoader, self).__init__(\n",
    "            dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        base_iterator = super(CharacterandTokenLevelDataLoader, self).__iter__()\n",
    "        for batch in base_iterator:\n",
    "            cumsum_vals = torch.cumsum(batch[0].num_tokens, dim=0).roll(1)\n",
    "            cumsum_vals[0] = 0\n",
    "            additions = torch.repeat_interleave(cumsum_vals, batch[0].character_length)\n",
    "            batch[0].cumulative_token_indices = batch[0].token_indices + additions\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [02:24<00:00, 172.43it/s]\n",
      "100%|██████████| 25000/25000 [02:18<00:00, 180.22it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CharacterandTokenLevelCustomDataset(train_df.Content.values, train_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, nlp)\n",
    "test_dataset = CharacterandTokenLevelCustomDataset(test_df.Content.values, test_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, nlp)\n",
    "max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[866], token_positions=[174], character_length=866, num_tokens=174, token_indices=[866], token_lengths=[174], token_embeddings=[174, 64]),\n",
       " tensor([1., 0.]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv\n",
    "\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, *args, **kwargs):\n",
    "        super(GCNN, self).__init__(*args, **kwargs)\n",
    "        # self.hidden_dim = hidden_dim\n",
    "        self.gnn = GATv2Conv(hidden_dim, hidden_dim//8, heads=4)\n",
    "        # self.gnn = SimpleConv(aggr='mean')\n",
    "        self.conv = nn.Conv1d(hidden_dim, hidden_dim//2, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        # self.out_fc = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim//2)\n",
    "        # self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        # self.bn4 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, graph, total_token_count, return_attention_weights = False):\n",
    "        x1, edge_weights = self.gnn(x, graph.edge_index, return_attention_weights=return_attention_weights) \n",
    "        x2 = F.relu(self.conv(x[:total_token_count].T).T)#self.bn2(self.conv(x[:total_token_count].T).T))\n",
    "        x3 =  F.leaky_relu_(self.bn3(self.fc(x1[total_token_count:])))\n",
    "        x1 = F.leaky_relu_(self.bn1(x1[:total_token_count]))\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = torch.cat([x, x3], dim=0)\n",
    "        # x = self.bn4(x)\n",
    "        return x, edge_weights #F.leaky_relu_(self.bn4(self.out_fc(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, to_undirected\n",
    "\n",
    "class GenGraph(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, virtual_nodes, lattice_step, *args, **kwargs):\n",
    "        super(GenGraph, self).__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.lattice_step = lattice_step\n",
    "        self.virtual_node_embeddings = nn.Embedding(self.virtual_nodes, hidden_dim)\n",
    "        \n",
    "    def gen_graph(self, x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        edge_index = torch.empty((2, base_numel + v_n_e_counts*2), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "            \n",
    "        if self.virtual_nodes > 0:\n",
    "            virtual_nodes_range = torch.arange(self.virtual_nodes, device=x.device).view(1, -1)\n",
    "            virtual_nodes_ids = torch.repeat_interleave(virtual_nodes_range, len(token_counts), dim=0)\n",
    "            v_n_idx = (virtual_nodes_ids + torch.arange(0, len(token_counts)*self.virtual_nodes, self.virtual_nodes, device=x.device).view(-1, 1) + total_token_coutns )\n",
    "            virtual_edge_ids = torch.repeat_interleave(v_n_idx.view(-1), token_counts.view(-1, 1).expand(len(token_counts), self.virtual_nodes).reshape(-1), dim=0).view(1, -1)\n",
    "            \n",
    "            embs = self.virtual_node_embeddings(virtual_nodes_ids.T).view(-1, self.hidden_dim)\n",
    "            x_extended = torch.cat([x, embs], dim=0)\n",
    "            x_index = torch.arange(total_token_coutns, device=x.device).repeat(self.virtual_nodes).view(1, -1)\n",
    "            edge_index[:, base_numel:base_numel+v_n_e_counts] = torch.cat([x_index, virtual_edge_ids], dim=0)\n",
    "            edge_index[:, base_numel+v_n_e_counts:] = torch.cat([virtual_edge_ids, x_index], dim=0)\n",
    "            x = x_extended\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "        \n",
    "    def re_gen_graph(self, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "        # for i in range(base.shape[1]):\n",
    "        #     edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "            \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "    \n",
    "    def replace_unimportant_edges(self, edge_weights, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2):\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        if v_n_e_counts>0:\n",
    "            important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        else:\n",
    "            important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "\n",
    "        important_indices = torch.arange(total_token_coutns, dtype=torch.int64, device=x.device) + important_indices*total_token_coutns\n",
    "        important_indices = important_indices.view(-1)\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "        new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_index[:, important_indices]\n",
    "        if(self.virtual_nodes>0):\n",
    "            new_edge_index[:, -2*v_n_e_counts:] = edge_index[:, -2*v_n_e_counts:]\n",
    "            \n",
    "        # for i in range(base.shape[1]):\n",
    "        #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "         \n",
    "    def calculate_graph(self, x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance):\n",
    "        tc_extended = torch.repeat_interleave(token_counts, token_counts, dim=0).view(-1,1)\n",
    "        tc_lower_bound = torch.empty((len(token_counts)+1), dtype=torch.long, device=x.device) #torch.cuda.IntTensor(len(token_counts)+1) #\n",
    "        tc_lower_bound[0] = 0\n",
    "        tc_lower_bound[1:] = torch.cumsum(token_counts, dim=0)\n",
    "        tc_lower_bound_extended = torch.repeat_interleave(tc_lower_bound[:-1], token_counts, dim=0).view(-1,1)\n",
    "        tc_range = torch.arange(tc_lower_bound[-1], device=x.device).view(-1,1)\n",
    "        # torch.arange(tc_lower_bound[-1], dtype=torch.int32, device=x.device).view(-1,1)\n",
    "        random_ints = torch.randint(0, 2*total_token_coutns, (total_token_coutns, random_edges), device=x.device) # torch.cuda.IntTensor(len(token_lengths), random_edges).random_()\n",
    "        lattice = torch.arange(lattice_start_distance, self.lattice_step*lattice_edges+1, self.lattice_step, device=x.device).view(1, -1)\n",
    "\n",
    "        # exponentials = torch.pow(2, torch.arange(1, self.exp_edges+1, device=x.device)).view(1, -1)\n",
    "        tc_local_range = tc_range - tc_lower_bound_extended\n",
    "        random_links = (((random_ints % (tc_extended - 1))+1 + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        lattice_links = ((lattice + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        # base = torch.cat([base1, base2], dim=1)\n",
    "        tc_range = tc_range.view(1,-1)\n",
    "        return random_links, lattice_links, tc_range\n",
    "    \n",
    "    def fill_lattice_and_random_edges(self, edge_index, random_links, lattice_links, tc_range):\n",
    "        for i in range(0, lattice_links.shape[1]*2, 2):\n",
    "            edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]] = torch.cat([lattice_links[:,i//2].view(1,-1), tc_range], dim=0)\n",
    "            edge_index[:, (i+1)*lattice_links.shape[0]:(i+2)*lattice_links.shape[0]] = edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]][[1, 0]]\n",
    "            \n",
    "        for i in range(random_links.shape[1]):\n",
    "            j = i + lattice_links.shape[1]*2\n",
    "            edge_index[:, j*random_links.shape[0]:(j+1)*random_links.shape[0]] = torch.cat([random_links[:,i].view(1,-1), tc_range], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv, summary\n",
    "\n",
    "class CNN_for_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embedding, pos_emb_size=8192, embedding_dim=64, hidden_dim=64, dropout=0.3, num_out_features=4, seed=-1, random_edges=4, lattice_edges=10, virtual_nodes=1, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64, *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text, self).__init__(*args, **kwargs)\n",
    "        self.pos_emb_size = pos_emb_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    " \n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.positional_encoding = nn.Embedding(pos_emb_size, embedding_dim)\n",
    "        self.positional_encoding.weight = self.create_positional_encoding()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(2*hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.gcnn2 = GCNN(hidden_dim + inject_embedding_dim)\n",
    "        self.graph_generator = GenGraph(hidden_dim, virtual_nodes, lattice_step)\n",
    "        \n",
    "        k = 4\n",
    "        self.fc0 = nn.Linear(hidden_dim , hidden_dim + inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim + inject_embedding_dim , hidden_dim * k)\n",
    "        self.fc2 = nn.Linear(hidden_dim * (2+virtual_nodes) * k , 32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, num_out_features)\n",
    "        self.max_length = 0\n",
    "    \n",
    "    def forward(self, g_data):\n",
    "        self.max_length = max(self.max_length, len(g_data.x))\n",
    "            \n",
    "        x = self.embedding(g_data.x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.T\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x1 = scatter_max(x, g_data.cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, g_data.cumulative_token_indices, dim=1)\n",
    "\n",
    "        x = torch.cat([x1, x2], dim=0)\n",
    "\n",
    "        x = F.relu(self.conv3(x)).T\n",
    "        \n",
    "        x = x + self.positional_encoding(g_data.token_positions)\n",
    "\n",
    "        rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "            \n",
    "        graph = self.graph_generator.gen_graph(x, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "        rand_edges = rand_edges-1\n",
    "        lattice_edges = lattice_edges-1\n",
    "        \n",
    "        x, edge_weights = self.gcnn1(graph.x, graph, len(g_data.token_lengths), return_attention_weights = True)\n",
    "        edge_weights = edge_weights[1][:graph.edge_index.shape[1], 0]\n",
    "        \n",
    "        graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, graph.edge_index, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        \n",
    "        x = torch.cat([graph.x[:g_data.token_embeddings.shape[0]], g_data.token_embeddings], dim=1)\n",
    "        x1 = F.relu(self.fc0(graph.x[g_data.token_embeddings.shape[0]:]))\n",
    "        x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "        x, edge_weights = self.gcnn2(x, graph, len(g_data.token_lengths))\n",
    "\n",
    "        x = F.elu_(self.fc1(x))\n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(g_data.num_tokens), device=x.device), g_data.num_tokens)\n",
    "        x1 = scatter_max(x[:len(g_data.token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(g_data.token_lengths)], doc_token_index, dim=0)\n",
    "        vn_embs = x[len(g_data.token_lengths):]\n",
    "        x_for_cat = [x1, x2]\n",
    "        x_for_cat.extend([vn_embs[i*x1.shape[0]:(i+1)*x1.shape[0]] for i in range(self.virtual_nodes)])\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        \n",
    "        x = F.elu_(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def create_positional_encoding(self):\n",
    "        position = torch.arange(self.pos_emb_size).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.hidden_dim, 2) * (-math.log(10000.0) / self.hidden_dim))\n",
    "        pe = torch.zeros(self.pos_emb_size, self.hidden_dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return torch.nn.Parameter(pe, requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CnnGnnClassifierLightningModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        num_classes,\n",
    "        optimizer=None,\n",
    "        loss_func=None,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=64,\n",
    "        lr_scheduler=None,\n",
    "        user_lr_scheduler=False,\n",
    "        min_lr=0.0,\n",
    "    ):\n",
    "        super(CnnGnnClassifierLightningModel, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.min_lr = min_lr\n",
    "        # self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        self.optimizer = self._get_optimizer(optimizer)\n",
    "        self.lr_scheduler = (\n",
    "            self._get_lr_scheduler(lr_scheduler) if user_lr_scheduler else None\n",
    "        )\n",
    "        self.loss_func = loss_func\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)\n",
    "\n",
    "    def on_train_epoch_start(self) -> None:\n",
    "        param_groups = next(iter(self.optimizer.param_groups))\n",
    "        if \"lr\" in param_groups and param_groups[\"lr\"] is not None:\n",
    "            current_learning_rate = float(param_groups[\"lr\"])\n",
    "            self.log(\n",
    "                \"lr\",\n",
    "                current_learning_rate,\n",
    "                batch_size=self.batch_size,\n",
    "                on_epoch=True,\n",
    "                on_step=False,\n",
    "            )\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.train()\n",
    "        y_out = self(X)\n",
    "\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.train_losses.append(loss.detach().item())\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        self.train_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        y_out = self(X)\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.val_losses.append(loss.detach().item())\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.val_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.lr_scheduler is None:\n",
    "            return self.optimizer\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": self.lr_scheduler,\n",
    "                \"monitor\": \"train_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def update_learning_rate(self, learning_rate: float):\n",
    "        self.learning_rate = learning_rate\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g[\"lr\"] = learning_rate\n",
    "\n",
    "    def _get_optimizer(self, optimizer):\n",
    "        return (\n",
    "            optimizer\n",
    "            if optimizer is not None\n",
    "            else torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        )\n",
    "\n",
    "    def _get_lr_scheduler(self, lr_scheduler):\n",
    "        return (\n",
    "            lr_scheduler\n",
    "            if lr_scheduler is not None\n",
    "            else torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer, patience=5, factor=0.5, mode=\"min\", min_lr=self.min_lr\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 128\n",
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "label_size = 1\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import Logger, CSVLogger\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from typing import List\n",
    "from pytorch_lightning.core.saving import save_hparams_to_yaml\n",
    "\n",
    "class ModelManager(ABC):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 max_epochs = 100,\n",
    "                 ckpt_path: str|None=None,\n",
    "                 accumulate_grad_batches=1):\n",
    "        self.torch_model = torch_model\n",
    "        self.lightning_model = lightning_model\n",
    "        self.log_dir = log_dir\n",
    "        self.log_name = log_name\n",
    "        self.model_save_dir = model_save_dir\n",
    "        self.device = device\n",
    "        self.accelerator = 'cpu' if self.device=='cpu' else 'gpu'\n",
    "        self.max_epochs = max_epochs\n",
    "        self.ckpt_path = ckpt_path\n",
    "\n",
    "        self.logger = self._create_logger()\n",
    "        self.callbacks = self._create_callbacks()\n",
    "        self.trainer: L.Trainer = self._create_trainer(accumulate_grad_batches)\n",
    "        self.tuner = Tuner(self.trainer)\n",
    "        self.tuning_result = None\n",
    "\n",
    "    def tune(self, data_manager=None, train_dataloaders=None, val_dataloaders=None, datamodule=None, draw_result=True, min_lr=0.0000001, max_lr=0.1):\n",
    "        self.tuning_result = self.tuner.lr_find(self.lightning_model, datamodule=data_manager, train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders, min_lr=min_lr,max_lr=max_lr, num_training=150)\n",
    "        if draw_result:\n",
    "            fig = self.tuning_result.plot(suggest=True)\n",
    "            fig.show()\n",
    "        self.update_learning_rate(self.tuning_result.suggestion())\n",
    "        return self.tuning_result.suggestion()\n",
    "    \n",
    "    def update_learning_rate(self, lr):\n",
    "        self.lightning_model.update_learning_rate(lr)\n",
    "\n",
    "    def fit(self, train_dataloaders=None, val_dataloaders=None, datamodule=None, max_epochs = -1, ckpt_path=None):\n",
    "        if ckpt_path is not None and ckpt_path != '':\n",
    "            self.ckpt_path = ckpt_path\n",
    "        if max_epochs>0:\n",
    "            self.trainer.fit_loop.max_epochs = max_epochs\n",
    "            # self.max_epochs = max_epochs\n",
    "            # self.trainer = self._create_trainer()\n",
    "        self.trainer.fit(self.lightning_model,\n",
    "                         datamodule=datamodule,\n",
    "                         train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders,\n",
    "                         ckpt_path = self.ckpt_path\n",
    "                         )\n",
    "\n",
    "    def validate(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.validate(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def predict(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.predict(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def _create_trainer(self, accumulate_grad_batches) -> L.Trainer:\n",
    "        return L.Trainer(\n",
    "            callbacks=self.callbacks,\n",
    "            max_epochs=self.max_epochs,\n",
    "            accelerator=self.accelerator,\n",
    "            logger=self.logger,\n",
    "            num_sanity_val_steps=0,\n",
    "            default_root_dir=self.model_save_dir,\n",
    "            accumulate_grad_batches=accumulate_grad_batches\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        pass\n",
    "\n",
    "    def _create_logger(self) -> Logger:\n",
    "        return CSVLogger(save_dir=self.log_dir, name=self.log_name)\n",
    "\n",
    "    @abstractmethod\n",
    "    def draw_summary(self, dataloader):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def plot_csv_logger(self, loss_names, eval_names):\n",
    "        pass\n",
    "    \n",
    "    def save_hyper_parameters(self):\n",
    "        mhparams = {\n",
    "            'start_lr': 0.045,\n",
    "            'ckpt_lrs' :  {51: 0.002, 65: 0.00058},\n",
    "            'last_lr' : 0.0003,\n",
    "            'ac_loss_factor': 0.0002,\n",
    "            'weight_decay': 0.0012\n",
    "        }\n",
    "        save_hparams_to_yaml(config_yaml=r'logs\\hetero_model_17_AG\\version_12\\hparams.yaml',\n",
    "                     hparams=mhparams)\n",
    "        \n",
    "    # def find_best_settings(data_manager,\n",
    "    #                        lrs: List[float]=[0.001], dropouts: List[float]=[0.2], \n",
    "    #                        weight_decays: List[float]=[0.00055], emb_factors: List[float]=[0.1], \n",
    "    #                        batch_sizes: List[int]=[128], log_name='find_best_settings'):\n",
    "    #     for lr in lrs:\n",
    "    #         for dropout in dropouts:\n",
    "    #             for wd in weight_decays:\n",
    "    #                 for emb_factor in emb_factors:\n",
    "    #                     for bs in batch_sizes:\n",
    "    #                         data_manager.update_batch_size(bs)\n",
    "    #                         torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 128, dropout=dropout)\n",
    "    #                         lightning_model = HeteroBinaryLightningModel(torch_model,\n",
    "    #                                         torch.optim.Adam(torch_model.parameters(), lr=lr, weight_decay=wd),\n",
    "    #                                             loss_func=HeteroLoss1(exception_keys='word', enc_factor=emb_factor),\n",
    "    #                                             learning_rate=lr,\n",
    "    #                                             batch_size=bs,\n",
    "    #                                             user_lr_scheduler=True\n",
    "    #                                             ).to(device)\n",
    "    #                         model_manager = ClassifierModelManager(torch_model, lightning_model, log_name=log_name, device=device, num_train_epoch=10)\n",
    "    #                         model_manager.fit(datamodule=data_manager)\n",
    "    #                         model_manager.save_plot_csv_logger(name_prepend=f'{lr}_{dropout}_{wd}_{emb_factor}_{bs}', loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "import torch\n",
    "# from scripts.managers.ModelManager import ModelManager\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from torch_geometric.nn import summary\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from os import path\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "class ClassifierModelManager(ModelManager):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 num_train_epoch = 100,\n",
    "                 accumulate_grad_batches=1):\n",
    "        super(ClassifierModelManager, self).__init__(torch_model, lightning_model, model_save_dir, log_dir, log_name, device, num_train_epoch, accumulate_grad_batches=accumulate_grad_batches)\n",
    "\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        return [\n",
    "            ModelCheckpoint(save_top_k=2, mode='max', monitor='val_acc', save_last=True),\n",
    "            # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "        ]\n",
    "\n",
    "    def draw_summary(self, dataloader):\n",
    "        X, y = next(iter(dataloader))\n",
    "        print(summary(self.torch_model, X.to(self.device)))\n",
    "\n",
    "    def plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    def save_plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc'], name_prepend: str=\"\"):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        \n",
    "        loss_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_loss_metric.png')\n",
    "        plt.savefig(loss_png)\n",
    "        \n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        \n",
    "        acc_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_acc_metric.png')\n",
    "        plt.savefig(acc_png)\n",
    "        \n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate(self, eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.lightning_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        # if(give_hinge_loss):\n",
    "        #     print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')\n",
    "                \n",
    "    def evaluate_best_models(self, lightning_type: L.LightningModule, eval_dataloader,\n",
    "                             give_confusion_matrix: bool=True, \n",
    "                             give_report: bool=True, \n",
    "                             give_f1_score: bool=False, \n",
    "                             give_accuracy_score: bool=False, \n",
    "                             give_precision_score: bool=False, \n",
    "                             give_recall_score: bool=False, \n",
    "                             give_hinge_loss: bool=False,\n",
    "                             multi_class: bool=False, **kwargs):\n",
    "        self.lightning_model = lightning_type.load_from_checkpoint(rf'{self.trainer.checkpoint_callback.best_model_path}', map_location=None, hparams_file=None, strict=True, **kwargs).eval()\n",
    "        self.save_evaluation(eval_dataloader, 'best_model', give_confusion_matrix, give_report,\n",
    "                             give_f1_score, give_accuracy_score, give_precision_score, give_recall_score, give_hinge_loss, multi_class)\n",
    "            \n",
    "    def save_evaluation(self, eval_dataloader, name_prepend: str='',\n",
    "                    give_confusion_matrix: bool=True, \n",
    "                    give_report: bool=True, \n",
    "                    give_f1_score: bool=False, \n",
    "                    give_accuracy_score: bool=False, \n",
    "                    give_precision_score: bool=False, \n",
    "                    give_recall_score: bool=False, \n",
    "                    give_hinge_loss: bool=False,\n",
    "                    multi_class: bool=False\n",
    "                    ):\n",
    "            \n",
    "            test_metrics_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_test_metrics.txt')\n",
    "            \n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            self.lightning_model.eval()\n",
    "            self.lightning_model.model.eval()\n",
    "            self.torch_model.eval()\n",
    "            self.trainer.model.eval()\n",
    "            for X, y in eval_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    y_p = self.lightning_model(X.to(self.device))\n",
    "                if type(y_p) is tuple:\n",
    "                    y_p = y_p[0]\n",
    "                \n",
    "                if multi_class:\n",
    "                    y_pred.append(y_p.detach().to(y.device))\n",
    "                    y_true.append(y)\n",
    "                else:\n",
    "                    y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "                    y_true.append(y.to(torch.int32))\n",
    "                    \n",
    "            y_true = torch.concat(y_true)\n",
    "            y_pred = torch.concat(y_pred)\n",
    "            print(y_true.shape)\n",
    "            print(y_pred.shape)\n",
    "            if multi_class:\n",
    "                y_true_num = torch.argmax(y_true, dim=1)\n",
    "                y_pred_num = torch.argmax(y_pred, dim=1)\n",
    "            else:\n",
    "                y_true_num = y_true\n",
    "                y_pred_num = y_pred\n",
    "                \n",
    "            print(y_true_num.shape)\n",
    "            print(y_pred_num.shape)\n",
    "            with open(test_metrics_path, 'at+') as f:\n",
    "                if(give_confusion_matrix):\n",
    "                    print(f'confusion_matrix: \\n{confusion_matrix(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_report):\n",
    "                    print(classification_report(y_true_num, y_pred_num), file=f)\n",
    "                if(give_f1_score):\n",
    "                    if multi_class:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_accuracy_score):\n",
    "                    print(f'accuracy_score: {accuracy_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_precision_score):\n",
    "                    if multi_class:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_recall_score):\n",
    "                    if multi_class:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num)}', file=f)\n",
    "                # if(give_hinge_loss):\n",
    "                #     print(f'hinge_loss: {hinge_loss(y_true_num, y_pred)}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "def train_model(epochs=30, dropout=0.2, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True):\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 38, 40,45,50],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name='CNN-GNN14_imdb',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.torch_model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(CnnGnnClassifierLightningModel, test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     time.sleep(60)\n",
    "#     torch.cuda.empty_cache()\n",
    "#     import gc\n",
    "#     gc.collect()\n",
    "#     time.sleep(60)\n",
    "#     train_model(70, 0.2, 0.000012, 0.0032, amsgrad=False, fused=True, long_limit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | CNN_for_Text       | 1.1 M \n",
      "1 | loss_func | BCEWithLogitsLoss  | 0     \n",
      "2 | train_acc | MulticlassAccuracy | 0     \n",
      "3 | val_acc   | MulticlassAccuracy | 0     \n",
      "4 | test_acc  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "550 K     Trainable params\n",
      "524 K     Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.300     Total estimated model params size (MB)\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af6d0b31a2842cfa03017ee20be0c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bccd9dafef047d1ae8bf133a4d3b23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073c6e2ed33946cdb38ffcb28414dbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7341e6088d8f4ce6829cb6ef1d1c9827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81ecb3b625e48928cb50c73dcaf9292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e428b53b0134a70bd97d31b1cd88ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57b5cf37a354aeab7812e03aa894dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8615b0264446aaac84036f31826923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b3945cb5b64d2f9412d1e4b0b405d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb4f40103404c34be319d9aaf5b40b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf0388aac47409ab4960bfa05e38ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4327a47e6f8b485ab09d2a62a7deebd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10692724bd24ae18db5728f4c33b943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dbf29eb63f4c819da5f7cac00c858e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163e38c76c564a71b383ced220f4389c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83e7eeed27143b8ad3a04d5c8f6c614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4a7f7f50d2472693e3eef4f9295531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3669891acc764fddbc8e065a3bd2c081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a589fccc99b34c559e2921676e1e828e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3401fefaf1634b2e81abddf2ea125648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b8f9d1de234d0592e121bedb4b7f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83282934c8f64eaca6eefb7595aa69f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54daef7fecf4204bcc8afbc23409913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d956b0a126645c786b8445c36d9b2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c98a7f7f0641e5822a77957ad8ae2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3aed1ad70f43cf8b733e2060ffad86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46e352695b84964af0e59913f2386d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dede420dd3f442aa685edbafd8c87c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b49d95ab7444cccafd755d694eb9394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478da7587044482f9894506d02b4a6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f49ed00d5b4d62bb4a878be3e42367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24960, 2])\n",
      "torch.Size([24960, 2])\n",
      "torch.Size([24960])\n",
      "torch.Size([24960])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:24<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9308    0.8615    0.8948     12481\n",
      "           1     0.8711    0.9360    0.9023     12479\n",
      "\n",
      "    accuracy                         0.8987     24960\n",
      "   macro avg     0.9009    0.8987    0.8986     24960\n",
      "weighted avg     0.9009    0.8987    0.8986     24960\n",
      "\n",
      "confusion matrix:\n",
      " tensor([[10752,  1729],\n",
      "        [  799, 11680]])\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24960, 2])\n",
      "torch.Size([24960, 2])\n",
      "torch.Size([24960])\n",
      "torch.Size([24960])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ClassifierModelManager at 0x2a4a7e54150>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for i in range(5):\n",
    "train_model(30, 0.2, 0.000012, 0.0032, amsgrad=False, fused=True)\n",
    "    # time.sleep(60)\n",
    "    # torch.cuda.empty_cache()\n",
    "    # import gc\n",
    "    # gc.collect()\n",
    "    # time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoints = {'3_1': r'logs\\CNN-GNN14_imdb\\version_3\\checkpoints\\epoch=18-step=3724.ckpt',\n",
    "                    '3_2': r'logs\\CNN-GNN14_imdb\\version_3\\checkpoints\\epoch=21-step=4312.ckpt',\n",
    "                    '4_1': r'logs\\CNN-GNN14_imdb\\version_4\\checkpoints\\epoch=21-step=4312.ckpt',\n",
    "                    '4_2': r'logs\\CNN-GNN14_imdb\\version_4\\checkpoints\\epoch=29-step=5880.ckpt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 3_1: 0.9016266025641025\n",
      "f1 3_1: 0.9016267907990174\n",
      "prec 3_1: 0.901626983887693\n",
      "rec 3_1: 0.9016265977104807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 3_2: 0.9044391025641026\n",
      "f1 3_2: 0.9044397519063028\n",
      "prec 3_2: 0.9044405139228923\n",
      "rec 3_2: 0.9044389898919913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 4_1: 0.9043910256410257\n",
      "f1 4_1: 0.9051648417962352\n",
      "prec 4_1: 0.9059365058620049\n",
      "rec 4_1: 0.9043944936980092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 4_2: 0.9042788461538462\n",
      "f1 4_2: 0.9048116765944922\n",
      "prec 4_2: 0.9053422769446587\n",
      "rec 4_2: 0.9042816991204085\n",
      "total_accuracy: 0.9036838942307692\n",
      "total_f1: 0.9040107652740119\n",
      "total_prec: 0.9043365701543122\n",
      "total_rec: 0.9036854451052224\n"
     ]
    }
   ],
   "source": [
    "total_accuracy = []\n",
    "total_f1 = []\n",
    "total_prec = []\n",
    "total_rec = []\n",
    "\n",
    "\n",
    "for k in best_checkpoints:\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(best_checkpoints[k], model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "    mean_infer_acc = []\n",
    "    mean_infer_f1 = []\n",
    "    mean_infer_prec = []\n",
    "    mean_infer_rec = []\n",
    "    for i in range(5):\n",
    "        all_ys = []\n",
    "        all_y_preds = []\n",
    "        for X, y in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                y_pred = classfier_lightning_model(X.to(device))\n",
    "            all_ys.append(torch.argmax(y,dim=1))\n",
    "            all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "        all_ys = torch.concat(all_ys)\n",
    "        all_y_preds = torch.concat(all_y_preds)\n",
    "        \n",
    "        cm = confusion_matrix(all_ys, all_y_preds)\n",
    "        \n",
    "        accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "        precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
    "        recall = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "        f1_score = (2*precision*recall)/(precision + recall)\n",
    "        \n",
    "        mean_infer_acc.append(accuracy)\n",
    "        mean_infer_f1.append(f1_score)\n",
    "        mean_infer_prec.append(precision)\n",
    "        mean_infer_rec.append(recall)\n",
    "    mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "    mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "    mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "    mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "    \n",
    "    print(f'accuracy {k}: {mean_infer_acc}')\n",
    "    print(f'f1 {k}: {mean_infer_f1}')\n",
    "    print(f'prec {k}: {mean_infer_prec}')\n",
    "    print(f'rec {k}: {mean_infer_rec}')\n",
    "    total_accuracy.append(mean_infer_acc)\n",
    "    total_f1.append(mean_infer_f1)\n",
    "    total_prec.append(mean_infer_prec)\n",
    "    total_rec.append(mean_infer_rec)\n",
    "\n",
    "total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "total_prec = torch.mean(torch.tensor(total_prec))\n",
    "total_rec = torch.mean(torch.tensor(total_rec))\n",
    "print(f'total_accuracy: {total_accuracy}')\n",
    "print(f'total_f1: {total_f1}')\n",
    "print(f'total_prec: {total_prec}')\n",
    "print(f'total_rec: {total_rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoints = {'0': r'logs\\CNN-GNN14_imdb\\version_0\\checkpoints\\epoch=21-step=4312.ckpt',\n",
    "                    '1': r'logs\\CNN-GNN14_imdb\\version_1\\checkpoints\\epoch=16-step=3332.ckpt',\n",
    "                    '2': r'logs\\CNN-GNN14_imdb\\version_2\\checkpoints\\epoch=15-step=3136.ckpt',\n",
    "                    '3': r'logs\\CNN-GNN14_imdb\\version_3\\checkpoints\\epoch=21-step=4312.ckpt',\n",
    "                    '4': r'logs\\CNN-GNN14_imdb\\version_4\\checkpoints\\epoch=21-step=4312.ckpt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0: 0.9033974358974358\n",
      "f1 0: 0.9035064435254805\n",
      "prec 0: 0.9036141853536996\n",
      "rec 0: 0.9033987280164777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1: 0.903790064102564\n",
      "f1 1: 0.9038367718697391\n",
      "prec 1: 0.9038826411572842\n",
      "rec 1: 0.9037909074346764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 2: 0.9012660256410256\n",
      "f1 2: 0.901268346364156\n",
      "prec 2: 0.9012704902530799\n",
      "rec 2: 0.9012662024884375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 3: 0.9044391025641026\n",
      "f1 3: 0.9044397519063028\n",
      "prec 3: 0.9044405139228923\n",
      "rec 3: 0.9044389898919913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 4: 0.9043910256410257\n",
      "f1 4: 0.9051648417962352\n",
      "prec 4: 0.9059365058620049\n",
      "rec 4: 0.9043944936980092\n",
      "total_accuracy: 0.9034567307692308\n",
      "total_f1: 0.9036432310923826\n",
      "total_prec: 0.9038288673097922\n",
      "total_rec: 0.9034578643059185\n"
     ]
    }
   ],
   "source": [
    "total_accuracy = []\n",
    "total_f1 = []\n",
    "total_prec = []\n",
    "total_rec = []\n",
    "\n",
    "\n",
    "for k in best_checkpoints:\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(best_checkpoints[k], model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "    mean_infer_acc = []\n",
    "    mean_infer_f1 = []\n",
    "    mean_infer_prec = []\n",
    "    mean_infer_rec = []\n",
    "    for i in range(5):\n",
    "        all_ys = []\n",
    "        all_y_preds = []\n",
    "        for X, y in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                y_pred = classfier_lightning_model(X.to(device))\n",
    "            all_ys.append(torch.argmax(y,dim=1))\n",
    "            all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "        all_ys = torch.concat(all_ys)\n",
    "        all_y_preds = torch.concat(all_y_preds)\n",
    "        \n",
    "        cm = confusion_matrix(all_ys, all_y_preds)\n",
    "        \n",
    "        accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "        precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
    "        recall = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "        f1_score = (2*precision*recall)/(precision + recall)\n",
    "        \n",
    "        mean_infer_acc.append(accuracy)\n",
    "        mean_infer_f1.append(f1_score)\n",
    "        mean_infer_prec.append(precision)\n",
    "        mean_infer_rec.append(recall)\n",
    "    mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "    mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "    mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "    mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "    \n",
    "    print(f'accuracy {k}: {mean_infer_acc}')\n",
    "    print(f'f1 {k}: {mean_infer_f1}')\n",
    "    print(f'prec {k}: {mean_infer_prec}')\n",
    "    print(f'rec {k}: {mean_infer_rec}')\n",
    "    total_accuracy.append(mean_infer_acc)\n",
    "    total_f1.append(mean_infer_f1)\n",
    "    total_prec.append(mean_infer_prec)\n",
    "    total_rec.append(mean_infer_rec)\n",
    "\n",
    "total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "total_prec = torch.mean(torch.tensor(total_prec))\n",
    "total_rec = torch.mean(torch.tensor(total_rec))\n",
    "print(f'total_accuracy: {total_accuracy}')\n",
    "print(f'total_f1: {total_f1}')\n",
    "print(f'total_prec: {total_prec}')\n",
    "print(f'total_rec: {total_rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0: 0.9033974358974358\n",
      "f1 0: 0.9035064435254805\n",
      "prec 0: 0.9036141853536996\n",
      "rec 0: 0.9033987280164777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1: 0.903790064102564\n",
      "f1 1: 0.9038367718697391\n",
      "prec 1: 0.9038826411572842\n",
      "rec 1: 0.9037909074346764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 2: 0.9012660256410256\n",
      "f1 2: 0.901268346364156\n",
      "prec 2: 0.9012704902530799\n",
      "rec 2: 0.9012662024884375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\Form&ColorIntelligence\\notebooks\\Task1_X_3\\text_classification\\text_classification_test_1_imdb.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m test_dataloader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         y_pred \u001b[39m=\u001b[39m classfier_lightning_model(X\u001b[39m.\u001b[39;49mto(device))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     all_ys\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39margmax(y,dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     all_y_preds\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39margmax(y_pred\u001b[39m.\u001b[39mcpu(), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\Form&ColorIntelligence\\notebooks\\Task1_X_3\\text_classification\\text_classification_test_1_imdb.ipynb Cell 37\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\Form&ColorIntelligence\\notebooks\\Task1_X_3\\text_classification\\text_classification_test_1_imdb.ipynb Cell 37\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m x1 \u001b[39m=\u001b[39m scatter_max(x, g_data\u001b[39m.\u001b[39;49mcumulative_token_indices, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m x2 \u001b[39m=\u001b[39m scatter_mean(x, g_data\u001b[39m.\u001b[39mcumulative_token_indices, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x1, x2], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_scatter\\scatter.py:72\u001b[0m, in \u001b[0;36mscatter_max\u001b[1;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter_max\u001b[39m(\n\u001b[0;32m     69\u001b[0m         src: torch\u001b[39m.\u001b[39mTensor, index: torch\u001b[39m.\u001b[39mTensor, dim: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     70\u001b[0m         out: Optional[torch\u001b[39m.\u001b[39mTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m         dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mtorch_scatter\u001b[39m.\u001b[39;49mscatter_max(src, index, dim, out, dim_size)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_ops.py:692\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    688\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    689\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    691\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_accuracy = []\n",
    "total_f1 = []\n",
    "total_prec = []\n",
    "total_rec = []\n",
    "\n",
    "\n",
    "for k in best_checkpoints:\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(best_checkpoints[k], model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "    mean_infer_acc = []\n",
    "    mean_infer_f1 = []\n",
    "    mean_infer_prec = []\n",
    "    mean_infer_rec = []\n",
    "    for i in range(5):\n",
    "        all_ys = []\n",
    "        all_y_preds = []\n",
    "        for X, y in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                y_pred = classfier_lightning_model(X.to(device))\n",
    "            all_ys.append(torch.argmax(y,dim=1))\n",
    "            all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "        all_ys = torch.concat(all_ys)\n",
    "        all_y_preds = torch.concat(all_y_preds)\n",
    "        \n",
    "        cm = confusion_matrix(all_ys, all_y_preds)\n",
    "        \n",
    "        accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "        precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
    "        recall = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "        f1_score = (2*precision*recall)/(precision + recall)\n",
    "        \n",
    "        mean_infer_acc.append(accuracy)\n",
    "        mean_infer_f1.append(f1_score)\n",
    "        mean_infer_prec.append(precision)\n",
    "        mean_infer_rec.append(recall)\n",
    "    mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "    mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "    mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "    mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "    \n",
    "    print(f'accuracy {k}: {mean_infer_acc}')\n",
    "    print(f'f1 {k}: {mean_infer_f1}')\n",
    "    print(f'prec {k}: {mean_infer_prec}')\n",
    "    print(f'rec {k}: {mean_infer_rec}')\n",
    "    total_accuracy.append(mean_infer_acc)\n",
    "    total_f1.append(mean_infer_f1)\n",
    "    total_prec.append(mean_infer_prec)\n",
    "    total_rec.append(mean_infer_rec)\n",
    "\n",
    "total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "total_prec = torch.mean(torch.tensor(total_prec))\n",
    "total_rec = torch.mean(torch.tensor(total_rec))\n",
    "print(f'total_accuracy: {total_accuracy}')\n",
    "print(f'total_f1: {total_f1}')\n",
    "print(f'total_prec: {total_prec}')\n",
    "print(f'total_rec: {total_rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "def train_model(epochs=30, dropout=0.2, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True):\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=14336, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 38, 40,45,50],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name='CNN-GNN13_large_models',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.torch_model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(CnnGnnClassifierLightningModel, test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
