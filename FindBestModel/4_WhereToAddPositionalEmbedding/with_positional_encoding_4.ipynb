{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import time\n",
    "from torch_scatter import scatter_max, scatter_mean, scatter_std\n",
    "from sklearn.model_selection import KFold\n",
    "import torchmetrics\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "from transformers import AutoModel, DebertaV2Tokenizer, AutoTokenizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vocab = {v:k for k,v in tokenizer.vocab.items()}\n",
    "all_vocab_indices = list(id_vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all_vocab_str = []\n",
    "# vector_keys = list(nlp.vocab.vectors.keys())\n",
    "# for i in range(len(vector_keys)):\n",
    "#     try:\n",
    "#         t = nlp.vocab.strings[vector_keys[i]]\n",
    "#         all_vocab_str.append(t)\n",
    "#     except:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# Create a set of all English characters, numbers, and punctuation\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation\n",
    "all_chars = set(allowed_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Data\\ReducedEmbeddings\\deberta_larg_reduced_embeddings_64.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "all_vocab_str = []\n",
    "for i in range(len(id_vocab)):\n",
    "    all_vocab_str.append(id_vocab[i])\n",
    "    \n",
    "# embeddings = (embeddings - torch.min(embeddings)) / (torch.max(embeddings)-torch.min(embeddings))\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))\n",
    "# del all_vocab_str\n",
    "# del all_vocab_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'Data\\ReducedEmbeddings\\polarity_debertav3_tokens_gpt_mini_emb.npy', 'rb') as f:\n",
    "    polarities_subjectivities= np.load(f)\n",
    "polarities_subjectivities = torch.from_numpy(polarities_subjectivities)\n",
    "polarity_vocab_dict = dict(zip(all_vocab_str, polarities_subjectivities))\n",
    "polarity_vocab_dict['<n>'] = torch.tensor([0.0, 0.0])\n",
    "len(token_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128001, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarities_subjectivities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085 tensor([0.7000, 0.6000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_vocab_str)):\n",
    "    if 'nice' in all_vocab_str[i]:\n",
    "        print(i, polarities_subjectivities[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# Create a set of all English characters, numbers, and punctuation\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' \\t'\n",
    "all_chars = set(allowed_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 224\n",
    "folder_path = r'data\\TextClassification\\IMDB'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I have seen this movie twice and it's theme is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I happened to catch this on community TV a few...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  I have seen this movie twice and it's theme is...\n",
       "1      1  I happened to catch this on community TV a few..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(r'data\\TextClassification\\IMDB\\test.csv')\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_ratio = 1.0\n",
    "test_df = pd.read_csv(r'data\\TextClassification\\IMDB\\test.csv')\n",
    "test_df['Topic'] = test_df['label']\n",
    "test_df['Content'] = test_df['text']\n",
    "test_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df = test_df.iloc[:int(keep_ratio*test_df.shape[0])]\n",
    "train_df = pd.read_csv(r'data\\TextClassification\\IMDB\\train.csv')\n",
    "train_df['Topic'] = train_df['label']\n",
    "train_df['Content'] = train_df['text']\n",
    "train_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df = train_df.iloc[:int(keep_ratio*train_df.shape[0])]\n",
    "sst_classes = [\"Negative\", \"Positive\"]\n",
    "df = pd.concat([train_df, test_df])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13704\n"
     ]
    }
   ],
   "source": [
    "doc_lengths = np.array([len(tx) for tx in df['Content'].values])\n",
    "print(np.max(doc_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a histogram\n",
    "plt.hist(doc_lengths, bins='auto', edgecolor='black')\n",
    "# plt.xlim([0,138000])\n",
    "# Add labels and title\n",
    "plt.xlabel('Document Lengths')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Document Lengths')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = df.Topic.unique()\n",
    "class_id = {sst_classes[i]:i for i in class_list}\n",
    "id_class = {i:sst_classes[i] for i in class_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set = set()\n",
    "for doc in df.Content.values:\n",
    "    char_set.update(set(' '.join(tokenizer.tokenize(doc))))\n",
    "len(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_dict = {c:i for i, c in enumerate(allowed_chars)}\n",
    "# if '\\x01' not in vocab_dict:\n",
    "#     vocab_dict['\\x01'] = len(vocab_dict)\n",
    "# char_Set = set(vocab_dict.keys())\n",
    "# len(char_Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAHHCAYAAABnS/bqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABV9klEQVR4nO3dd1gU1/4G8Hcpu4C4ICIgCtgRsWMjdiWiwdjwRo09qFeDMahRrzeJ9Sa22GKMpoqxxGhiTOwiYicWFCtiQ9coRVRAFFhkz+8Pw/xYQQTcYSnv53n2eXZnzs58zwLr68yZMwohhAARERERGZyJsQsgIiIiKqsYtIiIiIhkwqBFREREJBMGLSIiIiKZMGgRERERyYRBi4iIiEgmDFpEREREMmHQIiIiIpIJgxYRERGRTBi0iGQwa9YsKBSKYtlXp06d0KlTJ+n1wYMHoVAo8OuvvxbL/keMGIEaNWoUy76KKjU1FaNGjYKTkxMUCgWCgoKMVotCocCsWbOMtv/SKPvvKTEx0dilEBUagxbRKwQHB0OhUEgPCwsLODs7w9fXF19++SUeP35skP3cu3cPs2bNQmRkpEG2Z0glubaC+PzzzxEcHIxx48Zh3bp1GDp06EvbarVaLF++HM2aNYNarYatrS08PT0xZswYXLlyRWp3/PhxzJo1C0lJScXQg9d369YtKBQKfPHFF8Yu5aU+//xzbNu2zdhlEBmUmbELICot5syZg5o1ayIzMxNxcXE4ePAggoKCsGTJEvz5559o3Lix1PaTTz7Bf/7zn0Jt/969e5g9ezZq1KiBpk2bFvh9+/btK9R+iiK/2r777jvodDrZa3gdBw4cQJs2bTBz5sxXtvX398fu3bsxaNAgjB49GpmZmbhy5Qp27NiBN954A/Xr1wfwPGjNnj0bI0aMgK2tbYFrSUtLg5kZv3rz8vnnn6N///7o06ePsUshMhj+tRMVUI8ePdCiRQvp9fTp03HgwAH07NkTvXr1QlRUFCwtLQEAZmZmsv9j+vTpU1hZWUGpVMq6n1cxNzc36v4LIiEhAQ0aNHhlu1OnTmHHjh347LPP8N///ldv3VdffVXko1c6nQ5arRYWFhawsLAo0jaIqHTiqUOi19ClSxd8+umnuH37NtavXy8tz2uMVkhICNq1awdbW1tYW1vD3d1d+sf84MGDaNmyJQBg5MiR0mnK4OBgAM/HYTVs2BARERHo0KEDrKyspPe+OEYrW1ZWFv773//CyckJFSpUQK9evXDnzh29NjVq1MCIESNyvTfnNl9VW15jtJ48eYLJkyfDxcUFKpUK7u7u+OKLLyCE0GunUCgwfvx4bNu2DQ0bNoRKpYKnpyf27NmT9wf+goSEBAQEBMDR0REWFhZo0qQJ1q5dK63PHq8WExODnTt3SrXfunUrz+3duHEDANC2bdtc60xNTVG5cmUAz3++U6ZMAQDUrFkz13az+7VhwwZ4enpCpVJJfXpxjFb278r169elo2M2NjYYOXIknj59qldDWloaJkyYAHt7e1SsWBG9evXC3bt3DTruKyMjAzNnzkSdOnWgUqng4uKCqVOnIiMjQ69dYX52Bw8eRIsWLWBhYYHatWvjm2++yfU3olAo8OTJE6xdu1b6PF/83UxKSnrlZ5Tf3xmRMfCIFtFrGjp0KP773/9i3759GD16dJ5tLl26hJ49e6Jx48aYM2cOVCoVrl+/jmPHjgEAPDw8MGfOHMyYMQNjxoxB+/btAQBvvPGGtI0HDx6gR48eGDhwIIYMGQJHR8d86/rss8+gUCgwbdo0JCQkYNmyZfDx8UFkZKR05K0gClJbTkII9OrVC2FhYQgICEDTpk2xd+9eTJkyBXfv3sXSpUv12h89ehRbt27F+++/j4oVK+LLL7+Ev78/NBqNFGzykpaWhk6dOuH69esYP348atasiS1btmDEiBFISkrChx9+CA8PD6xbtw4TJ05E9erVMXnyZABAlSpV8tymm5sbAGDDhg1o27btS49K9uvXD1evXsXPP/+MpUuXwt7ePtd2Dxw4gM2bN2P8+PGwt7d/5QUD77zzDmrWrIl58+bhzJkz+P777+Hg4IAFCxZIbUaMGIHNmzdj6NChaNOmDQ4dOgQ/P798t1sYOp0OvXr1wtGjRzFmzBh4eHjgwoULWLp0Ka5evZpr/FRBfnZnz55F9+7dUbVqVcyePRtZWVmYM2dOrp/BunXrMGrUKLRq1QpjxowBANSuXbtQn9Gr/s6IjEIQUb7WrFkjAIhTp069tI2NjY1o1qyZ9HrmzJki55/X0qVLBQBx//79l27j1KlTAoBYs2ZNrnUdO3YUAMTq1avzXNexY0fpdVhYmAAgqlWrJlJSUqTlmzdvFgDE8uXLpWVubm5i+PDhr9xmfrUNHz5cuLm5Sa+3bdsmAIj//e9/eu369+8vFAqFuH79urQMgFAqlXrLzp07JwCIFStW5NpXTsuWLRMAxPr166VlWq1WeHt7C2tra72+u7m5CT8/v3y3J4QQOp1O+qwdHR3FoEGDxMqVK8Xt27dztV20aJEAIGJiYnKtAyBMTEzEpUuX8lw3c+ZM6XX278p7772n165v376icuXK0uuIiAgBQAQFBem1GzFiRK5t5iUmJkYAEIsWLXppm3Xr1gkTExNx5MgRveWrV68WAMSxY8f0+lGQn93bb78trKysxN27d6Vl165dE2ZmZuLFf4IqVKiQ5+9jQT+jgvydERU3njokMgBra+t8rz7MHiz9xx9/FHnguEqlwsiRIwvcftiwYahYsaL0un///qhatSp27dpVpP0X1K5du2BqaooJEyboLZ88eTKEENi9e7fech8fH70jF40bN4ZarcbNmzdfuR8nJycMGjRIWmZubo4JEyYgNTUVhw4dKnTtCoUCe/fuxf/+9z9UqlQJP//8MwIDA+Hm5oYBAwYUaoxWx44dCzQuLNvYsWP1Xrdv3x4PHjxASkoKAEin5N5//329dh988EGB9/EqW7ZsgYeHB+rXr4/ExETp0aVLFwBAWFiYXvtX/eyysrKwf/9+9OnTB87OzlK7OnXqoEePHoWu71WfkSH+zogMjUGLyABSU1P1Qs2LBgwYgLZt22LUqFFwdHTEwIEDsXnz5kL9Y1CtWrVCDXyvW7eu3muFQoE6deq8dHySody+fRvOzs65Pg8PDw9pfU6urq65tlGpUiU8evTolfupW7cuTEz0v8Zetp+CUqlU+PjjjxEVFYV79+7h559/Rps2baTTgAVVs2bNQu33xc+hUqVKACB9Drdv34aJiUmu7dapU6dQ+8nPtWvXcOnSJVSpUkXvUa9ePQDPx8TlV3N23dk1JyQkIC0tLc8ai1L3qz4jQ/ydERkax2gRvaa///4bycnJ+f7DYWlpicOHDyMsLAw7d+7Enj178Msvv6BLly7Yt28fTE1NX7mfwoyrKqiXTaqalZVVoJoM4WX7ES8MnDeGqlWrYuDAgfD394enpyc2b96M4ODgAl1RWtifV0n4HHQ6HRo1aoQlS5bkud7FxUXvdXHX/Kr9GeLvjMjQeESL6DWtW7cOAODr65tvOxMTE3Tt2hVLlizB5cuX8dlnn+HAgQPS6RhDzyR/7do1vddCCFy/fl1vUHalSpXyPB324tGgwtTm5uaGe/fu5TqVmj3ZZ/aA89fl5uaGa9eu5TpaYej9AM9PSTZu3BiZmZnS7OTFNfN/Njc3N+h0OsTExOgtv379usH2Ubt2bTx8+BBdu3aFj49Proe7u3uhtufg4AALC4s8a8xrmSE+01f9nREVNwYtotdw4MABzJ07FzVr1sTgwYNf2u7hw4e5lmVP/Jl92XyFChUAwGAzjf/00096YefXX39FbGys3tiY2rVr46+//oJWq5WW7dixI9c0EIWp7a233kJWVha++uorveVLly6FQqEo0ticl+0nLi4Ov/zyi7Ts2bNnWLFiBaytrdGxY8dCb/PatWvQaDS5liclJSE8PByVKlWSrpYz9M/rVbKD/Ndff623fMWKFQbbxzvvvIO7d+/iu+++y7UuLS0NT548KdT2TE1N4ePjg23btuHevXvS8uvXr+caqwc8/0xf5/MsyN8ZUXHjqUOiAtq9ezeuXLmCZ8+eIT4+HgcOHEBISAjc3Nzw559/5jsR5Zw5c3D48GH4+fnBzc0NCQkJ+Prrr1G9enW0a9cOwPPQY2tri9WrV6NixYqoUKECWrduXeixPtns7OzQrl07jBw5EvHx8Vi2bBnq1KmjNwXFqFGj8Ouvv6J79+545513cOPGDaxfvz7XZfWFqe3tt99G586d8fHHH+PWrVto0qQJ9u3bhz/++ANBQUG5tl1UY8aMwTfffIMRI0YgIiICNWrUwK+//opjx45h2bJl+Y6Ze5lz587h3XffRY8ePdC+fXvY2dnh7t27WLt2Le7du4dly5ZJp5+8vLwAAB9//DEGDhwIc3NzvP3221IAMzQvLy/4+/tj2bJlePDggTS9w9WrVwEU/GhQaGgo0tPTcy3v06cPhg4dis2bN2Ps2LEICwtD27ZtkZWVhStXrmDz5s3Yu3ev3qS9BTFr1izs27cPbdu2xbhx46QQ3rBhw1y3dPLy8sL+/fuxZMkSODs7o2bNmmjdunWB91WQvzOiYmfMSx6JSoPs6R2yH0qlUjg5OYk333xTLF++XG8agWwvTu8QGhoqevfuLZydnYVSqRTOzs5i0KBB4urVq3rv++OPP0SDBg2kS9+zp1Po2LGj8PT0zLO+l03v8PPPP4vp06cLBwcHYWlpKfz8/PKcpmDx4sWiWrVqQqVSibZt24rTp0/n2mZ+tb04vYMQQjx+/FhMnDhRODs7C3Nzc1G3bl2xaNEiodPp9NoBEIGBgblqetm0Ey+Kj48XI0eOFPb29kKpVIpGjRrlOQVFQad3iI+PF/PnzxcdO3YUVatWFWZmZqJSpUqiS5cu4tdff83Vfu7cuaJatWrCxMREb6qHl/Ure11e0zu8OCVB9u9dzukjnjx5IgIDA4WdnZ2wtrYWffr0EdHR0QKAmD9/fr59y57e4WWPdevWCSGeT5GxYMEC4enpKVQqlahUqZLw8vISs2fPFsnJyXr9KOjPLjQ0VDRr1kwolUpRu3Zt8f3334vJkycLCwsLvXZXrlwRHTp0EJaWlgKAtJ2CfkYF/TsjKk4KIUrAiFMiIiqSyMhINGvWDOvXr8/39HVJ06dPH1y6dCnXWEKisoZjtIiISom0tLRcy5YtWwYTExN06NDBCBUVzIt1X7t2Dbt27crz1lFEZQ3HaBERlRILFy5EREQEOnfuDDMzM+zevRu7d+/GmDFjck29UJLUqlULI0aMQK1atXD79m2sWrUKSqUSU6dONXZpRLLjqUMiolIiJCQEs2fPxuXLl5GamgpXV1cMHToUH3/8cYHm9jKWkSNHIiwsDHFxcVCpVPD29sbnn3+O5s2bG7s0ItkxaBERERHJhGO0iIiIiGTCoEVEREQkk5J7Ur8E0el0uHfvHipWrFjst90gIiKiohFC4PHjx3B2ds51A/riwqBVAPfu3SvRV/QQERHRy925cwfVq1c3yr4ZtAog+1Yed+7cgVqtNnI1REREVBApKSlwcXEp0i25DIVBqwCyTxeq1WoGLSIiolLGmMN+OBieiIiISCYMWkREREQyYdAiIiIikgmDFhEREZFMGLSIiIiIZMKgRURERCQTBi0iIiIimTBoEREREcmEQYuIiIhIJgxaRERERDJh0CIiIiKSCYMWERERkUwYtIiIiIhkwqBFREREJBMGLSPSaDTQaDTGLoOIiIhkwqBlJBqNBu71PeBe34Nhi4iIqIxi0DKSxMREpKc9RXraUyQmJhq7HCIiIpIBgxYRERGRTBi0iIiIiGTCoEVEREQkEwYtIiIiIpkwaBERERHJhEGLiIiISCYMWkREREQyYdAiIiIikgmDFhEREZFMGLSIiIiIZMKgRURERCQTBi0iIiIimTBoEREREcmEQYuIiIhIJgxaRERERDJh0CIiIiKSCYMWERERkUwYtIiIiIhkwqBFREREJBMGLSIiIiKZGDVorVq1Co0bN4ZarYZarYa3tzd2794trU9PT0dgYCAqV64Ma2tr+Pv7Iz4+Xm8bGo0Gfn5+sLKygoODA6ZMmYJnz57ptTl48CCaN28OlUqFOnXqIDg4uDi6R0REROWcUYNW9erVMX/+fEREROD06dPo0qULevfujUuXLgEAJk6ciO3bt2PLli04dOgQ7t27h379+knvz8rKgp+fH7RaLY4fP461a9ciODgYM2bMkNrExMTAz88PnTt3RmRkJIKCgjBq1Cjs3bu32PtLRERE5YtCCCGMXUROdnZ2WLRoEfr3748qVapg48aN6N+/PwDgypUr8PDwQHh4ONq0aYPdu3ejZ8+euHfvHhwdHQEAq1evxrRp03D//n0olUpMmzYNO3fuxMWLF6V9DBw4EElJSdizZ0+BakpJSYGNjQ2Sk5OhVqsN0s8zZ87Ay8sLABAREYHmzZsbZLtERET0nBz/fhdWiRmjlZWVhU2bNuHJkyfw9vZGREQEMjMz4ePjI7WpX78+XF1dER4eDgAIDw9Ho0aNpJAFAL6+vkhJSZGOioWHh+ttI7tN9jbykpGRgZSUFL0HERERUWEZPWhduHAB1tbWUKlUGDt2LH7//Xc0aNAAcXFxUCqVsLW11Wvv6OiIuLg4AEBcXJxeyMpen70uvzYpKSlIS0vLs6Z58+bBxsZGeri4uBiiq0RERFTOGD1oubu7IzIyEidOnMC4ceMwfPhwXL582ag1TZ8+HcnJydLjzp07Rq2HiIiISiczYxegVCpRp04dAICXlxdOnTqF5cuXY8CAAdBqtUhKStI7qhUfHw8nJycAgJOTE06ePKm3veyrEnO2efFKxfj4eKjValhaWuZZk0qlgkqlMkj/iIiIqPwy+hGtF+l0OmRkZMDLywvm5uYIDQ2V1kVHR0Oj0cDb2xsA4O3tjQsXLiAhIUFqExISArVajQYNGkhtcm4ju032NoiIiIjkYtQjWtOnT0ePHj3g6uqKx48fY+PGjTh48CD27t0LGxsbBAQEYNKkSbCzs4NarcYHH3wAb29vtGnTBgDQrVs3NGjQAEOHDsXChQsRFxeHTz75BIGBgdIRqbFjx+Krr77C1KlT8d577+HAgQPYvHkzdu7cacyuExERUTlg1KCVkJCAYcOGITY2FjY2NmjcuDH27t2LN998EwCwdOlSmJiYwN/fHxkZGfD19cXXX38tvd/U1BQ7duzAuHHj4O3tjQoVKmD48OGYM2eO1KZmzZrYuXMnJk6ciOXLl6N69er4/vvv4evrW+z9JSIiovKlxM2jVRJxHi0iIqLSh/NoEREREZVhDFpEREREMmHQIiIiIpIJgxYRERGRTBi0iIiIiGTCoEVEREQkEwatEiAqKgoajcbYZRAREZGBMWgZm0KBIUOGwL2+B8MWERFRGcOgZWxCwMZ7ANLTniIxMdHY1RAREZEBMWiVAKY2DsYugYiIiGTAoEVEREQkEwYtIiIiIpkwaBERERHJhEGLiIiISCYMWkREREQyYdAiIiIikgmDFhEREZFMGLSIiIiIZMKgRURERCQTBi0iIiIimTBoGYFGo0FUVJSxyyAiIiKZmRm7gPJGo9HAvb4H0tOeGrsUIiIikhmPaBWzxMREpKc9hXWjN41dChEREcmMQctITKztjF0CERERyYxBi4iIiEgmDFpEREREMmHQIiIiIpIJgxYRERGRTBi0iIiIiGTCoEVEREQkEwYtIiIiIpkwaBERERHJhEGLiIiISCYMWkREREQyYdAiIiIikgmDFhEREZFMGLSIiIiIZMKgRURERCQTBi0iIiIimTBoEREREcmEQYuIiIhIJgxaRERERDJh0CIiIiKSiVGD1rx589CyZUtUrFgRDg4O6NOnD6Kjo/XadOrUCQqFQu8xduxYvTYajQZ+fn6wsrKCg4MDpkyZgmfPnum1OXjwIJo3bw6VSoU6deogODhY7u4RERFROWfUoHXo0CEEBgbir7/+QkhICDIzM9GtWzc8efJEr93o0aMRGxsrPRYuXCity8rKgp+fH7RaLY4fP461a9ciODgYM2bMkNrExMTAz88PnTt3RmRkJIKCgjBq1Cjs3bu32PpKRERE5Y+ZMXe+Z88evdfBwcFwcHBAREQEOnToIC23srKCk5NTntvYt28fLl++jP3798PR0RFNmzbF3LlzMW3aNMyaNQtKpRKrV69GzZo1sXjxYgCAh4cHjh49iqVLl8LX11e+DhIREVG5VqLGaCUnJwMA7Ozs9JZv2LAB9vb2aNiwIaZPn46nT59K68LDw9GoUSM4OjpKy3x9fZGSkoJLly5JbXx8fPS26evri/DwcLm6QkRERGTcI1o56XQ6BAUFoW3btmjYsKG0/N1334WbmxucnZ1x/vx5TJs2DdHR0di6dSsAIC4uTi9kAZBex8XF5dsmJSUFaWlpsLS01FuXkZGBjIwM6XVKSorhOkpERETlRokJWoGBgbh48SKOHj2qt3zMmDHS80aNGqFq1aro2rUrbty4gdq1a8tSy7x58zB79mxZtk1ERETlR4k4dTh+/Hjs2LEDYWFhqF69er5tW7duDQC4fv06AMDJyQnx8fF6bbJfZ4/relkbtVqd62gWAEyfPh3JycnS486dO0XrGBEREZVrRg1aQgiMHz8ev//+Ow4cOICaNWu+8j2RkZEAgKpVqwIAvL29ceHCBSQkJEhtQkJCoFar0aBBA6lNaGio3nZCQkLg7e2d5z5UKhXUarXeg4iIiKiwjBq0AgMDsX79emzcuBEVK1ZEXFwc4uLikJaWBgC4ceMG5s6di4iICNy6dQt//vknhg0bhg4dOqBx48YAgG7duqFBgwYYOnQozp07h7179+KTTz5BYGAgVCoVAGDs2LG4efMmpk6diitXruDrr7/G5s2bMXHiRKP1nYiIiMo+owatVatWITk5GZ06dULVqlWlxy+//AIAUCqV2L9/P7p164b69etj8uTJ8Pf3x/bt26VtmJqaYseOHTA1NYW3tzeGDBmCYcOGYc6cOVKbmjVrYufOnQgJCUGTJk2wePFifP/995zagYiIiGRl1MHwQoh817u4uODQoUOv3I6bmxt27dqVb5tOnTrh7NmzhaqvuMXGxhq7BCIiIjKgEjEYvrzLSnsMKBTo598fGo3G2OUQERGRgTBolQBCmwYIAW1GOhITE41dDhERERkIgxYRERGRTBi0iIiIiGTCoEVEREQkEwYtIiIiIpkwaBERERHJhEGLiIiISCYMWkREREQyYdAiIiIikgmDFhEREZFMGLSIiIiIZMKgRURERCQTBi0iIiIimTBoEREREcmEQYuIiIhIJgxaRERERDJh0CIiIiKSCYMWERERkUwYtIiIiIhkwqBFREREJBMGLSIiIiKZMGgRERERyYRBi4iIiEgmDFolTFRUFDQajbHLICIiIgNg0CpJFAoMGTIE7vU9GLaIiIjKAAatkkQI2HgPQHraUyQmJhq7GiIiInpNDFoljKmNg7FLICIiIgNh0CIiIiKSCYMWERERkUwYtIiIiIhkwqBFREREJBMGLSIiIiKZMGgRERERyYRBi4iIiEgmDFpEREREMmHQIiIiIpIJgxYRERGRTBi0iIiIiGTCoEVEREQkEwYtIiIiIpkwaBERERHJhEGLiIiISCYMWkREREQyMWrQmjdvHlq2bImKFSvCwcEBffr0QXR0tF6b9PR0BAYGonLlyrC2toa/vz/i4+P12mg0Gvj5+cHKygoODg6YMmUKnj17ptfm4MGDaN68OVQqFerUqYPg4GC5u0dERETlnFGD1qFDhxAYGIi//voLISEhyMzMRLdu3fDkyROpzcSJE7F9+3Zs2bIFhw4dwr1799CvXz9pfVZWFvz8/KDVanH8+HGsXbsWwcHBmDFjhtQmJiYGfn5+6Ny5MyIjIxEUFIRRo0Zh7969xdpfIiIiKmdECZKQkCAAiEOHDgkhhEhKShLm5uZiy5YtUpuoqCgBQISHhwshhNi1a5cwMTERcXFxUptVq1YJtVotMjIyhBBCTJ06VXh6eurta8CAAcLX17dAdSUnJwsAIjk5+bX6J4QQERERAoBQew8QAHI9t+v+gQAgIiIiXntfRERE5Zkh//0uqiId0bp586ZhUt4LkpOTAQB2dnYAgIiICGRmZsLHx0dqU79+fbi6uiI8PBwAEB4ejkaNGsHR0VFq4+vri5SUFFy6dElqk3Mb2W2yt/GijIwMpKSk6D2IiIiICqtIQatOnTro3Lkz1q9fj/T0dIMUotPpEBQUhLZt26Jhw4YAgLi4OCiVStja2uq1dXR0RFxcnNQmZ8jKXp+9Lr82KSkpSEtLy1XLvHnzYGNjIz1cXFwM0kciIiIqX4oUtM6cOYPGjRtj0qRJcHJywr///W+cPHnytQoJDAzExYsXsWnTptfajiFMnz4dycnJ0uPOnTvGLomIiIhKoSIFraZNm2L58uW4d+8efvzxR8TGxqJdu3Zo2LAhlixZgvv37xdqe+PHj8eOHTsQFhaG6tWrS8udnJyg1WqRlJSk1z4+Ph5OTk5SmxevQsx+/ao2arUalpaWuepRqVRQq9V6DyIiIqLCeq2rDs3MzNCvXz9s2bIFCxYswPXr1/HRRx/BxcUFw4YNQ2xsbL7vF0Jg/Pjx+P3333HgwAHUrFlTb72XlxfMzc0RGhoqLYuOjoZGo4G3tzcAwNvbGxcuXEBCQoLUJiQkBGq1Gg0aNJDa5NxGdpvsbRARERHJ4bWC1unTp/H++++jatWqWLJkCT766CPcuHEDISEhuHfvHnr37p3v+wMDA7F+/Xps3LgRFStWRFxcHOLi4qRxUzY2NggICMCkSZMQFhaGiIgIjBw5Et7e3mjTpg0AoFu3bmjQoAGGDh2Kc+fOYe/evfjkk08QGBgIlUoFABg7dixu3ryJqVOn4sqVK/j666+xefNmTJw48XW6T0RERJS/olyquHjxYtGwYUNhbm4uevfuLbZv3y6ysrL02ty5c0eYmprmux38M6XBi481a9ZIbdLS0sT7778vKlWqJKysrETfvn1FbGys3nZu3bolevToISwtLYW9vb2YPHmyyMzM1GsTFhYmmjZtKpRKpahVq5bePl6F0zsQERGVPiVhegezooSzVatW4b333sOIESNQtWrVPNs4ODjghx9+eFXIe+W+LCwssHLlSqxcufKlbdzc3LBr1658t9OpUyecPXv2lfsjIiIiMpQiBa1r1669so1SqcTw4cOLsnkiIiKiMqFIY7TWrFmDLVu25Fq+ZcsWrF279rWLIiIiIioLihS05s2bB3t7+1zLHRwc8Pnnn792UURERERlQZGClkajyTUVA/B8rJRGo3ntooiIiIjKgiIFLQcHB5w/fz7X8nPnzqFy5cqvXRQRERFRWVCkoDVo0CBMmDABYWFhyMrKQlZWFg4cOIAPP/wQAwcONHSNRERERKVSka46nDt3Lm7duoWuXbvCzOz5JnQ6HYYNG8YxWkRERET/KFLQUiqV+OWXXzB37lycO3cOlpaWaNSoEdzc3AxdX7n1qtsXERERUclXpKCVrV69eqhXr56haiEAWWmPAYUC/fz749rVaLi6uhq7JCIiIiqiIgWtrKwsBAcHIzQ0FAkJCdDpdHrrDxw4YJDiyiOhTQOEgDYjHYmJiQxaREREpViRgtaHH36I4OBg+Pn5oWHDhlAoFIaui4iIiKjUK1LQ2rRpEzZv3oy33nrL0PUQERERlRlFmt5BqVSiTp06hq6FiIiIqEwpUtCaPHkyli9fDiGEoeshIiIiKjOKdOrw6NGjCAsLw+7du+Hp6Qlzc3O99Vu3bjVIcURERESlWZGClq2tLfr27WvoWoiIiIjKlCIFrTVr1hi6DiIiIqIyp0hjtADg2bNn2L9/P7755hs8fvwYAHDv3j2kpqYarDgiIiKi0qxIR7Ru376N7t27Q6PRICMjA2+++SYqVqyIBQsWICMjA6tXrzZ0nURERESlTpGOaH344Ydo0aIFHj16BEtLS2l53759ERoaarDiiIiIiEqzIh3ROnLkCI4fPw6lUqm3vEaNGrh7965BCiMiIiIq7Yp0REun0yErKyvX8r///hsVK1Z87aKIiIiIyoIiBa1u3bph2bJl0muFQoHU1FTMnDmTt+UxoKioKGg0GmOXQUREREVUpFOHixcvhq+vLxo0aID09HS8++67uHbtGuzt7fHzzz8busbySaHAkCFDYGFphegrUXB1dTV2RURERFRIRQpa1atXx7lz57Bp0yacP38eqampCAgIwODBg/UGx9NrEAI23gOQHP4LEhMTGbSIiIhKoSIFLQAwMzPDkCFDDFkLvcDUxsHYJRAREdFrKFLQ+umnn/JdP2zYsCIVQ0RERFSWFCloffjhh3qvMzMz8fTpUyiVSlhZWTFoEREREaGIVx0+evRI75Gamoro6Gi0a9eOg+FlEBsba+wSiIiIqAiKfK/DF9WtWxfz58/PdbSLii4r7TGgUKCff39O80BERFQKGSxoAc8HyN+7d8+QmyzXhDYNEALajHQkJiYauxwiIiIqpCKN0frzzz/1XgshEBsbi6+++gpt27Y1SGFEREREpV2RglafPn30XisUClSpUgVdunTB4sWLDVEXERERUalXpKCl0+kMXQcRERFRmWPQMVpERERE9P+KdERr0qRJBW67ZMmSouyCiIiIqNQrUtA6e/Yszp49i8zMTLi7uwMArl69ClNTUzRv3lxqp1AoDFMlERERUSlUpKD19ttvo2LFili7di0qVaoE4PkkpiNHjkT79u0xefJkgxZJREREVBoVaYzW4sWLMW/ePClkAUClSpXwv//9j1cdEhEREf2jSEErJSUF9+/fz7X8/v37ePz48WsXRURERFQWFClo9e3bFyNHjsTWrVvx999/4++//8Zvv/2GgIAA9OvXz9A1EhEREZVKRRqjtXr1anz00Ud49913kZmZ+XxDZmYICAjAokWLDFogERERUWlVpKBlZWWFr7/+GosWLcKNGzcAALVr10aFChUMWhwRERFRafZaE5bGxsYiNjYWdevWRYUKFSCEKNT7Dx8+jLfffhvOzs5QKBTYtm2b3voRI0ZAoVDoPbp3767X5uHDhxg8eDDUajVsbW0REBCA1NRUvTbnz59H+/btYWFhARcXFyxcuLBI/SUiIiIqjCIFrQcPHqBr166oV68e3nrrLcTGxgIAAgICCjW1w5MnT9CkSROsXLnypW26d+8uBbrY2Fj8/PPPeusHDx6MS5cuISQkBDt27MDhw4cxZswYaX1KSgq6desGNzc3REREYNGiRZg1axa+/fbbQvaaiIiIqHCKdOpw4sSJMDc3h0ajgYeHh7R8wIABmDRpUoGneOjRowd69OiRbxuVSgUnJ6c810VFRWHPnj04deoUWrRoAQBYsWIF3nrrLXzxxRdwdnbGhg0boNVq8eOPP0KpVMLT0xORkZFYsmSJXiAjIiIiMrQiHdHat28fFixYgOrVq+str1u3Lm7fvm2QwrIdPHgQDg4OcHd3x7hx4/DgwQNpXXh4OGxtbaWQBQA+Pj4wMTHBiRMnpDYdOnSAUqmU2vj6+iI6OhqPHj3Kc58ZGRlISUnRexAREREVVpGC1pMnT2BlZZVr+cOHD6FSqV67qGzdu3fHTz/9hNDQUCxYsACHDh1Cjx49kJWVBQCIi4uDg4OD3nvMzMxgZ2eHuLg4qY2jo6Nem+zX2W1eNG/ePNjY2EgPFxcXg/WJiIiIyo8iBa327dvjp59+kl4rFArodDosXLgQnTt3NlhxAwcORK9evdCoUSP06dMHO3bswKlTp3Dw4EGD7SMv06dPR3JysvS4c+eOrPsjIiKisqlIY7QWLlyIrl274vTp09BqtZg6dSouXbqEhw8f4tixY4auUVKrVi3Y29vj+vXr6Nq1K5ycnJCQkKDX5tmzZ3j48KE0rsvJyQnx8fF6bbJfv2zsl0qlMuiROSIiIiqfinREq2HDhrh69SratWuH3r1748mTJ+jXrx/Onj2L2rVrG7pGyd9//40HDx6gatWqAABvb28kJSUhIiJCanPgwAHodDq0bt1aanP48GFpYlUACAkJgbu7u969GomIiIgMrdBHtDIzM9G9e3esXr0aH3/88WvtPDU1FdevX5dex8TEIDIyEnZ2drCzs8Ps2bPh7+8PJycn3LhxA1OnTkWdOnXg6+sLAPDw8ED37t0xevRorF69GpmZmRg/fjwGDhwIZ2dnAMC7776L2bNnIyAgANOmTcPFixexfPlyLF269LVqJyIiInqVQh/RMjc3x/nz5w2y89OnT6NZs2Zo1qwZAGDSpElo1qwZZsyYAVNTU5w/fx69evVCvXr1EBAQAC8vLxw5ckTvtN6GDRtQv359dO3aFW+99RbatWunN0eWjY0N9u3bh5iYGHh5eWHy5MmYMWMGp3YgIiIi2RVpjNaQIUPwww8/YP78+a+1806dOuU7m/zevXtfuQ07Ozts3Lgx3zaNGzfGkSNHCl1fSRIVFQV7e3u4uroauxQiIiIqoCIFrWfPnuHHH3/E/v374eXlleseh0uWLDFIcfQPhQJDhgyBhaUVoq9EMWwRERGVEoUKWjdv3kSNGjVw8eJFNG/eHABw9epVvTYKhcJw1dFzQsDGewCSw39BYmIigxYREVEpUaigVbduXcTGxiIsLAzA81vufPnll7kmBCXDM7VxeHUjIiIiKlEKNRj+xfFUu3fvxpMnTwxaEBEREVFZUaR5tLLlN5CdiIiIqLwrVNBSKBS5xmBxTBYRERFR3go1RksIgREjRkjzWKWnp2Ps2LG5rjrcunWr4SokIiIiKqUKFbSGDx+u93rIkCEGLYaIiIioLClU0FqzZo1cdRARERGVOa81GJ6IiIiIXo5Bi4iIiEgmDFpEREREMmHQIiIiIpIJgxYRERGRTBi0iIiIiGTCoEVEREQkEwatUiY2NtbYJRAREVEBMWiVEllpjwGFAv38+0Oj0Ri7HCIiIioABq1SQmjTACGgzUhHYmKiscshIiKiAmDQIiIiIpIJg1YpFBUVxdOHREREpQCDVmmjUGDIkCFwr+/BsEVERFTCMWiVNkLAxnsA0tOecqwWERFRCcegVQqZ2jgYuwQiIiIqAAYtIiIiIpkwaBERERHJhEGLiIiISCYMWkREREQyYdAiIiIikgmDFhEREZFMGLSKWWxsrLFLICIiomLCoFWMNBoN+vn3N3YZREREVEwYtIpRYmIitBnpxi6DiIiIigmDFhEREZFMGLSIiIiIZMKgVYpxYD0REVHJxqBVCmWlPQYUCvTz7w+NRmPscoiIiOglGLRKIaFNA4SANiMdiYmJxi6HiIiIXoJBi4iIiEgmDFpEREREMmHQIiIiIpIJgxYRERGRTBi0SrmoqCheeUhERFRCGTVoHT58GG+//TacnZ2hUCiwbds2vfVCCMyYMQNVq1aFpaUlfHx8cO3aNb02Dx8+xODBg6FWq2Fra4uAgACkpqbqtTl//jzat28PCwsLuLi4YOHChXJ3rXgoFBgyZAjc63swbBEREZVARg1aT548QZMmTbBy5co81y9cuBBffvklVq9ejRMnTqBChQrw9fVFevr/3y9w8ODBuHTpEkJCQrBjxw4cPnwYY8aMkdanpKSgW7ducHNzQ0REBBYtWoRZs2bh22+/lb1/shMCNt4DkJ72lNM8EBERlUBmxtx5jx490KNHjzzXCSGwbNkyfPLJJ+jduzcA4KeffoKjoyO2bduGgQMHIioqCnv27MGpU6fQokULAMCKFSvw1ltv4YsvvoCzszM2bNgArVaLH3/8EUqlEp6enoiMjMSSJUv0AllpZWrjYOwSiIiI6CVK7BitmJgYxMXFwcfHR1pmY2OD1q1bIzw8HAAQHh4OW1tbKWQBgI+PD0xMTHDixAmpTYcOHaBUKqU2vr6+iI6OxqNHj/Lcd0ZGBlJSUvQeRERERIVVYoNWXFwcAMDR0VFvuaOjo7QuLi4ODg76R3TMzMxgZ2en1yavbeTcx4vmzZsHGxsb6eHi4vL6HSIiIqJyp8QGLWOaPn06kpOTpcedO3eMXRIRERGVQiU2aDk5OQEA4uPj9ZbHx8dL65ycnJCQkKC3/tmzZ3j48KFem7y2kXMfL1KpVFCr1XoPIiIiosIqsUGrZs2acHJyQmhoqLQsJSUFJ06cgLe3NwDA29sbSUlJiIiIkNocOHAAOp0OrVu3ltocPnwYmZmZUpuQkBC4u7ujUqVKxdQbIiIiKo+MGrRSU1MRGRmJyMhIAM8HwEdGRkKj0UChUCAoKAj/+9//8Oeff+LChQsYNmwYnJ2d0adPHwCAh4cHunfvjtGjR+PkyZM4duwYxo8fj4EDB8LZ2RkA8O6770KpVCIgIACXLl3CL7/8guXLl2PSpElG6jURERGVF0ad3uH06dPo3Lmz9Do7/AwfPhzBwcGYOnUqnjx5gjFjxiApKQnt2rXDnj17YGFhIb1nw4YNGD9+PLp27QoTExP4+/vjyy+/lNbb2Nhg3759CAwMhJeXF+zt7TFjxowyMbUDERERlWxGDVqdOnWCEOKl6xUKBebMmYM5c+a8tI2dnR02btyY734aN26MI0eOFLnO0iA2NtbYJRAREdELSuwYLSqYrLTHgEKBfv79eRseIiKiEoZBq5QT2jRACGgz0nkbHiIiohKGQYuIiIhIJgxaRERERDJh0CIiIiKSCYMWERERkUwYtIiIiIhkYtR5tMoijUaDxMRE2Nvbw9XV1djlEBERkRExaBmQRqOBe30PpKc9hYWlFaKvRDFsERERlWM8dWhAiYmJSE97ChvvAUhPe2qUea00Gg0nLiUiIiohGLQMKPs2OKY2Dkbbv3t9D7jX92DYIiIiKgEYtAxEo9Ggn39/o9Zw9uxZpKc9NdrRNCIiItLHoGUgiYmJ0Gak6y0r1hs9KxT49NNPi29/RERE9EoMWjLI60bPGo0GUVFR8u1UCFg3elO+7RMREVGh8apDGeR1o+fsqxHlZGJtJ+v2iYiIqHB4RKsYZF+NyCNORERE5QuDVjHiESciIqLyhUGLiIiISCYMWsWgWK8+JCIiohKDQUtmR44cQd9+/sYug4iIiIyAVx3KSaFAUFCQsasgIiIiI+ERLQN46RxZnNuKiIioXOMRrdek0WjynSPLWFcaRkVFwd7eHq6urkbZPxEREfGI1msrkXNkKRQYMmQIby5NRERkZAxaBlKi5sgSAjbeA3hzaSIiIiNj0CqjTG0cjF0CERFRucegRURERCQTBi0iIiIimTBolXGxsbE4c+YMB8UTEREZAad3KOP6+feHNiMdFpZWiL4SxekeiIiIihGPaJVx2ox0XoFIRERkJAxa5UD2FYi8uTUREVHxYtAqo7LSHus/VyjQz78/x2oREREVIwatMkpo0/SfCwFtRjpPHxIRERUjBi0iIiIimTBoEREREcmEQauciYqK4jgtIiKiYsKgVZ4oFBgyZAjc63swbBERERUDBq3yRAjOqUVERFSMGLTKmew5tYiIiEh+DFrlFCcvJSIikh+DVjnDyUuJiIiKD4NWOcPJS4mIiIpPiQ5as2bNgkKh0HvUr19fWp+eno7AwEBUrlwZ1tbW8Pf3R3x8vN42NBoN/Pz8YGVlBQcHB0yZMgXPnj0r7q4QERFROWRm7AJexdPTE/v375dem5n9f8kTJ07Ezp07sWXLFtjY2GD8+PHo168fjh07BgDIysqCn58fnJyccPz4ccTGxmLYsGEwNzfH559/Xux9KWmioqJgb28PV1dXY5dCRERUJpX4oGVmZgYnJ6dcy5OTk/HDDz9g48aN6NKlCwBgzZo18PDwwF9//YU2bdpg3759uHz5Mvbv3w9HR0c0bdoUc+fOxbRp0zBr1iwolcri7k7J8c+cWhaWVoi+EsWwRUREJIMSfeoQAK5duwZnZ2fUqlULgwcPlgZwR0REIDMzEz4+PlLb+vXrw9XVFeHh4QCA8PBwNGrUCI6OjlIbX19fpKSk4NKlS8XbkZKGc2oRERHJrkQf0WrdujWCg4Ph7u6O2NhYzJ49G+3bt8fFixcRFxcHpVIJW1tbvfc4OjoiLi4OABAXF6cXsrLXZ697mYyMDGRkZEivU1JSDNSjkoVzahEREcmrRAetHj16SM8bN26M1q1bw83NDZs3b4alpaVs+503bx5mz54t2/ZLGs6pRUREJI8Sf+owJ1tbW9SrVw/Xr1+Hk5MTtFotkpKS9NrEx8dLY7qcnJxyXYWY/TqvcV/Zpk+fjuTkZOlx584dw3akhMieU6tvP3/s3LmT82oREREZWKkKWqmpqbhx4waqVq0KLy8vmJubIzQ0VFofHR0NjUYDb29vAIC3tzcuXLiAhIQEqU1ISAjUajUaNGjw0v2oVCqo1Wq9R1mUPadWZqYWPXv25M2miYiIDKxEB62PPvoIhw4dwq1bt3D8+HH07dsXpqamGDRoEGxsbBAQEIBJkyYhLCwMERERGDlyJLy9vdGmTRsAQLdu3dCgQQMMHToU586dw969e/HJJ58gMDAQKpXKyL0rQTgwnoiISBYleozW33//jUGDBuHBgweoUqUK2rVrh7/++gtVqlQBACxduhQmJibw9/dHRkYGfH198fXXX0vvNzU1xY4dOzBu3Dh4e3ujQoUKGD58OObMmWOsLpVY2QPjOV6LiIjIcEp00Nq0aVO+6y0sLLBy5UqsXLnypW3c3Nywa9cuQ5dW5uS8B+K1q9GcV4uIiMgASvSpQyo+Oe+BeOTIEY7VIiIiMgAGLdL3z4zx9eq5SxO/EhERUdEwaJE+IVCxeU9kaDPQqXMXHtkiIiJ6DQxalItCVUE6jcirEImIiIqOQYvyFRUVxaNaRERERcSgRS/3z3gtTmRKRERUNAxa9HKcyJSIiOi1MGhRvrInMiUiIqLCK9ETllLJce7cOQCAvb09JzMlIiIqIAYtyldW2mMAwHsBowChg4WlFaKvRDFsERERFQBPHVK+hDbtnyc6jtciIiIqJAYtKjCO1yIiIiocBi0iIiIimTBoUaHFxsYCADQaDefXIiIiygeD1mvKDh3lQVbaY0ChQN9+/lizZg3quddHvXru2LlzJwMXERFRHnjV4WvQaDTo59/f2GUUG6FNA4RAZqYW77333vOFCgV69uzJqxGJiIjywCNaryExMRHajHRjl1H8hIB1ozel59lXI164cMG4dREREZUwDFpUJCbWdv//QmkJKBTo59+fpxCJiIhyYNCi15Z9SlGbkc45toiIiHJg0CKD49WIREREzzFokUHFxsbCvb4Hr0YkIiICgxYZ2NmzZ5Ge9hQZ2gz07NkT7vU9GLaIiKjcYtAiw1Eo8Omnnz5/nuNqRI7bIiKi8opBiwwn57QP+P97I8bGxuLMmTM8skVEROUOJywlg9Kb9uEf/fz7Q5uRDpXKAmFhB+Dt7W2EyoiIiIofj2iR7LQZ6ajYvCcytBno1LkLj2wREVG5waBFxUKhqiDNtXXkyBGGLSIiKhcYtEg2WWmPcy9UKDBkyBBejUhEROUCgxbJRmjT8liY+96InOCUiIjKKgYtKn7/3Buxbz9/rFmzBvXc6+d5hIsBjIiISjtedUjFLvveiJmZWrz33nvS8iNHjqBWrVqoVq0aAMC9vgcAIPpKFFxdXY1SKxER0etg0CLj+WferdQLIdLYLShMoFSaY+GCBUhPewpAP4AxcBERUWnCoEVGJc27lSN0abVaBAUFPV+eI4CpVCpcjb7CsEVERKUGx2hRifFi6NJ7LnTISE/j7XyIiKhU4REtKpFyzjCf83lUVBQyMjIAACqVChkZGdIpxeyB8zziRUREJQWDFpUe2acRoQAUCkDopDFdq1etwrj3A6FQKDh4noiISgyeOqTSQzqlKAChk04parXPr17MSE9DetpTHDlyBOHh4ZwagoiIjI5HtIpIo9EgKirK2GWUO3meUszn6sWtv/0GOzs7XrFIRERGwaBVBBqNBu71PaTpB8j4Xnb1Ys+ePXNdsajRaJCYmKg3vouIiEgODFpFkJiYiPS0p/9/FIVKlLxCV0Z6Go4cOQIrKysMencwMtLT9I56NWrUSC9wZYcxe3v7Ai0nIiLKC4PWa8h5GotKJulnlHMgPXIf9VKpLPDzzxvh5uaG27dvS2HMwtJKGlwfHh6Ozl26IiM9DSqVBcLCDsDb2xsAAxgREeWNQYvKh5zjuKB/1Kti8554fGYH+vn3f34l4z9hzMZ7AJLDf0FoaCgcHBzQt58/MrUZz9uf3YlOnbvg2tVoAJBOJecMZkRERAxaVG687AikQlXh+ZN/rmSUTgcrLQEA7wWM+ieA5WgvBLQZ6Thy5AhsbW2RnvZUCmYXLlyQglbOI10Ach314txfRERlW7kKWitXrsSiRYsQFxeHJk2aYMWKFWjVqpWxy6ISJGcYE9q0f57o8h6P98/pSHNz5fPXSktAoUDffv74fetv0Gq10ilIpVIFKBTQZqRLpx2rVasG9/oeEDodfvvtV71xYjkDmEajwd27d6FSqQp0ajK/8Paq4EdERIZVboLWL7/8gkmTJmH16tVo3bo1li1bBl9fX0RHR8PBwaFQ24qNjZWpSiqp8jwaluO0I/BPMBMCmZn/XO34zynInG2yTzt27NQZixb+c+NshUJvnJhSqYR//38BQmDVqq8xdtw4aLWZgNDpjSV7cYZ8AHj48KH03t9++xV2dnZSm5xjz3IGP57uJCKST7kJWkuWLMHo0aMxcuRIAMDq1auxc+dO/Pjjj/jPf/5ToG3cuXMHt27dQt9+/nKWSqWIdNoxpxfGg+Vsk33aMTMzx42z8xwnBkChwHvvvSe9N8+xZNkz5Os9hxTecrV5IfjlHIfWpEkTTnlBRGRg5SJoabVaREREYPr06dIyExMT+Pj4IDw8vMDb8WrR8vm0AESv8MorUl8WxnKepixsm4I8xwvh8MVxaC9M9ApAOmUJoNjnH+MYNiIq7cpF0EpMTERWVhYcHR31ljs6OuLKlSu52mdkZEinYgAgOTn5+fL0NKhqNkdGzBkAQFZygtSGz/m8sM9F1rNXLi9sm4I8z7mdZ/dv/9NAJ/1uazMy/jkaZgJAABAwVyoBKJCpzQAUpqhgXQFrfvgeVatWBQDodDqYmJgY9HlsbCwCRo8BBPDD99/Kuq+XPS/u/fE5nxf1uYODA5ycnED6UlJSAABCCOMVIcqBu3fvCgDi+PHjesunTJkiWrVqlav9zJkzn//rwgcffPDBBx98lPrHjRs3iity5FIujmjZ29vD1NQU8fHxesvj4+Pz/B/A9OnTMWnSJOl1UlIS3NzcoNFoYGNjI3u9JUVKSgpcXFxw584dqNVqY5dTbNhv9rs8YL/Z7/IgOTkZrq6u0lAIYygXQUupVMLLywuhoaHo06cPgOeHW0NDQzF+/Phc7VUqFVQqVa7lNjY25eoXNJtarWa/yxH2u3xhv8uX8trvnMMBilu5CFoAMGnSJAwfPhwtWrRAq1atsGzZMjx58kS6CpGIiIjI0MpN0BowYADu37+PGTNmIC4uDk2bNsWePXtyDZAnIiIiMpRyE7QAYPz48XmeKnwVlUqFmTNn5nk6sSxjv9nv8oD9Zr/LA/bbeP1WCGHMax6JiIiIyi7jjQ4jIiIiKuMYtIiIiIhkwqBFREREJBMGLSIiIiKZMGgVwMqVK1GjRg1YWFigdevWOHnypLFLKrB58+ahZcuWqFixIhwcHNCnTx9ER0frtUlPT0dgYCAqV64Ma2tr+Pv755pFX6PRwM/PD1ZWVnBwcMCUKVPw7NkzvTYHDx5E8+bNoVKpUKdOHQQHB8vdvQKbP38+FAoFgoKCpGVltd93797FkCFDULlyZVhaWqJRo0Y4ffq0tF4IgRkzZqBq1aqwtLSEj48Prl27preNhw8fYvDgwVCr1bC1tUVAQABSU1P12pw/fx7t27eHhYUFXFxcsHDhwmLpX16ysrLw6aefombNmrC0tETt2rUxd+5cvfublYV+Hz58GG+//TacnZ2hUCiwbds2vfXF2cctW7agfv36sLCwQKNGjbBr1y6D9zdbfv3OzMzEtGnT0KhRI1SoUAHOzs4YNmwY7t27p7eNstbvF40dOxYKhQLLli3TW15W+x0VFYVevXrBxsYGFSpUQMuWLaWb0AMl7PvdaDf/KSU2bdoklEql+PHHH8WlS5fE6NGjha2trYiPjzd2aQXi6+sr1qxZIy5evCgiIyPFW2+9JVxdXUVqaqrUZuzYscLFxUWEhoaK06dPizZt2og33nhDWv/s2TPRsGFD4ePjI86ePSt27dol7O3txfTp06U2N2/eFFZWVmLSpEni8uXLYsWKFcLU1FTs2bOnWPubl5MnT4oaNWqIxo0biw8//FBaXhb7/fDhQ+Hm5iZGjBghTpw4IW7evCn27t0rrl+/LrWZP3++sLGxEdu2bRPnzp0TvXr1EjVr1hRpaWlSm+7du4smTZqIv/76Sxw5ckTUqVNHDBo0SFqfnJwsHB0dxeDBg8XFixfFzz//LCwtLcU333xTrP3N9tlnn4nKlSuLHTt2iJiYGLFlyxZhbW0tli9fLrUpC/3etWuX+Pjjj8XWrVsFAPH777/rrS+uPh47dkyYmpqKhQsXisuXL4tPPvlEmJubiwsXLhR7v5OSkoSPj4/45ZdfxJUrV0R4eLho1aqV8PLy0ttGWet3Tlu3bhVNmjQRzs7OYunSpXrrymK/r1+/Luzs7MSUKVPEmTNnxPXr18Uff/yh9+9ySfp+Z9B6hVatWonAwEDpdVZWlnB2dhbz5s0zYlVFl5CQIACIQ4cOCSGef0mZm5uLLVu2SG2ioqIEABEeHi6EeP5Lb2JiIuLi4qQ2q1atEmq1WmRkZAghhJg6darw9PTU29eAAQOEr6+v3F3K1+PHj0XdunVFSEiI6NixoxS0ymq/p02bJtq1a/fS9TqdTjg5OYlFixZJy5KSkoRKpRI///yzEEKIy5cvCwDi1KlTUpvdu3cLhUIh7t69K4QQ4uuvvxaVKlWSPofsfbu7uxu6SwXi5+cn3nvvPb1l/fr1E4MHDxZClM1+v/gPUHH28Z133hF+fn569bRu3Vr8+9//Nmgf85Jf4Mh28uRJAUDcvn1bCFG2+/3333+LatWqiYsXLwo3Nze9oFVW+z1gwAAxZMiQl76npH2/89RhPrRaLSIiIuDj4yMtMzExgY+PD8LDw41YWdElJycDgHSDzYiICGRmZur1sX79+nB1dZX6GB4ejkaNGunNou/r64uUlBRcunRJapNzG9ltjP05BQYGws/PL1dtZbXff/75J1q0aIF//etfcHBwQLNmzfDdd99J62NiYhAXF6dXs42NDVq3bq3Xb1tbW7Ro0UJq4+PjAxMTE5w4cUJq06FDByiVSqmNr68voqOj8ejRI7m7mcsbb7yB0NBQXL16FQBw7tw5HD16FD169ABQdvudU3H2saT93r8oOTkZCoUCtra2AMpuv3U6HYYOHYopU6bA09Mz1/qy2G+dToedO3eiXr168PX1hYODA1q3bq13erGkfb8zaOUjMTERWVlZuW7T4+joiLi4OCNVVXQ6nQ5BQUFo27YtGjZsCACIi4uDUqmUvpCy5exjXFxcnp9B9rr82qSkpCAtLU2O7rzSpk2bcObMGcybNy/XurLa75s3b2LVqlWoW7cu9u7di3HjxmHChAlYu3atXt35/U7HxcXBwcFBb72ZmRns7OwK9dkUp//85z8YOHAg6tevD3NzczRr1gxBQUEYPHiwXk1lrd85FWcfX9bG2J8B8HxszrRp0zBo0CDp5slltd8LFiyAmZkZJkyYkOf6stjvhIQEpKamYv78+ejevTv27duHvn37ol+/fjh06JBUb0n6fi9Xt+Ap7wIDA3Hx4kUcPXrU2KXI7s6dO/jwww8REhICCwsLY5dTbHQ6HVq0aIHPP/8cANCsWTNcvHgRq1evxvDhw41cnXw2b96MDRs2YOPGjfD09ERkZCSCgoLg7OxcpvtN+jIzM/HOO+9ACIFVq1YZuxxZRUREYPny5Thz5gwUCoWxyyk2Op0OANC7d29MnDgRANC0aVMcP34cq1evRseOHY1ZXp54RCsf9vb2MDU1zXWlQnx8PJycnIxUVdGMHz8eO3bsQFhYGKpXry4td3JyglarRVJSkl77nH10cnLK8zPIXpdfG7VaDUtLS0N355UiIiKQkJCA5s2bw8zMDGZmZjh06BC+/PJLmJmZwdHRsUz2u2rVqmjQoIHeMg8PD+lqnOy68/uddnJyQkJCgt76Z8+e4eHDh4X6bIrTlClTpKNajRo1wtChQzFx4kTpaGZZ7XdOxdnHl7Ux5meQHbJu376NkJAQ6WgWUDb7feTIESQkJMDV1VX6jrt9+zYmT56MGjVqSPWWtX7b29vDzMzsld9zJen7nUErH0qlEl5eXggNDZWW6XQ6hIaGwtvb24iVFZwQAuPHj8fvv/+OAwcOoGbNmnrrvby8YG5urtfH6OhoaDQaqY/e3t64cOGC3h9s9hdZ9i+7t7e33jay2xjrc+ratSsuXLiAyMhI6dGiRQsMHjxYel4W+922bdtc03dcvXoVbm5uAICaNWvCyclJr+aUlBScOHFCr99JSUmIiIiQ2hw4cAA6nQ6tW7eW2hw+fBiZmZlSm5CQELi7u6NSpUqy9e9lnj59ChMT/a8zU1NT6X+/ZbXfORVnH0va7312yLp27Rr279+PypUr660vi/0eOnQozp8/r/cd5+zsjClTpmDv3r1SvWWt30qlEi1btsz3e67E/btWqKHz5dCmTZuESqUSwcHB4vLly2LMmDHC1tZW70qFkmzcuHHCxsZGHDx4UMTGxkqPp0+fSm3Gjh0rXF1dxYEDB8Tp06eFt7e38Pb2ltZnXwbbrVs3ERkZKfbs2SOqVKmS52WwU6ZMEVFRUWLlypUlZnqHbDmvOhSibPb75MmTwszMTHz22Wfi2rVrYsOGDcLKykqsX79eajN//nxha2sr/vjjD3H+/HnRu3fvPKcAaNasmThx4oQ4evSoqFu3rt4l4UlJScLR0VEMHTpUXLx4UWzatElYWVkZbXqH4cOHi2rVqknTO2zdulXY29uLqVOnSm3KQr8fP34szp49K86ePSsAiCVLloizZ89KV9cVVx+PHTsmzMzMxBdffCGioqLEzJkzZb3cP79+a7Va0atXL1G9enURGRmp9z2X80q6stbvvLx41WFZ7ffWrVuFubm5+Pbbb8W1a9ekaReOHDkibaMkfb8zaBXAihUrhKurq1AqlaJVq1bir7/+MnZJBQYgz8eaNWukNmlpaeL9998XlSpVElZWVqJv374iNjZWbzu3bt0SPXr0EJaWlsLe3l5MnjxZZGZm6rUJCwsTTZs2FUqlUtSqVUtvHyXBi0GrrPZ7+/btomHDhkKlUon69euLb7/9Vm+9TqcTn376qXB0dBQqlUp07dpVREdH67V58OCBGDRokLC2thZqtVqMHDlSPH78WK/NuXPnRLt27YRKpRLVqlUT8+fPl71vL5OSkiI+/PBD4erqKiwsLEStWrXExx9/rPcPbVnod1hYWJ5/z8OHDxdCFG8fN2/eLOrVqyeUSqXw9PQUO3fuNEq/Y2JiXvo9FxYWVmb7nZe8glZZ7fcPP/wg6tSpIywsLESTJk3Etm3b9LZRkr7fFULkmDqZiIiIiAyGY7SIiIiIZMKgRURERCQTBi0iIiIimTBoEREREcmEQYuIiIhIJgxaRERERDJh0CIiIiKSCYMWURnWqVMnBAUFGbsMozL0ZzBr1iw0bdrUYNvLD39+RKUfgxZRCXL//n2MGzcOrq6uUKlUcHJygq+vL44dOya1USgU2LZtW4G2t3XrVsydO1emav9fSQgEBw8ehEKhyHUjWUP76KOPct3/rCi0Wi0WLlyIJk2awMrKCvb29mjbti3WrFmjd9+5kio4OBi2trbGLoOoxDMzdgFE9P/8/f2h1Wqxdu1a1KpVC/Hx8QgNDcWDBw8KtR2tVgulUgk7OzuZKi2/rK2tYW1t/Vrb0Gq18PX1xblz5zB37ly0bdsWarUaf/31F7744gs0a9ZMtqNmWVlZUCgUuW7CbSwlrR4igyv0TXuISBaPHj0SAMTBgwdf2sbNzU3v3l9ubm5CCCFmzpwpmjRpIr777jtRo0YNoVAohBC57+/o5uYmPvvsMzFy5EhhbW0tXFxcct0Q+dixY6JJkyZCpVIJLy8v8fvvvwsA4uzZsy+t68X9vOjIkSOiXbt2wsLCQlSvXl188MEHIjU11WB15XW/u+z7onXs2FF88MEHYsqUKaJSpUrC0dFRzJw5U9quTqcTM2fOFC4uLkKpVIqqVauKDz744KV9yf6ssw0fPlz07t1bLFq0SDg5OQk7Ozvx/vvvC61W+9JtLFiwQJiYmIgzZ87kWqfVaqXP5lW1CyHE4sWLRcOGDYWVlZWoXr26GDdunN697NasWSNsbGzEH3/8ITw8PISpqamIiYkRJ0+eFD4+PqJy5cpCrVaLDh06iIiICL1tP3r0SIwZM0Y4ODgIlUolPD09xfbt2/O8F112Xenp6WLy5MnC2dlZWFlZiVatWundc/Bl9RCVVQxaRCVEZmamsLa2FkFBQSI9PT3PNgkJCdJNwWNjY0VCQoIQ4vk//hUqVBDdu3cXZ86cEefOnRNC5B207OzsxMqVK8W1a9fEvHnzhImJibhy5YoQQojk5GRhZ2cnhgwZIi5duiR27dol6tWr91pB6/r166JChQpi6dKl4urVq+LYsWOiWbNmYsSIEQar69mzZ+K3334TAER0dLSIjY0VSUlJUm1qtVrMmjVLXL16Vaxdu1YoFAqxb98+IYQQW7ZsEWq1WuzatUvcvn1bnDhxIteNuHPKK2ip1WoxduxYERUVJbZv3y6srKzy3Ubjxo1Ft27dXro+5+eaX+1CCLF06VJx4MABERMTI0JDQ4W7u7sYN26ctH7NmjXC3NxcvPHGG+LYsWPiypUr4smTJyI0NFSsW7dOREVFicuXL4uAgADh6OgoUlJShBBCZGVliTZt2ghPT0+xb98+cePGDbF9+3axa9cukZGRIZYtWybUarWIjY0VsbGxUrgbNWqUeOONN8Thw4fF9evXxaJFi4RKpRJXr17Ntx6isopBi6gE+fXXX0WlSpWEhYWFeOONN8T06dOl0JQNgPj999/1ls2cOVOYm5tLwStbXkFryJAh0mudTiccHBzEqlWrhBBCrFq1SlSuXFmkpaVJbb777rvXCloBAQFizJgxesuOHDkiTExMpP0Yoq7soyyPHj3KVVu7du30lrVs2VJMmzZNCPH8iFC9evXyPQKVU15By83NTTx79kxa9q9//UsMGDDgpduwtLQUEyZMeOW+XlV7XrZs2SIqV64svV6zZo0AICIjI/PdV1ZWlqhYsaLYvn27EEKIvXv3ChMTExEdHZ1n++wjUzndvn1bmJqairt37+ot79q1q5g+fXqh6iEqK3hSnKgE8ff3x7179/Dnn3+ie/fuOHjwIJo3b47g4OBXvtfNzQ1VqlR5ZbvGjRtLzxUKBZycnJCQkAAAiI6ORuPGjWFhYSG1adWqVeE7ksO5c+cQHBwsjW2ytraGr68vdDodYmJiiqWunNsGgKpVq0rb/te//oW0tDTUqlULo0ePxu+//45nz54Vqo+enp4wNTXNc/t5EUIYpHYA2L9/P7p27Ypq1aqhYsWKGDp0KB48eICnT59KbZRKZa7txMfHY/To0ahbty5sbGygVquRmpoKjUYDAIiMjET16tVRr169Atd64cIFZGVloV69eno/70OHDuHGjRv51kNUVnEwPFEJY2FhgTfffBNvvvkmPv30U4waNQozZ87EiBEj8n1fhQoVCrR9c3NzvdcKhQI6na6o5b5Samoq/v3vf2PChAm51rm6uhZLXflt28XFBdHR0di/fz9CQkLw/vvvY9GiRTh06FCu9xVl+3mpV68erly58trbvnXrFnr27Ilx48bhs88+g52dHY4ePYqAgABotVpYWVkBACwtLaFQKPS2M3z4cDx48ADLly+Hm5sbVCoVvL29odVqpfcUVmpqKkxNTREREaEXPAHoXUCQVz1EZRWPaBGVcA0aNMCTJ0+k1+bm5sjKypJlX+7u7rhw4QIyMjKkZadOnXqtbTZv3hyXL19GnTp1cj2USqXB6sreVlE+G0tLS7z99tv48ssvcfDgQYSHh+PChQuF3k5Bvfvuu9i/fz/Onj2ba11mZqbezzs/ERER0Ol0WLx4Mdq0aYN69erh3r17BXrvsWPHMGHCBLz11lvw9PSESqVCYmKitL5x48b4+++/cfXq1Tzfr1Qqc33WzZo1Q1ZWFhISEnL9rJ2cnApUF1FZw6BFVEI8ePAAXbp0wfr163H+/HnExMRgy5YtWLhwIXr37i21q1GjBkJDQxEXF4dHjx4ZtIZ3330XOp0OY8aMQVRUFPbu3YsvvvgCAF55BOL+/fuIjIzUe8THx2PatGk4fvw4xo8fj8jISFy7dg1//PEHxo8fb9C63NzcoFAosGPHDty/fx+pqakF2nZwcDB++OEHXLx4ETdv3sT69ethaWkJNze3AtdXWEFBQWjbti26du2KlStX4ty5c7h58yY2b96MNm3a4Nq1awXaTp06dZCZmYkVK1bg5s2bWLduHVavXl2g99atWxfr1q1DVFQUTpw4gcGDB+sdxerYsSM6dOgAf39/hISEICYmBrt378aePXsAPP89TE1NRWhoKBITE/H06VPUq1cPgwcPxrBhw7B161bExMTg5MmTmDdvHnbu3Fn4D4qoDGDQIiohrK2t0bp1ayxduhQdOnRAw4YN8emnn2L06NH46quvpHaLFy9GSEgIXFxc0KxZM4PWoFarsX37dkRGRqJp06b4+OOPMWPGDADQGx+Vl40bN6JZs2Z6j++++w6NGzfGoUOHcPXqVbRv3x7NmjXDjBkz4OzsbNC6qlWrhtmzZ+M///kPHB0dCxzkbG1t8d1336Ft27Zo3Lgx9u/fj+3bt6Ny5coFrq+wVCoVQkJCMHXqVHzzzTdo06YNWrZsiS+//BITJkxAw4YNC7SdJk2aYMmSJViwYAEaNmyIDRs2YN68eQV67w8//IBHjx6hefPmGDp0KCZMmAAHBwe9Nr/99htatmyJQYMGoUGDBpg6dap0FOuNN97A2LFjMWDAAFSpUgULFy4EAKxZswbDhg3D5MmT4e7ujj59+uDUqVN6p4mJyhOFKMyoTCIqdzZs2ICRI0ciOTm5SON25FJS6yIiyomD4YlIz08//YRatWqhWrVqOHfuHKZNm4Z33nnH6GGmpNZFRJQfBi0i0hMXF4cZM2YgLi4OVatWxb/+9S989tlnxi6rxNZFRJQfnjokIiIikgkHwxMRERHJhEGLiIiISCYMWkREREQyYdAiIiIikgmDFhEREZFMGLSIiIiIZMKgRURERCQTBi0iIiIimTBoEREREcnk/wDCWssUpchb/AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a histogram\n",
    "plt.hist(doc_lengths, bins='auto', edgecolor='black')\n",
    "plt.xlim([0,16000])\n",
    "# Add labels and title\n",
    "plt.xlabel('String Lengths in Character')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of String Lengths')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Steven what have you done you have hit an all new low. It is weird since Steven's last film shadow man was directed by the same director who did this trash. Shadow man was good this was diabolically bad so bad it wasn't even funny Steven is hardly in the movie and feels like he is in a cameo appearance and when he is in the film he is dubbed half the time anyway. As for the action well let's just say the wizard of oz had more action than this trash there is hardly any action in the film and when it does finally arrive it is boring depressing badly shot so called action scenes. Seagal hardly kills anyone unlike his over films where he goes one man army ie under siege 1 and 2 and exit wounds. the plot is so confusing with so many plot holes that it doesn't make scenes sometimes. flight of fury better be good what a shame i wasted 5 pounds on this garbage 0 out of ten better luck next time\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_token_lengths = np.array([len(tokenizer.tokenize(df['Content'].values[i])) for i in df.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2986"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(doc_token_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a histogram\n",
    "plt.hist(doc_token_lengths, bins='auto', edgecolor='black')\n",
    "plt.xlim([0,3500])\n",
    "# Add labels and title\n",
    "plt.xlabel('String Lengths in Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of String Lengths')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' '\n",
    "all_chars = set(''.join(char_set).join(allowed_chars))\n",
    "vocab_dict = {c:i for i, c in enumerate(all_chars)}\n",
    "if '\\x01' not in vocab_dict:\n",
    "    vocab_dict['\\x01'] = len(vocab_dict)\n",
    "char_Set = set(vocab_dict.keys())\n",
    "num_embedding = len(vocab_dict)\n",
    "vocab_dict_rev = dict(zip(list(vocab_dict.values()), list(vocab_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterandTokenLevelCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, num_classes, char_dict, token_dict, sentiment_dict, tokenizer, shuffle=True, batch_size=128) -> None:\n",
    "        super().__init__()\n",
    "        # y = y[indices].values\n",
    "        # y = torch.from_numpy(np.array([class_id[c] for c in y], dtype=np.longlong))\n",
    "        \n",
    "        # print(f'self.num_sections1: {len(y) // batch_size}')\n",
    "        \n",
    "        if len(y) % batch_size != 0:\n",
    "            self.shortage = ((len(y) // batch_size)+1)*batch_size - len(y)\n",
    "            empty_labels = [i%2 for i in range(self.shortage)]\n",
    "            empty_strings = [id_class[l] for l in empty_labels]\n",
    "            \n",
    "            # print(f'y1 - {y.shape}: {y}')\n",
    "            y = np.concatenate([y, empty_labels])\n",
    "            # print(f'y2 - {y.shape}: {y}')\n",
    "            # print(f'X1 - {X.shape}: {X}')\n",
    "            X = np.concatenate([X, empty_strings])\n",
    "        #     print(f'X2 - {X.shape}: {X}')\n",
    "        \n",
    "        # print(f'self.num_sections2: {len(y) // batch_size}')\n",
    "        \n",
    "        y = torch.from_numpy(y)\n",
    "        self.shuffle = shuffle\n",
    "        self.y = torch.nn.functional.one_hot(y, num_classes=num_classes).float()\n",
    "        self.X = X\n",
    "        self.char_dict = char_dict\n",
    "        self.char_Set = set(char_dict.keys())\n",
    "        self.vocab_size = len(self.char_dict)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_dict = token_dict\n",
    "        self.sentiment_dict = sentiment_dict\n",
    "        self.max_token_count = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.all_data = []\n",
    "        self.token_lengths = []\n",
    "        self.token_embeddign_ids = []\n",
    "        \n",
    "        self.sum_a = 0\n",
    "        \n",
    "        for doc in tqdm(self.X):\n",
    "            # tokens = self.tokenizer(''.join(c for c in doc if c in self.char_Set))\n",
    "            # tokens = [t.text for t in tokens]\n",
    "            tokens = self.tokenizer(doc)\n",
    "            if len(tokens) == 0:\n",
    "                tokens = ['empty']\n",
    "                            \n",
    "            token_lengths = [len(t) for t in tokens]\n",
    "            tokens.append('\\x01')\n",
    "            \n",
    "            token_lengths.append(len(tokens[-1])-1)\n",
    "            token_lengths = torch.from_numpy(np.array(token_lengths, dtype=np.longlong))+1\n",
    "            token_embs = [self.token_dict[t] if t in self.token_dict else torch.zeros((64, ), dtype=torch.float32) for t in tokens]\n",
    "            token_sentiments = [self.sentiment_dict[t] if t in self.sentiment_dict else (0.0, 0.0) for t in tokens]\n",
    "            token_embs = torch.from_numpy(np.array(token_embs, dtype=np.float32))\n",
    "            token_sentiments = torch.from_numpy(np.array(token_sentiments, dtype=np.float32))\n",
    "            doc = ' '.join(tokens)\n",
    "            characters = torch.from_numpy(np.array([self.char_dict[t] for t in doc], dtype=np.longlong))\n",
    "            token_positions = torch.arange(len(token_lengths), dtype=torch.long)\n",
    "            token_indices = torch.repeat_interleave(token_positions, token_lengths)\n",
    "            num_tokens = len(token_lengths)\n",
    "            if num_tokens > self.max_token_count:\n",
    "                self.max_token_count = num_tokens\n",
    "            g_data = Data(x=characters,\n",
    "                            token_positions=token_positions,\n",
    "                            character_length = len(characters),\n",
    "                            num_tokens = num_tokens,\n",
    "                            token_indices=token_indices,\n",
    "                            token_lengths=token_lengths,\n",
    "                            token_embeddings=token_embs,\n",
    "                            token_sentiments=token_sentiments)\n",
    "            self.all_data.append(g_data)\n",
    "        \n",
    "        \n",
    "        self.num_sections = len(y) // batch_size\n",
    "        self.x_lengths = np.array([self.all_data[i].character_length for i in range(len(self.all_data))])\n",
    "        self.x_len_args = np.argsort(self.x_lengths)[::-1]\n",
    "        \n",
    "        self.section_ranges = np.linspace(0, len(self.x_len_args), self.num_sections+1)\n",
    "        self.section_ranges = [(int(self.section_ranges[i-1]), int(self.section_ranges[i])) for i in range(1, len(self.section_ranges))]\n",
    "\n",
    "        self.position_j = 0\n",
    "        self.section_i = 0\n",
    "        self.epoch = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "        self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        index = self.get_section_index()\n",
    "        return self.all_data[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def get_section_index(self):\n",
    "        # if self.shuffle:\n",
    "            \n",
    "        #     t_range = self.section_ranges[self.section_i]\n",
    "        #     target_index = np.random.randint(t_range[0], t_range[1])\n",
    "        # else:\n",
    "        #     t_range = self.section_ranges[self.section_i]\n",
    "        #     target_index = t_range[0] + self.each_section_i[self.section_i]\n",
    "        #     self.each_section_i[self.section_i] = (self.each_section_i[self.section_i] + 1) % (t_range[1] - t_range[0])\n",
    "        # print()\n",
    "        # print(f'self.section_i: {self.section_i},   self.position_j: {self.position_j}')\n",
    "        target_index = self.sections[self.section_i, self.position_j]\n",
    "        \n",
    "        self.position_j = (self.position_j + 1) % self.section_size\n",
    "        if self.position_j == 0:\n",
    "            self.section_i = (self.section_i + 1) % self.num_sections\n",
    "            if self.shuffle and self.section_i == 0:\n",
    "                self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "                # random_positions = np.random.choice(np.arange(0, self.section_size), size=self.section_size, replace=False)\n",
    "        # return self.x_len_args[target_index]\n",
    "        return target_index\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.section_i = 0\n",
    "        self.position_j = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "    def split_into_k_groups(self, len_sorted_args, lengths:np.array, k):\n",
    "        if self.shuffle and self.epoch > 0:\n",
    "            randomize_sections = np.concatenate([np.random.choice(np.arange(r[0], r[1]), size=r[1]-r[0], replace=False) for r in self.section_ranges])\n",
    "            len_sorted_args = len_sorted_args[randomize_sections]\n",
    "        \n",
    "        nums = lengths[len_sorted_args]\n",
    "        groups_size = len(len_sorted_args) // k\n",
    "        \n",
    "        \n",
    "        groups = [[] for _ in range(k)]\n",
    "        group_sums = np.zeros(k, dtype=int)\n",
    "        group_sizes = np.zeros(k, dtype=int)\n",
    "        \n",
    "        # print(f'groups_size: {groups_size}')\n",
    "        # print(f'len(len_sorted_args): {len(len_sorted_args)}')\n",
    "        # print(f'k: {k}')\n",
    "        for i, num in enumerate(nums):\n",
    "            candidate_indices = np.where(group_sizes<groups_size)[0]\n",
    "            # print(f'candidate_indices: {candidate_indices}')\n",
    "            min_group_idx = candidate_indices[np.argmin(group_sums[candidate_indices])]\n",
    "            groups[min_group_idx].append(len_sorted_args[i])\n",
    "            group_sums[min_group_idx] += num\n",
    "            group_sizes[min_group_idx] += 1\n",
    "        self.epoch += 1\n",
    "        \n",
    "        groups = np.array(groups)\n",
    "        group_sums_argsort = np.argsort(group_sums)[::-1]\n",
    "        groups = groups[group_sums_argsort]\n",
    "        \n",
    "        # check_x = self.X[groups]\n",
    "        # check_x_lens = [np.sum(np.array([len(sx) for sx in rx])) for rx in check_x]\n",
    "        # print(f'check_x: {check_x}')\n",
    "        \n",
    "        \n",
    "        return np.array(groups), groups_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CharacterandTokenLevelDataLoader(DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        follow_batch: List[str] | None = None,\n",
    "        exclude_keys: List[str] | None = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CharacterandTokenLevelDataLoader, self).__init__(\n",
    "            dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        base_iterator = super(CharacterandTokenLevelDataLoader, self).__iter__()\n",
    "        for batch in base_iterator:\n",
    "            cumsum_vals = torch.cumsum(batch[0].num_tokens, dim=0).roll(1)\n",
    "            cumsum_vals[0] = 0\n",
    "            additions = torch.repeat_interleave(cumsum_vals, batch[0].character_length)\n",
    "            batch[0].cumulative_token_indices = batch[0].token_indices + additions\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def double_tokenizer(doc):\n",
    "#     tokens = t_tokenizer.tokenize(doc)\n",
    "#     tokens = nlp(' '.join(tokens))\n",
    "#     tokens = [t.text for t in tokens]\n",
    "#     return tokens\n",
    "\n",
    "# def nlp_tokenizer(doc):\n",
    "#     tokens = nlp(doc)\n",
    "#     tokens = [t.text for t in tokens]\n",
    "#     return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(df.Content.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'have' in token_vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in tokens if t not in token_vocab_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 35/25088 [00:00<07:54, 52.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 25088/25088 [06:24<00:00, 65.19it/s] \n",
      "100%|| 25088/25088 [05:56<00:00, 70.44it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CharacterandTokenLevelCustomDataset(train_df.Content.values, train_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, batch_size=batch_size)\n",
    "test_dataset = CharacterandTokenLevelCustomDataset(test_df.Content.values, test_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, batch_size=batch_size)\n",
    "max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=False)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[12420], token_positions=[2098], character_length=12420, num_tokens=2098, token_indices=[12420], token_lengths=[2098], token_embeddings=[2098, 64], token_sentiments=[2098, 2]),\n",
       " tensor([0., 1.]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2987\n",
      "3089\n"
     ]
    }
   ],
   "source": [
    "train_lengths = np.array([train_dataset[i][0].num_tokens for i in range(len(train_dataset))])\n",
    "test_lengths = np.array([test_dataset[i][0].num_tokens for i in range(len(test_dataset))])\n",
    "print(np.max(train_lengths))\n",
    "print(np.max(test_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[6926], token_positions=[1192], character_length=6926, num_tokens=1192, token_indices=[6926], token_lengths=[1192], token_embeddings=[1192, 64], token_sentiments=[1192, 2]),\n",
       " tensor([0., 1.]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [ CON TAIN S SPOILER S ! ! ! ] < br / > < br / > Garfield and his owner Jon Arbuckle were in a rut . They basically had no life at all . All they did was lay around and count the ceiling tiles . Jon even organized his sock drawer according to color and fabric . He needed a life . So he consults a book on the subject that tells him to meet a woman . A singles ' bar was a great place to start . Unfortunately , when the music started and Jon hit the dance floor , we see what made disco die : Jon killed it . Jon next tried to pick up girls at the video store . He ended up feeling down in the mouth . Literally . The laundromat was no prize either when Jon and his would - be date get a glimpse of each other ' s underwear . Jon tried to act all buff at the beach , but soon he angered a real buff guy , which left Jon feeling , once again , down in the mouth . Literally . Jon then tried to pick up girls walking and jogging by . No avail . Jon pulled out a guitar and sings the blues . Unfortunately when he mentioned his cat being fat , a fat man walked up and stomped Jon ' s guitar . It was hopeless . < br / > < br / > Fortunately for Jon , an ad flashed on the TV : an ad for Lorenzo ' s School for the Personality Impaired . It guaranteed a lifeless person to get a life in a few easy steps . Jon and Garfield attend the class . The building didn ' t exactly look the same way it did on TV , nor did Lorenzo act as peppy as he did on TV . Jon sat next to a pretty girl named Mona . So while Lorenzo taught his lessons of introducing yourself , checking your pulse , and pretending to speak a foreign language , Jon and Mona get to know one another . They leave together , forgetting all about Garfield . At home , Jon and Mona just sat on the porch and talked . Garfield was jealous of Mona for fear that she would take Jon away from him . Garfield envisioned the future : Jon and Mona get married , she moves in , and soon she gives birth to a little Arbuckle who is overjoyed at pulling Garfield ' s tale . Back to the present , Garfield would not stand for it . He tried to get Jon to get rid of Mona , until she started scratching behind his ears . But then Jon learned that Mona was allergic to cats . So that was basically the end of their relationship . But they still saw each other every now and then , and Garfield was sure to be with them . < br / > < br / > Another hilarious Garfield TV special ! This one was made during the run of TV ' s Garfield and Friends . Garfield was slimmed down somewhat . SOME what . Since hi e early 1980 ' s cartoons . The scenes of Jon trying to pick up chicks is funny , so is the one where the fat guy stomp s on Jon ' s guitar . Good ol ' Lorenzo Music is back as Garfield . Thom Huge is Jon . Frank Welker ( The third man of 1 , 000 voices ) is Lorenzo . And June For ay ( The woman of 1 , 000 voices ) is Mona . If you like Garfield , then I recommend you see Garfield Gets A Life today ! It , along with Here Comes Garfield , and Garfield on the Town , were just released on DVD ! So check them all out today ! You are guaranteed a good time . Hey , has Garfield ever let you down before ? < br / > < br / > - \u0001\n",
      "1 Harvey Kei tel gives a typically top - rate performance in one of his first - ever lead roles as brash , ambitious , uncompromising young staff producer Coleman Buck master , a real talented hot shot with a discerning \" golden ear \" and the son of a famous jazz pianist to boot . Coleman ' s eager to cut some tracks with the smokin ' R & B outfit the Group ( none other than Earth , Wind & Fire in their awesomely funky prime ) , but his rigidly commercial greed head label A - Cho rd Records run by uptight , mob - connected middle - of - the - road square Jerry ( a properly un hip Ed Nelson ) wants him to record a hit single for the hideously insipid Carpenter s - like pop pap trio the Pages , an allegedly squeaky clean bunch which includes sm army ped ophile step - dad Franklin ( a perfectly vile Bert Parks ) , bitchy , neurotic daughter Vel our ( a fine , flight y turn by perky , come ly brunette Cynthia Bos t wick ) , and hedonistic smack addict son Gary ( former 50 ' s juvenile sitcom staple Jimmy Boyd ) . The extremely naive and idealistic Coleman must learn pronto how the music business truly works and play the lowdown dirty game as best he can or else he ' ll lose both the Group and his credibility . < br / > < br / > Adopt ing an acrid , incisive , corrosive ly harsh and un sparing ly biased script from syndicated columnist and rock journalist Robert Lips yte , director Sig Shore ( who ' s most famous for producing \" Super fly \" ) shows a decidedly cynical and unflattering depiction of the various bribes , pay - offs , broken promises , back - sta bbing s , du plic ities and double - dealing s which are an unpleasant , yet intrinsic part of the largely corrupt rock music business , with particularly thoughtful thematic aside s concerning Art vs . Commerce , fighting to retain one ' s artistic integrity , and the then recent push to  homogen ize rock into bland , useless , creatively stagnant mainstream respectability . Moreover , this gritty , downbeat gem offers a rare fascinating , minute ly detailed and wholly believable backstage glimpse at the recording process as recording booth console cowboy Coleman struggles game ly in his own words to \" make chicken salad out of chicken s * * t . \" Appearing in nifty bits are disc jockey and legendary \" fifth Beatle \" Murray the K as leer ing , leche rous DJ Big John Little ( Vel our bites his hand after Big John paws her thigh during a live on - air interview ! ) , New York soul DJ and host of NBC ' s \" Friday Night Videos \" Frankie Crocker as his own jazzy ' n ' ji vin ' self , R & B singer - songwriter Doris Troy ( she penned the lovely \" Just One Look \" ) as a church pianist , and tub by , bald - pat ed 70 ' s bla x plo itation favorite Charles MacGregor as a priest at a wedding . The rather poor sound and Allan Metzger ' s sloppy cinematography inadvertently add to the film ' s overall ragged , rough - around - the - edge s documentary - style authenticity . Although technically a bit lacking , this movie overall still rates as one of the great , most bitterly pessimistic unsung behind - the - scenes rocks plo itation gems from the 70 ' s . \u0001\n",
      "0 This movie was awful , especially considering the work that must have gone into its production . Though it ' s not as bad as Ax ' Em , it is quite awful . Take into account the obvious rip - offs from Gladiator and Raiders of the Lost Ark , and what do you get ? This smorgasbord of awful make - up and wooden acting . < br / > < br / > The movie starts as most zombie movies nowadays do . A montage of interesting jump - cuts and a radio broadcast of the outbreak at hand . We see our hero ( R yn , quite possibly the worst ' zombie hunter ' in modern era ; counted about four or five times where he either scratched his head with the barrel of his pistol or looked down the barrel while blowing ) cutting off fingers of zombies . We later learn that these fingers are collected for bounties . < br / > < br / > Well , R yn seems to be a rebel in his ways of dispensing of zombies ; going so far as to purchase chum * gasp * from his French buddy Hans ( who isn ' t really French , speaks with an odd Middle - Eastern accent ) . As R yn uses the chum to collect a plentiful bounty from Lost Hills , all hell breaks loose . < br / > < br / > And cue the awful ness of the movie . The zombies are put together quite poorly . I ' ve seen comments praising their make - up , but it was quite amateur in my opinion . Obvious Halloween adhesives were used to make the zombies ' faces and there were points at which one girl looked as if she were donning a clown mask instead of a freshly peeled face . Oy V ey . < br / > < br / > To sum the next sixty minutes up in a few lines : R yn is back stabbed by Hans ( who made a deal with some other zombie hunters , Blythe being the ringleader ) , gives him a second chance , gets back stabbed again by Hans , then shoots Hans and gets to Union City where he finds Blythe is poisoning the cities for profit . < br / > < br / > That ' s it really in regards to plot . When R yn reaches Union City all the baddies are gathered around in a house that evidently is so massive it takes R yn hours to reach the top floor . People die , R yn lives , and the movie ends with one of those cynical \" is he going to kill himself ? \" scenes . < br / > < br / > * END SPOILER S * I ' m going to have to blame most of this mess on Not t . The direction was awful . EVERY character featured a scowl other than Hans , who was easily the best ' actor ' in this group of Mac Beth rejects . When they reach Union City , a hoard of zombies attacks the crew and the zombies were obviously given no tips or ideas about how to walk as if your appendages were rotten . One woman is swaying as if she ' s swimming in mid - air on a Sunday stroll . < br / > < br / > Some movies are awful . This movie is one of them simply on the grounds of how logic seemed to be abandoned in order to keep a story flowing . Works occasionally , but in this regard ( where the story was already in shambles ) , it doesn ' t . < br / > < br / > Avoid it unless you want a decent laugh . \u0001\n",
      "0 Let me first off say that I am a believer of ghosts , and I do indeed know they exist . I have had enough experiences with them to know they are there . < br / > < br / > What I hate is the people who bring the Bible and Religion into all of this . People forget there is more than one \" Bible \" , thousands of religions and beliefs , and different ways to interpret what is said in the Bible . Not everyone believes in God , and not everyone believes in stereo - typical religion . < br / > < br / > Religion does not make everything fact , one of the things I should mention in the Bible that many do not know is that even the most rampant Bible thump er is breaking the very rules written within . . . . you are supposed to never wear more than one fabric at one time , slavery is OK , and you may murder your neighbor under certain circumstances . None of this , \" Oh that was the Old testament , and now we have the New Testament . \" If the Bible is the word of God , and cannot be changed . . there should be no changes , or versions . Religion is full of misinterpretation s , mixed facts , and people who so blindly follow it that there , \" Is no other way . \" The excuses these said blind followers use are either pathetic , or they themselves cannot explain the discrepancies properly , and instead use excuses handed down to them from either their Pastor or teacher . < br / > < br / > But anyhow , onto the review . I am a decent fan of \" Ghost Hunters \" and when I heard this show was coming soon , I was pretty excited and thought it had some potential . As much as I like watching \" Ghost Hunters \" , I do not like some of their members , and I do not like the way they can dismiss a place as being haunted , yet cannot explain anything that is going on . Just because your investigation equipment does not pick it up , does not mean the camera filming the show did not . I am glad they are skeptical , but it ' s like they do not understand that just because you did not get anything on your recorder and film does not make the place haunted or not . If Ghosts were that easy to capture , it would be known as a fact , not a belief . It ' s more of a \" right place at the right time \" kind of thing , as well as if there is something there , what makes you think it ' s going to \" perform \" for you ? This show is kind of silly . It ' s usually boring , and there is lots of talk , lots of psychics , yet hardly anything happens . The main guy ' s filtered narration is usually either boring to listen to , or is basically not needed . < br / > < br / > Also , the reliance on psychics is too abundant , as I believe VERY few of them are actually gifted . Silvia Brown is one I definitely believe in , but most are sometimes hard to believe . < br / > < br / > I really wanted to like this show , but of the few I have seen I have yet to be terribly impressed . \u0001\n",
      "1 I thought Rachel York was fantastic as \" Lucy . \" I have seen her in \" Kiss Me , Kate \" and \" Victor / Victoria , \" as well , and in each of these performances she has developed very different , and very real , characterization s . She is a chameleon who can play ( and sing ) anything ! < br / > < br / > I am very surprised at how many negative reviews appear here regarding Rachel ' s performance in \" Lucy . \" Even some bonafide TV and entertainment critics seem to have missed the point of her portrayal . So many people have focused on the fact that Rachel doesn ' t really look like Lucy . My response to that is , \" So what ? \" I wasn ' t looking for a superficial impersonation of Lucy . I wanted to know more about the real woman behind the clown . And Rachel certainly gave us that , in great depth . I also didn ' t want to see someone simply \" doing \" classic Lucy routines . Therefore I was very pleased with the decision by the producers and director to have Rachel portray Lucy in rehearsal for the most memorable of these skits - Vita meat ave gam in and The Candy Factory . ( It seems that some of the reviewers didn ' t realize that these two scenes were meant to be rehearsal sequences and not the actual skits ) . This approach , I thought , gave an innovative twist to sketches that so many of us know by heart . I also thought Rachel was terrific ally fresh and funny in these scenes . And she absolutely nailed the routines that were recreated - the Professor and the Grape Stomp ing , in particular . There was one moment in the Grape scene where the corner of Rachel ' s mouth had the exact little upturn that I remember Lucy having . I couldn ' t believe she was able to capture that - and so naturally . < br / > < br / > I wonder if many of the folks who criticized the performance were expecting to see the Lucille Ball of \" I Love Lucy \" throughout the entire movie . After all , those of us who came to know her only through TV would not have any idea what Lucy was really like in her early movie years . I think Rachel showed a natural progression in the character that was brilliant . She planted all the right seeds for us to see the clown just waiting to emerge , given the right set of circumstances . Lucy didn ' t fit the mold of the old studio system . In her frustrated attempts to become the stereotypical movie star of that era , she kept repressing what would prove to be her ultimate gifts . < br / > < br / > I believe that Rachel deftly captured the comedy , drama , wit , sadness , anger , passion , love , ambition , loyalty , sexiness , self absorption , childish ness , and stoicism all rolled into one complex American icon . And she did it with an authenticity and freshness that was totally endearing . \" Lucy \" was a star turn for Rachel York . I hope it brings a flood of great roles her way in the future . I also hope it brings her an Emmy . \u0001\n"
     ]
    }
   ],
   "source": [
    "for i in range(15,20):\n",
    "    char_ids = X[i].x\n",
    "    text_for_ids = ''.join([vocab_dict_rev[ci.item()] for ci in char_ids])\n",
    "    print(torch.argmax(y[i]).item(), text_for_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rand = torch.randn((64, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9919)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rand.var(unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[355681], token_positions=[66512], character_length=[224], num_tokens=[224], token_indices=[355681], token_lengths=[66512], token_embeddings=[66512, 64], token_sentiments=[66512, 2], batch=[355681], ptr=[225], cumulative_token_indices=[355681])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = torch.randn((len(X.token_positions), 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([66512])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(torch.arange(len(X.num_tokens)), X.num_tokens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  ..., 34, 35, 36])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.token_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2902, -1.5769,  0.0973,  ...,  0.8986,  0.8537, -0.8959],\n",
       "        [-0.5405, -0.2818,  0.9853,  ...,  1.1739, -0.7419, -1.6283],\n",
       "        [-0.4099, -0.3418,  2.2702,  ..., -0.3704,  0.2404, -1.3291],\n",
       "        ...,\n",
       "        [ 1.9172,  0.8530,  0.7340,  ..., -1.0294,  1.9511,  0.2843],\n",
       "        [-1.1761,  0.5010,  0.2658,  ...,  0.1410,  0.5511,  0.6099],\n",
       "        [-2.1716, -1.0277,  0.4055,  ...,  0.9374, -0.8740, -0.1705]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv\n",
    "\n",
    "# Normalization on each feature of all tokens, for this we used batch norm class but with tokens at batch dimention\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, *args, **kwargs):\n",
    "        super(GCNN, self).__init__(*args, **kwargs)\n",
    "        self.gnn = GATv2Conv(hidden_dim, hidden_dim//8, heads=4, add_self_loops=False)\n",
    "        self.conv = nn.Conv1d(hidden_dim, hidden_dim//2, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim//2)\n",
    "        \n",
    "    def forward(self, x, edge_data, return_attention_weights = False):\n",
    "        x1, edge_weights = self.gnn(x, edge_data, return_attention_weights=return_attention_weights) \n",
    "        x2 = F.relu(self.conv(x.T).T)\n",
    "        x1 = F.leaky_relu_(self.bn1(x1))\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        return x, edge_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from copy import copy, deepcopy\n",
    "# gcnn_model = GCNN(64)\n",
    "# flopt_counter = FlopCounterMode(gcnn_model)\n",
    "# X.edge_index = torch.randint(0, len(X.token_positions), size=(2,200))\n",
    "# with flopt_counter:\n",
    "#     x_input = deepcopy(torch.randn((len(X.token_positions), 64)))\n",
    "#     edge_data = deepcopy(X.edge_index)\n",
    "#     gcnn_model(x_input, edge_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_t = torch.randn((400, 5))\n",
    "# sample_t.shape\n",
    "# print(torch.mean(sample_t, dim=0))\n",
    "# print(torch.std(sample_t, dim=0))\n",
    "# bn1 = nn.BatchNorm1d(5)\n",
    "# print(torch.mean(bn1(sample_t), dim=0).detach())\n",
    "# print(torch.std(bn1(sample_t), dim=0).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, to_undirected\n",
    "\n",
    "class GenGraph(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, virtual_nodes, lattice_step, lattice_pattern=None, *args, **kwargs):\n",
    "        super(GenGraph, self).__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.lattice_step = lattice_step\n",
    "        self.lp = lattice_pattern if lattice_pattern is None else torch.tensor(lattice_pattern)\n",
    "        self.virtual_node_embeddings = nn.Embedding(self.virtual_nodes, hidden_dim)\n",
    "        \n",
    "    def gen_graph(self, x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2, seed=-1):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance, seed)\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        edge_index = torch.empty((2, base_numel + v_n_e_counts*2), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "            \n",
    "        if self.virtual_nodes > 0:\n",
    "            virtual_nodes_range = torch.arange(self.virtual_nodes, device=x.device).view(1, -1)\n",
    "            virtual_nodes_ids = torch.repeat_interleave(virtual_nodes_range, len(token_counts), dim=0)\n",
    "            v_n_idx = (virtual_nodes_ids + torch.arange(0, len(token_counts)*self.virtual_nodes, self.virtual_nodes, device=x.device).view(-1, 1) + total_token_coutns )\n",
    "            virtual_edge_ids = torch.repeat_interleave(v_n_idx.view(-1), token_counts.view(-1, 1).expand(len(token_counts), self.virtual_nodes).reshape(-1), dim=0).view(1, -1)\n",
    "            \n",
    "            embs = self.virtual_node_embeddings(virtual_nodes_ids.T).view(-1, self.hidden_dim)\n",
    "            x_extended = torch.cat([x, embs], dim=0)\n",
    "            x_index = torch.arange(total_token_coutns, device=x.device).repeat(self.virtual_nodes).view(1, -1)\n",
    "            edge_index[:, base_numel:base_numel+v_n_e_counts] = torch.cat([x_index, virtual_edge_ids], dim=0)\n",
    "            edge_index[:, base_numel+v_n_e_counts:] = torch.cat([virtual_edge_ids, x_index], dim=0)\n",
    "            x = x_extended\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "        \n",
    "    def re_gen_graph(self, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2, seed=-1):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance, seed)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "        # for i in range(base.shape[1]):\n",
    "        #     edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "            \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "    \n",
    "    def replace_unimportant_edges(self, edge_weights, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2, seed=-1):\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        if v_n_e_counts>0:\n",
    "            important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        else:\n",
    "            important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "\n",
    "        important_indices = torch.arange(total_token_coutns, dtype=torch.int64, device=x.device) + important_indices*total_token_coutns\n",
    "        important_indices = important_indices.view(-1)\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance, seed)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "        new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_index[:, important_indices]\n",
    "        if(self.virtual_nodes>0):\n",
    "            new_edge_index[:, -2*v_n_e_counts:] = edge_index[:, -2*v_n_e_counts:]\n",
    "            \n",
    "        # for i in range(base.shape[1]):\n",
    "        #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "         \n",
    "    def calculate_graph(self, x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance, seed=-1):\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    "        tc_extended = torch.repeat_interleave(token_counts, token_counts, dim=0).view(-1,1)\n",
    "        tc_lower_bound = torch.empty((len(token_counts)+1), dtype=torch.long, device=x.device) #torch.cuda.IntTensor(len(token_counts)+1) #\n",
    "        tc_lower_bound[0] = 0\n",
    "        tc_lower_bound[1:] = torch.cumsum(token_counts, dim=0)\n",
    "        tc_lower_bound_extended = torch.repeat_interleave(tc_lower_bound[:-1], token_counts, dim=0).view(-1,1)\n",
    "        tc_range = torch.arange(tc_lower_bound[-1], device=x.device).view(-1,1)\n",
    "        # torch.arange(tc_lower_bound[-1], dtype=torch.int32, device=x.device).view(-1,1)\n",
    "        random_ints = torch.randint(0, 2*total_token_counts, (total_token_counts, random_edges), device=x.device) # torch.cuda.IntTensor(len(token_lengths), random_edges).random_()\n",
    "        lattice = self.lp.to(x.device) if self.lp is not None else torch.arange(lattice_start_distance, max(lattice_start_distance, self.lattice_step*lattice_edges+1), self.lattice_step, device=x.device).view(1, -1)\n",
    "        \n",
    "\n",
    "        # exponentials = torch.pow(2, torch.arange(1, self.exp_edges+1, device=x.device)).view(1, -1)\n",
    "        tc_local_range = tc_range - tc_lower_bound_extended\n",
    "        random_links = (((random_ints % (tc_extended - 1))+1 + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        lattice_links = ((lattice + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        # base = torch.cat([base1, base2], dim=1)\n",
    "        tc_range = tc_range.view(1,-1)\n",
    "        return random_links, lattice_links, tc_range\n",
    "    \n",
    "    def fill_lattice_and_random_edges(self, edge_index, random_links, lattice_links, tc_range):\n",
    "        for i in range(0, lattice_links.shape[1]*2, 2):\n",
    "            edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]] = torch.cat([lattice_links[:,i//2].view(1,-1), tc_range], dim=0)\n",
    "            edge_index[:, (i+1)*lattice_links.shape[0]:(i+2)*lattice_links.shape[0]] = edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]][[1, 0]]\n",
    "            \n",
    "        for i in range(random_links.shape[1]):\n",
    "            j = i + lattice_links.shape[1]*2\n",
    "            edge_index[:, j*random_links.shape[0]:(j+1)*random_links.shape[0]] = torch.cat([random_links[:,i].view(1,-1), tc_range], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment_Injection(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)        \n",
    "        self.conv1 = nn.Conv1d(2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim*2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, token_sentiments):\n",
    "        x1 = F.relu_(self.bn1(self.conv1(token_sentiments.T).T))\n",
    "        x = F.relu_(self.conv2(torch.cat([x, x1], dim=1).T))\n",
    "        # x = x + x1\n",
    "        return x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment1  = Sentiment_Injection(64)\n",
    "# sentiment1(torch.ones((41047, 64)), torch.ones((41047, 2))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv, summary\n",
    "\n",
    "class CNN_for_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embedding, pos_emb_size=8192, embedding_dim=64, hidden_dim=64, dropout=0.3, num_out_features=4, seed=-1, random_edges=4, lattice_edges=10, virtual_nodes=1, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64, use_positional_encoder=[False, False, False], *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text, self).__init__(*args, **kwargs)\n",
    "        self.pos_emb_size = pos_emb_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        # self.use_token_polarity = use_token_polarity\n",
    "        self.use_positional_encoder = use_positional_encoder\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    " \n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        \n",
    "        if True in use_positional_encoder:\n",
    "            self.positional_encoding = nn.Embedding(pos_emb_size, embedding_dim)\n",
    "            self.positional_encoding.weight = self.create_positional_encoding()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        \n",
    "        # if self.use_token_polarity[0]:\n",
    "        #     self.conv3 = nn.Conv1d(2*hidden_dim + 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        # else:\n",
    "        self.conv3 = nn.Conv1d(2*hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        # if self.use_token_polarity[1]:\n",
    "        self.sentiment1  = Sentiment_Injection(hidden_dim)\n",
    "        # if self.use_token_polarity[2]:\n",
    "        self.sentiment2  = Sentiment_Injection(hidden_dim)\n",
    "            \n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.gcnn2 = GCNN(hidden_dim+inject_embedding_dim)\n",
    "        self.graph_generator = GenGraph(hidden_dim, virtual_nodes, lattice_step)\n",
    "        \n",
    "        k = 4\n",
    "        self.fc0 = nn.Linear(hidden_dim , hidden_dim+inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim+inject_embedding_dim , hidden_dim * k)\n",
    "        self.fc2 = nn.Linear(hidden_dim * (2+virtual_nodes) * k , 32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, num_out_features)\n",
    "        self.max_length = 0\n",
    "    \n",
    "    def forward(self, g_data):\n",
    "            \n",
    "        x = self.embedding(g_data.x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.T\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x1 = scatter_max(x, g_data.cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, g_data.cumulative_token_indices, dim=1)\n",
    "\n",
    "        # if self.use_token_polarity[0]:\n",
    "        #     x = torch.cat([x1, x2, g_data.token_sentiments.T], dim=0)\n",
    "        # else:\n",
    "        x = torch.cat([x1, x2], dim=0)\n",
    "            \n",
    "        x = F.relu(self.conv3(x)).T\n",
    "        \n",
    "        if self.use_positional_encoder[0]:\n",
    "            x = x + self.positional_encoding(g_data.token_positions)\n",
    "            \n",
    "        # if self.use_token_polarity[1]:\n",
    "        x = self.sentiment1(x, g_data.token_sentiments)\n",
    "        \n",
    "            \n",
    "        # x = x + self.positional_encoding(g_data.token_positions)\n",
    "\n",
    "        rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "            \n",
    "        graph = self.graph_generator.gen_graph(x, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "        rand_edges = rand_edges-1\n",
    "        lattice_edges = lattice_edges-1\n",
    "        \n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(g_data.num_tokens), device=x.device), g_data.num_tokens)\n",
    "        x, edge_weights = self.gcnn1(graph.x, graph.edge_index, return_attention_weights = True)\n",
    "        edge_weights = edge_weights[1][:graph.edge_index.shape[1], 0]\n",
    "        \n",
    "        graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, graph.edge_index, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        \n",
    "        \n",
    "        # if self.use_token_polarity[2]:\n",
    "        x = self.sentiment2(x, g_data.token_sentiments)\n",
    "            \n",
    "        \n",
    "        if self.use_positional_encoder[1]:\n",
    "            xa = graph.x[:g_data.token_embeddings.shape[0]] + self.positional_encoding(g_data.token_positions)\n",
    "        else:\n",
    "            xa = graph.x[:g_data.token_embeddings.shape[0]]\n",
    "        if self.use_positional_encoder[2]:\n",
    "            xb = g_data.token_embeddings + self.positional_encoding(g_data.token_positions)\n",
    "        else:\n",
    "            xb = g_data.token_embeddings\n",
    "        x = torch.cat([xa, xb], dim=1)\n",
    "        # x = torch.cat([graph.x[:g_data.token_embeddings.shape[0]], g_data.token_embeddings], dim=1)\n",
    "        \n",
    "        x1 = F.relu(self.fc0(graph.x[g_data.token_embeddings.shape[0]:]))\n",
    "        x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "        x, edge_weights = self.gcnn2(x, graph.edge_index)\n",
    "\n",
    "        x = F.elu_(self.fc1(x))\n",
    "        x1 = scatter_max(x[:len(g_data.token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(g_data.token_lengths)], doc_token_index, dim=0)\n",
    "        vn_embs = x[len(g_data.token_lengths):]\n",
    "        x_for_cat = [x1, x2]\n",
    "        x_for_cat.extend([vn_embs[i*x1.shape[0]:(i+1)*x1.shape[0]] for i in range(self.virtual_nodes)])\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        \n",
    "        x = F.elu_(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def create_positional_encoding(self):\n",
    "        position = torch.arange(self.pos_emb_size).unsqueeze(1)\n",
    "        # div_term = self.pos_emb_size ** (torch.arange(0, 64, 2)/64.0)\n",
    "        div_term = torch.exp(torch.arange(0, self.hidden_dim, 2) * (-math.log(10000.0) / self.hidden_dim))\n",
    "        pe = torch.zeros(self.pos_emb_size, self.hidden_dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return torch.nn.Parameter(pe, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for p1 in [False, True]:\n",
    "# #     for p2 in [False, True]:\n",
    "# #         for p3 in [False, True]:\n",
    "# # print(f'\\n{p1}, {p2}, {p3}: \\n')\n",
    "# classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=64, embedding_dim=64, pos_emb_size=3200, dropout=0.2, num_out_features=len(class_id), seed=911, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2, use_positional_encoder=[True, False, False]).eval()\n",
    "# flopt_counter = FlopCounterMode(classifier_torch_model)\n",
    "# with flopt_counter:\n",
    "#     classifier_torch_model(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for p1 in [False, True]:\n",
    "# #     for p2 in [False, True]:\n",
    "# #         for p3 in [False, True]:\n",
    "# # print(f'\\n{p1}, {p2}, {p3}: \\n')\n",
    "# classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=64, embedding_dim=64, pos_emb_size=3200, dropout=0.2, num_out_features=len(class_id), seed=911, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2, use_positional_encoder=[False, False, False]).eval()\n",
    "# flopt_counter = FlopCounterMode(classifier_torch_model)\n",
    "# with flopt_counter:\n",
    "#     classifier_torch_model(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(classifier_torch_model.parameters())).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CnnGnnClassifierLightningModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        num_classes,\n",
    "        optimizer=None,\n",
    "        loss_func=None,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=64,\n",
    "        lr_scheduler=None,\n",
    "        user_lr_scheduler=False,\n",
    "        min_lr=0.0,\n",
    "    ):\n",
    "        super(CnnGnnClassifierLightningModel, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.min_lr = min_lr\n",
    "        # self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        self.optimizer = self._get_optimizer(optimizer)\n",
    "        self.lr_scheduler = (\n",
    "            self._get_lr_scheduler(lr_scheduler) if user_lr_scheduler else None\n",
    "        )\n",
    "        self.loss_func = loss_func\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)\n",
    "\n",
    "    def on_train_epoch_start(self) -> None:\n",
    "        param_groups = next(iter(self.optimizer.param_groups))\n",
    "        if \"lr\" in param_groups and param_groups[\"lr\"] is not None:\n",
    "            current_learning_rate = float(param_groups[\"lr\"])\n",
    "            self.log(\n",
    "                \"lr\",\n",
    "                current_learning_rate,\n",
    "                batch_size=self.batch_size,\n",
    "                on_epoch=True,\n",
    "                on_step=False,\n",
    "            )\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.train()\n",
    "        y_out = self(X)\n",
    "\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.train_losses.append(loss.detach().item())\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        self.train_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        y_out = self(X)\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.val_losses.append(loss.detach().item())\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.val_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.lr_scheduler is None:\n",
    "            return self.optimizer\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": self.lr_scheduler,\n",
    "                \"monitor\": \"train_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def update_learning_rate(self, learning_rate: float):\n",
    "        self.learning_rate = learning_rate\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g[\"lr\"] = learning_rate\n",
    "\n",
    "    def _get_optimizer(self, optimizer):\n",
    "        return (\n",
    "            optimizer\n",
    "            if optimizer is not None\n",
    "            else torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        )\n",
    "\n",
    "    def _get_lr_scheduler(self, lr_scheduler):\n",
    "        return (\n",
    "            lr_scheduler\n",
    "            if lr_scheduler is not None\n",
    "            else torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer, patience=5, factor=0.5, mode=\"min\", min_lr=self.min_lr\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import Logger, CSVLogger\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from typing import List\n",
    "from pytorch_lightning.core.saving import save_hparams_to_yaml\n",
    "\n",
    "class ModelManager(ABC):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 max_epochs = 100,\n",
    "                 ckpt_path: str|None=None,\n",
    "                 accumulate_grad_batches=1):\n",
    "        self.torch_model = torch_model\n",
    "        self.lightning_model = lightning_model\n",
    "        self.log_dir = log_dir\n",
    "        self.log_name = log_name\n",
    "        self.model_save_dir = model_save_dir\n",
    "        self.device = device\n",
    "        self.accelerator = 'cpu' if self.device=='cpu' else 'gpu'\n",
    "        self.max_epochs = max_epochs\n",
    "        self.ckpt_path = ckpt_path\n",
    "\n",
    "        self.logger = self._create_logger()\n",
    "        self.callbacks = self._create_callbacks()\n",
    "        self.trainer: L.Trainer = self._create_trainer(accumulate_grad_batches)\n",
    "        self.tuner = Tuner(self.trainer)\n",
    "        self.tuning_result = None\n",
    "\n",
    "    def tune(self, data_manager=None, train_dataloaders=None, val_dataloaders=None, datamodule=None, draw_result=True, min_lr=0.0000001, max_lr=0.1):\n",
    "        self.tuning_result = self.tuner.lr_find(self.lightning_model, datamodule=data_manager, train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders, min_lr=min_lr,max_lr=max_lr, num_training=150)\n",
    "        if draw_result:\n",
    "            fig = self.tuning_result.plot(suggest=True)\n",
    "            fig.show()\n",
    "        self.update_learning_rate(self.tuning_result.suggestion())\n",
    "        return self.tuning_result.suggestion()\n",
    "    \n",
    "    def update_learning_rate(self, lr):\n",
    "        self.lightning_model.update_learning_rate(lr)\n",
    "\n",
    "    def fit(self, train_dataloaders=None, val_dataloaders=None, datamodule=None, max_epochs = -1, ckpt_path=None):\n",
    "        if ckpt_path is not None and ckpt_path != '':\n",
    "            self.ckpt_path = ckpt_path\n",
    "        if max_epochs>0:\n",
    "            self.trainer.fit_loop.max_epochs = max_epochs\n",
    "            # self.max_epochs = max_epochs\n",
    "            # self.trainer = self._create_trainer()\n",
    "        self.trainer.fit(self.lightning_model,\n",
    "                         datamodule=datamodule,\n",
    "                         train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders,\n",
    "                         ckpt_path = self.ckpt_path\n",
    "                         )\n",
    "\n",
    "    def validate(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.validate(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def predict(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.predict(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def _create_trainer(self, accumulate_grad_batches) -> L.Trainer:\n",
    "        return L.Trainer(\n",
    "            callbacks=self.callbacks,\n",
    "            max_epochs=self.max_epochs,\n",
    "            accelerator=self.accelerator,\n",
    "            logger=self.logger,\n",
    "            num_sanity_val_steps=0,\n",
    "            default_root_dir=self.model_save_dir,\n",
    "            accumulate_grad_batches=accumulate_grad_batches\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        pass\n",
    "\n",
    "    def _create_logger(self) -> Logger:\n",
    "        return CSVLogger(save_dir=self.log_dir, name=self.log_name)\n",
    "\n",
    "    @abstractmethod\n",
    "    def draw_summary(self, dataloader):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def plot_csv_logger(self, loss_names, eval_names):\n",
    "        pass\n",
    "    \n",
    "    def save_hyper_parameters(self):\n",
    "        mhparams = {\n",
    "            'start_lr': 0.045,\n",
    "            'ckpt_lrs' :  {51: 0.002, 65: 0.00058},\n",
    "            'last_lr' : 0.0003,\n",
    "            'ac_loss_factor': 0.0002,\n",
    "            'weight_decay': 0.0012\n",
    "        }\n",
    "        save_hparams_to_yaml(config_yaml=r'logs\\hetero_model_17_AG\\version_12\\hparams.yaml',\n",
    "                     hparams=mhparams)\n",
    "        \n",
    "    # def find_best_settings(data_manager,\n",
    "    #                        lrs: List[float]=[0.001], dropouts: List[float]=[0.2], \n",
    "    #                        weight_decays: List[float]=[0.00055], emb_factors: List[float]=[0.1], \n",
    "    #                        batch_sizes: List[int]=[128], log_name='find_best_settings'):\n",
    "    #     for lr in lrs:\n",
    "    #         for dropout in dropouts:\n",
    "    #             for wd in weight_decays:\n",
    "    #                 for emb_factor in emb_factors:\n",
    "    #                     for bs in batch_sizes:\n",
    "    #                         data_manager.update_batch_size(bs)\n",
    "    #                         torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 128, dropout=dropout)\n",
    "    #                         lightning_model = HeteroBinaryLightningModel(torch_model,\n",
    "    #                                         torch.optim.Adam(torch_model.parameters(), lr=lr, weight_decay=wd),\n",
    "    #                                             loss_func=HeteroLoss1(exception_keys='word', enc_factor=emb_factor),\n",
    "    #                                             learning_rate=lr,\n",
    "    #                                             batch_size=bs,\n",
    "    #                                             user_lr_scheduler=True\n",
    "    #                                             ).to(device)\n",
    "    #                         model_manager = ClassifierModelManager(torch_model, lightning_model, log_name=log_name, device=device, num_train_epoch=10)\n",
    "    #                         model_manager.fit(datamodule=data_manager)\n",
    "    #                         model_manager.save_plot_csv_logger(name_prepend=f'{lr}_{dropout}_{wd}_{emb_factor}_{bs}', loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "import torch\n",
    "# from scripts.managers.ModelManager import ModelManager\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from torch_geometric.nn import summary\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from os import path\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "class ClassifierModelManager(ModelManager):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 num_train_epoch = 100,\n",
    "                 accumulate_grad_batches=1):\n",
    "        super(ClassifierModelManager, self).__init__(torch_model, lightning_model, model_save_dir, log_dir, log_name, device, num_train_epoch, accumulate_grad_batches=accumulate_grad_batches)\n",
    "\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        return [\n",
    "            ModelCheckpoint(save_top_k=2, mode='max', monitor='val_acc', save_last=True),\n",
    "            # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "        ]\n",
    "\n",
    "    def draw_summary(self, dataloader):\n",
    "        X, y = next(iter(dataloader))\n",
    "        print(summary(self.torch_model, X.to(self.device)))\n",
    "\n",
    "    def plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    def save_plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc'], name_prepend: str=\"\"):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        \n",
    "        loss_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_loss_metric.png')\n",
    "        plt.savefig(loss_png)\n",
    "        \n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        \n",
    "        acc_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_acc_metric.png')\n",
    "        plt.savefig(acc_png)\n",
    "        \n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate(self, eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.lightning_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        # if(give_hinge_loss):\n",
    "        #     print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')\n",
    "                \n",
    "    def evaluate_best_models(self, lightning_type: L.LightningModule, eval_dataloader,\n",
    "                             give_confusion_matrix: bool=True, \n",
    "                             give_report: bool=True, \n",
    "                             give_f1_score: bool=False, \n",
    "                             give_accuracy_score: bool=False, \n",
    "                             give_precision_score: bool=False, \n",
    "                             give_recall_score: bool=False, \n",
    "                             give_hinge_loss: bool=False,\n",
    "                             multi_class: bool=False, **kwargs):\n",
    "        self.lightning_model = lightning_type.load_from_checkpoint(rf'{self.trainer.checkpoint_callback.best_model_path}', map_location=None, hparams_file=None, strict=True, **kwargs).eval()\n",
    "        self.save_evaluation(eval_dataloader, 'best_model', give_confusion_matrix, give_report,\n",
    "                             give_f1_score, give_accuracy_score, give_precision_score, give_recall_score, give_hinge_loss, multi_class)\n",
    "            \n",
    "    def save_evaluation(self, eval_dataloader, name_prepend: str='',\n",
    "                    give_confusion_matrix: bool=True, \n",
    "                    give_report: bool=True, \n",
    "                    give_f1_score: bool=False, \n",
    "                    give_accuracy_score: bool=False, \n",
    "                    give_precision_score: bool=False, \n",
    "                    give_recall_score: bool=False, \n",
    "                    give_hinge_loss: bool=False,\n",
    "                    multi_class: bool=False\n",
    "                    ):\n",
    "            \n",
    "            test_metrics_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_test_metrics.txt')\n",
    "            \n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            self.lightning_model.eval()\n",
    "            self.lightning_model.model.eval()\n",
    "            self.torch_model.eval()\n",
    "            self.trainer.model.eval()\n",
    "            for X, y in eval_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    y_p = self.lightning_model(X.to(self.device))\n",
    "                if type(y_p) is tuple:\n",
    "                    y_p = y_p[0]\n",
    "                \n",
    "                if multi_class:\n",
    "                    y_pred.append(y_p.detach().to(y.device))\n",
    "                    y_true.append(y)\n",
    "                else:\n",
    "                    y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "                    y_true.append(y.to(torch.int32))\n",
    "                    \n",
    "            y_true = torch.concat(y_true)\n",
    "            y_pred = torch.concat(y_pred)\n",
    "            print(y_true.shape)\n",
    "            print(y_pred.shape)\n",
    "            if multi_class:\n",
    "                y_true_num = torch.argmax(y_true, dim=1)\n",
    "                y_pred_num = torch.argmax(y_pred, dim=1)\n",
    "            else:\n",
    "                y_true_num = y_true\n",
    "                y_pred_num = y_pred\n",
    "                \n",
    "            print(y_true_num.shape)\n",
    "            print(y_pred_num.shape)\n",
    "            with open(test_metrics_path, 'at+') as f:\n",
    "                if(give_confusion_matrix):\n",
    "                    print(f'confusion_matrix: \\n{confusion_matrix(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_report):\n",
    "                    print(classification_report(y_true_num, y_pred_num), file=f)\n",
    "                if(give_f1_score):\n",
    "                    if multi_class:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_accuracy_score):\n",
    "                    print(f'accuracy_score: {accuracy_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_precision_score):\n",
    "                    if multi_class:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_recall_score):\n",
    "                    if multi_class:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num)}', file=f)\n",
    "                # if(give_hinge_loss):\n",
    "                #     print(f'hinge_loss: {hinge_loss(y_true_num, y_pred)}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 128\n",
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "label_size = 1\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_size = 32\n",
    "# hidden_dim = 16\n",
    "# embedding_dim = 16\n",
    "# label_size = 1\n",
    "# seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "def train_model(epochs=30, dropout=0.25, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True, use_positional_encoder=[False, True, True]):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=3200, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=8, lattice_step=2, virtual_nodes=0, lattice_start_distance=2, use_positional_encoder=use_positional_encoder).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 40, 45,50,55],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name=f'CNN-GNN_{use_positional_encoder[0]}_{use_positional_encoder[1]}_{use_positional_encoder[2]}',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    train_dataset.reset_params()\n",
    "    train_dataset.position_j = 0\n",
    "    test_dataset.reset_params()\n",
    "    test_dataset.position_j = 0\n",
    "    \n",
    "    # train_dataset.section_i = 0\n",
    "    # train_dataset.each_section_i = np.zeros((train_dataset.num_sections, ), dtype=int)\n",
    "    # test_dataset.section_i = 0\n",
    "    # test_dataset.each_section_i = np.zeros((test_dataset.num_sections, ), dtype=int)\n",
    "    \n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.torch_model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(CnnGnnClassifierLightningModel, test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25088"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions = []\n",
    "# j = 0\n",
    "# for i in range(len(test_dataset)):\n",
    "#     # if i% 1000 ==0:\n",
    "#     #     print(j)\n",
    "#     X, y = test_dataset[i]\n",
    "#     positions.append(len(X.token_positions))\n",
    "# positions = np.array(positions)\n",
    "# positions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_manager = train_model(1, 0.2, 0.000012, 0.0032, fused=False, use_positional_encoder=[False, False, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\CGNet\\FindBestModel\\4_WhereToAddPositionalEmbedding\\with_positional_encoding_4.ipynb Cell 65\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/4_WhereToAddPositionalEmbedding/with_positional_encoding_4.ipynb#Y121sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m [[\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m]]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/4_WhereToAddPositionalEmbedding/with_positional_encoding_4.ipynb#Y121sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/4_WhereToAddPositionalEmbedding/with_positional_encoding_4.ipynb#Y121sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         model_manager \u001b[39m=\u001b[39m train_model(\u001b[39m70\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m0.000012\u001b[39m, \u001b[39m0.0032\u001b[39m, fused\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, use_positional_encoder\u001b[39m=\u001b[39m[_[\u001b[39m0\u001b[39m], _[\u001b[39m1\u001b[39m], _[\u001b[39m2\u001b[39m]])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/4_WhereToAddPositionalEmbedding/with_positional_encoding_4.ipynb#Y121sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         time\u001b[39m.\u001b[39msleep(\u001b[39m20\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/4_WhereToAddPositionalEmbedding/with_positional_encoding_4.ipynb#Y121sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_model' is not defined"
     ]
    }
   ],
   "source": [
    "for _ in [[True, False, False]]:\n",
    "    for j in range(3):\n",
    "        model_manager = train_model(70, 0.2, 0.000012, 0.0032, fused=False, use_positional_encoder=[_[0], _[1], _[2]])\n",
    "        time.sleep(20)\n",
    "        torch.cuda.empty_cache()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in [[False, False, False]]:\n",
    "#     for j in range(3):\n",
    "#         model_manager = train_model(70, 0.2, 0.000012, 0.0032, fused=False, use_positional_encoder=[_[0], _[1], _[2]])\n",
    "#         time.sleep(20)\n",
    "#         torch.cuda.empty_cache()\n",
    "#         import gc\n",
    "#         gc.collect()\n",
    "#         time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatge_metrics(chpt_path, target_data_loader, use_positional_encoder=[False, False, False]):    \n",
    "        classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=3200, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=8, lattice_step=2, virtual_nodes=0, lattice_start_distance=2, use_positional_encoder=use_positional_encoder)\n",
    "        classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(chpt_path, model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "        mean_infer_acc = []\n",
    "        mean_infer_f1 = []\n",
    "        mean_infer_prec = []\n",
    "        mean_infer_rec = []\n",
    "        for i in range(5):\n",
    "            all_ys = []\n",
    "            all_y_preds = []\n",
    "            for X, y in target_data_loader:\n",
    "                with torch.no_grad():\n",
    "                    y_pred = classfier_lightning_model(X.to(device))\n",
    "                all_ys.append(torch.argmax(y,dim=1))\n",
    "                all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "            all_ys = torch.concat(all_ys)\n",
    "            all_y_preds = torch.concat(all_y_preds)\n",
    "            \n",
    "            cm = confusion_matrix(all_ys, all_y_preds)\n",
    "            \n",
    "            accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "            precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
    "            recall = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "            f1_score = (2*precision*recall)/(precision + recall)\n",
    "            \n",
    "            mean_infer_acc.append(accuracy)\n",
    "            mean_infer_f1.append(f1_score)\n",
    "            mean_infer_prec.append(precision)\n",
    "            mean_infer_rec.append(recall)\n",
    "        mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "        mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "        mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "        mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "        return mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "def get_best_chpt(metrics_path, epoch_numbers):\n",
    "    epoch_data = pd.read_csv(metrics_path)\n",
    "    if 'val_acc_epoch' in epoch_data.columns and epoch_data['val_acc_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_acc_epoch'].idxmax()]\n",
    "    elif 'val_loss_epoch' in epoch_data.columns and epoch_data['val_loss_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_loss_epoch'].idxmin()]\n",
    "    else:\n",
    "        raise ValueError(f\"No valid validation metrics available for epoch {epoch_numbers}.\")\n",
    "    return np.argwhere(np.array(epoch_numbers)==best_chpt['epoch']).item(), best_chpt['val_loss_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_metrics_mean(base_path = 'logs\\CNN-GNN18_mr2k_seeds', use_positional_encoder=[False, False, False]):\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "    total_loss = []\n",
    "\n",
    "    for k_fold_num in range(1):\n",
    "        infer_acc, infer_f1, infer_prec, infer_rec, infer_loss = [], [], [], [], []\n",
    "        for j in range(3):\n",
    "            # i = k_fold_num*3 + j\n",
    "            # k_fold_num = i//3\n",
    "            # test_dataset.set_active_fold(k_fold_num)\n",
    "            # test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)\n",
    "            \n",
    "            version_path = join(base_path, f'version_{j}')\n",
    "            checkpoint_path = join(version_path, f'checkpoints')\n",
    "            onlyfiles  = [f for f in listdir(checkpoint_path) if (isfile(join(checkpoint_path, f)) and 'epoch' in f) ]\n",
    "            epoch_numbers = [int(re.search(r'\\d+', f).group()) for f in onlyfiles]\n",
    "            best_chpt_id, loss = get_best_chpt(join(version_path, 'metrics.csv'), epoch_numbers)\n",
    "            print(onlyfiles[best_chpt_id])\n",
    "            mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec = calculatge_metrics(join(checkpoint_path, f'{onlyfiles[best_chpt_id]}'), test_dataloader, use_positional_encoder=use_positional_encoder)\n",
    "                \n",
    "            infer_acc.append(mean_infer_acc)\n",
    "            infer_f1.append(mean_infer_f1)\n",
    "            infer_prec.append(mean_infer_prec)\n",
    "            infer_rec.append(mean_infer_rec)\n",
    "            infer_loss.append(loss)\n",
    "\n",
    "        total_accuracy.append(torch.mean(torch.tensor(infer_acc)))\n",
    "        total_f1.append(torch.mean(torch.tensor(infer_f1)))\n",
    "        total_prec.append(torch.mean(torch.tensor(infer_prec)))\n",
    "        total_rec.append(torch.mean(torch.tensor(infer_rec)))\n",
    "        total_loss.append(torch.mean(torch.tensor(infer_loss)))\n",
    "\n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    total_loss = torch.mean(torch.tensor(total_loss))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')\n",
    "    print(f'total_loss: {total_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_metrics_max(base_path = 'logs\\CNN-GNN18_mr2k_seeds', use_positional_encoder=[False, False, False]):\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "    total_loss = []\n",
    "\n",
    "    for k_fold_num in range(10):\n",
    "        infer_acc, infer_f1, infer_prec, infer_rec, infer_loss = [], [], [], [], []\n",
    "        for j in range(3):\n",
    "            i = k_fold_num*3 + j\n",
    "            # k_fold_num = i//3\n",
    "            test_dataset.set_active_fold(k_fold_num)\n",
    "            test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)\n",
    "            \n",
    "            version_path = join(base_path, f'version_{i}')\n",
    "            checkpoint_path = join(version_path, f'checkpoints')\n",
    "            onlyfiles  = [f for f in listdir(checkpoint_path) if (isfile(join(checkpoint_path, f)) and 'epoch' in f) ]\n",
    "            epoch_numbers = [int(re.search(r'\\d+', f).group()) for f in onlyfiles]\n",
    "            best_chpt_id, loss = get_best_chpt(join(version_path, 'metrics.csv'), epoch_numbers)\n",
    "            print(onlyfiles[best_chpt_id])\n",
    "            mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec = calculatge_metrics(join(checkpoint_path, f'{onlyfiles[best_chpt_id]}'), test_dataloader, use_positional_encoder=use_positional_encoder)\n",
    "                \n",
    "            infer_acc.append(mean_infer_acc)\n",
    "            infer_f1.append(mean_infer_f1)\n",
    "            infer_prec.append(mean_infer_prec)\n",
    "            infer_rec.append(mean_infer_rec)\n",
    "            infer_loss.append(loss)\n",
    "\n",
    "        total_accuracy.append(torch.max(torch.tensor(infer_acc)))\n",
    "        total_f1.append(torch.max(torch.tensor(infer_f1)))\n",
    "        total_prec.append(torch.max(torch.tensor(infer_prec)))\n",
    "        total_rec.append(torch.max(torch.tensor(infer_rec)))\n",
    "        total_loss.append(torch.min(torch.tensor(infer_loss)))\n",
    "\n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    total_loss = torch.mean(torch.tensor(total_loss))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')\n",
    "    print(f'total_loss: {total_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_average_metrics_mean(r'logs\\CNN-GNN_True_True_True', [True, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_average_metrics_mean(r'logs\\CNN-GNN_True_True_False', [True, True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_average_metrics_mean(r'logs\\CNN-GNN_True_False_True', [True, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=49-step=5600.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=24-step=2800.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=40-step=4592.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Temp\\ipykernel_1576\\1074748613.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
      "C:\\Users\\fardin\\AppData\\Local\\Temp\\ipykernel_1576\\1074748613.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
      "C:\\Users\\fardin\\AppData\\Local\\Temp\\ipykernel_1576\\1074748613.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
      "C:\\Users\\fardin\\AppData\\Local\\Temp\\ipykernel_1576\\1074748613.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.5245588860544218\n",
      "total_f1: nan\n",
      "total_prec: nan\n",
      "total_rec: 0.5245494198642423\n",
      "total_loss: 0.30885953704516095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Temp\\ipykernel_1576\\1074748613.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n"
     ]
    }
   ],
   "source": [
    "calculate_average_metrics_mean(r'logs\\CNN-GNN_True_False_False', [True, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_average_metrics_mean(r'logs\\CNN-GNN_False_True_True', [False, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_average_metrics_mean(r'logs\\CNN-GNN_False_True_False', [False, True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_average_metrics_mean(r'logs\\CNN-GNN_False_False_True', [False, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=21-step=2464.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=21-step=2464.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=22-step=2576.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.9092155612244898\n",
      "total_f1: 0.909334022870215\n",
      "total_prec: 0.9094525515881827\n",
      "total_rec: 0.9092155612244898\n",
      "total_loss: 0.25597233573595685\n"
     ]
    }
   ],
   "source": [
    "calculate_average_metrics_mean(r'logs\\CNN-GNN_False_False_False', [False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.908203125, 0.90824427, 0.908203125, 0.908223697034005, 0.3088666666666667)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = (0.9080835459183674 + 0.9083227040816326 + 0.908203125)/3.0\n",
    "prec = ((0.90932352+0.90685106)/2 + (0.91167015+0.90502926)/2 + (0.91444759 + 0.90214404)/2) / 3\n",
    "recal = ((0.90656888+0.90959821)/2 +(0.90425702+0.91238839)/2+ (0.90066964+0.91573661)/2)/3\n",
    "f1 = 2*prec*recal/(prec+recal)\n",
    "loss = (0.3364 + 0.2623 + 0.3279)/3\n",
    "acc, prec, recal, f1, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.91977188081937"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=85.78\n",
    "r=86.06\n",
    "2*p*r/(p+r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
