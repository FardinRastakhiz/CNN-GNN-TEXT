{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch_scatter import scatter_max, scatter_mean\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from torch import nn\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vocab = {v:k for k,v in tokenizer.vocab.items()}\n",
    "all_vocab_indices = list(id_vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation\n",
    "all_chars = set(allowed_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Data\\ReducedEmbeddings\\deberta_larg_reduced_embeddings_64.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "all_vocab_str = []\n",
    "for i in range(len(id_vocab)):\n",
    "    all_vocab_str.append(id_vocab[i])\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'Data\\ReducedEmbeddings\\polarity_debertav3_tokens_gpt_mini_emb.npy', 'rb') as f:\n",
    "    polarities_subjectivities= np.load(f)\n",
    "polarities_subjectivities = torch.from_numpy(polarities_subjectivities)\n",
    "polarity_vocab_dict = dict(zip(all_vocab_str, polarities_subjectivities))\n",
    "polarity_vocab_dict['<n>'] = torch.tensor([0.0, 0.0])\n",
    "len(token_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128001, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarities_subjectivities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085 tensor([0.7000, 0.6000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_vocab_str)):\n",
    "    if 'nice' in all_vocab_str[i]:\n",
    "        print(i, polarities_subjectivities[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# Create a set of all English characters, numbers, and punctuation\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' \\t'\n",
    "all_chars = set(allowed_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 256\n",
    "folder_path = r'C:\\Users\\fardin\\Projects\\CGNet\\Data\\TextClassification\\IMDB'\n",
    "# t_tokenizer = TweetTokenizer()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_ratio = 0.1\n",
    "test_df = pd.read_csv(r'data\\TextClassification\\IMDB\\test.csv')\n",
    "test_df['Topic'] = test_df['label']\n",
    "test_df['Content'] = test_df['text']\n",
    "test_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.iloc[:int(keep_ratio*test_df.shape[0])]\n",
    "train_df = pd.read_csv(r'data\\TextClassification\\IMDB\\train.csv')\n",
    "train_df['Topic'] = train_df['label']\n",
    "train_df['Content'] = train_df['text']\n",
    "train_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df = train_df.iloc[:int(keep_ratio*train_df.shape[0])]\n",
    "sst_classes = [\"Negative\", \"Positive\"]\n",
    "df = pd.DataFrame(np.concatenate([train_df.values, test_df.values]), columns=train_df.columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = {c:i for i, c in enumerate(sst_classes)}\n",
    "id_class = {i:c for i, c in enumerate(sst_classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "vocabs_lists = list(token_vocab_dict.keys())\n",
    "term_frequencies = {t:1 for t in vocabs_lists}\n",
    "temp_term_frequencies = {}\n",
    "\n",
    "char_set = set()\n",
    "for doc in train_df.Content.values:\n",
    "    tokens_list = tokenizer.tokenize(doc)\n",
    "    char_set.update(set(' '.join(tokens_list)))\n",
    "    char_set.update(set(doc))\n",
    "    new_tokens = {t.strip('▁').lower() for t in tokens_list}\n",
    "    for t in new_tokens:\n",
    "        if t not in temp_term_frequencies:\n",
    "            temp_term_frequencies[t] = 0\n",
    "        temp_term_frequencies[t] += 1\n",
    "        \n",
    "for k, v in term_frequencies.items():\n",
    "    stripped_token = k.strip('▁').lower()\n",
    "    term_frequencies[k] = temp_term_frequencies[stripped_token] if stripped_token in temp_term_frequencies else 1\n",
    "\n",
    "# del temp_term_frequencies\n",
    "    \n",
    "for doc in test_df.Content.values:\n",
    "    char_set.update(set(' '.join(tokenizer.tokenize(doc))))\n",
    "    char_set.update(set(doc))\n",
    "len(char_set)\n",
    "\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' '\n",
    "all_chars = set(''.join(char_set).join(allowed_chars))\n",
    "vocab_dict = {c:i for i, c in enumerate(all_chars)}  # [Problems]\n",
    "if '\\x01' not in vocab_dict:\n",
    "    vocab_dict['\\x01'] = len(vocab_dict)\n",
    "char_Set = set(vocab_dict.keys())\n",
    "num_embedding = len(vocab_dict)\n",
    "vocab_dict_rev = dict(zip(list(vocab_dict.values()), list(vocab_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '\\x80',\n",
       " '\\x84',\n",
       " '\\x85',\n",
       " '\\x8d',\n",
       " '\\x91',\n",
       " '\\x96',\n",
       " '\\x97',\n",
       " '\\xa0',\n",
       " '¡',\n",
       " '£',\n",
       " '¦',\n",
       " '¨',\n",
       " '«',\n",
       " '®',\n",
       " '´',\n",
       " '»',\n",
       " '½',\n",
       " 'Á',\n",
       " 'Ã',\n",
       " 'É',\n",
       " 'Ö',\n",
       " 'Ü',\n",
       " 'ß',\n",
       " 'à',\n",
       " 'á',\n",
       " 'â',\n",
       " 'ã',\n",
       " 'ä',\n",
       " 'å',\n",
       " 'æ',\n",
       " 'ç',\n",
       " 'è',\n",
       " 'é',\n",
       " 'ê',\n",
       " 'í',\n",
       " 'î',\n",
       " 'ï',\n",
       " 'ñ',\n",
       " 'ó',\n",
       " 'ô',\n",
       " 'ö',\n",
       " 'ø',\n",
       " 'ù',\n",
       " 'ü',\n",
       " '́',\n",
       " '̈',\n",
       " '–',\n",
       " '’',\n",
       " '“',\n",
       " '”',\n",
       " '⁄',\n",
       " '▁'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.00001\n",
    "total_token_count = np.array(list(term_frequencies.values())).sum()\n",
    "one_tensor = torch.tensor(1)\n",
    "def subsampling_equation_linear(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = torch.min(one_tensor, torch.sqrt_(threshold/f_x))\n",
    "    return x\n",
    "\n",
    "def subsampling_equation_sigmoid(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = 1-0.95*F.sigmoid(0.05*((f_x/threshold)-90))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterandTokenLevelCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, num_classes, char_dict, token_dict, sentiment_dict, tokenizer, token_frequencies, sampling_equation, shuffle=True, batch_size=128) -> None:\n",
    "        super().__init__()\n",
    "        if len(y) % batch_size != 0:\n",
    "            self.shortage = ((len(y) // batch_size)+1)*batch_size - len(y)\n",
    "            empty_labels = [i%2 for i in range(self.shortage)]\n",
    "            empty_strings = [id_class[l] for l in empty_labels]\n",
    "            y = np.concatenate([y, empty_labels])\n",
    "            X = np.concatenate([X, empty_strings])\n",
    "        \n",
    "        y = torch.from_numpy(y)\n",
    "        self.shuffle = shuffle\n",
    "        self.y = torch.nn.functional.one_hot(y, num_classes=num_classes).float()\n",
    "        self.X = X\n",
    "        self.char_dict = char_dict\n",
    "        self.char_Set = set(char_dict.keys())\n",
    "        self.vocab_size = len(self.char_dict)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_dict = token_dict\n",
    "        self.sentiment_dict = sentiment_dict\n",
    "        self.token_frequencies = token_frequencies\n",
    "        self.max_token_count = 0\n",
    "        self.all_data = []\n",
    "        self.token_lengths = []\n",
    "        self.token_embeddign_ids = []\n",
    "        \n",
    "        self.sum_a = 0\n",
    "        \n",
    "        for doc in tqdm(self.X):\n",
    "            g_data = self.content_to_graph(doc, sampling_equation)\n",
    "            self.all_data.append(g_data)\n",
    "        \n",
    "        \n",
    "        self.num_sections = len(y) // batch_size\n",
    "        self.x_lengths = np.array([self.all_data[i].character_length for i in range(len(self.all_data))])\n",
    "        self.x_len_args = np.argsort(self.x_lengths)[::-1]\n",
    "        \n",
    "        self.section_ranges = np.linspace(0, len(self.x_len_args), self.num_sections+1)\n",
    "        self.section_ranges = [(int(self.section_ranges[i-1]), int(self.section_ranges[i])) for i in range(1, len(self.section_ranges))]\n",
    "\n",
    "        self.position_j = 0\n",
    "        self.section_i = 0\n",
    "        self.epoch = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "        self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        index = self.get_section_index()\n",
    "        return self.all_data[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def get_section_index(self):\n",
    "        target_index = self.sections[self.section_i, self.position_j]\n",
    "        \n",
    "        self.position_j = (self.position_j + 1) % self.section_size\n",
    "        if self.position_j == 0:\n",
    "            self.section_i = (self.section_i + 1) % self.num_sections\n",
    "            if self.shuffle and self.section_i == 0:\n",
    "                self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        return target_index\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.section_i = 0\n",
    "        self.position_j = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "    def split_into_k_groups(self, len_sorted_args, lengths:np.array, k):\n",
    "        if self.shuffle and self.epoch > 0:\n",
    "            randomize_sections = np.concatenate([np.random.choice(np.arange(r[0], r[1]), size=r[1]-r[0], replace=False) for r in self.section_ranges])\n",
    "            len_sorted_args = len_sorted_args[randomize_sections]\n",
    "        \n",
    "        nums = lengths[len_sorted_args]\n",
    "        groups_size = len(len_sorted_args) // k\n",
    "        \n",
    "        \n",
    "        groups = [[] for _ in range(k)]\n",
    "        group_sums = np.zeros(k, dtype=int)\n",
    "        group_sizes = np.zeros(k, dtype=int)\n",
    "        \n",
    "        for i, num in enumerate(nums):\n",
    "            candidate_indices = np.where(group_sizes<groups_size)[0]\n",
    "            min_group_idx = candidate_indices[np.argmin(group_sums[candidate_indices])]\n",
    "            groups[min_group_idx].append(len_sorted_args[i])\n",
    "            group_sums[min_group_idx] += num\n",
    "            group_sizes[min_group_idx] += 1\n",
    "        self.epoch += 1\n",
    "        \n",
    "        groups = np.array(groups)\n",
    "        group_sums_argsort = np.argsort(group_sums)[::-1]\n",
    "        groups = groups[group_sums_argsort]\n",
    "        return np.array(groups), groups_size\n",
    "        \n",
    "    def content_to_graph(self, doc, sampling_equation):\n",
    "        tokens = self.tokenizer(doc)\n",
    "        if len(tokens) == 0:\n",
    "            tokens = ['empty']\n",
    "                        \n",
    "        token_lengths = [len(t) for t in tokens]\n",
    "        tokens.append('\\x01')\n",
    "        \n",
    "        token_lengths.append(len(tokens[-1])-1)\n",
    "        token_lengths = torch.from_numpy(np.array(token_lengths, dtype=np.longlong))+1\n",
    "        token_embs = [self.token_dict[t] if t in self.token_dict else torch.zeros((64, ), dtype=torch.float32) for t in tokens]\n",
    "        token_sentiments = [self.sentiment_dict[t] if t in self.sentiment_dict else (0.0, 0.0) for t in tokens]\n",
    "        token_embs = torch.from_numpy(np.array(token_embs, dtype=np.float32))\n",
    "        token_sentiments = torch.from_numpy(np.array(token_sentiments, dtype=np.float32))\n",
    "        doc = ' '.join(tokens)\n",
    "        characters = torch.from_numpy(np.array([self.char_dict[t] for t in doc], dtype=np.longlong))\n",
    "        token_positions = torch.arange(len(token_lengths), dtype=torch.long)\n",
    "        token_indices = torch.repeat_interleave(token_positions, token_lengths)\n",
    "        token_subsampling_probabilities = sampling_equation(torch.from_numpy(np.array([self.token_frequencies[t] if t in self.token_frequencies else 1 for t in tokens])))\n",
    "        num_tokens = len(token_lengths)\n",
    "        if num_tokens > self.max_token_count:\n",
    "            self.max_token_count = num_tokens\n",
    "        g_data = Data(x=characters,\n",
    "                        token_positions=token_positions,\n",
    "                        character_length = len(characters),\n",
    "                        num_tokens = num_tokens,\n",
    "                        token_indices=token_indices,\n",
    "                        token_lengths=token_lengths,\n",
    "                        token_embeddings=token_embs,\n",
    "                        token_sentiments=token_sentiments,\n",
    "                        token_subsampling_probabilities=token_subsampling_probabilities)\n",
    "        return g_data\n",
    " \n",
    "    def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "        cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "        cumsum_vals[0] = 0\n",
    "        additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "        cumulative_token_indices = token_indices + additions\n",
    "        return cumulative_token_indices       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CharacterandTokenLevelDataLoader(DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        follow_batch: List[str] | None = None,\n",
    "        exclude_keys: List[str] | None = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CharacterandTokenLevelDataLoader, self).__init__(\n",
    "            dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        base_iterator = super(CharacterandTokenLevelDataLoader, self).__iter__()\n",
    "        for batch in base_iterator:\n",
    "            cumsum_vals = torch.cumsum(batch[0].num_tokens, dim=0).roll(1)\n",
    "            cumsum_vals[0] = 0\n",
    "            additions = torch.repeat_interleave(cumsum_vals, batch[0].character_length)\n",
    "            batch[0].cumulative_token_indices = batch[0].token_indices + additions\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2560/2560 [00:36<00:00, 69.95it/s] \n",
      "100%|██████████| 2560/2560 [00:37<00:00, 67.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 48s\n",
      "Wall time: 1min 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = CharacterandTokenLevelCustomDataset(train_df.Content.values, train_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, batch_size=batch_size)\n",
    "test_dataset = CharacterandTokenLevelCustomDataset(test_df.Content.values, test_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, batch_size=batch_size)\n",
    "max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv\n",
    "\n",
    "# Normalization on each feature of all tokens, for this we used batch norm class but with tokens at batch dimention\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, *args, **kwargs):\n",
    "        super(GCNN, self).__init__(*args, **kwargs)\n",
    "        self.gnn = GATv2Conv(hidden_dim, hidden_dim//8, heads=4, add_self_loops=False)\n",
    "        self.conv = nn.Conv1d(hidden_dim, hidden_dim//2, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim//2)\n",
    "        \n",
    "    def forward(self, x, edge_data, return_attention_weights = False):\n",
    "        x1, edge_weights = self.gnn(x, edge_data, return_attention_weights=return_attention_weights) \n",
    "        x2 = F.relu(self.conv(x.T).T)\n",
    "        x1 = F.leaky_relu_(self.bn1(x1))\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        return x, edge_weights, edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, to_undirected\n",
    "\n",
    "class GenGraph(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, virtual_nodes, lattice_step, lattice_pattern=None, *args, **kwargs):\n",
    "        super(GenGraph, self).__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.lattice_step = lattice_step\n",
    "        self.lp = lattice_pattern if lattice_pattern is None else torch.tensor(lattice_pattern)\n",
    "        self.virtual_node_embeddings = nn.Embedding(self.virtual_nodes, hidden_dim)\n",
    "        \n",
    "    def gen_graph(self, x, token_subsampling_probabilities, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        v_n_e_counts = total_token_counts*self.virtual_nodes\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        edge_indices = torch.empty((2, base_numel + v_n_e_counts*2), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(edge_indices, random_links, lattice_links, tc_range)\n",
    "            \n",
    "        if self.virtual_nodes > 0:\n",
    "            virtual_nodes_range = torch.arange(self.virtual_nodes, device=x.device).view(1, -1)\n",
    "            virtual_nodes_ids = torch.repeat_interleave(virtual_nodes_range, len(token_counts), dim=0)\n",
    "            v_n_idx = (virtual_nodes_ids + torch.arange(0, len(token_counts)*self.virtual_nodes, self.virtual_nodes, device=x.device).view(-1, 1) + total_token_counts )\n",
    "            virtual_edge_ids = torch.repeat_interleave(v_n_idx.view(-1), token_counts.view(-1, 1).expand(len(token_counts), self.virtual_nodes).reshape(-1), dim=0).view(1, -1)\n",
    "            \n",
    "            embs = self.virtual_node_embeddings(virtual_nodes_ids.T).view(-1, self.hidden_dim)\n",
    "            x_extended = torch.cat([x, embs], dim=0)\n",
    "            x_index = torch.arange(total_token_counts, device=x.device).repeat(self.virtual_nodes).view(1, -1)\n",
    "            edge_indices[:, base_numel:base_numel+v_n_e_counts] = torch.cat([x_index, virtual_edge_ids], dim=0)\n",
    "            edge_indices[:, base_numel+v_n_e_counts:] = torch.cat([virtual_edge_ids, x_index], dim=0)\n",
    "            x = x_extended\n",
    "        \n",
    "        edge_indices = self.subsample_edges(edge_indices, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_indices)])\n",
    "        \n",
    "    def re_gen_graph(self, x, edge_indices, token_subsampling_probabilities, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        self.fill_lattice_and_random_edges(edge_indices, random_links, lattice_links, tc_range)\n",
    "        # for i in range(base.shape[1]):\n",
    "        #     edge_indices[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        edge_indices = self.subsample_edges(edge_indices, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_indices)])\n",
    "    \n",
    "    def replace_unimportant_edges(self, edge_weights, x, edge_indices, token_subsampling_probabilities, total_token_counts, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2):\n",
    "        v_n_e_counts = total_token_counts*self.virtual_nodes\n",
    "        # if v_n_e_counts>0:\n",
    "        #     important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # else:\n",
    "        #     print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "        #     print(f'total_token_coutns: {total_token_coutns}')\n",
    "        #     print(f'p_keep: {p_keep}')\n",
    "        #     important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "        # print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "        # print(f'edge_indices.shape: {edge_indices.shape}')\n",
    "        # print(f'1: edge_weights: {edge_weights.shape}')\n",
    "        important_indices = torch.topk(edge_weights.squeeze(), p_keep*total_token_counts, dim=0).indices\n",
    "        # print(f'2: important_indices: {important_indices.shape}')\n",
    "        # print(f'2.5: \\n {edge_weights} \\n\\n {important_indices}')\n",
    "\n",
    "        # important_indices = torch.arange(total_token_counts, dtype=torch.int64, device=x.device)\n",
    "        # important_indices = important_indices.view(-1)\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        # print(f'3: random_links: {random_links.shape}, lattice_links: {lattice_links.shape}, tc_range: {tc_range.shape},')\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        # print(f'4: base_numel: {base_numel}')\n",
    "        \n",
    "        new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "        # print(f'5: new_edge_index: {new_edge_index.shape}')\n",
    "        # print(f'new_edge_index.shape 1: {new_edge_index.shape}, base_numel + important_indices.shape[0] + 2*v_n_e_counts: {base_numel + important_indices.shape[0] + 2*v_n_e_counts}')\n",
    "        self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "        # print(f'6: new_edge_index: {new_edge_index.shape}, random_links: {random_links.shape}, lattice_links: {lattice_links.shape}, tc_range: {tc_range.shape}')\n",
    "        # print(f'new_edge_index.shape 2: {new_edge_index.shape}, edge_indices: {edge_indices.shape}, important_indices shape: {important_indices.shape}, important_indices max: {important_indices.max()}')\n",
    "        new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_indices[:, important_indices]\n",
    "        # print(f'7: new_edge_index: {new_edge_index.shape}')\n",
    "\n",
    "        if(self.virtual_nodes>0):\n",
    "            new_edge_index[:, -2*v_n_e_counts:] = edge_indices[:, -2*v_n_e_counts:]\n",
    "            \n",
    "        # for i in range(base.shape[1]):\n",
    "        #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        # print(f'7.5: \\n {new_edge_index} \\n\\n {token_subsampling_probabilities}')\n",
    "        new_edge_index = self.subsample_edges(new_edge_index, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "    \n",
    "    # def replace_unimportant_edges(self, edge_weights, x, edge_index, token_subsampling_probabilities, total_token_coutns, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2, seed=-1):\n",
    "    #     v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "    #     if v_n_e_counts>0:\n",
    "    #         important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "    #     else:\n",
    "    #         print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "    #         print(f'total_token_coutns: {total_token_coutns}')\n",
    "    #         print(f'p_keep: {p_keep}')\n",
    "    #         important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "    #     # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "\n",
    "    #     important_indices = torch.arange(total_token_coutns, dtype=torch.int64, device=x.device) + important_indices*total_token_coutns\n",
    "    #     important_indices = important_indices.view(-1)\n",
    "    #     random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance, seed)\n",
    "    #     base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "    #     new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "    #     self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "    #     new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_index[:, important_indices]\n",
    "    #     if(self.virtual_nodes>0):\n",
    "    #         new_edge_index[:, -2*v_n_e_counts:] = edge_index[:, -2*v_n_e_counts:]\n",
    "            \n",
    "    #     # for i in range(base.shape[1]):\n",
    "    #     #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "    #     new_edge_index = self.subsample_edges(new_edge_index, token_subsampling_probabilities)\n",
    "    #     return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "    \n",
    "    \n",
    "         \n",
    "    def calculate_graph(self, x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance):\n",
    "\n",
    "        tc_extended = torch.repeat_interleave(token_counts, token_counts, dim=0).view(-1,1)\n",
    "        tc_lower_bound = torch.empty((len(token_counts)+1), dtype=torch.long, device=x.device) #torch.cuda.IntTensor(len(token_counts)+1) #\n",
    "        tc_lower_bound[0] = 0\n",
    "        tc_lower_bound[1:] = torch.cumsum(token_counts, dim=0)\n",
    "        tc_lower_bound_extended = torch.repeat_interleave(tc_lower_bound[:-1], token_counts, dim=0).view(-1,1)\n",
    "        tc_range = torch.arange(tc_lower_bound[-1], device=x.device).view(-1,1)\n",
    "        # torch.arange(tc_lower_bound[-1], dtype=torch.int32, device=x.device).view(-1,1)\n",
    "        \n",
    "        random_ints = torch.randint(0, 2*total_token_counts, (total_token_counts, random_edges), device=x.device) # torch.cuda.IntTensor(len(token_lengths), random_edges).random_()\n",
    "        lattice = self.lp.to(x.device) if self.lp is not None else torch.arange(lattice_start_distance, max(lattice_start_distance, self.lattice_step*lattice_edges+1), self.lattice_step, device=x.device).view(1, -1)\n",
    "        \n",
    "\n",
    "        # exponentials = torch.pow(2, torch.arange(1, self.exp_edges+1, device=x.device)).view(1, -1)\n",
    "        tc_local_range = tc_range - tc_lower_bound_extended\n",
    "        random_links = (((random_ints % (tc_extended - 1))+1 + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        lattice_links = ((lattice + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        # base = torch.cat([base1, base2], dim=1)\n",
    "        tc_range = tc_range.view(1,-1)\n",
    "        return random_links, lattice_links, tc_range\n",
    "    \n",
    "    def fill_lattice_and_random_edges(self, edge_indices, random_links, lattice_links, tc_range):\n",
    "        for i in range(0, lattice_links.shape[1]*2, 2):\n",
    "            edge_indices[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]] = torch.cat([lattice_links[:,i//2].view(1,-1), tc_range], dim=0)\n",
    "            edge_indices[:, (i+1)*lattice_links.shape[0]:(i+2)*lattice_links.shape[0]] = edge_indices[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]][[1, 0]]\n",
    "            \n",
    "        for i in range(random_links.shape[1]):\n",
    "            j = i + lattice_links.shape[1]*2\n",
    "            edge_indices[:, j*random_links.shape[0]:(j+1)*random_links.shape[0]] = torch.cat([random_links[:,i].view(1,-1), tc_range], dim=0)\n",
    "            \n",
    "    def subsample_edges(self, edge_indices, token_subsampling_probabilities, keep_ratio=0.65):\n",
    "        \n",
    "        p = torch.rand(edge_indices.shape, dtype=torch.float, device=edge_indices.device)\n",
    "        to_keep = (p<token_subsampling_probabilities[edge_indices]).float()\n",
    "        to_keep = torch.topk(to_keep[0] + to_keep[1], (int)(edge_indices.shape[1]*keep_ratio), dim=0).indices\n",
    "        edge_indices = edge_indices[:, to_keep]\n",
    "        return edge_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment_Injection(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)        \n",
    "        self.conv1 = nn.Conv1d(2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim*2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, token_sentiments):\n",
    "        x1 = F.relu_(self.bn1(self.conv1(token_sentiments.T).T))\n",
    "        x = F.relu_(self.conv2(torch.cat([x, x1], dim=1).T))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv, summary\n",
    "import math\n",
    "\n",
    "class CNN_for_Text_No_Positional_Encoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embedding, pos_emb_size=8192, embedding_dim=64, hidden_dim=64, dropout=0.3, num_out_features=4, seed=-1, random_edges=4, lattice_edges=10, virtual_nodes=1, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64, isXaiTests=False, step_of_test = 0, num_tests=50, *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text_No_Positional_Encoding, self).__init__(*args, **kwargs)\n",
    "        self.pos_emb_size = pos_emb_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        self.num_out_features = num_out_features\n",
    "        self.isXaiTests = int(isXaiTests)\n",
    "        self.num_tests = num_tests\n",
    "        self.step_of_test = step_of_test\n",
    "\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.positional_encoding = nn.Embedding(pos_emb_size, embedding_dim)\n",
    "        self.positional_encoding.weight = self.create_positional_encoding()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        \n",
    "        # if self.use_token_polarity[0]:\n",
    "        self.conv3 = nn.Conv1d(2*hidden_dim + 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        # else:\n",
    "        # self.conv3 = nn.Conv1d(2*hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        # if self.use_token_polarity[1]:\n",
    "        # self.sentiment1  = Sentiment_Injection(hidden_dim)\n",
    "        # if self.use_token_polarity[2]:\n",
    "        # self.sentiment2  = Sentiment_Injection(hidden_dim)\n",
    "            \n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.gcnn2 = GCNN(hidden_dim+inject_embedding_dim)\n",
    "        self.graph_generator = GenGraph(hidden_dim, virtual_nodes, lattice_step)\n",
    "        \n",
    "        k = 4\n",
    "        self.fc0 = nn.Linear(hidden_dim , hidden_dim+inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim+inject_embedding_dim , hidden_dim * k)\n",
    "        self.fc2 = nn.Linear(hidden_dim * (2+virtual_nodes) * k , 32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, self.num_out_features)\n",
    "        self.max_length = 0\n",
    "    \n",
    "    def forward(self, x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings, token_positions):\n",
    "        # cumulative_token_indices = token_indices if not self.isXaiTests else self.caluculate_batch_token_positions(num_tokens, character_length, token_indices)\n",
    "        cumulative_token_indices = self.caluculate_batch_token_positions(num_tokens, character_length, token_indices)\n",
    "        \n",
    "        # print(f'2: {x.shape}')\n",
    "        x = self.embedding(x)\n",
    "        # print(f'2.5: {x.shape}')\n",
    "        x = self.dropout(x)\n",
    "        # print(f'2.6: {x.shape}')\n",
    "        x = x.T\n",
    "        # print(f'2.7: {x.shape}')\n",
    "        # x = self.refine_shape(1, x, 0)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # print(f'2.8: {x.shape}')\n",
    "        x = self.refine_shape(1, x, self.hidden_dim, 0)\n",
    "        # print(f'2.8 refined: {x.shape}')\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.refine_shape(2, x, self.hidden_dim, 0)\n",
    "        # print(f'2.9: {x.shape}')\n",
    "        x = self.dropout(x)\n",
    "        # x = self.refine_shape(4, x, 0)\n",
    "        # print(f'3: {x.shape}')\n",
    "        x1 = scatter_max(x, cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, cumulative_token_indices, dim=1)\n",
    "\n",
    "        # if self.use_token_polarity[0]:\n",
    "        x = torch.cat([x1, x2, token_sentiments.T], dim=0)\n",
    "        # else:\n",
    "        # x = torch.cat([x1, x2], dim=0)\n",
    "            \n",
    "        # print(f'4: {x.shape}')\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x + self.positional_encoding(token_positions).T\n",
    "        \n",
    "        # print(f'4.5: {x.shape}, self.hidden_dim: {self.hidden_dim}, self.is_tests_token_level: {self.step_of_test}')\n",
    "        # if self.isXaiTests and x.shape[0] != self.hidden_dim:\n",
    "        # x = torch.chunk(x, self.num_tests ** (1 - self.isXaiTests), dim=0)\n",
    "        x = self.refine_shape(3, x, self.hidden_dim, 0)\n",
    "        \n",
    "        # x = torch.chunk(x, (x.shape[0] // self.hidden_dim)**self.is_tests_token_level, dim=0)\n",
    "        # x = torch.cat(x, dim=1)\n",
    "        \n",
    "        # if self.isXaiTests and x.shape[0] != self.hidden_dim:\n",
    "        #     x = torch.chunk(x, self.num_tests, dim=0)\n",
    "        #     x = torch.cat(x, dim=1)\n",
    "        # x = x.reshape(self.hidden_dim, -1)\n",
    "        # print(\"abababdadasd\")\n",
    "        # print(f'5: {x.shape}, {edge_index.shape}, {cumulative_token_indices.shape}, {token_sentiments.shape}, {token_lengths.shape}, {num_tokens.shape}, {character_length.shape}, {token_embeddings.shape}')\n",
    "        # if self.use_token_polarity[1]:\n",
    "        # x = self.sentiment1(x.T, token_sentiments)\n",
    "\n",
    "        # print(f'6: {x.shape}')\n",
    "        x = self.refine_shape(4, x.T, self.hidden_dim, 1)\n",
    "        # print(f'6 refined: {x.shape}')\n",
    "        rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "            \n",
    "        graph = self.graph_generator.gen_graph(x, token_subsampling_probabilities, len(token_lengths), num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "        rand_edges = rand_edges-1\n",
    "        lattice_edges = lattice_edges-1\n",
    "        \n",
    "        # print(f'7: {graph.x.shape}')\n",
    "        \n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(num_tokens), device=x.device), num_tokens)\n",
    "        x, edge_weights, edge_index = self.gcnn1(graph.x, graph.edge_index, return_attention_weights = True)\n",
    "        # print(f'7.1: {x.shape}')\n",
    "        x = self.refine_shape(5, x, self.hidden_dim, 1)\n",
    "        # print(f'7.1 2 : {len(torch.cat(edge_weights[1::2], dim=0))}')\n",
    "        edge_weights = self.refine_edge_weights(edge_weights)\n",
    "        edge_index = self.refine_edge_index(edge_index)\n",
    "        \n",
    "        # edge_weights = edge_weights[1].unsqueeze(-1)\n",
    "        # print(f'7.5 edge_weights: {edge_weights.shape}, - {graph.edge_index.shape[1]}, {edge_weights.shape[0]}')\n",
    "        # edge_weights = edge_weights[:min(graph.edge_index.shape[1], edge_weights.shape[0]), 0]\n",
    "        # edge_weights = edge_weights.squeeze()\n",
    "        \n",
    "        edge_weights = edge_weights.unsqueeze(-1)\n",
    "        # print(f'7.5 edge_weights: {edge_weights.shape}, - {edge_weights.shape[0]}')\n",
    "        edge_weights = edge_weights[:edge_weights.shape[0], 0]\n",
    "        \n",
    "        # print(f'7.6 edge_weights: {edge_weights.shape}')\n",
    "        # print(f'7.7: {x.shape}')\n",
    "        x = self.refine_shape(5, x, self.hidden_dim, 1)\n",
    "        # print(f'7.8 refined: {x.shape}')\n",
    "        \n",
    "        graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, edge_index, token_subsampling_probabilities, len(token_lengths), num_tokens, rand_edges, lattice_edges, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        \n",
    "        # print(f'8: {graph.x.shape}')\n",
    "        \n",
    "        # if self.use_token_polarity[2]:\n",
    "        # x = self.sentiment2(x, token_sentiments)\n",
    "          \n",
    "        # print(f'8.1: {x.shape}')\n",
    "        x = self.refine_shape(6, x.T, self.hidden_dim, 1)\n",
    "        # print(f'8.2 refined: {x.shape}')\n",
    "        \n",
    "        # print(f'9: {x.shape}')  \n",
    "        xa = graph.x[:token_embeddings.shape[0]]\n",
    "        xb = token_embeddings\n",
    "        x = torch.cat([xa, xb], dim=1)\n",
    "        # x = torch.cat([graph.x[:g_data.token_embeddings.shape[0]], g_data.token_embeddings], dim=1)\n",
    "        \n",
    "        # print(f'10: {x.shape}')  \n",
    "        x1 = F.relu(self.fc0(graph.x[token_embeddings.shape[0]:]))\n",
    "        x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "        # print(f'11: {x.shape}')  \n",
    "        sum1 = torch.sum(edge_weights) + torch.sum(edge_index)\n",
    "        x, edge_weights, edge_index = self.gcnn2(x, graph.edge_index)\n",
    "        edge_weights = self.refine_edge_weights(edge_weights)\n",
    "        sum1 = sum1 + torch.sum(edge_weights) + torch.sum(edge_index) \n",
    "        \n",
    "        # print(f'12: {x.shape}')  \n",
    "        x = F.elu_(self.fc1(x))\n",
    "        x1 = scatter_max(x[:len(token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(token_lengths)], doc_token_index, dim=0)\n",
    "        vn_embs = x[len(token_lengths):]\n",
    "        x_for_cat = [x1, x2]\n",
    "        x_for_cat.extend([vn_embs[i*x1.shape[0]:(i+1)*x1.shape[0]] for i in range(self.virtual_nodes)])\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        \n",
    "        # print(f'13: {x.shape}')  \n",
    "        x = F.elu_(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        # print(f'14: {x.shape}')  \n",
    "        return x + sum1 * 0.0\n",
    "    \n",
    "    def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "        cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "        cumsum_vals[0] = 0\n",
    "        additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "        cumulative_token_indices = token_indices + additions\n",
    "        return cumulative_token_indices\n",
    "    \n",
    "    def create_positional_encoding(self):\n",
    "        position = torch.arange(self.pos_emb_size).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.hidden_dim, 2) * (-math.log(10000.0) / self.hidden_dim))\n",
    "        pe = torch.zeros(self.pos_emb_size, self.hidden_dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return torch.nn.Parameter(pe, requires_grad=False)\n",
    "    \n",
    "    def refine_shape(self, test_step, x, num_chunks, section=0):\n",
    "        x = torch.chunk(x, (x.shape[section] // num_chunks)**(self.step_of_test==test_step), dim=0)\n",
    "        x = torch.cat(x, dim=1-section)\n",
    "        return x\n",
    "        \n",
    "    def refine_edge_weights(self, edge_weights):\n",
    "        edge_weights = edge_weights[1::2] + edge_weights[0::2] * 0\n",
    "        edge_weights = [edge_weights[i] for i in range(len(edge_weights))]\n",
    "        edge_weights = torch.cat(edge_weights, dim=0)\n",
    "        return edge_weights\n",
    "        \n",
    "    def refine_edge_index(self, edge_index):\n",
    "        edge_index = torch.cat([edge_index[::2].reshape(1, -1), edge_index[1::2].reshape(1, -1)], dim=0)\n",
    "        return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for p1 in [False, True]:\n",
    "# #     for p2 in [False, True]:\n",
    "# #         for p3 in [False, True]:\n",
    "# # print(f'\\n{p1}, {p2}, {p3}: \\n')\n",
    "# classifier_torch_model = CNN_for_Text_No_Positional_Encoding(num_embedding=num_embedding, hidden_dim=64, embedding_dim=64, pos_emb_size=3080, dropout=0.2, num_out_features=len(class_id), seed=911, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2, isXaiTests=True, num_tests=len(X.num_tokens)).eval()\n",
    "# flopt_counter = FlopCounterMode(classifier_torch_model)\n",
    "# with flopt_counter:\n",
    "#     classifier_torch_model(X.x, torch.zeros((2, 0)), X.token_subsampling_probabilities, X.token_indices, X.token_sentiments, X.token_lengths, X.num_tokens, X.character_length, X.token_embeddings, X.token_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.managers.ModelManager import ModelManager\n",
    "from utilities.managers.ClassifierModelManager import ClassifierModelManager\n",
    "from utilities.lightning_models.CnnGnnClassifierLightningModel import CnnGnnClassifierLightningModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 128\n",
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "label_size = 1\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, dropout=0.25, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True, use_positional_encoder=[False, False, False]):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    classifier_torch_model = CNN_for_Text_No_Positional_Encoding(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=4096, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=6, lattice_edges=10, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 40, 45,50,55],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name=f'CNN-GNN_{use_positional_encoder[0]}_{use_positional_encoder[1]}_{use_positional_encoder[2]}',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    train_dataset.reset_params()\n",
    "    train_dataset.position_j = 0\n",
    "    test_dataset.reset_params()\n",
    "    test_dataset.position_j = 0\n",
    "    \n",
    "    # train_dataset.section_i = 0\n",
    "    # train_dataset.each_section_i = np.zeros((train_dataset.num_sections, ), dtype=int)\n",
    "    # test_dataset.section_i = 0\n",
    "    # test_dataset.each_section_i = np.zeros((test_dataset.num_sections, ), dtype=int)\n",
    "    \n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.lightning_model.model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(model_manager.lightning_model, test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                                | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0 | model     | CNN_for_Text_No_Positional_Encoding | 470 K  | train\n",
      "1 | loss_func | BCEWithLogitsLoss                   | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy                  | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy                  | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy                  | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "208 K     Trainable params\n",
      "262 K     Non-trainable params\n",
      "470 K     Total params\n",
      "1.881     Total estimated model params size (MB)\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3100d0e73dd54907a53bc59f3b819f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f246d6321d2d4498b0024d990b072fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4fca36722a4c3cb6676b70510020df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b538633afa86426bafcc27fe5eba31b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a4861a57f549e6a33229306c57f28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc2f425456f410dae8b6319dd731439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4102bef74eeb4822bca1ab757eae3156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d4dfe3f4694546bae79127a28b7575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c9ebde68374c40b419990edf195644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd046b0436e47c9856e6f1c8adde8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc733d463594576822287f3be3a39c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b678a9b270764cc2832ec4d9ed28b070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1b613439ec4008bba62704591ab8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1caf9fc82f84f0ca8c6deb18976b316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b4a2eaa07f48b88d0f6d8e8df63f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94eb089fa7a54893afee060bbdfa3a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15da0ca9d995447499045b49b7bf33af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0810fada707b4447bb5640382d47a97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aded51649d3b4fcda3524640ffd51353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe107aa66b8411ebbedbf10ed1d1c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba8eb6e88a94abfb691c8f727ec2128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32641a7759144f7fb47e4987abefc391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24892c5cf3a4f4aab0767d22ab98695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72f916de6b748899adfe0ba9e36fcda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998be0d42b9e4453b305f2d4055c3b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f892763b4ff64654a9ad90980f8d8030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b097729af18e4c4e80fc91774cb2ffe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdea9527b2942e5bbbd4fabfd2c09c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c73471ddb8142ce9fc25dfc150093df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6339b8c9c74e5d8bf07e0d91035abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3b21b1fbe5440db949eac99f920989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b62e937806e41d4b8da20c5f79b4e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983778182c204a35bffc1179d14eaa59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bfbc56b1b07461caaf5138f1de2c1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0def71774ca547d4ad1221f9dea7bdc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1352e300edca44d8b7296f49a4551cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7ffb555ce745a5b6e77a5b0be863f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c07d7264a054e73b5c1935cd94f4892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e621fce361043c1874402cf5d0e0e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e74be7900aa47729567a27374d99a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb6fcc9601d45f4b1f8cb43a8c0e68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eda2071b0ce4d05acae954022b1f908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36f49cfa20541cc901625f60625b376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8640dd1e6b884cdaa95b87e21efc4811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c1eb44f30d412bb80521cdbe8c11f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf36b04f1ad417b9bb0d0f2f102c107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ff79d511714d7ca446879425372a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67fdb723b6b40cd9ca5b2d9f551e1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43833c4bbbba4aaba0b7667da32c835d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fd54d8c3614b7c873e23859a244a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d814f7c97d9747e5a2f9223b552e9359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b13a25200543f5a626a1cf07fb51fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb71451bbb845e08ca431d4ad695bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee49b81161014f51b085011f45408278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a31f8cec60144df891f1ddbab4e82c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1793e2f263c54ef385194119481e5ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfb2045b6364503a0de9209e0157010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a129e963e545f78abbd3b83e7969f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df39a55cbecd46688f9aa222c4fc9138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6834445f72cb4c4ea37faa03195659b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bec250092874f288d777a1644397001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411eac9f8b0c4dbeb595f2abc840d8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c9fd97067943b2b65706fac737eb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb21b32ff9094750b032bec34b780686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a9a674acd444ea8d3a212e5fa3ddb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e029630c134fb9a8d3c7a58e9b25c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2705565bd3546648d8e5cbddaf622e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c75fe447eb4fc4a69e2ad0c9ffc67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6950851dc1a444b589fadad7dc6a8805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d3f56f834c47e1a6c76a8556e8b4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa359318e3f48438f350c47f4c74f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=70` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2560, 2])\n",
      "torch.Size([2560, 2])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8211    0.8524    0.8364      1287\n",
      "           1     0.8448    0.8123    0.8282      1273\n",
      "\n",
      "    accuracy                         0.8324      2560\n",
      "   macro avg     0.8329    0.8323    0.8323      2560\n",
      "weighted avg     0.8329    0.8324    0.8323      2560\n",
      "\n",
      "confusion matrix:\n",
      " tensor([[1097,  190],\n",
      "        [ 239, 1034]])\n",
      "================================\n",
      "torch.Size([2560, 2])\n",
      "torch.Size([2560, 2])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_manager = train_model(70, 0.2, 0.000012, 0.0032, use_positional_encoder=[False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "p = Path(r'logs/CNN-GNN_False_False_False\\version_0\\checkpoints\\epoch=0-step=4.ckpt.pth')\n",
    "not p.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "def calculatge_metrics(chpt_path, target_data_loader, num_embedding):\n",
    "        classifier_torch_model = CNN_for_Text_No_Positional_Encoding(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=4096, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=8, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "        classifier_torch_model.load_state_dict(torch.load(chpt_path, weights_only=True, map_location=\"cuda:0\"))\n",
    "        classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                batch_size=batch_size,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device).eval()\n",
    "        \n",
    "        mean_infer_acc = []\n",
    "        mean_infer_f1 = []\n",
    "        mean_infer_prec = []\n",
    "        mean_infer_rec = []\n",
    "        for i in range(5):\n",
    "            all_ys = []\n",
    "            all_y_preds = []\n",
    "            for X, y in target_data_loader:\n",
    "                with torch.no_grad():\n",
    "                    y_pred = classfier_lightning_model(X.to(device))\n",
    "                all_ys.append(torch.argmax(y,dim=1))\n",
    "                all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "            all_ys = torch.concat(all_ys)\n",
    "            all_y_preds = torch.concat(all_y_preds)\n",
    "            \n",
    "            cm = confusion_matrix(all_ys, all_y_preds, labels=list(id_class.keys()))\n",
    "            \n",
    "            accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "            precision = np.mean(np.diag(cm) / (np.sum(cm, axis=0)+0.000001))\n",
    "            recall = np.mean(np.diag(cm) / (np.sum(cm, axis=1)+0.000001))\n",
    "            f1_score = (2*precision*recall)/(precision + recall+0.000001)\n",
    "            \n",
    "            mean_infer_acc.append(accuracy)\n",
    "            mean_infer_f1.append(f1_score)\n",
    "            mean_infer_prec.append(precision)\n",
    "            mean_infer_rec.append(recall)\n",
    "        mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "        mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "        mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "        mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "        return mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "def get_best_chpt(metrics_path, epoch_numbers):\n",
    "    epoch_data = pd.read_csv(metrics_path)\n",
    "    if 'val_acc_epoch' in epoch_data.columns and epoch_data['val_acc_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_acc_epoch'].idxmax()]\n",
    "    elif 'val_loss_epoch' in epoch_data.columns and epoch_data['val_loss_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_loss_epoch'].idxmin()]\n",
    "    else:\n",
    "        raise ValueError(f\"No valid validation metrics available for epoch {epoch_numbers}.\")\n",
    "    return np.argwhere(np.array(epoch_numbers)==best_chpt['epoch']).item(), best_chpt['val_loss_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_metrics_mean(num_embedding, base_path = 'logs\\CNN-GNN18_mr2k_seeds', start=0, interval=1):\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "    total_loss = []\n",
    "    \n",
    "    for i in range(start, start + interval):\n",
    "        version_path = join(base_path, f'version_{i}')\n",
    "        checkpoint_path = join(version_path, f'checkpoints')\n",
    "        onlyfiles  = [f for f in listdir(checkpoint_path) if (isfile(join(checkpoint_path, f)) and 'epoch' in f) ]\n",
    "        epoch_numbers = [int(re.search(r'\\d+', f).group()) for f in onlyfiles]\n",
    "        best_chpt_id, loss = get_best_chpt(join(version_path, 'metrics.csv'), epoch_numbers)\n",
    "        print(onlyfiles[best_chpt_id])\n",
    "        mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model = calculatge_metrics(join(checkpoint_path, f'{onlyfiles[best_chpt_id]}'), test_dataloader, num_embedding)\n",
    "            \n",
    "        total_accuracy.append(mean_infer_acc)\n",
    "        total_f1.append(mean_infer_f1)\n",
    "        total_prec.append(mean_infer_prec)\n",
    "        total_rec.append(mean_infer_rec)\n",
    "        total_loss.append(loss)\n",
    "\n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    total_loss = torch.mean(torch.tensor(total_loss))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')\n",
    "    print(f'total_loss: {total_loss}')\n",
    "    return classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=57-step=580.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.8321874999999999\n",
      "total_f1: 0.8322694632227202\n",
      "total_prec: 0.8323027605655657\n",
      "total_rec: 0.8322371695287962\n",
      "total_loss: 0.8554494976997375\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=52-step=530.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.8197656249999999\n",
      "total_f1: 0.8218056642761976\n",
      "total_prec: 0.8235600831808544\n",
      "total_rec: 0.8200597423567642\n",
      "total_loss: 0.8941477537155151\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=68-step=690.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.823515625\n",
      "total_f1: 0.8235975607805728\n",
      "total_prec: 0.8236315185104427\n",
      "total_rec: 0.8235646079172134\n",
      "total_loss: 0.8528066873550415\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=68-step=690.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.502890625\n",
      "total_f1: 0.4410279300106394\n",
      "total_prec: 0.4514062788732569\n",
      "total_rec: 0.5001571088022638\n",
      "total_loss: 0.8528066873550415\n",
      "epoch=57-step=580.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.8338281250000001\n",
      "total_f1: 0.8338761951710756\n",
      "total_prec: 0.8338887923554867\n",
      "total_rec: 0.833864598570518\n",
      "total_loss: 0.8554494976997375\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model1 = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=1)\n",
    "classfier_lightning_model3 = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2.1667, -1.0284, -0.3112,  ...,  0.8440,  0.4139, -1.3559],\n",
       "        [ 0.4477,  0.4483, -1.6092,  ...,  0.6777,  0.5552, -0.0789],\n",
       "        [-0.1111, -1.1905, -1.0991,  ...,  0.0750,  0.3222,  0.2924],\n",
       "        ...,\n",
       "        [-0.2027, -0.7937,  0.0352,  ..., -0.7527,  0.2331,  0.1826],\n",
       "        [ 0.3098,  0.4349, -0.3574,  ...,  0.1672,  0.1886, -0.9232],\n",
       "        [-1.0632, -0.6390,  1.7161,  ...,  1.0442,  0.9414, -0.1757]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier_lightning_model1.model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2.1667e+00, -1.0284e+00, -3.1116e-01,  ...,  8.4399e-01,\n",
       "          4.1394e-01, -1.3559e+00],\n",
       "        [ 5.2677e-01,  6.3853e-01, -1.5004e+00,  ...,  4.7975e-01,\n",
       "          5.7680e-01, -1.4392e-01],\n",
       "        [-1.2900e-01, -1.2595e+00, -1.1261e+00,  ...,  2.0922e-03,\n",
       "          3.4685e-01,  1.9804e-01],\n",
       "        ...,\n",
       "        [-2.5178e-01, -7.1559e-01, -1.1819e-01,  ..., -5.6713e-01,\n",
       "          4.9578e-01,  1.1270e-01],\n",
       "        [ 2.5813e-01,  3.8796e-01, -3.1091e-01,  ...,  1.9647e-01,\n",
       "          2.2127e-01, -9.7274e-01],\n",
       "        [-1.0966e+00, -6.0523e-01,  1.5983e+00,  ...,  1.0477e+00,\n",
       "          9.0805e-01, -8.9105e-02]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier_lightning_model3.model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([145,  77,  37,  ...,   1,  37, 148])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][0].x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
