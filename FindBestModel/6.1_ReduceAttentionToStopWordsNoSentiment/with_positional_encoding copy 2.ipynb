{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch_scatter import scatter_max, scatter_mean\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from torch import nn\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vocab = {v:k for k,v in tokenizer.vocab.items()}\n",
    "all_vocab_indices = list(id_vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation\n",
    "all_chars = set(allowed_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Data\\ReducedEmbeddings\\deberta_larg_reduced_embeddings_64.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "all_vocab_str = []\n",
    "for i in range(len(id_vocab)):\n",
    "    all_vocab_str.append(id_vocab[i])\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'Data\\ReducedEmbeddings\\polarity_debertav3_tokens_gpt_mini_emb.npy', 'rb') as f:\n",
    "    polarities_subjectivities= np.load(f)\n",
    "polarities_subjectivities = torch.from_numpy(polarities_subjectivities)\n",
    "polarity_vocab_dict = dict(zip(all_vocab_str, polarities_subjectivities))\n",
    "polarity_vocab_dict['<n>'] = torch.tensor([0.0, 0.0])\n",
    "len(token_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128001, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarities_subjectivities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085 tensor([0.7000, 0.6000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_vocab_str)):\n",
    "    if 'nice' in all_vocab_str[i]:\n",
    "        print(i, polarities_subjectivities[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# Create a set of all English characters, numbers, and punctuation\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' \\t'\n",
    "all_chars = set(allowed_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 256\n",
    "folder_path = r'C:\\Users\\fardin\\Projects\\CGNet\\Data\\TextClassification\\IMDB'\n",
    "# t_tokenizer = TweetTokenizer()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_ratio = 0.1\n",
    "test_df = pd.read_csv(r'data\\TextClassification\\IMDB\\test.csv')\n",
    "test_df['Topic'] = test_df['label']\n",
    "test_df['Content'] = test_df['text']\n",
    "test_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.iloc[:int(keep_ratio*test_df.shape[0])]\n",
    "train_df = pd.read_csv(r'data\\TextClassification\\IMDB\\train.csv')\n",
    "train_df['Topic'] = train_df['label']\n",
    "train_df['Content'] = train_df['text']\n",
    "train_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df = train_df.iloc[:int(keep_ratio*train_df.shape[0])]\n",
    "sst_classes = [\"Negative\", \"Positive\"]\n",
    "df = pd.DataFrame(np.concatenate([train_df.values, test_df.values]), columns=train_df.columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = {c:i for i, c in enumerate(sst_classes)}\n",
    "id_class = {i:c for i, c in enumerate(sst_classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "vocabs_lists = list(token_vocab_dict.keys())\n",
    "term_frequencies = {t:1 for t in vocabs_lists}\n",
    "temp_term_frequencies = {}\n",
    "\n",
    "char_set = set()\n",
    "for doc in train_df.Content.values:\n",
    "    tokens_list = tokenizer.tokenize(doc)\n",
    "    char_set.update(set(' '.join(tokens_list)))\n",
    "    char_set.update(set(doc))\n",
    "    new_tokens = {t.strip('▁').lower() for t in tokens_list}\n",
    "    for t in new_tokens:\n",
    "        if t not in temp_term_frequencies:\n",
    "            temp_term_frequencies[t] = 0\n",
    "        temp_term_frequencies[t] += 1\n",
    "        \n",
    "for k, v in term_frequencies.items():\n",
    "    stripped_token = k.strip('▁').lower()\n",
    "    term_frequencies[k] = temp_term_frequencies[stripped_token] if stripped_token in temp_term_frequencies else 1\n",
    "\n",
    "# del temp_term_frequencies\n",
    "    \n",
    "for doc in test_df.Content.values:\n",
    "    char_set.update(set(' '.join(tokenizer.tokenize(doc))))\n",
    "    char_set.update(set(doc))\n",
    "len(char_set)\n",
    "\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' '\n",
    "all_chars = set(''.join(char_set).join(allowed_chars))\n",
    "vocab_dict = {c:i for i, c in enumerate(all_chars)}\n",
    "if '\\x01' not in vocab_dict:\n",
    "    vocab_dict['\\x01'] = len(vocab_dict)\n",
    "char_Set = set(vocab_dict.keys())\n",
    "num_embedding = len(vocab_dict)\n",
    "vocab_dict_rev = dict(zip(list(vocab_dict.values()), list(vocab_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '\\x80',\n",
       " '\\x84',\n",
       " '\\x85',\n",
       " '\\x8d',\n",
       " '\\x91',\n",
       " '\\x96',\n",
       " '\\x97',\n",
       " '\\xa0',\n",
       " '¡',\n",
       " '£',\n",
       " '¦',\n",
       " '¨',\n",
       " '«',\n",
       " '®',\n",
       " '´',\n",
       " '»',\n",
       " '½',\n",
       " 'Á',\n",
       " 'Ã',\n",
       " 'É',\n",
       " 'Ö',\n",
       " 'Ü',\n",
       " 'ß',\n",
       " 'à',\n",
       " 'á',\n",
       " 'â',\n",
       " 'ã',\n",
       " 'ä',\n",
       " 'å',\n",
       " 'æ',\n",
       " 'ç',\n",
       " 'è',\n",
       " 'é',\n",
       " 'ê',\n",
       " 'í',\n",
       " 'î',\n",
       " 'ï',\n",
       " 'ñ',\n",
       " 'ó',\n",
       " 'ô',\n",
       " 'ö',\n",
       " 'ø',\n",
       " 'ù',\n",
       " 'ü',\n",
       " '́',\n",
       " '̈',\n",
       " '–',\n",
       " '’',\n",
       " '“',\n",
       " '”',\n",
       " '⁄',\n",
       " '▁'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.00001\n",
    "total_token_count = np.array(list(term_frequencies.values())).sum()\n",
    "one_tensor = torch.tensor(1)\n",
    "def subsampling_equation_linear(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = torch.min(one_tensor, torch.sqrt_(threshold/f_x))\n",
    "    return x\n",
    "\n",
    "def subsampling_equation_sigmoid(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = 1-0.95*F.sigmoid(0.05*((f_x/threshold)-90))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterandTokenLevelCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, num_classes, char_dict, token_dict, sentiment_dict, tokenizer, token_frequencies, sampling_equation, shuffle=True, batch_size=128) -> None:\n",
    "        super().__init__()\n",
    "        if len(y) % batch_size != 0:\n",
    "            self.shortage = ((len(y) // batch_size)+1)*batch_size - len(y)\n",
    "            empty_labels = [i%2 for i in range(self.shortage)]\n",
    "            empty_strings = [id_class[l] for l in empty_labels]\n",
    "            y = np.concatenate([y, empty_labels])\n",
    "            X = np.concatenate([X, empty_strings])\n",
    "        \n",
    "        y = torch.from_numpy(y)\n",
    "        self.shuffle = shuffle\n",
    "        self.y = torch.nn.functional.one_hot(y, num_classes=num_classes).float()\n",
    "        self.X = X\n",
    "        self.char_dict = char_dict\n",
    "        self.char_Set = set(char_dict.keys())\n",
    "        self.vocab_size = len(self.char_dict)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_dict = token_dict\n",
    "        self.sentiment_dict = sentiment_dict\n",
    "        self.token_frequencies = token_frequencies\n",
    "        self.max_token_count = 0\n",
    "        self.all_data = []\n",
    "        self.token_lengths = []\n",
    "        self.token_embeddign_ids = []\n",
    "        \n",
    "        self.sum_a = 0\n",
    "        \n",
    "        for doc in tqdm(self.X):\n",
    "            g_data = self.content_to_graph(doc, sampling_equation)\n",
    "            self.all_data.append(g_data)\n",
    "        \n",
    "        \n",
    "        self.num_sections = len(y) // batch_size\n",
    "        self.x_lengths = np.array([self.all_data[i].character_length for i in range(len(self.all_data))])\n",
    "        self.x_len_args = np.argsort(self.x_lengths)[::-1]\n",
    "        \n",
    "        self.section_ranges = np.linspace(0, len(self.x_len_args), self.num_sections+1)\n",
    "        self.section_ranges = [(int(self.section_ranges[i-1]), int(self.section_ranges[i])) for i in range(1, len(self.section_ranges))]\n",
    "\n",
    "        self.position_j = 0\n",
    "        self.section_i = 0\n",
    "        self.epoch = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "        self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        index = self.get_section_index()\n",
    "        return self.all_data[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def get_section_index(self):\n",
    "        target_index = self.sections[self.section_i, self.position_j]\n",
    "        \n",
    "        self.position_j = (self.position_j + 1) % self.section_size\n",
    "        if self.position_j == 0:\n",
    "            self.section_i = (self.section_i + 1) % self.num_sections\n",
    "            if self.shuffle and self.section_i == 0:\n",
    "                self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        return target_index\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.section_i = 0\n",
    "        self.position_j = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "    def split_into_k_groups(self, len_sorted_args, lengths:np.array, k):\n",
    "        if self.shuffle and self.epoch > 0:\n",
    "            randomize_sections = np.concatenate([np.random.choice(np.arange(r[0], r[1]), size=r[1]-r[0], replace=False) for r in self.section_ranges])\n",
    "            len_sorted_args = len_sorted_args[randomize_sections]\n",
    "        \n",
    "        nums = lengths[len_sorted_args]\n",
    "        groups_size = len(len_sorted_args) // k\n",
    "        \n",
    "        \n",
    "        groups = [[] for _ in range(k)]\n",
    "        group_sums = np.zeros(k, dtype=int)\n",
    "        group_sizes = np.zeros(k, dtype=int)\n",
    "        \n",
    "        for i, num in enumerate(nums):\n",
    "            candidate_indices = np.where(group_sizes<groups_size)[0]\n",
    "            min_group_idx = candidate_indices[np.argmin(group_sums[candidate_indices])]\n",
    "            groups[min_group_idx].append(len_sorted_args[i])\n",
    "            group_sums[min_group_idx] += num\n",
    "            group_sizes[min_group_idx] += 1\n",
    "        self.epoch += 1\n",
    "        \n",
    "        groups = np.array(groups)\n",
    "        group_sums_argsort = np.argsort(group_sums)[::-1]\n",
    "        groups = groups[group_sums_argsort]\n",
    "        return np.array(groups), groups_size\n",
    "        \n",
    "    def content_to_graph(self, doc, sampling_equation):\n",
    "        tokens = self.tokenizer(doc)\n",
    "        if len(tokens) == 0:\n",
    "            tokens = ['empty']\n",
    "                        \n",
    "        token_lengths = [len(t) for t in tokens]\n",
    "        tokens.append('\\x01')\n",
    "        \n",
    "        token_lengths.append(len(tokens[-1])-1)\n",
    "        token_lengths = torch.from_numpy(np.array(token_lengths, dtype=np.longlong))+1\n",
    "        token_embs = [self.token_dict[t] if t in self.token_dict else torch.zeros((64, ), dtype=torch.float32) for t in tokens]\n",
    "        token_sentiments = [self.sentiment_dict[t] if t in self.sentiment_dict else (0.0, 0.0) for t in tokens]\n",
    "        token_embs = torch.from_numpy(np.array(token_embs, dtype=np.float32))\n",
    "        token_sentiments = torch.from_numpy(np.array(token_sentiments, dtype=np.float32))\n",
    "        doc = ' '.join(tokens)\n",
    "        characters = torch.from_numpy(np.array([self.char_dict[t] for t in doc], dtype=np.longlong))\n",
    "        token_positions = torch.arange(len(token_lengths), dtype=torch.long)\n",
    "        token_indices = torch.repeat_interleave(token_positions, token_lengths)\n",
    "        token_subsampling_probabilities = sampling_equation(torch.from_numpy(np.array([self.token_frequencies[t] if t in self.token_frequencies else 1 for t in tokens])))\n",
    "        num_tokens = len(token_lengths)\n",
    "        if num_tokens > self.max_token_count:\n",
    "            self.max_token_count = num_tokens\n",
    "        g_data = Data(x=characters,\n",
    "                        token_positions=token_positions,\n",
    "                        character_length = len(characters),\n",
    "                        num_tokens = num_tokens,\n",
    "                        token_indices=token_indices,\n",
    "                        token_lengths=token_lengths,\n",
    "                        token_embeddings=token_embs,\n",
    "                        token_sentiments=token_sentiments,\n",
    "                        token_subsampling_probabilities=token_subsampling_probabilities)\n",
    "        return g_data\n",
    " \n",
    "    def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "        cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "        cumsum_vals[0] = 0\n",
    "        additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "        cumulative_token_indices = token_indices + additions\n",
    "        return cumulative_token_indices       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CharacterandTokenLevelDataLoader(DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        follow_batch: List[str] | None = None,\n",
    "        exclude_keys: List[str] | None = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CharacterandTokenLevelDataLoader, self).__init__(\n",
    "            dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        base_iterator = super(CharacterandTokenLevelDataLoader, self).__iter__()\n",
    "        for batch in base_iterator:\n",
    "            cumsum_vals = torch.cumsum(batch[0].num_tokens, dim=0).roll(1)\n",
    "            cumsum_vals[0] = 0\n",
    "            additions = torch.repeat_interleave(cumsum_vals, batch[0].character_length)\n",
    "            batch[0].cumulative_token_indices = batch[0].token_indices + additions\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2560 [00:00<01:00, 42.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2560/2560 [00:42<00:00, 59.82it/s]\n",
      "100%|██████████| 2560/2560 [00:46<00:00, 54.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 13s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = CharacterandTokenLevelCustomDataset(train_df.Content.values, train_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, batch_size=batch_size)\n",
    "test_dataset = CharacterandTokenLevelCustomDataset(test_df.Content.values, test_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, batch_size=batch_size)\n",
    "max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv\n",
    "\n",
    "# Normalization on each feature of all tokens, for this we used batch norm class but with tokens at batch dimention\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, *args, **kwargs):\n",
    "        super(GCNN, self).__init__(*args, **kwargs)\n",
    "        self.gnn = GATv2Conv(hidden_dim, hidden_dim//8, heads=4, add_self_loops=False)\n",
    "        self.conv = nn.Conv1d(hidden_dim, hidden_dim//2, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim//2)\n",
    "        \n",
    "    def forward(self, x, edge_data, return_attention_weights = False):\n",
    "        x1, edge_weights = self.gnn(x, edge_data, return_attention_weights=return_attention_weights) \n",
    "        x2 = F.relu(self.conv(x.T).T)\n",
    "        x1 = F.leaky_relu_(self.bn1(x1))\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        return x, edge_weights, edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, to_undirected\n",
    "\n",
    "class GenGraph(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, virtual_nodes, lattice_step, lattice_pattern=None, *args, **kwargs):\n",
    "        super(GenGraph, self).__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.lattice_step = lattice_step\n",
    "        self.lp = lattice_pattern if lattice_pattern is None else torch.tensor(lattice_pattern)\n",
    "        self.virtual_node_embeddings = nn.Embedding(self.virtual_nodes, hidden_dim)\n",
    "        \n",
    "    def gen_graph(self, x, token_subsampling_probabilities, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        v_n_e_counts = total_token_counts*self.virtual_nodes\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        edge_indices = torch.empty((2, base_numel + v_n_e_counts*2), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(edge_indices, random_links, lattice_links, tc_range)\n",
    "            \n",
    "        if self.virtual_nodes > 0:\n",
    "            virtual_nodes_range = torch.arange(self.virtual_nodes, device=x.device).view(1, -1)\n",
    "            virtual_nodes_ids = torch.repeat_interleave(virtual_nodes_range, len(token_counts), dim=0)\n",
    "            v_n_idx = (virtual_nodes_ids + torch.arange(0, len(token_counts)*self.virtual_nodes, self.virtual_nodes, device=x.device).view(-1, 1) + total_token_counts )\n",
    "            virtual_edge_ids = torch.repeat_interleave(v_n_idx.view(-1), token_counts.view(-1, 1).expand(len(token_counts), self.virtual_nodes).reshape(-1), dim=0).view(1, -1)\n",
    "            \n",
    "            embs = self.virtual_node_embeddings(virtual_nodes_ids.T).view(-1, self.hidden_dim)\n",
    "            x_extended = torch.cat([x, embs], dim=0)\n",
    "            x_index = torch.arange(total_token_counts, device=x.device).repeat(self.virtual_nodes).view(1, -1)\n",
    "            edge_indices[:, base_numel:base_numel+v_n_e_counts] = torch.cat([x_index, virtual_edge_ids], dim=0)\n",
    "            edge_indices[:, base_numel+v_n_e_counts:] = torch.cat([virtual_edge_ids, x_index], dim=0)\n",
    "            x = x_extended\n",
    "        \n",
    "        edge_indices = self.subsample_edges(edge_indices, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_indices)])\n",
    "        \n",
    "    def re_gen_graph(self, x, edge_indices, token_subsampling_probabilities, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        self.fill_lattice_and_random_edges(edge_indices, random_links, lattice_links, tc_range)\n",
    "        # for i in range(base.shape[1]):\n",
    "        #     edge_indices[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        edge_indices = self.subsample_edges(edge_indices, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_indices)])\n",
    "    \n",
    "    def replace_unimportant_edges(self, edge_weights, x, edge_indices, token_subsampling_probabilities, total_token_counts, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2):\n",
    "        v_n_e_counts = total_token_counts*self.virtual_nodes\n",
    "        # if v_n_e_counts>0:\n",
    "        #     important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # else:\n",
    "        #     print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "        #     print(f'total_token_coutns: {total_token_coutns}')\n",
    "        #     print(f'p_keep: {p_keep}')\n",
    "        #     important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "        # print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "        # print(f'edge_indices.shape: {edge_indices.shape}')\n",
    "        # print(f'1: edge_weights: {edge_weights.shape}')\n",
    "        important_indices = torch.topk(edge_weights.squeeze(), p_keep*total_token_counts, dim=0).indices\n",
    "        # print(f'2: important_indices: {important_indices.shape}')\n",
    "        # print(f'2.5: \\n {edge_weights} \\n\\n {important_indices}')\n",
    "\n",
    "        # important_indices = torch.arange(total_token_counts, dtype=torch.int64, device=x.device)\n",
    "        # important_indices = important_indices.view(-1)\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        # print(f'3: random_links: {random_links.shape}, lattice_links: {lattice_links.shape}, tc_range: {tc_range.shape},')\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        # print(f'4: base_numel: {base_numel}')\n",
    "        \n",
    "        new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "        # print(f'5: new_edge_index: {new_edge_index.shape}')\n",
    "        # print(f'new_edge_index.shape 1: {new_edge_index.shape}, base_numel + important_indices.shape[0] + 2*v_n_e_counts: {base_numel + important_indices.shape[0] + 2*v_n_e_counts}')\n",
    "        self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "        # print(f'6: new_edge_index: {new_edge_index.shape}, random_links: {random_links.shape}, lattice_links: {lattice_links.shape}, tc_range: {tc_range.shape}')\n",
    "        # print(f'new_edge_index.shape 2: {new_edge_index.shape}, edge_indices: {edge_indices.shape}, important_indices shape: {important_indices.shape}, important_indices max: {important_indices.max()}')\n",
    "        new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_indices[:, important_indices]\n",
    "        # print(f'7: new_edge_index: {new_edge_index.shape}')\n",
    "\n",
    "        if(self.virtual_nodes>0):\n",
    "            new_edge_index[:, -2*v_n_e_counts:] = edge_indices[:, -2*v_n_e_counts:]\n",
    "            \n",
    "        # for i in range(base.shape[1]):\n",
    "        #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        # print(f'7.5: \\n {new_edge_index} \\n\\n {token_subsampling_probabilities}')\n",
    "        new_edge_index = self.subsample_edges(new_edge_index, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "    \n",
    "    # def replace_unimportant_edges(self, edge_weights, x, edge_index, token_subsampling_probabilities, total_token_coutns, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2, seed=-1):\n",
    "    #     v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "    #     if v_n_e_counts>0:\n",
    "    #         important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "    #     else:\n",
    "    #         print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "    #         print(f'total_token_coutns: {total_token_coutns}')\n",
    "    #         print(f'p_keep: {p_keep}')\n",
    "    #         important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "    #     # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "\n",
    "    #     important_indices = torch.arange(total_token_coutns, dtype=torch.int64, device=x.device) + important_indices*total_token_coutns\n",
    "    #     important_indices = important_indices.view(-1)\n",
    "    #     random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance, seed)\n",
    "    #     base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "    #     new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "    #     self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "    #     new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_index[:, important_indices]\n",
    "    #     if(self.virtual_nodes>0):\n",
    "    #         new_edge_index[:, -2*v_n_e_counts:] = edge_index[:, -2*v_n_e_counts:]\n",
    "            \n",
    "    #     # for i in range(base.shape[1]):\n",
    "    #     #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "    #     new_edge_index = self.subsample_edges(new_edge_index, token_subsampling_probabilities)\n",
    "    #     return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "    \n",
    "    \n",
    "         \n",
    "    def calculate_graph(self, x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance):\n",
    "\n",
    "        tc_extended = torch.repeat_interleave(token_counts, token_counts, dim=0).view(-1,1)\n",
    "        tc_lower_bound = torch.empty((len(token_counts)+1), dtype=torch.long, device=x.device) #torch.cuda.IntTensor(len(token_counts)+1) #\n",
    "        tc_lower_bound[0] = 0\n",
    "        tc_lower_bound[1:] = torch.cumsum(token_counts, dim=0)\n",
    "        tc_lower_bound_extended = torch.repeat_interleave(tc_lower_bound[:-1], token_counts, dim=0).view(-1,1)\n",
    "        tc_range = torch.arange(tc_lower_bound[-1], device=x.device).view(-1,1)\n",
    "        # torch.arange(tc_lower_bound[-1], dtype=torch.int32, device=x.device).view(-1,1)\n",
    "        \n",
    "        random_ints = torch.randint(0, 2*total_token_counts, (total_token_counts, random_edges), device=x.device) # torch.cuda.IntTensor(len(token_lengths), random_edges).random_()\n",
    "        lattice = self.lp.to(x.device) if self.lp is not None else torch.arange(lattice_start_distance, max(lattice_start_distance, self.lattice_step*lattice_edges+1), self.lattice_step, device=x.device).view(1, -1)\n",
    "        \n",
    "\n",
    "        # exponentials = torch.pow(2, torch.arange(1, self.exp_edges+1, device=x.device)).view(1, -1)\n",
    "        tc_local_range = tc_range - tc_lower_bound_extended\n",
    "        random_links = (((random_ints % (tc_extended - 1))+1 + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        lattice_links = ((lattice + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        # base = torch.cat([base1, base2], dim=1)\n",
    "        tc_range = tc_range.view(1,-1)\n",
    "        return random_links, lattice_links, tc_range\n",
    "    \n",
    "    def fill_lattice_and_random_edges(self, edge_indices, random_links, lattice_links, tc_range):\n",
    "        for i in range(0, lattice_links.shape[1]*2, 2):\n",
    "            edge_indices[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]] = torch.cat([lattice_links[:,i//2].view(1,-1), tc_range], dim=0)\n",
    "            edge_indices[:, (i+1)*lattice_links.shape[0]:(i+2)*lattice_links.shape[0]] = edge_indices[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]][[1, 0]]\n",
    "            \n",
    "        for i in range(random_links.shape[1]):\n",
    "            j = i + lattice_links.shape[1]*2\n",
    "            edge_indices[:, j*random_links.shape[0]:(j+1)*random_links.shape[0]] = torch.cat([random_links[:,i].view(1,-1), tc_range], dim=0)\n",
    "            \n",
    "    def subsample_edges(self, edge_indices, token_subsampling_probabilities, keep_ratio=0.65):\n",
    "        \n",
    "        p = torch.rand(edge_indices.shape, dtype=torch.float, device=edge_indices.device)\n",
    "        to_keep = (p<token_subsampling_probabilities[edge_indices]).float()\n",
    "        to_keep = torch.topk(to_keep[0] + to_keep[1], (int)(edge_indices.shape[1]*keep_ratio), dim=0).indices\n",
    "        edge_indices = edge_indices[:, to_keep]\n",
    "        return edge_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment_Injection(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)        \n",
    "        self.conv1 = nn.Conv1d(2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim*2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, token_sentiments):\n",
    "        x1 = F.relu_(self.bn1(self.conv1(token_sentiments.T).T))\n",
    "        x = F.relu_(self.conv2(torch.cat([x, x1], dim=1).T))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv, summary\n",
    "import math\n",
    "\n",
    "class CNN_for_Text_No_Positional_Encoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embedding, pos_emb_size=8192, embedding_dim=64, hidden_dim=64, dropout=0.3, num_out_features=4, seed=-1, random_edges=4, lattice_edges=10, virtual_nodes=1, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64, isXaiTests=False, step_of_test = 0, num_tests=50, *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text_No_Positional_Encoding, self).__init__(*args, **kwargs)\n",
    "        self.pos_emb_size = pos_emb_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        self.num_out_features = num_out_features\n",
    "        self.isXaiTests = int(isXaiTests)\n",
    "        self.num_tests = num_tests\n",
    "        self.step_of_test = step_of_test\n",
    "\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.positional_encoding = nn.Embedding(pos_emb_size, embedding_dim)\n",
    "        self.positional_encoding.weight = self.create_positional_encoding()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        \n",
    "        # if self.use_token_polarity[0]:\n",
    "        self.conv3 = nn.Conv1d(2*hidden_dim + 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        # else:\n",
    "        # self.conv3 = nn.Conv1d(2*hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        # if self.use_token_polarity[1]:\n",
    "        # self.sentiment1  = Sentiment_Injection(hidden_dim)\n",
    "        # if self.use_token_polarity[2]:\n",
    "        # self.sentiment2  = Sentiment_Injection(hidden_dim)\n",
    "            \n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.gcnn2 = GCNN(hidden_dim+inject_embedding_dim)\n",
    "        self.graph_generator = GenGraph(hidden_dim, virtual_nodes, lattice_step)\n",
    "        \n",
    "        k = 4\n",
    "        self.fc0 = nn.Linear(hidden_dim , hidden_dim+inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim+inject_embedding_dim , hidden_dim * k)\n",
    "        self.fc2 = nn.Linear(hidden_dim * (2+virtual_nodes) * k , 32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, self.num_out_features)\n",
    "        self.max_length = 0\n",
    "    \n",
    "    def forward(self, x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings, token_positions):\n",
    "        # cumulative_token_indices = token_indices if not self.isXaiTests else self.caluculate_batch_token_positions(num_tokens, character_length, token_indices)\n",
    "        cumulative_token_indices = self.caluculate_batch_token_positions(num_tokens, character_length, token_indices)\n",
    "        \n",
    "        # print(f'2: {x.shape}')\n",
    "        x = self.embedding(x)\n",
    "        # print(f'2.5: {x.shape}')\n",
    "        x = self.dropout(x)\n",
    "        # print(f'2.6: {x.shape}')\n",
    "        x = x.T\n",
    "        # print(f'2.7: {x.shape}')\n",
    "        # x = self.refine_shape(1, x, 0)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # print(f'2.8: {x.shape}')\n",
    "        x = self.refine_shape(1, x, self.hidden_dim, 0)\n",
    "        # print(f'2.8 refined: {x.shape}')\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.refine_shape(2, x, self.hidden_dim, 0)\n",
    "        # print(f'2.9: {x.shape}')\n",
    "        x = self.dropout(x)\n",
    "        # x = self.refine_shape(4, x, 0)\n",
    "        # print(f'3: {x.shape}')\n",
    "        x1 = scatter_max(x, cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, cumulative_token_indices, dim=1)\n",
    "\n",
    "        # if self.use_token_polarity[0]:\n",
    "        x = torch.cat([x1, x2, token_sentiments.T], dim=0)\n",
    "        # else:\n",
    "        # x = torch.cat([x1, x2], dim=0)\n",
    "            \n",
    "        # print(f'4: {x.shape}')\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x + self.positional_encoding(token_positions).T\n",
    "        \n",
    "        # print(f'4.5: {x.shape}, self.hidden_dim: {self.hidden_dim}, self.is_tests_token_level: {self.step_of_test}')\n",
    "        # if self.isXaiTests and x.shape[0] != self.hidden_dim:\n",
    "        # x = torch.chunk(x, self.num_tests ** (1 - self.isXaiTests), dim=0)\n",
    "        x = self.refine_shape(3, x, self.hidden_dim, 0)\n",
    "        \n",
    "        # x = torch.chunk(x, (x.shape[0] // self.hidden_dim)**self.is_tests_token_level, dim=0)\n",
    "        # x = torch.cat(x, dim=1)\n",
    "        \n",
    "        # if self.isXaiTests and x.shape[0] != self.hidden_dim:\n",
    "        #     x = torch.chunk(x, self.num_tests, dim=0)\n",
    "        #     x = torch.cat(x, dim=1)\n",
    "        # x = x.reshape(self.hidden_dim, -1)\n",
    "        # print(\"abababdadasd\")\n",
    "        # print(f'5: {x.shape}, {edge_index.shape}, {cumulative_token_indices.shape}, {token_sentiments.shape}, {token_lengths.shape}, {num_tokens.shape}, {character_length.shape}, {token_embeddings.shape}')\n",
    "        # if self.use_token_polarity[1]:\n",
    "        # x = self.sentiment1(x.T, token_sentiments)\n",
    "\n",
    "        # print(f'6: {x.shape}')\n",
    "        x = self.refine_shape(4, x.T, self.hidden_dim, 1)\n",
    "        # print(f'6 refined: {x.shape}')\n",
    "        rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "            \n",
    "        graph = self.graph_generator.gen_graph(x, token_subsampling_probabilities, len(token_lengths), num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "        rand_edges = rand_edges-1\n",
    "        lattice_edges = lattice_edges-1\n",
    "        \n",
    "        # print(f'7: {graph.x.shape}')\n",
    "        \n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(num_tokens), device=x.device), num_tokens)\n",
    "        x, edge_weights, edge_index = self.gcnn1(graph.x, graph.edge_index, return_attention_weights = True)\n",
    "        # print(f'7.1: {x.shape}')\n",
    "        x = self.refine_shape(5, x, self.hidden_dim, 1)\n",
    "        # print(f'7.1 2 : {len(torch.cat(edge_weights[1::2], dim=0))}')\n",
    "        edge_weights = self.refine_edge_weights(edge_weights)\n",
    "        edge_index = self.refine_edge_index(edge_index)\n",
    "        \n",
    "        # edge_weights = edge_weights[1].unsqueeze(-1)\n",
    "        # print(f'7.5 edge_weights: {edge_weights.shape}, - {graph.edge_index.shape[1]}, {edge_weights.shape[0]}')\n",
    "        # edge_weights = edge_weights[:min(graph.edge_index.shape[1], edge_weights.shape[0]), 0]\n",
    "        # edge_weights = edge_weights.squeeze()\n",
    "        \n",
    "        edge_weights = edge_weights.unsqueeze(-1)\n",
    "        # print(f'7.5 edge_weights: {edge_weights.shape}, - {edge_weights.shape[0]}')\n",
    "        edge_weights = edge_weights[:edge_weights.shape[0], 0]\n",
    "        \n",
    "        # print(f'7.6 edge_weights: {edge_weights.shape}')\n",
    "        # print(f'7.7: {x.shape}')\n",
    "        x = self.refine_shape(5, x, self.hidden_dim, 1)\n",
    "        # print(f'7.8 refined: {x.shape}')\n",
    "        \n",
    "        graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, edge_index, token_subsampling_probabilities, len(token_lengths), num_tokens, rand_edges, lattice_edges, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        \n",
    "        # print(f'8: {graph.x.shape}')\n",
    "        \n",
    "        # if self.use_token_polarity[2]:\n",
    "        # x = self.sentiment2(x, token_sentiments)\n",
    "          \n",
    "        # print(f'8.1: {x.shape}')\n",
    "        x = self.refine_shape(6, x.T, self.hidden_dim, 1)\n",
    "        # print(f'8.2 refined: {x.shape}')\n",
    "        \n",
    "        # print(f'9: {x.shape}')  \n",
    "        xa = graph.x[:token_embeddings.shape[0]]\n",
    "        xb = token_embeddings\n",
    "        x = torch.cat([xa, xb], dim=1)\n",
    "        # x = torch.cat([graph.x[:g_data.token_embeddings.shape[0]], g_data.token_embeddings], dim=1)\n",
    "        \n",
    "        # print(f'10: {x.shape}')  \n",
    "        x1 = F.relu(self.fc0(graph.x[token_embeddings.shape[0]:]))\n",
    "        x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "        # print(f'11: {x.shape}')  \n",
    "        sum1 = torch.sum(edge_weights) + torch.sum(edge_index)\n",
    "        x, edge_weights, edge_index = self.gcnn2(x, graph.edge_index)\n",
    "        edge_weights = self.refine_edge_weights(edge_weights)\n",
    "        sum1 = sum1 + torch.sum(edge_weights) + torch.sum(edge_index) \n",
    "        \n",
    "        # print(f'12: {x.shape}')  \n",
    "        x = F.elu_(self.fc1(x))\n",
    "        x1 = scatter_max(x[:len(token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(token_lengths)], doc_token_index, dim=0)\n",
    "        vn_embs = x[len(token_lengths):]\n",
    "        x_for_cat = [x1, x2]\n",
    "        x_for_cat.extend([vn_embs[i*x1.shape[0]:(i+1)*x1.shape[0]] for i in range(self.virtual_nodes)])\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        \n",
    "        # print(f'13: {x.shape}')  \n",
    "        x = F.elu_(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        # print(f'14: {x.shape}')  \n",
    "        return x + sum1 * 0.0\n",
    "    \n",
    "    def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "        cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "        cumsum_vals[0] = 0\n",
    "        additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "        cumulative_token_indices = token_indices + additions\n",
    "        return cumulative_token_indices\n",
    "    \n",
    "    def create_positional_encoding(self):\n",
    "        position = torch.arange(self.pos_emb_size).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.hidden_dim, 2) * (-math.log(10000.0) / self.hidden_dim))\n",
    "        pe = torch.zeros(self.pos_emb_size, self.hidden_dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return torch.nn.Parameter(pe, requires_grad=False)\n",
    "    \n",
    "    def refine_shape(self, test_step, x, num_chunks, section=0):\n",
    "        x = torch.chunk(x, (x.shape[section] // num_chunks)**(self.step_of_test==test_step), dim=0)\n",
    "        x = torch.cat(x, dim=1-section)\n",
    "        return x\n",
    "        \n",
    "    def refine_edge_weights(self, edge_weights):\n",
    "        edge_weights = edge_weights[1::2] + edge_weights[0::2] * 0\n",
    "        edge_weights = [edge_weights[i] for i in range(len(edge_weights))]\n",
    "        edge_weights = torch.cat(edge_weights, dim=0)\n",
    "        return edge_weights\n",
    "        \n",
    "    def refine_edge_index(self, edge_index):\n",
    "        edge_index = torch.cat([edge_index[::2].reshape(1, -1), edge_index[1::2].reshape(1, -1)], dim=0)\n",
    "        return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for p1 in [False, True]:\n",
    "# #     for p2 in [False, True]:\n",
    "# #         for p3 in [False, True]:\n",
    "# # print(f'\\n{p1}, {p2}, {p3}: \\n')\n",
    "# classifier_torch_model = CNN_for_Text_No_Positional_Encoding(num_embedding=num_embedding, hidden_dim=64, embedding_dim=64, pos_emb_size=3080, dropout=0.2, num_out_features=len(class_id), seed=911, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2, isXaiTests=True, num_tests=len(X.num_tokens)).eval()\n",
    "# flopt_counter = FlopCounterMode(classifier_torch_model)\n",
    "# with flopt_counter:\n",
    "#     classifier_torch_model(X.x, torch.zeros((2, 0)), X.token_subsampling_probabilities, X.token_indices, X.token_sentiments, X.token_lengths, X.num_tokens, X.character_length, X.token_embeddings, X.token_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.managers.ModelManager import ModelManager\n",
    "from utilities.managers.ClassifierModelManager import ClassifierModelManager\n",
    "from utilities.lightning_models.CnnGnnClassifierLightningModel import CnnGnnClassifierLightningModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 128\n",
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "label_size = 1\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, dropout=0.25, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True, use_positional_encoder=[False, False, False]):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    classifier_torch_model = CNN_for_Text_No_Positional_Encoding(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=4096, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=6, lattice_edges=10, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 40, 45,50,55],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name=f'CNN-GNN_{use_positional_encoder[0]}_{use_positional_encoder[1]}_{use_positional_encoder[2]}',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    train_dataset.reset_params()\n",
    "    train_dataset.position_j = 0\n",
    "    test_dataset.reset_params()\n",
    "    test_dataset.position_j = 0\n",
    "    \n",
    "    # train_dataset.section_i = 0\n",
    "    # train_dataset.each_section_i = np.zeros((train_dataset.num_sections, ), dtype=int)\n",
    "    # test_dataset.section_i = 0\n",
    "    # test_dataset.each_section_i = np.zeros((test_dataset.num_sections, ), dtype=int)\n",
    "    \n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.lightning_model.model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(model_manager.lightning_model, test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_manager = train_model(70, 0.2, 0.000012, 0.0032, use_positional_encoder=[False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "p = Path(r'logs/CNN-GNN_False_False_False\\version_0\\checkpoints\\epoch=0-step=4.ckpt.pth')\n",
    "not p.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "def calculatge_metrics(chpt_path, target_data_loader, num_embedding):\n",
    "        classifier_torch_model = CNN_for_Text_No_Positional_Encoding(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=4096, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=8, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "        classifier_torch_model.load_state_dict(torch.load(chpt_path, weights_only=True, map_location=\"cuda:0\"))\n",
    "        classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                batch_size=batch_size,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device).eval()\n",
    "        \n",
    "        mean_infer_acc = []\n",
    "        mean_infer_f1 = []\n",
    "        mean_infer_prec = []\n",
    "        mean_infer_rec = []\n",
    "        for i in range(5):\n",
    "            all_ys = []\n",
    "            all_y_preds = []\n",
    "            for X, y in target_data_loader:\n",
    "                with torch.no_grad():\n",
    "                    y_pred = classfier_lightning_model(X.to(device))\n",
    "                all_ys.append(torch.argmax(y,dim=1))\n",
    "                all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "            all_ys = torch.concat(all_ys)\n",
    "            all_y_preds = torch.concat(all_y_preds)\n",
    "            \n",
    "            cm = confusion_matrix(all_ys, all_y_preds, labels=list(id_class.keys()))\n",
    "            \n",
    "            accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "            precision = np.mean(np.diag(cm) / (np.sum(cm, axis=0)+0.000001))\n",
    "            recall = np.mean(np.diag(cm) / (np.sum(cm, axis=1)+0.000001))\n",
    "            f1_score = (2*precision*recall)/(precision + recall+0.000001)\n",
    "            \n",
    "            mean_infer_acc.append(accuracy)\n",
    "            mean_infer_f1.append(f1_score)\n",
    "            mean_infer_prec.append(precision)\n",
    "            mean_infer_rec.append(recall)\n",
    "        mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "        mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "        mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "        mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "        return mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "def get_best_chpt(metrics_path, epoch_numbers):\n",
    "    epoch_data = pd.read_csv(metrics_path)\n",
    "    if 'val_acc_epoch' in epoch_data.columns and epoch_data['val_acc_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_acc_epoch'].idxmax()]\n",
    "    elif 'val_loss_epoch' in epoch_data.columns and epoch_data['val_loss_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_loss_epoch'].idxmin()]\n",
    "    else:\n",
    "        raise ValueError(f\"No valid validation metrics available for epoch {epoch_numbers}.\")\n",
    "    return np.argwhere(np.array(epoch_numbers)==best_chpt['epoch']).item(), best_chpt['val_loss_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_metrics_mean(num_embedding, base_path = 'logs\\CNN-GNN18_mr2k_seeds', start=0, interval=1):\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "    total_loss = []\n",
    "    \n",
    "    for i in range(start, start + interval):\n",
    "        version_path = join(base_path, f'version_{i}')\n",
    "        checkpoint_path = join(version_path, f'checkpoints')\n",
    "        onlyfiles  = [f for f in listdir(checkpoint_path) if (isfile(join(checkpoint_path, f)) and 'epoch' in f) ]\n",
    "        epoch_numbers = [int(re.search(r'\\d+', f).group()) for f in onlyfiles]\n",
    "        best_chpt_id, loss = get_best_chpt(join(version_path, 'metrics.csv'), epoch_numbers)\n",
    "        print(onlyfiles[best_chpt_id])\n",
    "        mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model = calculatge_metrics(join(checkpoint_path, f'{onlyfiles[best_chpt_id]}'), test_dataloader, num_embedding)\n",
    "            \n",
    "        total_accuracy.append(mean_infer_acc)\n",
    "        total_f1.append(mean_infer_f1)\n",
    "        total_prec.append(mean_infer_prec)\n",
    "        total_rec.append(mean_infer_rec)\n",
    "        total_loss.append(loss)\n",
    "\n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    total_loss = torch.mean(torch.tensor(total_loss))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')\n",
    "    print(f'total_loss: {total_loss}')\n",
    "    return classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=57-step=580.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.50171875\n",
      "total_f1: 0.3340938021355776\n",
      "total_prec: 0.2508593749020081\n",
      "total_rec: 0.4999999996107022\n",
      "total_loss: 0.8554494976997375\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=52-step=530.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.5064062499999998\n",
      "total_f1: 0.561433874069864\n",
      "total_prec: 0.6351138530363641\n",
      "total_rec: 0.5036312091749704\n",
      "total_loss: 0.8941477537155151\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=68-step=690.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.5021875\n",
      "total_f1: 0.33429385421726043\n",
      "total_prec: 0.2510937499019165\n",
      "total_rec: 0.4999999996110251\n",
      "total_loss: 0.8528066873550415\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=68-step=690.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.50328125\n",
      "total_f1: 0.33477846526562793\n",
      "total_prec: 0.25164062490170286\n",
      "total_rec: 0.4999999996118719\n",
      "total_loss: 0.8528066873550415\n",
      "epoch=57-step=580.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.5037499999999999\n",
      "total_f1: 0.3349941331249763\n",
      "total_prec: 0.25187499990161133\n",
      "total_rec: 0.49999999961227626\n",
      "total_loss: 0.8554494976997375\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model1 = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=1)\n",
    "classfier_lightning_model3 = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2.1667, -1.0284, -0.3112,  ...,  0.8440,  0.4139, -1.3559],\n",
       "        [ 0.4477,  0.4483, -1.6092,  ...,  0.6777,  0.5552, -0.0789],\n",
       "        [-0.1111, -1.1905, -1.0991,  ...,  0.0750,  0.3222,  0.2924],\n",
       "        ...,\n",
       "        [-0.2027, -0.7937,  0.0352,  ..., -0.7527,  0.2331,  0.1826],\n",
       "        [ 0.3098,  0.4349, -0.3574,  ...,  0.1672,  0.1886, -0.9232],\n",
       "        [-1.0632, -0.6390,  1.7161,  ...,  1.0442,  0.9414, -0.1757]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier_lightning_model1.model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2.1667e+00, -1.0284e+00, -3.1116e-01,  ...,  8.4399e-01,\n",
       "          4.1394e-01, -1.3559e+00],\n",
       "        [ 5.2677e-01,  6.3853e-01, -1.5004e+00,  ...,  4.7975e-01,\n",
       "          5.7680e-01, -1.4392e-01],\n",
       "        [-1.2900e-01, -1.2595e+00, -1.1261e+00,  ...,  2.0922e-03,\n",
       "          3.4685e-01,  1.9804e-01],\n",
       "        ...,\n",
       "        [-2.5178e-01, -7.1559e-01, -1.1819e-01,  ..., -5.6713e-01,\n",
       "          4.9578e-01,  1.1270e-01],\n",
       "        [ 2.5813e-01,  3.8796e-01, -3.1091e-01,  ...,  1.9647e-01,\n",
       "          2.2127e-01, -9.7274e-01],\n",
       "        [-1.0966e+00, -6.0523e-01,  1.5983e+00,  ...,  1.0477e+00,\n",
       "          9.0805e-01, -8.9105e-02]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier_lightning_model3.model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset2 = []\n",
    "for i in range(len(test_dataset)):\n",
    "    test_dataset2.append(test_dataset[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, X in enumerate(test_dataset2):\n",
    "    if(X.x[0]==145 and  X.x[1]==77 and  X.x[2]==37):\n",
    "        print(i, X.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(73)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset2[1282].x[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
