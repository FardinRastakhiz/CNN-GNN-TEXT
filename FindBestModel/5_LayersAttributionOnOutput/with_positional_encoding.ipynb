{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import time\n",
    "from torch_scatter import scatter_max, scatter_mean, scatter_std\n",
    "from sklearn.model_selection import KFold\n",
    "import torchmetrics\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "from transformers import AutoModel, DebertaV2Tokenizer, AutoTokenizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vocab = {v:k for k,v in tokenizer.vocab.items()}\n",
    "all_vocab_indices = list(id_vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all_vocab_str = []\n",
    "# vector_keys = list(nlp.vocab.vectors.keys())\n",
    "# for i in range(len(vector_keys)):\n",
    "#     try:\n",
    "#         t = nlp.vocab.strings[vector_keys[i]]\n",
    "#         all_vocab_str.append(t)\n",
    "#     except:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# Create a set of all English characters, numbers, and punctuation\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation\n",
    "all_chars = set(allowed_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Data\\ReducedEmbeddings\\deberta_larg_reduced_embeddings_64.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "all_vocab_str = []\n",
    "for i in range(len(id_vocab)):\n",
    "    all_vocab_str.append(id_vocab[i])\n",
    "    \n",
    "# embeddings = (embeddings - torch.min(embeddings)) / (torch.max(embeddings)-torch.min(embeddings))\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))\n",
    "# del all_vocab_str\n",
    "# del all_vocab_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'Data\\ReducedEmbeddings\\polarity_debertav3_tokens_gpt_mini_emb.npy', 'rb') as f:\n",
    "    polarities_subjectivities= np.load(f)\n",
    "polarities_subjectivities = torch.from_numpy(polarities_subjectivities)\n",
    "polarity_vocab_dict = dict(zip(all_vocab_str, polarities_subjectivities))\n",
    "polarity_vocab_dict['<n>'] = torch.tensor([0.0, 0.0])\n",
    "len(token_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128001, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarities_subjectivities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085 tensor([0.7000, 0.6000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_vocab_str)):\n",
    "    if 'nice' in all_vocab_str[i]:\n",
    "        print(i, polarities_subjectivities[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# Create a set of all English characters, numbers, and punctuation\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' \\t'\n",
    "all_chars = set(allowed_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 224\n",
    "folder_path = r'C:\\Users\\fardin\\Projects\\CGNet\\Data\\TextClassification\\IMDB'\n",
    "# t_tokenizer = TweetTokenizer()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_ratio = 1.0\n",
    "test_df = pd.read_csv(r'data\\TextClassification\\IMDB\\test.csv')\n",
    "test_df['Topic'] = test_df['label']\n",
    "# test_df['Content'] = [test_df.text[i].values[0] + \" \\n \" + test_df.text[i].values[1] for i in range(len(test_df))]\n",
    "test_df['Content'] = test_df['text']\n",
    "# test_df['Content'] = test_df['Content']\n",
    "test_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df = test_df.iloc[:int(keep_ratio*test_df.shape[0])]\n",
    "train_df = pd.read_csv(r'data\\TextClassification\\IMDB\\train.csv')\n",
    "train_df['Topic'] = train_df['label']\n",
    "# train_df['Content'] = [train_df.text[i].values[0] + \" \\n \" + train_df.text[i].values[1] for i in range(len(train_df))]\n",
    "train_df['Content'] = train_df['text']\n",
    "train_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "# train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "# train_df = train_df.iloc[:int(keep_ratio*train_df.shape[0])]\n",
    "sst_classes = [\"Negative\", \"Positive\"]\n",
    "df = pd.DataFrame(np.concatenate([train_df.values, test_df.values]), columns=train_df.columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13704\n",
      "CPU times: total: 1.05 s\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_lengths = np.array([len(df.Content[i]) for i in df.index])\n",
    "print(np.max(doc_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_list = df.Topic.unique()\n",
    "class_id = {c:i for i, c in enumerate(sst_classes)}\n",
    "id_class = {i:c for i, c in enumerate(sst_classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 28s\n",
      "Wall time: 1min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_dict = {c:i for i, c in enumerate(allowed_chars)}\n",
    "# if '\\x01' not in vocab_dict:\n",
    "#     vocab_dict['\\x01'] = len(vocab_dict)\n",
    "# char_Set = set(vocab_dict.keys())\n",
    "# len(char_Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13704\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a histogram\n",
    "plt.hist(doc_lengths, bins='auto', edgecolor='black')\n",
    "plt.xlim([0,14000])\n",
    "# Add labels and title\n",
    "plt.xlabel('String Lengths in Character')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of String Lengths')\n",
    "print(doc_lengths.max())\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 25s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_token_lengths = np.array([len(tokenizer.tokenize(df.Content[i])) for i in df.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3088\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a histogram\n",
    "plt.hist(doc_token_lengths, bins='auto', edgecolor='black')\n",
    "plt.xlim([0,2000])\n",
    "# Add labels and title\n",
    "plt.xlabel('String Lengths in Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of String Lengths')\n",
    "print(doc_token_lengths.max())\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 24s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "char_set = set()\n",
    "for doc in df.Content.values:\n",
    "    char_set.update(set(' '.join(tokenizer.tokenize(doc))))\n",
    "    char_set.update(set(doc))\n",
    "len(char_set)\n",
    "\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' '\n",
    "all_chars = set(''.join(char_set).join(allowed_chars))\n",
    "vocab_dict = {c:i for i, c in enumerate(all_chars)}\n",
    "if '\\x01' not in vocab_dict:\n",
    "    vocab_dict['\\x01'] = len(vocab_dict)\n",
    "char_Set = set(vocab_dict.keys())\n",
    "num_embedding = len(vocab_dict)\n",
    "vocab_dict_rev = dict(zip(list(vocab_dict.values()), list(vocab_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterandTokenLevelCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, num_classes, char_dict, token_dict, sentiment_dict, tokenizer, shuffle=True, batch_size=128) -> None:\n",
    "        super().__init__()\n",
    "        # y = y[indices].values\n",
    "        # y = torch.from_numpy(np.array([class_id[c] for c in y], dtype=np.longlong))\n",
    "        \n",
    "        # print(f'self.num_sections1: {len(y) // batch_size}')\n",
    "        \n",
    "        if len(y) % batch_size != 0:\n",
    "            self.shortage = ((len(y) // batch_size)+1)*batch_size - len(y)\n",
    "            empty_labels = [i%2 for i in range(self.shortage)]\n",
    "            empty_strings = [id_class[l] for l in empty_labels]\n",
    "            \n",
    "            # print(f'y1 - {y.shape}: {y}')\n",
    "            y = np.concatenate([y, empty_labels])\n",
    "            # print(f'y2 - {y.shape}: {y}')\n",
    "            # print(f'X1 - {X.shape}: {X}')\n",
    "            X = np.concatenate([X, empty_strings])\n",
    "        #     print(f'X2 - {X.shape}: {X}')\n",
    "        \n",
    "        # print(f'self.num_sections2: {len(y) // batch_size}')\n",
    "        \n",
    "        y = torch.from_numpy(y)\n",
    "        self.shuffle = shuffle\n",
    "        self.y = torch.nn.functional.one_hot(y, num_classes=num_classes).float()\n",
    "        self.X = X\n",
    "        self.char_dict = char_dict\n",
    "        self.char_Set = set(char_dict.keys())\n",
    "        self.vocab_size = len(self.char_dict)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_dict = token_dict\n",
    "        self.sentiment_dict = sentiment_dict\n",
    "        self.max_token_count = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.all_data = []\n",
    "        self.token_lengths = []\n",
    "        self.token_embeddign_ids = []\n",
    "        \n",
    "        self.sum_a = 0\n",
    "        \n",
    "        for doc in tqdm(self.X):\n",
    "            # tokens = self.tokenizer(''.join(c for c in doc if c in self.char_Set))\n",
    "            # tokens = [t.text for t in tokens]\n",
    "            tokens = self.tokenizer(doc)\n",
    "            if len(tokens) == 0:\n",
    "                tokens = ['empty']\n",
    "                            \n",
    "            token_lengths = [len(t) for t in tokens]\n",
    "            tokens.append('\\x01')\n",
    "            \n",
    "            token_lengths.append(len(tokens[-1])-1)\n",
    "            token_lengths = torch.from_numpy(np.array(token_lengths, dtype=np.longlong))+1\n",
    "            token_embs = [self.token_dict[t] if t in self.token_dict else torch.zeros((64, ), dtype=torch.float32) for t in tokens]\n",
    "            token_sentiments = [self.sentiment_dict[t] if t in self.sentiment_dict else (0.0, 0.0) for t in tokens]\n",
    "            token_embs = torch.from_numpy(np.array(token_embs, dtype=np.float32))\n",
    "            token_sentiments = torch.from_numpy(np.array(token_sentiments, dtype=np.float32))\n",
    "            doc = ' '.join(tokens)\n",
    "            characters = torch.from_numpy(np.array([self.char_dict[t] for t in doc], dtype=np.longlong))\n",
    "            token_positions = torch.arange(len(token_lengths), dtype=torch.long)\n",
    "            token_indices = torch.repeat_interleave(token_positions, token_lengths)\n",
    "            num_tokens = len(token_lengths)\n",
    "            if num_tokens > self.max_token_count:\n",
    "                self.max_token_count = num_tokens\n",
    "            g_data = Data(x=characters,\n",
    "                            token_positions=token_positions,\n",
    "                            character_length = len(characters),\n",
    "                            num_tokens = num_tokens,\n",
    "                            token_indices=token_indices,\n",
    "                            token_lengths=token_lengths,\n",
    "                            token_embeddings=token_embs,\n",
    "                            token_sentiments=token_sentiments)\n",
    "            self.all_data.append(g_data)\n",
    "        \n",
    "        \n",
    "        self.num_sections = len(y) // batch_size\n",
    "        self.x_lengths = np.array([self.all_data[i].character_length for i in range(len(self.all_data))])\n",
    "        self.x_len_args = np.argsort(self.x_lengths)[::-1]\n",
    "        \n",
    "        self.section_ranges = np.linspace(0, len(self.x_len_args), self.num_sections+1)\n",
    "        self.section_ranges = [(int(self.section_ranges[i-1]), int(self.section_ranges[i])) for i in range(1, len(self.section_ranges))]\n",
    "\n",
    "        self.position_j = 0\n",
    "        self.section_i = 0\n",
    "        self.epoch = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "        self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        index = self.get_section_index()\n",
    "        return self.all_data[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def get_section_index(self):\n",
    "        # if self.shuffle:\n",
    "            \n",
    "        #     t_range = self.section_ranges[self.section_i]\n",
    "        #     target_index = np.random.randint(t_range[0], t_range[1])\n",
    "        # else:\n",
    "        #     t_range = self.section_ranges[self.section_i]\n",
    "        #     target_index = t_range[0] + self.each_section_i[self.section_i]\n",
    "        #     self.each_section_i[self.section_i] = (self.each_section_i[self.section_i] + 1) % (t_range[1] - t_range[0])\n",
    "        # print()\n",
    "        # print(f'self.section_i: {self.section_i},   self.position_j: {self.position_j}')\n",
    "        target_index = self.sections[self.section_i, self.position_j]\n",
    "        \n",
    "        self.position_j = (self.position_j + 1) % self.section_size\n",
    "        if self.position_j == 0:\n",
    "            self.section_i = (self.section_i + 1) % self.num_sections\n",
    "            if self.shuffle and self.section_i == 0:\n",
    "                self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "                # random_positions = np.random.choice(np.arange(0, self.section_size), size=self.section_size, replace=False)\n",
    "        # return self.x_len_args[target_index]\n",
    "        return target_index\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.section_i = 0\n",
    "        self.position_j = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "    def split_into_k_groups(self, len_sorted_args, lengths:np.array, k):\n",
    "        if self.shuffle and self.epoch > 0:\n",
    "            randomize_sections = np.concatenate([np.random.choice(np.arange(r[0], r[1]), size=r[1]-r[0], replace=False) for r in self.section_ranges])\n",
    "            len_sorted_args = len_sorted_args[randomize_sections]\n",
    "        \n",
    "        nums = lengths[len_sorted_args]\n",
    "        groups_size = len(len_sorted_args) // k\n",
    "        \n",
    "        \n",
    "        groups = [[] for _ in range(k)]\n",
    "        group_sums = np.zeros(k, dtype=int)\n",
    "        group_sizes = np.zeros(k, dtype=int)\n",
    "        \n",
    "        # print(f'groups_size: {groups_size}')\n",
    "        # print(f'len(len_sorted_args): {len(len_sorted_args)}')\n",
    "        # print(f'k: {k}')\n",
    "        for i, num in enumerate(nums):\n",
    "            candidate_indices = np.where(group_sizes<groups_size)[0]\n",
    "            # print(f'candidate_indices: {candidate_indices}')\n",
    "            min_group_idx = candidate_indices[np.argmin(group_sums[candidate_indices])]\n",
    "            groups[min_group_idx].append(len_sorted_args[i])\n",
    "            group_sums[min_group_idx] += num\n",
    "            group_sizes[min_group_idx] += 1\n",
    "        self.epoch += 1\n",
    "        \n",
    "        groups = np.array(groups)\n",
    "        group_sums_argsort = np.argsort(group_sums)[::-1]\n",
    "        groups = groups[group_sums_argsort]\n",
    "        \n",
    "        # check_x = self.X[groups]\n",
    "        # check_x_lens = [np.sum(np.array([len(sx) for sx in rx])) for rx in check_x]\n",
    "        # print(f'check_x: {check_x}')\n",
    "        \n",
    "        \n",
    "        return np.array(groups), groups_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CharacterandTokenLevelDataLoader(DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        follow_batch: List[str] | None = None,\n",
    "        exclude_keys: List[str] | None = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CharacterandTokenLevelDataLoader, self).__init__(\n",
    "            dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        base_iterator = super(CharacterandTokenLevelDataLoader, self).__iter__()\n",
    "        for batch in base_iterator:\n",
    "            cumsum_vals = torch.cumsum(batch[0].num_tokens, dim=0).roll(1)\n",
    "            cumsum_vals[0] = 0\n",
    "            additions = torch.repeat_interleave(cumsum_vals, batch[0].character_length)\n",
    "            batch[0].cumulative_token_indices = batch[0].token_indices + additions\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(df.Content.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25088/25088 [05:59<00:00, 69.86it/s]\n",
      "100%|██████████| 25088/25088 [05:43<00:00, 72.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 45min 45s\n",
      "Wall time: 11min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = CharacterandTokenLevelCustomDataset(train_df.Content.values, train_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, batch_size=batch_size)\n",
    "test_dataset = CharacterandTokenLevelCustomDataset(test_df.Content.values, test_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, batch_size=batch_size)\n",
    "max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[12420], token_positions=[2098], character_length=12420, num_tokens=2098, token_indices=[12420], token_lengths=[2098], token_embeddings=[2098, 64], token_sentiments=[2098, 2]),\n",
       " tensor([0., 1.]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2987\n",
      "3089\n"
     ]
    }
   ],
   "source": [
    "train_lengths = np.array([train_dataset[i][0].num_tokens for i in range(len(train_dataset))])\n",
    "test_lengths = np.array([test_dataset[i][0].num_tokens for i in range(len(test_dataset))])\n",
    "print(np.max(train_lengths))\n",
    "print(np.max(test_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[6991], token_positions=[1258], character_length=6991, num_tokens=1258, token_indices=[6991], token_lengths=[1258], token_embeddings=[1258, 64], token_sentiments=[1258, 2]),\n",
       " tensor([1., 0.]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic                                                      0\n",
       "Content    So I finally saw the film \"My Left Foot\" last ...\n",
       "Name: 19745, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[np.argwhere(['hardy' in c and 'obscure' in c for c in  df.Content.values]).squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ▁For ▁their ▁credit , ▁this ▁is ▁one ▁of ▁their ▁more ▁competent ▁pieces ▁of ▁trash , ▁and ▁that ' s ▁because ▁there ' s ▁considerably ▁good ▁go re , ▁and ▁an ▁interesting ▁take ▁on ▁ripping ▁off ▁\" Snake s ▁on ▁a ▁Plane . \" ▁But , ▁if ▁there ' s ▁any ▁more ▁of ▁example ▁of ▁the ▁inconsistency ▁behind ▁Asylum ' s ▁newest ▁rip - off ▁it ' s ▁the ▁two ▁characters ▁at ▁the ▁beginning ▁whom ▁are ▁illegal ▁immigrants ▁and ▁can ' t ▁understand ▁nor ▁speak ▁English ▁to ▁a ▁Texas ▁man ▁sneaking ▁them ▁across ▁the ▁border , ▁yet ▁when ▁they ▁get ▁on ▁a ▁train ▁and ▁meet ▁a ▁friend , ▁they ▁begin ▁understanding ▁and ▁speaking ▁perfect ▁English . < br ▁/ > < br ▁/ > A side ▁from ▁being ▁a ▁pretty ▁bad ▁depiction ▁of ▁a ▁Hollywood ▁formula , ▁\" Snake s ▁on ▁a ▁Train \" ▁is ▁utterly ▁boring . ▁At ▁least , ▁with ▁\" Snake s ▁on ▁a ▁Plane \" ▁we ▁were ▁given ▁the ▁chance ▁to ▁watch ▁actors ▁wax ▁comedic ▁and ▁attempt ▁to ▁be ▁remotely ▁interesting . ▁The ▁Mall achi ▁Brothers ▁installment ▁features ▁some ▁of ▁the ▁most ▁boring ▁characters ▁I ' ve ▁ever ▁seen , ▁from ▁an ▁electrical ▁engineer ▁( gee , ▁I ▁wonder ▁how ▁he ▁comes ▁in ▁handy ▁later ▁on ) , ▁to ▁some ▁stoner ▁surfers , ▁right ▁down ▁to ▁our ▁two ▁main ▁characters ▁attempting ▁to ▁fight ▁off ▁the ▁snake ▁curse ▁that ▁lurks ▁in ▁the ▁husband ' s ▁wife . < br ▁/ > < br ▁/ > \" Snake s \" ▁is ▁never ▁entertaining , ▁and ▁even ▁when ▁it ' s ▁very ▁gory , ▁it ' s ▁still ▁never ▁as ▁good ▁as ▁it ▁has ▁the ▁chance ▁to ▁be , ▁because ▁\" Snake s \" ▁could ▁have ▁been ▁a ▁funny ▁short ▁film , ▁and ▁instead ▁just ▁takes ▁itself ▁much ▁too ▁seriously , ▁and ▁never ▁camps ▁it ▁up ▁at ▁any ▁moment . ▁Instead ▁of ▁taking ▁their ▁small ▁budget ▁and ▁making ▁original ▁films ▁that ▁can ▁set ▁a ▁precedent , ▁they ▁instead ▁force ▁their ▁small ▁budget ▁to ▁work ▁against ▁them ▁in ▁these ▁knock ▁off s . ▁While ▁the ▁Mall achi ▁brothers ▁seem ▁to ▁be ▁trying , ▁the ▁train ▁just ▁looks ▁incredibly ▁artificial . < br ▁/ > < br ▁/ > It ▁seems ▁almost ▁like ▁a ▁stage ▁play ▁with ▁these ▁inconsistent ▁and ▁awfully ▁bland ▁set ▁pieces ▁that ▁try ▁desperately ▁to ▁look ▁like ▁actual ▁train ▁cars , ▁while ▁every ▁so ▁often ▁it ▁shakes , ▁the ▁background ▁of ▁the ▁windows ▁are ▁blurred , ▁and ▁the ▁sound ▁effects ▁go ▁off ▁every ▁now ▁and ▁then ▁to ▁let ▁us ▁know ▁they ' re ▁actually ▁on ▁a ▁train ; ▁not ▁to ▁mention ▁that ▁in ▁such ▁a ▁large ▁extended ▁train ▁there ▁only ▁seems ▁to ▁be ▁about ▁ten ▁passengers ▁on ▁it . ▁And ▁beyond ▁the ▁train ▁fight , ▁and ▁a ▁drawn ▁out ▁sex ▁scene , ▁we ' re ▁forced ▁to ▁be ▁subjected ▁to ▁a ▁plot ▁that ▁makes ▁zero ▁sense . ▁And ▁not ▁even ▁the ▁directors ▁can ▁work ▁around ▁the ▁fact ▁that ▁the ▁\" lethal \" ▁snakes ▁that ▁go ▁on ▁this ▁train ▁look ▁far ▁from ▁venomous ▁or ▁dangerous . < br ▁/ > < br ▁/ > The ▁rest ▁of ▁the ▁film ▁stagger s ▁onto ▁only ▁about ▁a ▁minute ▁of ▁snake ▁carnage ▁and ▁a ▁bad ▁subplot ▁of ▁an ▁ex ▁drug ▁agent ▁trying ▁to ▁molest ▁a ▁passenger . ▁All ▁of ▁this ▁dull ▁exposition ▁ends ▁with ▁a ▁really ▁ridiculous ▁climax ▁in ▁which ▁a ▁poorly ▁computer ▁generated ▁snake ▁( I ▁saw ▁better ▁animation ▁on ▁the ▁Super ▁Nintendo ) ▁completely ▁swallows ▁the ▁train ▁whole , ▁and ▁is ▁then ▁dispensed ▁in ▁a ▁method ▁that ▁should ▁have ▁been ▁exercised ▁from ▁the ▁very ▁beginning . ▁Asylum ▁scores ▁again . < br ▁/ > < br ▁/ > As y lum ▁scores ▁yet ▁again ▁with ▁a ▁hackneyed , ▁lazy , ▁horribly ▁directed , ▁and ▁boring ▁rip - off ▁of ▁another ▁better ▁film . ▁\" Snake s ▁on ▁a ▁Train \" ▁takes ▁itself ▁way ▁too ▁seriously , ▁and ▁that ' s ▁why ▁it ' s ▁never ▁entertaining ▁or ▁memorable . \u0001\n",
      "1 ▁Some ▁said ▁that ▁this ▁was ▁a ▁nose ▁candy ▁glorification ▁flick , ▁but ▁short ▁of ▁the ▁original ▁Dr . ▁Hyde ' s ▁concoction , ▁no ▁drug ▁has ▁yet ▁been ▁developed ▁that ▁can ▁provide ▁THIS ▁effect . ▁If ▁Viagra ▁was ▁the ▁slime ▁mold ▁stage , ▁that ▁white ▁sparkling ▁powder ▁is ▁the ▁Stephen ▁Hawking ▁evolutionary ▁rung ▁( or ▁at ▁least ▁the ▁pharmacist ▁idiot ▁savant ▁branch ) . ▁This ▁reality ▁show ▁is ▁really ▁about ▁the ▁sacred ▁cows ▁of ▁medicine , ▁seen ▁as ▁was ▁the ▁emperor ▁without ▁clothes . ▁Few ▁of ▁us ▁want ▁to ▁question ▁the ▁health ▁field ; ▁both ▁because ▁most ▁of ▁us ▁would ▁not ▁have ▁lived ▁to ▁our ▁current ▁age ▁had ▁we ▁been ▁born ▁before ▁\" modern ▁medicine \" , ▁and ▁because ▁our ▁subconscious ▁hopes ▁that ▁we ▁will ▁continue ▁to ▁live ▁on ▁if ▁we ▁have ▁faith ▁in ▁the ▁helping ▁professions . ▁So ▁the ▁geniuses ▁who ▁produced ▁this ▁movie ▁made ▁jokes ▁out ▁of ▁those ▁Calcutta ▁Bess y ' s , ▁giving ▁us ▁the ▁sugar ▁that ▁allows ▁us ▁to ▁swallow ▁the ▁modern ▁institution ▁of ▁medicine . ▁The ▁timing ▁was ▁right , ▁and ▁many ▁were ▁able ▁to ▁see ▁the ▁business ▁side ▁of ▁the ▁healing ▁companies ▁behind ▁the ▁curtain ▁of ▁Oz . ▁A ▁decade ▁before , ▁when ▁George ▁C . ▁Scott ▁rant ed ▁through ▁the ▁movie ▁The ▁Hospital , ▁my ▁wife ▁and ▁I ▁were ▁sitting ▁in ▁the ▁packed ▁premiere ▁in ▁Oklahoma ▁City . ▁Just ▁as ▁in ▁Jekyll ▁& ▁Hyde ' s ▁remake , ▁we ▁were ▁almost ▁unable ▁to ▁keep ▁from ▁falling ▁out ▁of ▁our ▁seat , ▁and ▁laughed ▁and ▁how led ▁uncontrollably ▁for ▁the ▁duration . ▁The ▁hundreds ▁of ▁other ▁audience ▁members ▁were ▁deadly ▁silent . ▁They ▁were ▁shocked ▁that ▁doctors , ▁nurses , ▁& ▁the ▁hospital ▁institution ▁were ▁being ▁mocked . ▁It ▁was ▁as ▁if ▁the ▁Pope , ▁Billy ▁Graham , ▁and ▁Gandhi ▁were ▁were ▁sitting ▁in ▁the ▁Animal ▁House , ▁beer ▁stained ▁tee ▁shirts ▁and ▁all , ▁competing ▁to ▁see ▁who ▁could ▁tell ▁the ▁funniest ▁God ▁knock - knock ▁jokes ▁between ▁be l ches . ▁Had ▁The ▁Hospital ▁been ▁a ▁slapstick ▁comedy ▁rather ▁than ▁a ▁satire , ▁they ▁might ▁have ▁been ▁able ▁to ▁see ▁what ▁was ▁being ▁shown ▁to ▁them . ▁Unfortunately ▁they ▁were ▁like ▁Republicans ▁at ▁a ▁screening ▁of ▁Michael ▁Moore ' s ▁9 / 11 . ▁Perhaps ▁smaller ▁golden ▁parachute s ▁would ▁have ▁been ▁given ▁to ▁the ▁corrupt ▁medical ▁corporation ▁leaders , ▁health ▁insurance ▁companies ▁would ▁have ▁had ▁a ▁tougher ▁time ▁denying ▁medical ▁care , ▁and ▁health ▁providers ▁would ▁have ▁been ▁de my st ified ▁earlier , ▁if ▁George ▁C . ▁Scott ▁had ▁tap ▁danced ▁in ▁a ▁tutu ▁while ▁delivering ▁his ▁terrible ▁truths . ▁But - - forget ▁everything ▁I ▁just ▁said . ▁Watch ▁the ▁movie , ▁be ▁consciously ▁made ▁as ▁happy ▁and ▁joyful ▁and ▁full ▁of ▁laughter ▁as ▁the ▁best ▁ever ▁Saturday ▁Night ▁Live ▁skit , ▁and ▁let ▁the ▁subconscious ▁soak ▁in ▁the ▁documentary ▁of ▁the ▁underlying ▁reality . ▁Just ▁don ' t ▁blame ▁me ▁when ▁\" Got ▁to ▁Got ▁to ▁Got ▁to ▁Got ▁to \" ▁becomes ▁one ▁of ▁your ▁saying s , ▁or ▁when ▁\" H yde ' s ▁Got ▁Nothing ▁to ▁Hide \" ▁occupies ▁that ▁portion ▁of ▁your ▁brain ▁now ▁paralyzed ▁by ▁\" It s ▁a ▁Small ▁World ▁After ▁All \" . ▁Or ▁when ▁you ▁start ▁calling ▁your ▁local ▁hospital ▁Our ▁Lady ▁of ▁Pain ▁and ▁Suffering ▁instead ▁of ▁Our ▁Lady ▁of ▁Eternal ▁Construction . ▁Even ▁Oklahoma ns ▁were ▁changing ▁their ▁favorite ▁terrible ▁boss ▁wishbone ▁winner ▁entreat y ▁from ▁\" Pi s s ▁on ▁him ▁and ▁leave ▁him ▁for ▁dead \" , ▁to ▁\" Body ▁in ▁a ▁pit , ▁you ▁in ▁it . . . . . \" ▁The ▁smell ▁of ▁death . . . it ' s ▁gone ! ▁Chicken ▁sushi ! ▁Mary . ▁MARY . ▁MARY E EEE EEE EEE EEE ! \u0001\n",
      "1 ▁When ▁I ▁watched ▁this ▁movie ▁when ▁I ▁was ▁a ▁kid ▁I ▁didn ' t ▁understand ▁the ▁premise ▁of ▁Hitchcock ▁movies , ▁and ▁dark ▁comedy . ▁Now ▁that ▁I ' m ▁in ▁my ▁mid ▁20 ' s ▁it ▁makes ▁a ▁lot ▁more ▁sense . < br ▁/ > < br ▁/ > I ▁think ▁the ▁reason ▁I ▁like ▁this ▁movie ▁so ▁much ▁is ▁that ▁the ▁comedy ▁duo ▁of ▁Billy ▁Crystal ▁and ▁Danny ▁DeVito ▁make ▁for ▁some ▁interesting ▁comedy , ▁both ▁slapstick ▁( the ▁frying ▁pan ▁and ▁car ▁scenes ) ▁and ▁verbal ▁( the ▁arguments / conversation s ▁over ▁murder ▁and ▁writing ) . < br ▁/ > < br ▁/ > The ▁story ▁revolves ▁around ▁Larry ▁Donner ( Crystal ) , ▁a ▁struggling ▁writer ▁who ▁has ▁his ▁masterpiece ▁stolen ▁from ▁him ▁by ▁his ▁wife ▁Margaret ▁( played ▁by ▁a ▁surprisingly ▁radiant ▁Kate ▁Mul grew , ▁aka ▁Capt . ▁Janeway ▁from ▁Star ▁Trek : ▁Voyager ) . < br ▁/ > < br ▁/ > While ▁he ▁shifts ▁between ▁writer ' s ▁block ▁and ▁teaching ▁creative ▁writing ▁class , ▁he ▁meets ▁with ▁student ▁Owen ▁Lift s ( De Vi to ) , ▁an ▁aspiring ▁writer ▁and ▁overgrown ▁mama ' s ▁boy ▁who ▁sadly ▁still ▁acts ▁like ▁a ▁kid . ▁He ▁has ▁toy ▁train ▁tracks , ▁need ▁I ▁say ▁more ? ▁Think ▁of ▁Failure ▁to ▁Launch , ▁only ▁Matt ▁McConaughey ▁is ▁short , ▁fat , ▁and ▁bald . < br ▁/ > < br ▁/ > Owen ▁is ▁stuck ▁in ▁his ▁own ▁life , ▁with ▁a ▁demanding ▁evil ▁mother ( Anne ▁Ramsey ) ▁who ▁he ▁can ' t ▁stand . ▁He ▁seeks ▁Larry ' s ▁advice ▁on ▁how ▁to ▁get ▁out ▁of ▁it , ▁and ▁when ▁he ▁says ▁to ▁go ▁see ▁a ▁Hitchcock ▁film ▁Owen ▁gets ▁the ▁wrong ▁idea ▁that ▁if ▁he ▁kills ▁Larry ' s ▁wife , ▁he ' ll ▁return ▁the ▁favor ▁and ▁kill ▁his ▁mom ▁for ▁him . ▁Hil arity ▁ensues ▁while ▁the ▁two ▁try ▁to ▁deal ▁with ▁each ▁other ' s ▁problem . ▁Owen ▁goes ▁to ▁extremes ▁to ▁kill ▁Margaret ▁while ▁Larry , ▁who ▁refuses ▁to ▁agree ▁to ▁do ▁his ▁\" part ▁of ▁the ▁plan \" , ▁is ▁driven ▁nuts ▁by ▁Owen ' s ▁mother . < br ▁/ > < br ▁/ > Throughout ▁the ▁film , ▁Larry ▁and ▁Owen ▁slowly ▁but ▁surely ▁form ▁a ▁bond ▁of ▁friendship ▁that ▁is ▁rare ▁in ▁dark ▁comedy ▁nowadays . ▁One ▁part ▁of ▁the ▁movie ▁I ▁really ▁loved ▁was ▁where ▁Owen ▁shows ▁Larry ▁his ▁coin ▁collection , ▁and ▁lets ▁just ▁say ▁its ▁more ▁a ▁sentimental ▁collection ▁than ▁anything . < br ▁/ > < br ▁/ > The ▁two ▁main ▁stars ▁aside , ▁the ▁late ▁Anne ▁Ramsey ▁is ▁hilarious ▁as ▁Mama , ▁and ▁deadly ▁with ▁that ▁can e ▁of ▁her s . ▁She ' s ▁a ▁lot ▁more ▁comedic ▁verbally ▁and ▁physically ▁in ▁this ▁as ▁opposed ▁to ▁her ▁role ▁as ▁Mama ▁Frat elli ▁from ▁The ▁Goon ies . ▁So ▁she ▁curses ▁like ▁a ▁sailor ▁and ▁belittle s ▁her ▁son ▁at ▁every ▁turn , ▁but ▁that s ▁what ▁makes ▁her ▁character ▁so ▁vivid . ▁She ▁makes ▁her ▁character ▁the ▁kind ▁of ▁person ▁you ▁love ▁to ▁hate . < br ▁/ > < br ▁/ > Another ▁treat ▁in ▁this ▁movie ▁is ▁the ▁music ▁of ▁jazz ▁great ▁Brand ford ▁Marsalis , ▁who ▁plays ▁Larry ' s ▁neighbor ▁and ▁friend ▁Lester . ▁There ▁is ▁a ▁great ▁moment ▁in ▁the ▁movie ▁where ▁he ▁plays ▁jazz ▁for ▁Larry , ▁who ▁is ▁depressed ▁and ▁needs ▁some ▁good ▁tunes ▁to ▁relieve ▁the ▁pain . ▁Jazz ▁can ▁do ▁that . < br ▁/ > < br ▁/ > In ▁closing , ▁I ▁wish ▁Billy ▁Crystal ▁and ▁Danny ▁DeVito ▁would ▁do ▁another ▁good ▁movie ▁together , ▁but ▁their ▁kinda ▁getting ▁too ▁old ▁for ▁the ▁game ▁I ' m ▁sad ▁to ▁say . ▁This ▁is ▁one ▁of ▁those ▁rare ▁movies ▁where ▁both ▁stars ▁shine ▁in ▁their ▁own ▁subtle ▁ways . ▁DeVito ' s ▁childish ▁comedy ▁and ▁Crystal ' s ▁sharp ▁wit ▁made ▁this ▁movie ▁for ▁me . ▁5 ▁star ▁comedy . \u0001\n",
      "0 ▁There ▁are ▁certain ▁horror ▁directors ▁for ▁whom ▁I ' ve ▁built ▁up ▁so ▁much ▁respect ▁& ▁admiration ▁over ▁the ▁years , ▁that ▁they ▁can ' t ▁possibly ▁disappoint ▁me ▁know ▁matter ▁what ▁garbage ▁to ▁decide ▁to ▁put ▁on ▁film . ▁Lucio ▁Ful ci ▁is ▁surely ▁one ▁of ▁them , ▁but ▁damned , ▁he ' s ▁trying ▁to ▁disappoint ▁me ▁with ▁his ▁later ▁efforts ! ▁You ▁can ▁easily ▁afford ▁yourself ▁to ▁skip ▁most ▁of ▁the ▁films ▁Ful ci ▁directed ▁or ▁produced ▁during ▁the ▁late ▁80 ' s ▁and ▁simply ▁watch ▁\" Cat ▁in ▁the ▁Brain \" ▁instead , ▁because ▁that ▁one ▁title ▁gathers ▁and ▁repeats ▁the ▁best ▁and ▁absolute ▁go ries t ▁footage ▁of ▁no ▁less ▁than ▁SEVEN ▁other ▁Ful ci - flick s , ▁including ▁the ▁sick est ▁murders ▁sequences ▁featuring ▁in ▁\" When ▁Alice ▁Broke ▁the ▁Mirror \" . ▁As ▁a ▁whole , ▁this ▁movie ▁definitely ▁ranks ▁among ▁our ▁director ' s ▁weakest ▁and ▁most ▁pointless ▁achievements . ▁The ▁script ▁is ▁incoherent ▁as ▁hell , ▁the ▁basic ▁premise ▁is ▁totally ▁implausible ▁and ▁somewhat ▁stupid ▁and ▁there ' s ▁absolutely ▁no ▁suspense ▁to ▁enjoy . ▁I ▁love ▁the ▁title , ▁but ▁it ' s ▁actually ▁quite ▁meaningless . ▁There ▁is ▁a ▁character ▁named ▁Alice ▁in ▁the ▁story , ▁but ▁it ' s ▁only ▁a ▁supportive ▁role ▁and ▁she ▁certainly ▁doesn ' t ▁break ▁any ▁mirrors . ▁I ▁suppose ▁she ▁could ▁break ▁stuff ▁simply ▁using ▁her ▁voice , ▁as ▁she ' s ▁an ▁opera ▁singer , ▁but ▁she ▁doesn ' t . ▁The ▁plot ▁revolves ▁on ▁a ▁middle - aged ▁and ▁gambling - addicted ▁play boy ▁who ▁spends ▁his ▁days ▁seducing ▁wealthy ▁widows ▁and ▁killing ▁them ▁for ▁their ▁money . ▁Lester ▁Parson ▁butchers ▁the ▁ladies ▁( as ▁well ▁as ▁unwelcome ▁witnesses ) ▁in ▁gruesome ▁ways , ▁makes ▁steaks ▁out ▁of ▁their ▁ju ic iest ▁body ▁parts ▁and ▁feeds ▁the ▁remainder s ▁to ▁his ▁cat . ▁There ' s ▁also ▁a ▁silly ▁psychological ▁sub ▁plot ▁in ▁which ▁he ▁thinks ▁his ▁own ▁shadow ▁is ▁responsible ▁for ▁the ▁murders ▁instead ▁of ▁him . ▁The ▁difference ▁between ▁\" When ▁Alice ▁Broke ▁the ▁Mirror \" ▁and ▁some ▁of ▁Ful ci ' s ▁greatest ▁horror ▁films ▁( \" The ▁Beyond \" , ▁\" City ▁of ▁the ▁Living ▁Dead \" , ▁  \" ) ▁lies ▁in ▁the ▁fact ▁that ▁he ▁totally ▁doesn ' t ▁bother ▁to ▁create ▁a ▁horrific ▁atmosphere . ▁The ▁characters , ▁Lester ▁included , ▁are ▁colorless ▁and ▁boring ▁and ▁the ▁murders ▁are ▁ordinarily ▁depicted ; ▁like ▁it ' s ▁the ▁most ▁common ▁thing ▁in ▁the ▁world ▁to ▁put ▁a ▁woman ' s ▁head ▁in ▁a ▁microwave ▁or ▁repeatedly ▁run ▁back ▁and ▁forth ▁over ▁a ▁human ▁body ▁with ▁a ▁car . ▁The ▁lighting ▁is ▁poor , ▁the ▁cinematography ▁super - ugly , ▁the ▁editing ▁clumsy ▁and ▁amateurish ▁and ▁the ▁acting ▁performances ▁are ▁downright ▁miserable . ▁If ▁I ▁didn ' t ▁know ▁any ▁better , ▁I ▁would ▁think ▁Lucio ▁deliberately ▁made ▁a ▁lousy ▁film ▁in ▁order ▁to ▁protest ▁against ▁all ▁the ▁harsh ▁critics ▁that ▁dislike ▁his ▁repertoire ▁no ▁matter ▁how ▁much ▁spirit ▁and ▁effort ▁he ▁put ▁into ▁it . ▁The ▁obvious ▁element ▁to ▁enjoy ▁here ▁is ▁simply ▁the ▁outrageous ▁go re ▁& ▁bloodshed , ▁because ▁even ▁the ▁attempt ▁to ▁blend ▁in ▁black ▁comedy ▁doesn ' t ▁work ▁properly . ▁As ▁long ▁as ▁Lester ▁swings ▁around ▁his ▁chainsaw ▁and ▁cuts ▁off ▁women ' s ▁feet , ▁\" When ▁Alice ▁Broke ▁the ▁Mirror \" ▁is ▁an ▁un demand ing ▁piece ▁of ▁horror ▁entertainment , ▁but ▁other ▁than ▁that , ▁there ' s ▁isn ' t ▁a ▁whole ▁lot ▁to ▁recommend . \u0001\n",
      "1 ▁This ▁indie ▁film ▁is ▁worth ▁a ▁look ▁because ▁of ▁the ▁enormous ▁talent ▁of ▁its ▁creators , ▁Wallace ▁W olo dar sky ▁and ▁Marsha ▁Forbes . ▁Mr . ▁W olo dar sky ▁has ▁directed ▁the ▁young ▁cast , ▁and ▁he ▁is ▁to ▁be ▁praised ▁for ▁this ▁effort . < br ▁/ > < br ▁/ > The ▁premise ▁of ▁the ▁film ▁is ▁a ▁cautionary ▁tale ▁of ▁the ▁danger ▁for ▁wanting ▁something ▁one ▁can ' t ▁have . ▁Which ▁is ▁the ▁story ▁of ▁Alice ▁and ▁Ed . ▁After ▁living ▁together ▁for ▁a ▁while , ▁Alice ▁suddenly ▁gets ▁restless ▁because ▁she ▁imagine s ▁she ' s ▁lacking ▁experience ▁in ▁the ▁sex ▁area . ▁Alice ▁and ▁Ed ' s ▁relationship , ▁while ▁not ▁an ▁example ▁of ▁ideal ▁happiness , ▁is ▁a ▁comfortable ▁way ▁to ▁share ▁their ▁lives ▁with ▁one ▁another . ▁That ▁is , ▁until ▁the ▁moment ▁Alice ▁and ▁Claire , ▁her ▁sister , ▁happened ▁to ▁bump ▁into ▁a ▁sexual ▁encounter ▁by ▁another ▁couple ▁that ▁has ▁no ▁clue ▁of ▁being ▁observed . < br ▁/ > < br ▁/ > This ▁incident ▁makes ▁Alice ▁reevaluate ▁her ▁own ▁sexual ▁life ▁with ▁Ed ; ▁she ▁finds ▁it ▁lacks ▁substance . ▁When ▁she ▁proposes ▁' seeing ▁other ▁people ' , ▁Ed ▁is ▁shocked , ▁to ▁put ▁it ▁mildly , ▁but ▁not ▁wanting ▁to ▁contradict ▁Alice , ▁he ▁decides ▁to ▁go ▁along . ▁What ▁happens ▁next ▁is ▁that ▁both ▁Alice ▁and ▁Ed ▁enter ▁into ▁a ▁world ▁that ' s ▁been ▁unknown ▁to ▁them . ▁The ▁people ▁they ▁meet , ▁in ▁the ▁end , ▁are ▁not ▁worth ▁the ▁trouble . ▁They ▁sadly ▁realize ▁at ▁the ▁end , ▁they ▁were ▁made ▁for ▁each ▁other . < br ▁/ > < br ▁/ > The ▁film ▁is ▁worth ▁watching ▁in ▁order ▁to ▁see ▁the ▁amazing ▁Julianne ▁Nicholson , ▁who ▁we ▁happen ▁to ▁have ▁liked ▁in ▁another ▁indie ▁film , ▁\" T ully \" . ▁Ms . ▁Nicholson ▁reminds ▁us ▁of ▁a ▁young ▁Shirley ▁McLa ine ; ▁she ▁projects ▁such ▁a ▁luminous ▁quality ▁about ▁her , ▁that ▁is ▁hard ▁to ▁take ▁one ' s ▁eyes ▁from ▁her ▁whenever ▁she ▁is ▁in ▁a ▁scene . ▁This ▁young ▁actress ▁proves ▁she ▁is ▁an ▁accomplished ▁performer ▁who ▁gets ▁better ▁with ▁each ▁new ▁appearance . ▁Basically , ▁she ▁carries ▁the ▁movie . ▁Her ▁Alice ▁is ▁a ▁study ▁in ▁contrasts . ▁Alice ▁is ▁a ▁decent ▁woman ▁who ▁thinks ▁she ▁is ▁inadequate ▁in ▁pleasing ▁Ed ▁because ▁of ▁her ▁inexperience . < br ▁/ > < br ▁/ > Jay ▁Mohr , ▁is ▁an ▁excellent ▁match ▁for ▁Ms . ▁Nicholson . ▁Both ▁do ▁wonders ▁together . ▁His ▁Ed ▁is ▁perfectly ▁credible . ▁We ▁have ▁known ▁people ▁like ▁him . ▁Deep ▁down ▁inside , ▁he ▁is ▁a ▁good ▁person , ▁who ▁suddenly ▁gets ▁himself ▁in ▁a ▁situation ▁he ▁didn ' t ▁call ▁for , ▁yet , ▁he ▁goes ▁along ▁only ▁to ▁discover ▁he ▁is ▁too ▁decent ▁and ▁not ▁cut ▁out ▁for ▁a ▁life ▁of ▁gratuitous ▁sex ▁with ▁the ▁willing ▁women ▁that ▁have ▁no ▁problem ▁with ▁a ▁tumble ▁in ▁the ▁hay , ▁just ▁for ▁fun . < br ▁/ > < br ▁/ > The ▁rest ▁of ▁the ▁cast ▁is ▁wonderful . ▁Lauren ▁Graham ▁does ▁some ▁amazing ▁work ▁as ▁Claire , ▁Alice ' s ▁yuppie ▁sister . ▁Andy ▁Rit cher ▁is ▁also ▁wonderful ▁as ▁the ▁grounded ▁Carl , ▁the ▁nerdy ▁friend ▁who ▁finally ▁finds ▁out ▁fulfillment ▁when ▁he ▁meets ▁Penelope , ▁a ▁single ▁mother . ▁As ▁Penelope , ▁Helen ▁Slater , ▁makes ▁a ▁felici tous , ▁albeit ▁of ▁a ▁short , ▁appearance ▁in ▁the ▁film . < br ▁/ > < br ▁/ > The ▁director ▁is ▁enormously ▁gifted , ▁who ▁will ▁no ▁doubt ▁go ▁places ▁because ▁he ▁shows ▁he ▁is ▁well ▁suited ▁for ▁the ▁job . \u0001\n"
     ]
    }
   ],
   "source": [
    "for i in range(15,20):\n",
    "    char_ids = X[i].x\n",
    "    text_for_ids = ''.join([vocab_dict_rev[ci.item()] for ci in char_ids])\n",
    "    print(torch.argmax(y[i]).item(), text_for_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rand = torch.randn((64, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0044)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rand.var(unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[355358], token_positions=[66080], character_length=[224], num_tokens=[224], token_indices=[355358], token_lengths=[66080], token_embeddings=[66080, 64], token_sentiments=[66080, 2], batch=[355358], ptr=[225], cumulative_token_indices=[355358])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = torch.randn((len(X.token_positions), 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([66080])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(torch.arange(len(X.num_tokens)), X.num_tokens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  ..., 27, 28, 29])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.token_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0709, -0.2983,  0.2832,  ...,  0.5918,  0.8283,  2.0296],\n",
       "        [ 1.1111,  1.2459,  1.4224,  ...,  1.8944, -0.4097,  0.4660],\n",
       "        [ 0.0923,  0.0040,  0.6422,  ...,  0.5246,  1.2957,  2.0529],\n",
       "        ...,\n",
       "        [-0.5893,  0.3900, -0.6723,  ...,  0.3900, -1.2879, -0.2733],\n",
       "        [-1.2590, -0.5400,  0.7138,  ...,  0.4161,  0.6023, -0.2398],\n",
       "        [-0.8433, -0.7905,  1.6584,  ..., -0.1454, -0.2498,  1.3088]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv\n",
    "\n",
    "# Normalization on each feature of all tokens, for this we used batch norm class but with tokens at batch dimention\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, *args, **kwargs):\n",
    "        super(GCNN, self).__init__(*args, **kwargs)\n",
    "        self.gnn = GATv2Conv(hidden_dim, hidden_dim//8, heads=4, add_self_loops=False)\n",
    "        self.conv = nn.Conv1d(hidden_dim, hidden_dim//2, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim//2)\n",
    "        \n",
    "    def forward(self, x, edge_data, return_attention_weights = False):\n",
    "        x1, edge_weights = self.gnn(x, edge_data, return_attention_weights=return_attention_weights) \n",
    "        x2 = F.relu(self.conv(x.T).T)\n",
    "        x1 = F.leaky_relu_(self.bn1(x1))\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        return x, edge_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from copy import copy, deepcopy\n",
    "# gcnn_model = GCNN(64)\n",
    "# flopt_counter = FlopCounterMode(gcnn_model)\n",
    "# X.edge_index = torch.randint(0, len(X.token_positions), size=(2,200))\n",
    "# with flopt_counter:\n",
    "#     x_input = deepcopy(torch.randn((len(X.token_positions), 64)))\n",
    "#     edge_data = deepcopy(X.edge_index)\n",
    "#     gcnn_model(x_input, edge_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, to_undirected\n",
    "\n",
    "class GenGraph(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, virtual_nodes, lattice_step, lattice_pattern=None, *args, **kwargs):\n",
    "        super(GenGraph, self).__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.lattice_step = lattice_step\n",
    "        self.lp = lattice_pattern if lattice_pattern is None else torch.tensor(lattice_pattern)\n",
    "        self.virtual_node_embeddings = nn.Embedding(self.virtual_nodes, hidden_dim)\n",
    "        \n",
    "    def gen_graph(self, x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2, seed=-1):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance, seed)\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        edge_index = torch.empty((2, base_numel + v_n_e_counts*2), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "            \n",
    "        if self.virtual_nodes > 0:\n",
    "            virtual_nodes_range = torch.arange(self.virtual_nodes, device=x.device).view(1, -1)\n",
    "            virtual_nodes_ids = torch.repeat_interleave(virtual_nodes_range, len(token_counts), dim=0)\n",
    "            v_n_idx = (virtual_nodes_ids + torch.arange(0, len(token_counts)*self.virtual_nodes, self.virtual_nodes, device=x.device).view(-1, 1) + total_token_coutns )\n",
    "            virtual_edge_ids = torch.repeat_interleave(v_n_idx.view(-1), token_counts.view(-1, 1).expand(len(token_counts), self.virtual_nodes).reshape(-1), dim=0).view(1, -1)\n",
    "            \n",
    "            embs = self.virtual_node_embeddings(virtual_nodes_ids.T).view(-1, self.hidden_dim)\n",
    "            x_extended = torch.cat([x, embs], dim=0)\n",
    "            x_index = torch.arange(total_token_coutns, device=x.device).repeat(self.virtual_nodes).view(1, -1)\n",
    "            edge_index[:, base_numel:base_numel+v_n_e_counts] = torch.cat([x_index, virtual_edge_ids], dim=0)\n",
    "            edge_index[:, base_numel+v_n_e_counts:] = torch.cat([virtual_edge_ids, x_index], dim=0)\n",
    "            x = x_extended\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "        \n",
    "    def re_gen_graph(self, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2, seed=-1):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance, seed)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "        # for i in range(base.shape[1]):\n",
    "        #     edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "            \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "    \n",
    "    def replace_unimportant_edges(self, edge_weights, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2, seed=-1):\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        if v_n_e_counts>0:\n",
    "            important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        else:\n",
    "            important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "\n",
    "        important_indices = torch.arange(total_token_coutns, dtype=torch.int64, device=x.device) + important_indices*total_token_coutns\n",
    "        important_indices = important_indices.view(-1)\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance, seed)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "        new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_index[:, important_indices]\n",
    "        if(self.virtual_nodes>0):\n",
    "            new_edge_index[:, -2*v_n_e_counts:] = edge_index[:, -2*v_n_e_counts:]\n",
    "            \n",
    "        # for i in range(base.shape[1]):\n",
    "        #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "         \n",
    "    def calculate_graph(self, x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance, seed=-1):\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    "        tc_extended = torch.repeat_interleave(token_counts, token_counts, dim=0).view(-1,1)\n",
    "        tc_lower_bound = torch.empty((len(token_counts)+1), dtype=torch.long, device=x.device) #torch.cuda.IntTensor(len(token_counts)+1) #\n",
    "        tc_lower_bound[0] = 0\n",
    "        tc_lower_bound[1:] = torch.cumsum(token_counts, dim=0)\n",
    "        tc_lower_bound_extended = torch.repeat_interleave(tc_lower_bound[:-1], token_counts, dim=0).view(-1,1)\n",
    "        tc_range = torch.arange(tc_lower_bound[-1], device=x.device).view(-1,1)\n",
    "        # torch.arange(tc_lower_bound[-1], dtype=torch.int32, device=x.device).view(-1,1)\n",
    "        random_ints = torch.randint(0, 2*total_token_counts, (total_token_counts, random_edges), device=x.device) # torch.cuda.IntTensor(len(token_lengths), random_edges).random_()\n",
    "        lattice = self.lp.to(x.device) if self.lp is not None else torch.arange(lattice_start_distance, max(lattice_start_distance, self.lattice_step*lattice_edges+1), self.lattice_step, device=x.device).view(1, -1)\n",
    "        \n",
    "\n",
    "        # exponentials = torch.pow(2, torch.arange(1, self.exp_edges+1, device=x.device)).view(1, -1)\n",
    "        tc_local_range = tc_range - tc_lower_bound_extended\n",
    "        random_links = (((random_ints % (tc_extended - 1))+1 + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        lattice_links = ((lattice + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        # base = torch.cat([base1, base2], dim=1)\n",
    "        tc_range = tc_range.view(1,-1)\n",
    "        return random_links, lattice_links, tc_range\n",
    "    \n",
    "    def fill_lattice_and_random_edges(self, edge_index, random_links, lattice_links, tc_range):\n",
    "        for i in range(0, lattice_links.shape[1]*2, 2):\n",
    "            edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]] = torch.cat([lattice_links[:,i//2].view(1,-1), tc_range], dim=0)\n",
    "            edge_index[:, (i+1)*lattice_links.shape[0]:(i+2)*lattice_links.shape[0]] = edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]][[1, 0]]\n",
    "            \n",
    "        for i in range(random_links.shape[1]):\n",
    "            j = i + lattice_links.shape[1]*2\n",
    "            edge_index[:, j*random_links.shape[0]:(j+1)*random_links.shape[0]] = torch.cat([random_links[:,i].view(1,-1), tc_range], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment_Injection(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)        \n",
    "        self.conv1 = nn.Conv1d(2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim*2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, token_sentiments):\n",
    "        x1 = F.relu_(self.bn1(self.conv1(token_sentiments.T).T))\n",
    "        x = F.relu_(self.conv2(torch.cat([x, x1], dim=1).T))\n",
    "        # x = x + x1\n",
    "        return x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment1  = Sentiment_Injection(64)\n",
    "# sentiment1(torch.ones((41047, 64)), torch.ones((41047, 2))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.nn import GATv2Conv, SimpleConv, summary\n",
    "\n",
    "# class CNN_for_Text(nn.Module):\n",
    "    \n",
    "#     def __init__(self, num_embedding, pos_emb_size=8192, embedding_dim=64, hidden_dim=64, dropout=0.3, num_out_features=4, seed=-1, random_edges=4, lattice_edges=10, virtual_nodes=1, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64, use_positional_encoder=[False, False, False], *args, **kwargs) -> None:\n",
    "#         super(CNN_for_Text, self).__init__(*args, **kwargs)\n",
    "#         self.pos_emb_size = pos_emb_size\n",
    "#         self.embedding_dim = embedding_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.virtual_nodes = virtual_nodes\n",
    "#         self.base_random_edges = random_edges\n",
    "#         self.base_lattice_edges = lattice_edges\n",
    "#         self.lattice_start_distance = lattice_start_distance\n",
    "#         # self.use_token_polarity = use_token_polarity\n",
    "#         self.use_positional_encoder = use_positional_encoder\n",
    "#         if seed>-1:\n",
    "#             torch.manual_seed(seed)\n",
    " \n",
    "#         self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "#         self.positional_encoding = nn.Embedding(pos_emb_size, embedding_dim)\n",
    "#         self.positional_encoding.weight = self.create_positional_encoding()\n",
    "\n",
    "#         self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "#         self.pool1 = nn.MaxPool1d(2)\n",
    "#         self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        \n",
    "#         # if self.use_token_polarity[0]:\n",
    "#         #     self.conv3 = nn.Conv1d(2*hidden_dim + 2, hidden_dim, kernel_size=3, padding=1)\n",
    "#         # else:\n",
    "#         self.conv3 = nn.Conv1d(2*hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "#         self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "#         # if self.use_token_polarity[1]:\n",
    "#         self.sentiment1  = Sentiment_Injection(hidden_dim)\n",
    "#         # if self.use_token_polarity[2]:\n",
    "#         self.sentiment2  = Sentiment_Injection(hidden_dim)\n",
    "            \n",
    "#         self.gcnn1 = GCNN(hidden_dim)\n",
    "#         self.gcnn2 = GCNN(hidden_dim+inject_embedding_dim)\n",
    "#         self.graph_generator = GenGraph(hidden_dim, virtual_nodes, lattice_step)\n",
    "        \n",
    "#         k = 4\n",
    "#         self.fc0 = nn.Linear(hidden_dim , hidden_dim+inject_embedding_dim)\n",
    "#         self.fc1 = nn.Linear(hidden_dim+inject_embedding_dim , hidden_dim * k)\n",
    "#         self.fc2 = nn.Linear(hidden_dim * (2+virtual_nodes) * k , 32)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.fc_out = nn.Linear(32, num_out_features)\n",
    "#         self.max_length = 0\n",
    "    \n",
    "#     def forward(self, g_data):\n",
    "            \n",
    "#         x = self.embedding(g_data.x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = x.T\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x1 = scatter_max(x, g_data.cumulative_token_indices, dim=1)[0]\n",
    "#         x2 = scatter_mean(x, g_data.cumulative_token_indices, dim=1)\n",
    "\n",
    "#         # if self.use_token_polarity[0]:\n",
    "#         #     x = torch.cat([x1, x2, g_data.token_sentiments.T], dim=0)\n",
    "#         # else:\n",
    "#         x = torch.cat([x1, x2], dim=0)\n",
    "            \n",
    "#         x = F.relu(self.conv3(x)).T\n",
    "        \n",
    "#         # if self.use_token_polarity[1]:\n",
    "#         x = self.sentiment1(x, g_data.token_sentiments)\n",
    "            \n",
    "#         if self.use_positional_encoder[0]:\n",
    "#             x = x + self.positional_encoding(g_data.token_positions)\n",
    "#         # x = x + self.positional_encoding(g_data.token_positions)\n",
    "\n",
    "#         rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "            \n",
    "#         graph = self.graph_generator.gen_graph(x, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "#         rand_edges = rand_edges-1\n",
    "#         lattice_edges = lattice_edges-1\n",
    "        \n",
    "        \n",
    "#         doc_token_index = torch.repeat_interleave(torch.arange(len(g_data.num_tokens), device=x.device), g_data.num_tokens)\n",
    "#         x, edge_weights = self.gcnn1(graph.x, graph.edge_index, return_attention_weights = True)\n",
    "#         edge_weights = edge_weights[1][:graph.edge_index.shape[1], 0]\n",
    "        \n",
    "#         graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, graph.edge_index, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        \n",
    "        \n",
    "#         # if self.use_token_polarity[2]:\n",
    "#         x = self.sentiment2(x, g_data.token_sentiments)\n",
    "            \n",
    "        \n",
    "#         if self.use_positional_encoder[1]:\n",
    "#             xa = graph.x[:g_data.token_embeddings.shape[0]] + self.positional_encoding(g_data.token_positions)\n",
    "#         else:\n",
    "#             xa = graph.x[:g_data.token_embeddings.shape[0]]\n",
    "#         if self.use_positional_encoder[2]:\n",
    "#             xb = g_data.token_embeddings + self.positional_encoding(g_data.token_positions)\n",
    "#         else:\n",
    "#             xb = g_data.token_embeddings\n",
    "#         x = torch.cat([xa, xb], dim=1)\n",
    "#         # x = torch.cat([graph.x[:g_data.token_embeddings.shape[0]], g_data.token_embeddings], dim=1)\n",
    "        \n",
    "#         x1 = F.relu(self.fc0(graph.x[g_data.token_embeddings.shape[0]:]))\n",
    "#         x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "#         x, edge_weights = self.gcnn2(x, graph.edge_index)\n",
    "\n",
    "#         x = F.elu_(self.fc1(x))\n",
    "#         x1 = scatter_max(x[:len(g_data.token_lengths)], doc_token_index, dim=0)[0]\n",
    "#         x2 = scatter_mean(x[:len(g_data.token_lengths)], doc_token_index, dim=0)\n",
    "#         vn_embs = x[len(g_data.token_lengths):]\n",
    "#         x_for_cat = [x1, x2]\n",
    "#         x_for_cat.extend([vn_embs[i*x1.shape[0]:(i+1)*x1.shape[0]] for i in range(self.virtual_nodes)])\n",
    "#         x = torch.cat(x_for_cat, dim=1)\n",
    "        \n",
    "#         x = F.elu_(self.fc2(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc_out(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "#     def create_positional_encoding(self):\n",
    "#         position = torch.arange(self.pos_emb_size).unsqueeze(1)\n",
    "#         div_term = torch.exp(torch.arange(0, self.hidden_dim, 2) * (-math.log(10000.0) / self.hidden_dim))\n",
    "#         pe = torch.zeros(self.pos_emb_size, self.hidden_dim)\n",
    "#         pe[:, 0::2] = torch.sin(position * div_term)\n",
    "#         pe[:, 1::2] = torch.cos(position * div_term)\n",
    "#         return torch.nn.Parameter(pe, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv, summary\n",
    "\n",
    "class CNN_for_Text_No_Positional_Encoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embedding, pos_emb_size=8192, embedding_dim=64, hidden_dim=64, dropout=0.3, num_out_features=4, seed=-1, random_edges=4, lattice_edges=10, virtual_nodes=1, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64, *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text_No_Positional_Encoding, self).__init__(*args, **kwargs)\n",
    "        self.pos_emb_size = pos_emb_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        # self.use_token_polarity = use_token_polarity\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    " \n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        \n",
    "        # if self.use_token_polarity[0]:\n",
    "        #     self.conv3 = nn.Conv1d(2*hidden_dim + 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        # else:\n",
    "        self.conv3 = nn.Conv1d(2*hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        # if self.use_token_polarity[1]:\n",
    "        self.sentiment1  = Sentiment_Injection(hidden_dim)\n",
    "        # if self.use_token_polarity[2]:\n",
    "        self.sentiment2  = Sentiment_Injection(hidden_dim)\n",
    "            \n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.gcnn2 = GCNN(hidden_dim+inject_embedding_dim)\n",
    "        self.graph_generator = GenGraph(hidden_dim, virtual_nodes, lattice_step)\n",
    "        \n",
    "        k = 4\n",
    "        self.fc0 = nn.Linear(hidden_dim , hidden_dim+inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim+inject_embedding_dim , hidden_dim * k)\n",
    "        self.fc2 = nn.Linear(hidden_dim * (2+virtual_nodes) * k , 32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, num_out_features)\n",
    "        self.max_length = 0\n",
    "    \n",
    "    def forward(self, g_data):\n",
    "            \n",
    "        x = self.embedding(g_data.x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.T\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x1 = scatter_max(x, g_data.cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, g_data.cumulative_token_indices, dim=1)\n",
    "\n",
    "        # if self.use_token_polarity[0]:\n",
    "        #     x = torch.cat([x1, x2, g_data.token_sentiments.T], dim=0)\n",
    "        # else:\n",
    "        x = torch.cat([x1, x2], dim=0)\n",
    "            \n",
    "        x = F.relu(self.conv3(x)).T\n",
    "        \n",
    "        # if self.use_token_polarity[1]:\n",
    "        x = self.sentiment1(x, g_data.token_sentiments)\n",
    "            \n",
    "\n",
    "        rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "            \n",
    "        graph = self.graph_generator.gen_graph(x, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "        rand_edges = rand_edges-1\n",
    "        lattice_edges = lattice_edges-1\n",
    "        \n",
    "        \n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(g_data.num_tokens), device=x.device), g_data.num_tokens)\n",
    "        x, edge_weights = self.gcnn1(graph.x, graph.edge_index, return_attention_weights = True)\n",
    "        edge_weights = edge_weights[1][:graph.edge_index.shape[1], 0]\n",
    "        \n",
    "        graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, graph.edge_index, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        \n",
    "        \n",
    "        # if self.use_token_polarity[2]:\n",
    "        x = self.sentiment2(x, g_data.token_sentiments)\n",
    "            \n",
    "        xa = graph.x[:g_data.token_embeddings.shape[0]]\n",
    "        xb = g_data.token_embeddings\n",
    "        x = torch.cat([xa, xb], dim=1)\n",
    "        # x = torch.cat([graph.x[:g_data.token_embeddings.shape[0]], g_data.token_embeddings], dim=1)\n",
    "        \n",
    "        x1 = F.relu(self.fc0(graph.x[g_data.token_embeddings.shape[0]:]))\n",
    "        x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "        x, edge_weights = self.gcnn2(x, graph.edge_index)\n",
    "\n",
    "        x = F.elu_(self.fc1(x))\n",
    "        x1 = scatter_max(x[:len(g_data.token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(g_data.token_lengths)], doc_token_index, dim=0)\n",
    "        vn_embs = x[len(g_data.token_lengths):]\n",
    "        x_for_cat = [x1, x2]\n",
    "        x_for_cat.extend([vn_embs[i*x1.shape[0]:(i+1)*x1.shape[0]] for i in range(self.virtual_nodes)])\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        \n",
    "        x = F.elu_(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module                                              FLOP    % Total\n",
      "-----------------------------------------------  -------  ---------\n",
      " CNN_for_Text_No_Positional_Encoding.conv1       14.555B     29.08%\n",
      "  - aten.convolution                             14.555B     29.08%\n",
      "CNN_for_Text_No_Positional_Encoding              50.061B    100.00%\n",
      " - aten.convolution                              43.016B     85.93%\n",
      " - aten.addmm                                     7.045B     14.07%\n",
      " CNN_for_Text_No_Positional_Encoding.conv2       14.555B     29.08%\n",
      "  - aten.convolution                             14.555B     29.08%\n",
      " CNN_for_Text_No_Positional_Encoding.conv3        3.248B      6.49%\n",
      "  - aten.convolution                              3.248B      6.49%\n",
      " CNN_for_Text_No_Positional_Encoding.sentiment1   3.299B      6.59%\n",
      "  - aten.convolution                              3.299B      6.59%\n",
      " CNN_for_Text_No_Positional_Encoding.gcnn1        1.353B      2.70%\n",
      "  - aten.addmm                                    0.541B      1.08%\n",
      "  - aten.convolution                              0.812B      1.62%\n",
      " CNN_for_Text_No_Positional_Encoding.sentiment2   3.299B      6.59%\n",
      "  - aten.convolution                              3.299B      6.59%\n",
      " CNN_for_Text_No_Positional_Encoding.fc0          0.000B      0.00%\n",
      "  - aten.addmm                                    0.000B      0.00%\n",
      " CNN_for_Text_No_Positional_Encoding.gcnn2        5.413B     10.81%\n",
      "  - aten.addmm                                    2.165B      4.33%\n",
      "  - aten.convolution                              3.248B      6.49%\n",
      " CNN_for_Text_No_Positional_Encoding.fc1          4.331B      8.65%\n",
      "  - aten.addmm                                    4.331B      8.65%\n",
      " CNN_for_Text_No_Positional_Encoding.fc2          0.007B      0.01%\n",
      "  - aten.addmm                                    0.007B      0.01%\n",
      " CNN_for_Text_No_Positional_Encoding.fc_out       0.000B      0.00%\n",
      "  - aten.addmm                                    0.000B      0.00%\n"
     ]
    }
   ],
   "source": [
    "# for p1 in [False, True]:\n",
    "#     for p2 in [False, True]:\n",
    "#         for p3 in [False, True]:\n",
    "# print(f'\\n{p1}, {p2}, {p3}: \\n')\n",
    "classifier_torch_model = CNN_for_Text_No_Positional_Encoding(num_embedding=num_embedding, hidden_dim=64, embedding_dim=64, pos_emb_size=3080, dropout=0.2, num_out_features=len(class_id), seed=911, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).eval()\n",
    "flopt_counter = FlopCounterMode(classifier_torch_model)\n",
    "with flopt_counter:\n",
    "    classifier_torch_model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(classifier_torch_model.parameters())).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CnnGnnClassifierLightningModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        num_classes,\n",
    "        optimizer=None,\n",
    "        loss_func=None,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=64,\n",
    "        lr_scheduler=None,\n",
    "        user_lr_scheduler=False,\n",
    "        min_lr=0.0,\n",
    "    ):\n",
    "        super(CnnGnnClassifierLightningModel, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.min_lr = min_lr\n",
    "        # self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        self.optimizer = self._get_optimizer(optimizer)\n",
    "        self.lr_scheduler = (\n",
    "            self._get_lr_scheduler(lr_scheduler) if user_lr_scheduler else None\n",
    "        )\n",
    "        self.loss_func = loss_func\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)\n",
    "\n",
    "    def on_train_epoch_start(self) -> None:\n",
    "        param_groups = next(iter(self.optimizer.param_groups))\n",
    "        if \"lr\" in param_groups and param_groups[\"lr\"] is not None:\n",
    "            current_learning_rate = float(param_groups[\"lr\"])\n",
    "            self.log(\n",
    "                \"lr\",\n",
    "                current_learning_rate,\n",
    "                batch_size=self.batch_size,\n",
    "                on_epoch=True,\n",
    "                on_step=False,\n",
    "            )\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.train()\n",
    "        y_out = self(X)\n",
    "\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.train_losses.append(loss.detach().item())\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        self.train_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        y_out = self(X)\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.val_losses.append(loss.detach().item())\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.val_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.lr_scheduler is None:\n",
    "            return self.optimizer\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": self.lr_scheduler,\n",
    "                \"monitor\": \"train_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def update_learning_rate(self, learning_rate: float):\n",
    "        self.learning_rate = learning_rate\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g[\"lr\"] = learning_rate\n",
    "\n",
    "    def _get_optimizer(self, optimizer):\n",
    "        return (\n",
    "            optimizer\n",
    "            if optimizer is not None\n",
    "            else torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        )\n",
    "\n",
    "    def _get_lr_scheduler(self, lr_scheduler):\n",
    "        return (\n",
    "            lr_scheduler\n",
    "            if lr_scheduler is not None\n",
    "            else torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer, patience=5, factor=0.5, mode=\"min\", min_lr=self.min_lr\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import Logger, CSVLogger\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from typing import List\n",
    "from pytorch_lightning.core.saving import save_hparams_to_yaml\n",
    "\n",
    "class ModelManager(ABC):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 max_epochs = 100,\n",
    "                 ckpt_path: str|None=None,\n",
    "                 accumulate_grad_batches=1):\n",
    "        self.torch_model = torch_model\n",
    "        self.lightning_model = lightning_model\n",
    "        self.log_dir = log_dir\n",
    "        self.log_name = log_name\n",
    "        self.model_save_dir = model_save_dir\n",
    "        self.device = device\n",
    "        self.accelerator = 'cpu' if self.device=='cpu' else 'gpu'\n",
    "        self.max_epochs = max_epochs\n",
    "        self.ckpt_path = ckpt_path\n",
    "\n",
    "        self.logger = self._create_logger()\n",
    "        self.callbacks = self._create_callbacks()\n",
    "        self.trainer: L.Trainer = self._create_trainer(accumulate_grad_batches)\n",
    "        self.tuner = Tuner(self.trainer)\n",
    "        self.tuning_result = None\n",
    "\n",
    "    def tune(self, data_manager=None, train_dataloaders=None, val_dataloaders=None, datamodule=None, draw_result=True, min_lr=0.0000001, max_lr=0.1):\n",
    "        self.tuning_result = self.tuner.lr_find(self.lightning_model, datamodule=data_manager, train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders, min_lr=min_lr,max_lr=max_lr, num_training=150)\n",
    "        if draw_result:\n",
    "            fig = self.tuning_result.plot(suggest=True)\n",
    "            fig.show()\n",
    "        self.update_learning_rate(self.tuning_result.suggestion())\n",
    "        return self.tuning_result.suggestion()\n",
    "    \n",
    "    def update_learning_rate(self, lr):\n",
    "        self.lightning_model.update_learning_rate(lr)\n",
    "\n",
    "    def fit(self, train_dataloaders=None, val_dataloaders=None, datamodule=None, max_epochs = -1, ckpt_path=None):\n",
    "        if ckpt_path is not None and ckpt_path != '':\n",
    "            self.ckpt_path = ckpt_path\n",
    "        if max_epochs>0:\n",
    "            self.trainer.fit_loop.max_epochs = max_epochs\n",
    "            # self.max_epochs = max_epochs\n",
    "            # self.trainer = self._create_trainer()\n",
    "        self.trainer.fit(self.lightning_model,\n",
    "                         datamodule=datamodule,\n",
    "                         train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders,\n",
    "                         ckpt_path = self.ckpt_path\n",
    "                         )\n",
    "\n",
    "    def validate(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.validate(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def predict(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.predict(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def _create_trainer(self, accumulate_grad_batches) -> L.Trainer:\n",
    "        return L.Trainer(\n",
    "            callbacks=self.callbacks,\n",
    "            max_epochs=self.max_epochs,\n",
    "            accelerator=self.accelerator,\n",
    "            logger=self.logger,\n",
    "            num_sanity_val_steps=0,\n",
    "            default_root_dir=self.model_save_dir,\n",
    "            accumulate_grad_batches=accumulate_grad_batches\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        pass\n",
    "\n",
    "    def _create_logger(self) -> Logger:\n",
    "        return CSVLogger(save_dir=self.log_dir, name=self.log_name)\n",
    "\n",
    "    @abstractmethod\n",
    "    def draw_summary(self, dataloader):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def plot_csv_logger(self, loss_names, eval_names):\n",
    "        pass\n",
    "    \n",
    "    def save_hyper_parameters(self):\n",
    "        mhparams = {\n",
    "            'start_lr': 0.045,\n",
    "            'ckpt_lrs' :  {51: 0.002, 65: 0.00058},\n",
    "            'last_lr' : 0.0003,\n",
    "            'ac_loss_factor': 0.0002,\n",
    "            'weight_decay': 0.0012\n",
    "        }\n",
    "        save_hparams_to_yaml(config_yaml=r'logs\\hetero_model_17_AG\\version_12\\hparams.yaml',\n",
    "                     hparams=mhparams)\n",
    "        \n",
    "    # def find_best_settings(data_manager,\n",
    "    #                        lrs: List[float]=[0.001], dropouts: List[float]=[0.2], \n",
    "    #                        weight_decays: List[float]=[0.00055], emb_factors: List[float]=[0.1], \n",
    "    #                        batch_sizes: List[int]=[128], log_name='find_best_settings'):\n",
    "    #     for lr in lrs:\n",
    "    #         for dropout in dropouts:\n",
    "    #             for wd in weight_decays:\n",
    "    #                 for emb_factor in emb_factors:\n",
    "    #                     for bs in batch_sizes:\n",
    "    #                         data_manager.update_batch_size(bs)\n",
    "    #                         torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 128, dropout=dropout)\n",
    "    #                         lightning_model = HeteroBinaryLightningModel(torch_model,\n",
    "    #                                         torch.optim.Adam(torch_model.parameters(), lr=lr, weight_decay=wd),\n",
    "    #                                             loss_func=HeteroLoss1(exception_keys='word', enc_factor=emb_factor),\n",
    "    #                                             learning_rate=lr,\n",
    "    #                                             batch_size=bs,\n",
    "    #                                             user_lr_scheduler=True\n",
    "    #                                             ).to(device)\n",
    "    #                         model_manager = ClassifierModelManager(torch_model, lightning_model, log_name=log_name, device=device, num_train_epoch=10)\n",
    "    #                         model_manager.fit(datamodule=data_manager)\n",
    "    #                         model_manager.save_plot_csv_logger(name_prepend=f'{lr}_{dropout}_{wd}_{emb_factor}_{bs}', loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "import torch\n",
    "# from scripts.managers.ModelManager import ModelManager\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from torch_geometric.nn import summary\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from os import path\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "class ClassifierModelManager(ModelManager):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 num_train_epoch = 100,\n",
    "                 accumulate_grad_batches=1):\n",
    "        super(ClassifierModelManager, self).__init__(torch_model, lightning_model, model_save_dir, log_dir, log_name, device, num_train_epoch, accumulate_grad_batches=accumulate_grad_batches)\n",
    "\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        return [\n",
    "            ModelCheckpoint(save_top_k=2, mode='max', monitor='val_acc', save_last=True),\n",
    "            # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "        ]\n",
    "\n",
    "    def draw_summary(self, dataloader):\n",
    "        X, y = next(iter(dataloader))\n",
    "        print(summary(self.torch_model, X.to(self.device)))\n",
    "\n",
    "    def plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    def save_plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc'], name_prepend: str=\"\"):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        \n",
    "        loss_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_loss_metric.png')\n",
    "        plt.savefig(loss_png)\n",
    "        \n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        \n",
    "        acc_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_acc_metric.png')\n",
    "        plt.savefig(acc_png)\n",
    "        \n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate(self, eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.lightning_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        # if(give_hinge_loss):\n",
    "        #     print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')\n",
    "                \n",
    "    def evaluate_best_models(self, lightning_type: L.LightningModule, eval_dataloader,\n",
    "                             give_confusion_matrix: bool=True, \n",
    "                             give_report: bool=True, \n",
    "                             give_f1_score: bool=False, \n",
    "                             give_accuracy_score: bool=False, \n",
    "                             give_precision_score: bool=False, \n",
    "                             give_recall_score: bool=False, \n",
    "                             give_hinge_loss: bool=False,\n",
    "                             multi_class: bool=False, **kwargs):\n",
    "        self.lightning_model = lightning_type.load_from_checkpoint(rf'{self.trainer.checkpoint_callback.best_model_path}', map_location=None, hparams_file=None, strict=True, **kwargs).eval()\n",
    "        self.save_evaluation(eval_dataloader, 'best_model', give_confusion_matrix, give_report,\n",
    "                             give_f1_score, give_accuracy_score, give_precision_score, give_recall_score, give_hinge_loss, multi_class)\n",
    "            \n",
    "    def save_evaluation(self, eval_dataloader, name_prepend: str='',\n",
    "                    give_confusion_matrix: bool=True, \n",
    "                    give_report: bool=True, \n",
    "                    give_f1_score: bool=False, \n",
    "                    give_accuracy_score: bool=False, \n",
    "                    give_precision_score: bool=False, \n",
    "                    give_recall_score: bool=False, \n",
    "                    give_hinge_loss: bool=False,\n",
    "                    multi_class: bool=False\n",
    "                    ):\n",
    "            \n",
    "            test_metrics_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_test_metrics.txt')\n",
    "            \n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            self.lightning_model.eval()\n",
    "            self.lightning_model.model.eval()\n",
    "            self.torch_model.eval()\n",
    "            self.trainer.model.eval()\n",
    "            for X, y in eval_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    y_p = self.lightning_model(X.to(self.device))\n",
    "                if type(y_p) is tuple:\n",
    "                    y_p = y_p[0]\n",
    "                \n",
    "                if multi_class:\n",
    "                    y_pred.append(y_p.detach().to(y.device))\n",
    "                    y_true.append(y)\n",
    "                else:\n",
    "                    y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "                    y_true.append(y.to(torch.int32))\n",
    "                    \n",
    "            y_true = torch.concat(y_true)\n",
    "            y_pred = torch.concat(y_pred)\n",
    "            print(y_true.shape)\n",
    "            print(y_pred.shape)\n",
    "            if multi_class:\n",
    "                y_true_num = torch.argmax(y_true, dim=1)\n",
    "                y_pred_num = torch.argmax(y_pred, dim=1)\n",
    "            else:\n",
    "                y_true_num = y_true\n",
    "                y_pred_num = y_pred\n",
    "                \n",
    "            print(y_true_num.shape)\n",
    "            print(y_pred_num.shape)\n",
    "            with open(test_metrics_path, 'at+') as f:\n",
    "                if(give_confusion_matrix):\n",
    "                    print(f'confusion_matrix: \\n{confusion_matrix(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_report):\n",
    "                    print(classification_report(y_true_num, y_pred_num), file=f)\n",
    "                if(give_f1_score):\n",
    "                    if multi_class:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_accuracy_score):\n",
    "                    print(f'accuracy_score: {accuracy_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_precision_score):\n",
    "                    if multi_class:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_recall_score):\n",
    "                    if multi_class:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num)}', file=f)\n",
    "                # if(give_hinge_loss):\n",
    "                #     print(f'hinge_loss: {hinge_loss(y_true_num, y_pred)}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 128\n",
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "label_size = 1\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_size = 32\n",
    "# hidden_dim = 16\n",
    "# embedding_dim = 16\n",
    "# label_size = 1\n",
    "# seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "def train_model(epochs=30, dropout=0.25, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True, use_positional_encoder=[False, False, False]):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    classifier_torch_model = CNN_for_Text_No_Positional_Encoding(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=4096, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=8, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 40, 45,50,55],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name=f'CNN-GNN_{use_positional_encoder[0]}_{use_positional_encoder[1]}_{use_positional_encoder[2]}',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    train_dataset.reset_params()\n",
    "    train_dataset.position_j = 0\n",
    "    test_dataset.reset_params()\n",
    "    test_dataset.position_j = 0\n",
    "    \n",
    "    # train_dataset.section_i = 0\n",
    "    # train_dataset.each_section_i = np.zeros((train_dataset.num_sections, ), dtype=int)\n",
    "    # test_dataset.section_i = 0\n",
    "    # test_dataset.each_section_i = np.zeros((test_dataset.num_sections, ), dtype=int)\n",
    "    \n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.torch_model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(CnnGnnClassifierLightningModel, test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2342"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                                | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0 | model     | CNN_for_Text_No_Positional_Encoding | 262 K  | train\n",
      "1 | loss_func | BCEWithLogitsLoss                   | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy                  | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy                  | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy                  | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "262 K     Trainable params\n",
      "0         Non-trainable params\n",
      "262 K     Total params\n",
      "1.049     Total estimated model params size (MB)\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f5feef4b15430281e3c4abfcda3d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d7fd914a3c43b7a9522f6846d74ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2666390850a64bf8b5b114e36df73b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0409b82799476f87b5c00a03d0dfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8847b27aca4b85ac9ff4985163676c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a21d712194e465fa34e3b849693e2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfadbb8876943a4bacd92f679967954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb98a62ba534f69bccc0411e777ae51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde7bb06e7ba49ad92372be2fa3be8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf8e1aa33ba4d0b9795d9a1f3c3e07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344a9e2982c046d8b0a9e1bb61f52802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2edae35dd2b4fad89be01032b1b92af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd35b65476d4d10a2d5444c71d861da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efee24494494439a9b571c78a41f1d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ee647f105b4747b757cef6e09c809e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dadc9efc961b477992ed2937865ec3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de791fa0c589499ca939ded516f331e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8385d9f18228427ab0bda1cdcfd42773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de75ebe095d544bca79375fb349002a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d0e4a901944c5fa1f805b518a01607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfdf95f6c534095940b6cdc0d874f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30880bacbe4a48038b88040576a286df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481a18c7c1e049f3a58b6e25ff115827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51a031919494721b990d6ea6fd84e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d151e0506e894eb78b5333e5fc285bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9406a02f0c4b359ff0769eb6d10742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac38b5a3368845c0a880a67bed127835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de53a149e59423085c3a6c3d35f8384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2ad52e400349b2aaed873e635b129f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1d8064bafc47d5bbee940123281c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181652225e3e48968d4f2d3dfb84df1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519da9ae08d54d828732080f97d1b5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b587874f6494676978e9a9af066b562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c130653531e740789b515e8dd42f2d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc94fdd58c74b429dd4dad5f57a3a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a78faa4e244a7f92501eca4cd67c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cffe100d2cec40dc83b3a3f7c74bceeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ce21f06b6f4a44ad516a8be90e26c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52821b3b73334121a24d512c4afc25da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b37502882847e1aeaa059f32dca32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a331a973144977ad4a42f9007f5725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f930aa0c66e64e9483c035f227c8151e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8be775a00c4f5d920f68cdc22bf5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1f970d39c54256a072050b8c0a6216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4ce0c086784010925a28c7c839c436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061b8f60c3be44c0978348a28b59e8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78221ed561a94f33a1739eb6d8a7996d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10cb25f6d694bba987749299f67c654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f28a2065de749d8971395f13a918fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8418963620cf47528a839f7c9ffd0305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57dd2152d93f4339b82e1f1b7e9ca287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c00df622bf9463d978462165d3ffb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09bd89499aa45b4aa5e597805873d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962ab378b2b644ce9ae9d3985b8810d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967f660359b647579109daf56b245b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9419b0bbdde7460384632fc74d4b216c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a79189cc0dc42429495cacf27bcdcaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241f3d6f1a5e444887c38939aed6e8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45336f5950644f36b97f75f544faf294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33982d0e574c4dce8c90150ce639d98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158ba5a4909849c29311f905bbfd1c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3baa8f631c47ecb6de94fb6485824a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868cc6f2544541b1b3e85d4443e5b242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f63718608943e183ca2ed196807f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06ab2d366fe4c57af6b6ac38368c703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c48a7fdd0a9452aab319bc74e037d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c80b25993c4fbba48741e534cd8180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d998a7bb5640d6be4ca1a11aa66cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277aac3aab8b4d74a982e46b17fe250e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95aafa0d6104de7838efc41e6f4f13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0dac6889494a53933be6faef7e4cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=70` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25088, 2])\n",
      "torch.Size([25088, 2])\n",
      "torch.Size([25088])\n",
      "torch.Size([25088])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:13<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9371    0.8616    0.8978     12544\n",
      "           1     0.8719    0.9422    0.9057     12544\n",
      "\n",
      "    accuracy                         0.9019     25088\n",
      "   macro avg     0.9045    0.9019    0.9017     25088\n",
      "weighted avg     0.9045    0.9019    0.9017     25088\n",
      "\n",
      "confusion matrix:\n",
      " tensor([[10808,  1736],\n",
      "        [  725, 11819]])\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25088, 2])\n",
      "torch.Size([25088, 2])\n",
      "torch.Size([25088])\n",
      "torch.Size([25088])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_manager = train_model(70, 0.2, 0.000012, 0.0032, use_positional_encoder=[False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatge_metrics(chpt_path, target_data_loader):\n",
    "        classifier_torch_model = CNN_for_Text_No_Positional_Encoding(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=4096, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=8, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "        classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(chpt_path, model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "        mean_infer_acc = []\n",
    "        mean_infer_f1 = []\n",
    "        mean_infer_prec = []\n",
    "        mean_infer_rec = []\n",
    "        for i in range(5):\n",
    "            all_ys = []\n",
    "            all_y_preds = []\n",
    "            for X, y in target_data_loader:\n",
    "                with torch.no_grad():\n",
    "                    y_pred = classfier_lightning_model(X.to(device))\n",
    "                all_ys.append(torch.argmax(y,dim=1))\n",
    "                all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "            all_ys = torch.concat(all_ys)\n",
    "            all_y_preds = torch.concat(all_y_preds)\n",
    "            \n",
    "            cm = confusion_matrix(all_ys, all_y_preds)\n",
    "            \n",
    "            accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "            precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
    "            recall = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "            f1_score = (2*precision*recall)/(precision + recall)\n",
    "            \n",
    "            mean_infer_acc.append(accuracy)\n",
    "            mean_infer_f1.append(f1_score)\n",
    "            mean_infer_prec.append(precision)\n",
    "            mean_infer_rec.append(recall)\n",
    "        mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "        mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "        mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "        mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "        return mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "def get_best_chpt(metrics_path, epoch_numbers):\n",
    "    epoch_data = pd.read_csv(metrics_path)\n",
    "    if 'val_acc_epoch' in epoch_data.columns and epoch_data['val_acc_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_acc_epoch'].idxmax()]\n",
    "    elif 'val_loss_epoch' in epoch_data.columns and epoch_data['val_loss_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_loss_epoch'].idxmin()]\n",
    "    else:\n",
    "        raise ValueError(f\"No valid validation metrics available for epoch {epoch_numbers}.\")\n",
    "    return np.argwhere(np.array(epoch_numbers)==best_chpt['epoch']).item(), best_chpt['val_loss_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_metrics_mean(base_path = 'logs\\CNN-GNN18_mr2k_seeds'):\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "    total_loss = []\n",
    "    \n",
    "    for i in range(1):\n",
    "        version_path = join(base_path, f'version_{i}')\n",
    "        checkpoint_path = join(version_path, f'checkpoints')\n",
    "        onlyfiles  = [f for f in listdir(checkpoint_path) if (isfile(join(checkpoint_path, f)) and 'epoch' in f) ]\n",
    "        epoch_numbers = [int(re.search(r'\\d+', f).group()) for f in onlyfiles]\n",
    "        best_chpt_id, loss = get_best_chpt(join(version_path, 'metrics.csv'), epoch_numbers)\n",
    "        print(onlyfiles[best_chpt_id])\n",
    "        mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec = calculatge_metrics(join(checkpoint_path, f'{onlyfiles[best_chpt_id]}'), test_dataloader)\n",
    "            \n",
    "        total_accuracy.append(mean_infer_acc)\n",
    "        total_f1.append(mean_infer_f1)\n",
    "        total_prec.append(mean_infer_prec)\n",
    "        total_rec.append(mean_infer_rec)\n",
    "        total_loss.append(loss)\n",
    "\n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    total_loss = torch.mean(torch.tensor(total_loss))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')\n",
    "    print(f'total_loss: {total_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=19-step=2240.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.9084024234693878\n",
      "total_f1: 0.9084767725069568\n",
      "total_prec: 0.9085511339076053\n",
      "total_rec: 0.9084024234693878\n",
      "total_loss: 0.2442921549081802\n"
     ]
    }
   ],
   "source": [
    "calculate_average_metrics_mean(r'logs\\CNN-GNN_False_False_False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization, IntegratedGradients\n",
    "from torch_geometric.nn.models.captum import to_captum_model, CaptumModel\n",
    "from torch_geometric.explain.algorithm import CaptumExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(base_path = 'logs\\CNN-GNN18_mr2k_seeds', version=0):\n",
    "        version_path = join(base_path, f'version_{version}')\n",
    "        checkpoint_path = join(version_path, f'checkpoints')\n",
    "        onlyfiles  = [f for f in listdir(checkpoint_path) if (isfile(join(checkpoint_path, f)) and 'epoch' in f) ]\n",
    "        epoch_numbers = [int(re.search(r'\\d+', f).group()) for f in onlyfiles]\n",
    "        best_chpt_id, loss = get_best_chpt(join(version_path, 'metrics.csv'), epoch_numbers)\n",
    "        chpt_path = join(checkpoint_path, f'{onlyfiles[best_chpt_id]}')\n",
    "        classifier_torch_model = CNN_for_Text_No_Positional_Encoding(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=4096, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=8, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "        classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(chpt_path, model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "        return classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(r'logs\\CNN-GNN_False_False_False', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CaptumModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "captum_model = to_captum_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "lig = LayerIntegratedGradients(model, model.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "captum_exp = CaptumExplainer(IntegratedGradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captum_exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumalate couple samples in this array for visualization purposes\n",
    "\n",
    "def prepare_input_indices(graph, id_char_dict):\n",
    "    \n",
    "    characters = [id_char_dict[i.item()] for i in graph.x]\n",
    "    tokens = ['']*len(graph.token_indices)\n",
    "    for i, j in enumerate(graph.token_indices):\n",
    "        j = j.item()\n",
    "        tokens[j] += id_char_dict[graph.x[i].item()]\n",
    "    ref_graph = deepcopy(graph)\n",
    "    ref_graph.x = torch.ones_like(graph.x) * list(id_char_dict.keys())[-1]\n",
    "\n",
    "    return graph, ref_graph, tokens, characters\n",
    "\n",
    "\n",
    "token_reference = TokenReferenceBase(reference_token_idx=211)\n",
    "vis_data_records_ig = []\n",
    "\n",
    "def interpret_sentence(model, target_dataset, id_char_dict, min_len = 7, label = 0, visualize_on_tokens=False):\n",
    "    graph, label = next(iter(target_dataset))\n",
    "    label = label.argmax().item()\n",
    "    graph.cumulative_token_indices = graph.token_indices\n",
    "\n",
    "    graph, ref_graph, tokens, characters = prepare_input_indices(graph, id_char_dict)\n",
    "    #[tok.text for tok in tokenizer(sentence.lower())]\n",
    "    \n",
    "    graph = Batch.from_data_list([graph])\n",
    "    \n",
    "    model.zero_grad()\n",
    "    # predict\n",
    "    pred = torch.softmax(model.model(graph.to(device)), dim=1).detach()\n",
    "    pred_ind = torch.argmax(pred).item()\n",
    "\n",
    "    seq_length = min_len\n",
    "    # generate reference indices for each sample\n",
    "    reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n",
    "\n",
    "    # compute attributions and approximation delta using layer integrated gradients\n",
    "    attributions_ig, delta = lig.attribute(graph, ref_graph.x, \\\n",
    "                                           n_steps=500, return_convergence_delta=True,\n",
    "                                           target=label)\n",
    "    \n",
    "    captum_exp = CaptumExplainer(IntegratedGradients)\n",
    "\n",
    "    print(f'true: {id_class[label]}({label}), pred: {id_class[pred_ind]}({pred_ind}), max delta: {delta}')\n",
    "    \n",
    "    print(f'text: {tokens}, attributions_ig: {attributions_ig.shape}, label: {label}, delta: {delta}')\n",
    "\n",
    "    \n",
    "    if visualize_on_tokens:\n",
    "        add_attributions_to_visualizer(attributions_ig, tokens, pred[0,pred_ind], pred_ind, label, delta, vis_data_records_ig)\n",
    "    else:\n",
    "        add_attributions_to_visualizer(attributions_ig, characters, pred[0,pred_ind], pred_ind, label, delta, vis_data_records_ig)\n",
    "            \n",
    "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n",
    "    attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.cpu().detach().numpy()\n",
    "\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pred,\n",
    "                            id_class[pred_ind],\n",
    "                            id_class[label],\n",
    "                            id_class[1],\n",
    "                            attributions.sum(),\n",
    "                            text,\n",
    "                            delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "`inputs` must be a torch.Tensor or a tuple[torch.Tensor] but found: <class 'torch_geometric.data.batch.DataBatch'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\CGNet\\FindBestModel\\5_LayersAttributionOnOutput\\with_positional_encoding.ipynb Cell 68\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/5_LayersAttributionOnOutput/with_positional_encoding.ipynb#Y213sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m interpret_sentence(captum_model, test_dataset, vocab_dict_rev, \u001b[39m7\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\CGNet\\FindBestModel\\5_LayersAttributionOnOutput\\with_positional_encoding.ipynb Cell 68\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/5_LayersAttributionOnOutput/with_positional_encoding.ipynb#Y213sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m reference_indices \u001b[39m=\u001b[39m token_reference\u001b[39m.\u001b[39mgenerate_reference(seq_length, device\u001b[39m=\u001b[39mdevice)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/5_LayersAttributionOnOutput/with_positional_encoding.ipynb#Y213sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# compute attributions and approximation delta using layer integrated gradients\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/5_LayersAttributionOnOutput/with_positional_encoding.ipynb#Y213sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m attributions_ig, delta \u001b[39m=\u001b[39m lig\u001b[39m.\u001b[39;49mattribute(graph, ref_graph\u001b[39m.\u001b[39;49mx, \\\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/5_LayersAttributionOnOutput/with_positional_encoding.ipynb#Y213sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                                        n_steps\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, return_convergence_delta\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/5_LayersAttributionOnOutput/with_positional_encoding.ipynb#Y213sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m                                        target\u001b[39m=\u001b[39;49mlabel)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/5_LayersAttributionOnOutput/with_positional_encoding.ipynb#Y213sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrue: \u001b[39m\u001b[39m{\u001b[39;00mid_class[label]\u001b[39m}\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m), pred: \u001b[39m\u001b[39m{\u001b[39;00mid_class[pred_ind]\u001b[39m}\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00mpred_ind\u001b[39m}\u001b[39;00m\u001b[39m), max delta: \u001b[39m\u001b[39m{\u001b[39;00mdelta\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/CGNet/FindBestModel/5_LayersAttributionOnOutput/with_positional_encoding.ipynb#Y213sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtext: \u001b[39m\u001b[39m{\u001b[39;00mtokens\u001b[39m}\u001b[39;00m\u001b[39m, attributions_ig: \u001b[39m\u001b[39m{\u001b[39;00mattributions_ig\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, label: \u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m, delta: \u001b[39m\u001b[39m{\u001b[39;00mdelta\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\captum\\log\\__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\captum\\attr\\_core\\layer\\layer_integrated_gradients.py:355\u001b[0m, in \u001b[0;36mLayerIntegratedGradients.attribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta, attribute_to_layer_input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39m@log_usage\u001b[39m()\n\u001b[0;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mattribute\u001b[39m(\n\u001b[0;32m    164\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m     ],\n\u001b[0;32m    180\u001b[0m ]:\n\u001b[0;32m    181\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[39m    This method attributes the output of the model with given target index\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[39m    (in case it is provided, otherwise it assumes that output is a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39m        >>> attribution = lig.attribute(input, target=3)\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m     inps, baselines \u001b[39m=\u001b[39m _format_input_baseline(inputs, baselines)\n\u001b[0;32m    356\u001b[0m     _validate_input(inps, baselines, n_steps, method)\n\u001b[0;32m    358\u001b[0m     baselines \u001b[39m=\u001b[39m _tensorize_baseline(inps, baselines)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\captum\\attr\\_utils\\common.py:88\u001b[0m, in \u001b[0;36m_format_input_baseline\u001b[1;34m(inputs, baselines)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_format_input_baseline\u001b[39m(\n\u001b[0;32m     86\u001b[0m     inputs: Union[Tensor, Tuple[Tensor, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]], baselines: BaselineType\n\u001b[0;32m     87\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tuple[Tensor, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m], Tuple[Union[Tensor, \u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m], \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]]:\n\u001b[1;32m---> 88\u001b[0m     inputs \u001b[39m=\u001b[39m _format_tensor_into_tuples(inputs)\n\u001b[0;32m     89\u001b[0m     baselines \u001b[39m=\u001b[39m _format_baseline(baselines, inputs)\n\u001b[0;32m     90\u001b[0m     \u001b[39mreturn\u001b[39;00m inputs, baselines\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\captum\\_utils\\common.py:227\u001b[0m, in \u001b[0;36m_format_tensor_into_tuples\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 227\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, torch\u001b[39m.\u001b[39mTensor), (\n\u001b[0;32m    228\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`inputs` must be a torch.Tensor or a tuple[torch.Tensor] \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut found: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(inputs)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m     )\n\u001b[0;32m    231\u001b[0m     inputs \u001b[39m=\u001b[39m (inputs,)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m inputs\n",
      "\u001b[1;31mAssertionError\u001b[0m: `inputs` must be a torch.Tensor or a tuple[torch.Tensor] but found: <class 'torch_geometric.data.batch.DataBatch'>"
     ]
    }
   ],
   "source": [
    "interpret_sentence(captum_model, test_dataset, vocab_dict_rev, 7, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][1].argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = test_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4988], token_positions=[924], character_length=4988, num_tokens=924, token_indices=[4988], token_lengths=[924], token_embeddings=[924, 64], token_sentiments=[924, 2])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([211, 211, 211,  ..., 211, 211, 211])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = test_dataset[0][0]\n",
    "graph.cumulative_token_indices = graph.token_indices\n",
    "graph = Batch.from_data_list([graph])\n",
    "pred = torch.softmax(model(graph.to(device)), dim=1).detach()\n",
    "pred_ind = torch.argmax(pred).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6096, 0.3904]], device='cuda:0')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[326], token_positions=[59], character_length=326, num_tokens=59, token_indices=[326], token_lengths=[59], token_embeddings=[59, 64], token_sentiments=[59, 2])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0)\n",
      "1 tensor(0)\n",
      "2 tensor(0)\n",
      "3 tensor(0)\n",
      "4 tensor(0)\n",
      "5 tensor(0)\n",
      "6 tensor(1)\n",
      "7 tensor(1)\n",
      "8 tensor(1)\n",
      "9 tensor(1)\n",
      "10 tensor(1)\n",
      "11 tensor(1)\n",
      "12 tensor(1)\n",
      "13 tensor(2)\n",
      "14 tensor(2)\n",
      "15 tensor(2)\n",
      "16 tensor(2)\n",
      "17 tensor(2)\n",
      "18 tensor(2)\n",
      "19 tensor(2)\n",
      "20 tensor(3)\n",
      "21 tensor(3)\n",
      "22 tensor(3)\n",
      "23 tensor(3)\n",
      "24 tensor(3)\n",
      "25 tensor(4)\n",
      "26 tensor(4)\n",
      "27 tensor(4)\n",
      "28 tensor(4)\n",
      "29 tensor(4)\n",
      "30 tensor(4)\n",
      "31 tensor(5)\n",
      "32 tensor(5)\n",
      "33 tensor(5)\n",
      "34 tensor(5)\n",
      "35 tensor(5)\n",
      "36 tensor(5)\n",
      "37 tensor(6)\n",
      "38 tensor(6)\n",
      "39 tensor(6)\n",
      "40 tensor(6)\n",
      "41 tensor(6)\n",
      "42 tensor(6)\n",
      "43 tensor(6)\n",
      "44 tensor(7)\n",
      "45 tensor(7)\n",
      "46 tensor(7)\n",
      "47 tensor(7)\n",
      "48 tensor(7)\n",
      "49 tensor(8)\n",
      "50 tensor(8)\n",
      "51 tensor(8)\n",
      "52 tensor(8)\n",
      "53 tensor(8)\n",
      "54 tensor(9)\n",
      "55 tensor(9)\n",
      "56 tensor(9)\n",
      "57 tensor(9)\n",
      "58 tensor(9)\n",
      "59 tensor(9)\n",
      "60 tensor(10)\n",
      "61 tensor(10)\n",
      "62 tensor(10)\n",
      "63 tensor(11)\n",
      "64 tensor(11)\n",
      "65 tensor(11)\n",
      "66 tensor(11)\n",
      "67 tensor(11)\n",
      "68 tensor(11)\n",
      "69 tensor(12)\n",
      "70 tensor(12)\n",
      "71 tensor(13)\n",
      "72 tensor(13)\n",
      "73 tensor(13)\n",
      "74 tensor(13)\n",
      "75 tensor(13)\n",
      "76 tensor(14)\n",
      "77 tensor(14)\n",
      "78 tensor(14)\n",
      "79 tensor(14)\n",
      "80 tensor(15)\n",
      "81 tensor(15)\n",
      "82 tensor(15)\n",
      "83 tensor(15)\n",
      "84 tensor(15)\n",
      "85 tensor(16)\n",
      "86 tensor(16)\n",
      "87 tensor(16)\n",
      "88 tensor(16)\n",
      "89 tensor(16)\n",
      "90 tensor(17)\n",
      "91 tensor(17)\n",
      "92 tensor(17)\n",
      "93 tensor(17)\n",
      "94 tensor(17)\n",
      "95 tensor(17)\n",
      "96 tensor(17)\n",
      "97 tensor(17)\n",
      "98 tensor(18)\n",
      "99 tensor(18)\n",
      "100 tensor(18)\n",
      "101 tensor(19)\n",
      "102 tensor(19)\n",
      "103 tensor(20)\n",
      "104 tensor(20)\n",
      "105 tensor(20)\n",
      "106 tensor(21)\n",
      "107 tensor(21)\n",
      "108 tensor(21)\n",
      "109 tensor(21)\n",
      "110 tensor(21)\n",
      "111 tensor(21)\n",
      "112 tensor(22)\n",
      "113 tensor(22)\n",
      "114 tensor(22)\n",
      "115 tensor(22)\n",
      "116 tensor(22)\n",
      "117 tensor(22)\n",
      "118 tensor(22)\n",
      "119 tensor(22)\n",
      "120 tensor(23)\n",
      "121 tensor(23)\n",
      "122 tensor(23)\n",
      "123 tensor(23)\n",
      "124 tensor(23)\n",
      "125 tensor(24)\n",
      "126 tensor(24)\n",
      "127 tensor(24)\n",
      "128 tensor(24)\n",
      "129 tensor(25)\n",
      "130 tensor(25)\n",
      "131 tensor(26)\n",
      "132 tensor(26)\n",
      "133 tensor(26)\n",
      "134 tensor(26)\n",
      "135 tensor(27)\n",
      "136 tensor(27)\n",
      "137 tensor(28)\n",
      "138 tensor(28)\n",
      "139 tensor(29)\n",
      "140 tensor(29)\n",
      "141 tensor(29)\n",
      "142 tensor(29)\n",
      "143 tensor(29)\n",
      "144 tensor(29)\n",
      "145 tensor(30)\n",
      "146 tensor(30)\n",
      "147 tensor(30)\n",
      "148 tensor(30)\n",
      "149 tensor(30)\n",
      "150 tensor(30)\n",
      "151 tensor(31)\n",
      "152 tensor(31)\n",
      "153 tensor(31)\n",
      "154 tensor(31)\n",
      "155 tensor(32)\n",
      "156 tensor(32)\n",
      "157 tensor(32)\n",
      "158 tensor(32)\n",
      "159 tensor(32)\n",
      "160 tensor(32)\n",
      "161 tensor(32)\n",
      "162 tensor(33)\n",
      "163 tensor(33)\n",
      "164 tensor(33)\n",
      "165 tensor(33)\n",
      "166 tensor(34)\n",
      "167 tensor(34)\n",
      "168 tensor(34)\n",
      "169 tensor(35)\n",
      "170 tensor(35)\n",
      "171 tensor(35)\n",
      "172 tensor(35)\n",
      "173 tensor(35)\n",
      "174 tensor(35)\n",
      "175 tensor(35)\n",
      "176 tensor(36)\n",
      "177 tensor(36)\n",
      "178 tensor(36)\n",
      "179 tensor(36)\n",
      "180 tensor(36)\n",
      "181 tensor(36)\n",
      "182 tensor(36)\n",
      "183 tensor(37)\n",
      "184 tensor(37)\n",
      "185 tensor(37)\n",
      "186 tensor(37)\n",
      "187 tensor(37)\n",
      "188 tensor(37)\n",
      "189 tensor(38)\n",
      "190 tensor(38)\n",
      "191 tensor(38)\n",
      "192 tensor(38)\n",
      "193 tensor(38)\n",
      "194 tensor(38)\n",
      "195 tensor(39)\n",
      "196 tensor(39)\n",
      "197 tensor(39)\n",
      "198 tensor(39)\n",
      "199 tensor(39)\n",
      "200 tensor(40)\n",
      "201 tensor(40)\n",
      "202 tensor(40)\n",
      "203 tensor(40)\n",
      "204 tensor(40)\n",
      "205 tensor(40)\n",
      "206 tensor(41)\n",
      "207 tensor(41)\n",
      "208 tensor(41)\n",
      "209 tensor(41)\n",
      "210 tensor(41)\n",
      "211 tensor(41)\n",
      "212 tensor(41)\n",
      "213 tensor(41)\n",
      "214 tensor(42)\n",
      "215 tensor(42)\n",
      "216 tensor(43)\n",
      "217 tensor(43)\n",
      "218 tensor(43)\n",
      "219 tensor(43)\n",
      "220 tensor(43)\n",
      "221 tensor(43)\n",
      "222 tensor(44)\n",
      "223 tensor(44)\n",
      "224 tensor(45)\n",
      "225 tensor(45)\n",
      "226 tensor(46)\n",
      "227 tensor(46)\n",
      "228 tensor(47)\n",
      "229 tensor(47)\n",
      "230 tensor(47)\n",
      "231 tensor(48)\n",
      "232 tensor(48)\n",
      "233 tensor(48)\n",
      "234 tensor(48)\n",
      "235 tensor(48)\n",
      "236 tensor(48)\n",
      "237 tensor(48)\n",
      "238 tensor(48)\n",
      "239 tensor(48)\n",
      "240 tensor(49)\n",
      "241 tensor(49)\n",
      "242 tensor(49)\n",
      "243 tensor(49)\n",
      "244 tensor(49)\n",
      "245 tensor(49)\n",
      "246 tensor(49)\n",
      "247 tensor(49)\n",
      "248 tensor(50)\n",
      "249 tensor(50)\n",
      "250 tensor(50)\n",
      "251 tensor(50)\n",
      "252 tensor(50)\n",
      "253 tensor(50)\n",
      "254 tensor(50)\n",
      "255 tensor(51)\n",
      "256 tensor(51)\n",
      "257 tensor(51)\n",
      "258 tensor(51)\n",
      "259 tensor(52)\n",
      "260 tensor(52)\n",
      "261 tensor(53)\n",
      "262 tensor(53)\n",
      "263 tensor(53)\n",
      "264 tensor(53)\n",
      "265 tensor(53)\n",
      "266 tensor(54)\n",
      "267 tensor(54)\n",
      "268 tensor(54)\n",
      "269 tensor(54)\n",
      "270 tensor(54)\n",
      "271 tensor(55)\n",
      "272 tensor(55)\n",
      "273 tensor(55)\n",
      "274 tensor(55)\n",
      "275 tensor(55)\n",
      "276 tensor(55)\n",
      "277 tensor(55)\n",
      "278 tensor(56)\n",
      "279 tensor(56)\n",
      "280 tensor(57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"▁This ▁movie ▁makes ▁you ▁wish ▁imdb ▁would ▁let ▁you ▁vote ▁a ▁zero . ▁One ▁of ▁the ▁two ▁movies ▁I ' ve ▁ever ▁walked ▁out ▁of . ▁It ' s ▁very ▁hard ▁to ▁think ▁of ▁a ▁worse ▁movie ▁with ▁such ▁big ▁name ▁actors . ▁Well . . . Ar mageddon ▁almost ▁takes ▁it , ▁but ▁not ▁quite . \\x01\""
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = test_dataset[0][0]\n",
    "tokens = ['']*len(graph.token_indices)\n",
    "for i, j in enumerate(graph.token_indices):\n",
    "    print(i, j)\n",
    "    j = j.item()\n",
    "    tokens[j] += vocab_dict_rev[graph.x[i].item()]\n",
    "''.join(tokens)\n",
    "# test_dataset[0][0].x\n",
    "# test_dataset[0][0].token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([157,  56, 129,  ..., 141,  70, 211])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁When ▁the ▁Romulan s ▁come , ▁they ▁will ▁not ▁be ▁bearing ▁gifts ; ▁no , ▁they ▁bring ▁with ▁them ▁war ▁- ▁war ▁and ▁conquest . ▁As ▁any ▁familiar ▁with ▁this ▁episode ▁know , ▁it ▁is ▁a ▁red ux ▁of ▁the ▁war ▁film ▁\" The ▁Enemy ▁Below \" ▁from ▁the ▁fifties . ▁The ▁obvious ▁difference ▁is ▁that ▁instead ▁of ▁a ▁battleship ▁and ▁a ▁submarine ▁( or ▁an ▁American ▁Destroyer ▁& ▁German ▁U - boat ) ▁engaged ▁in ▁lethal ▁war ▁games , ▁it ▁is ▁two ▁starship s ▁in ▁outer ▁space . ▁In ▁Trek ▁history , ▁about ▁100 ▁years ▁before ▁the ▁events ▁here , ▁according ▁to ▁this ▁episode , ▁Earth ▁fought ▁the ▁Romulan ▁Wars . ▁After ▁about ▁5 ▁years ▁of ▁conflict , ▁a ▁stalemate ▁brought ▁about ▁a ▁treaty ▁and ▁the ▁institution ▁of ▁the ▁Neutral ▁Zone , ▁a ▁boundary ▁between ▁us ▁and ▁the ▁Romulan ▁Empire . ▁Now , ▁on ▁this ▁star date , ▁the ▁treaty ▁appears ▁to ▁be ▁broken , ▁as ▁our ▁outposts ▁are ▁being ▁attacked ▁and ▁destroyed ▁by ▁some ▁weapon ▁of ▁immense ▁power . ▁Yes , ▁the ▁Romulan s ▁are ▁back , ▁testing ▁their ▁new ▁war ▁toy , ▁and ▁Kirk ▁must ▁now ▁earn ▁his ▁pay : ▁he ▁must ▁make ▁decisions ▁that ▁would ▁affect ▁this ▁sector ▁of ▁the ▁galaxy , ▁such ▁as ▁figuring ▁out ▁how ▁to ▁avoid ▁a . . . oh , ▁I ▁dunno ▁- ▁an ▁interstellar ▁war , ▁maybe ? ▁< br ▁/ > < br ▁/ > I ▁think ▁what ▁makes ▁this ▁episode ▁so ▁effective ▁is ▁that ▁it ▁doesn \\' t ▁shy ▁away ▁from ▁the ▁grim ▁aspects ▁of ▁war , ▁as ▁one ▁would ▁expect ▁of ▁a ▁mere ▁TV ▁episode ▁from ▁the ▁sixties ▁- ▁especially ▁an ▁episode ▁from ▁a ▁science ▁fiction ▁show . ▁It \\' s ▁all ▁very ▁tense ▁and ▁gripping , ▁like ▁the ▁best ▁war ▁films , ▁such ▁as ▁when ▁Kirk ▁sits ▁down ▁with ▁his ▁key ▁officers ▁for ▁what ▁amounts ▁to ▁a ▁war ▁council . ▁The ▁writers ▁and ▁the ▁actors ▁aren \\' t ▁kidding ▁around ▁here : ▁this ▁is ▁all ▁preparation ▁for ▁a ▁ghastly ▁conflict , ▁potentially ▁the ▁beginning ▁of ▁another ▁years - long ▁battleground . ▁In ▁the ▁final ▁analysis , ▁Kirk \\' s ▁aim ▁is ▁to ▁keep ▁this ▁battleground ▁to ▁just ▁the ▁two ▁ships ▁- ▁but ▁even ▁then ▁it \\' s ▁an ▁endeavor ▁fraught ▁with ▁peril ▁and ▁probable ▁casualties . ▁In ▁fact , ▁I ▁believe ▁this ▁episode ▁holds ▁the ▁record ▁for ▁ship ▁casualties ▁by ▁the ▁end ▁of ▁it . ▁Right ▁at ▁the ▁start ▁of ▁the ▁episode , ▁we ▁see ▁the ▁devastation ▁such ▁battle ▁can ▁produce , ▁in ▁that ▁supposedly ▁well - protected ▁outpost . ▁Then ▁begin ▁the ▁cat - and - mouse ▁war ▁games ▁between ▁the ▁Enterprise ▁and ▁the ▁Romulan ▁ship ▁- ▁it \\' s ▁as ▁exciting ▁as ▁any ▁conflict ▁we \\' ve ▁seen ▁on ▁the ▁big ▁screen . ▁Of ▁course , ▁if ▁you \\' re ▁not ▁into ▁war ▁films , ▁you \\' d ▁have ▁to ▁look ▁for ▁other ▁things ▁to ▁admire ▁in ▁this ▁episode . < br ▁/ > < br ▁/ > What ▁elevates ▁this ▁episode ▁even ▁further ▁is ▁the ▁revelation ▁of ▁just ▁what ▁and ▁who ▁the ▁Romulan s ▁are ▁- ▁it \\' s ▁an ▁electric ▁shock ▁of ▁a ▁sort . ▁Now ▁we ▁have ▁even ▁further ▁inter - crew ▁conflict ▁on ▁the ▁bridge ▁of ▁the ▁Enterprise ▁- ▁war ▁does ▁tend ▁to ▁bring ▁out ▁the ▁worst ▁in ▁some ▁people . ▁Due ▁to ▁still ▁nasty ▁attitudes ▁about ▁race ▁in ▁this ▁future , ▁the ▁tension ▁is ▁ratcheted ▁up ▁even ▁further ▁- ▁Kirk ▁has ▁his ▁hands ▁full ▁in ▁this ▁one . ▁I ▁suppose ▁the ▁one ▁weakness ▁in ▁the ▁story ▁is ▁the ▁convenient ▁relent ing ▁of ▁the ▁bigotry ▁issue ▁by ▁the ▁conclusion . ▁On ▁the ▁Romulan ▁side , ▁actor ▁Lena rd ▁makes ▁his ▁first ▁appearance ▁in ▁the ▁Trek ▁universe ▁as ▁the ▁Romulan ▁commander ; ▁he \\' s ▁terrific ▁in ▁the ▁role , ▁the ▁flip ▁side ▁of ▁Capt . ▁Kirk ▁or ▁Capt . ▁Pike , ▁take ▁your ▁pick , ▁done ▁up ▁to ▁resemble ▁Spock ▁more ▁than ▁a ▁little . ▁Surprisingly , ▁his ▁character ▁is ▁not ▁war ▁hungry ▁as ▁we ▁would ▁expect , ▁another ▁eye - opener ▁for ▁this ▁episode . ▁The ▁actor ▁would ▁next ▁return ▁to ▁this ▁universe ▁as ▁S arek , ▁Spock \\' s ▁father , ▁so ▁he \\' s ▁nothing ▁if ▁not ▁versatile . ▁It \\' s ▁also ▁telling ▁how ▁the ▁first ▁appearance ▁of ▁such ▁characters ▁as ▁the ▁Romulan s ▁is ▁usually ▁their ▁best ▁shot , ▁as ▁it ▁is ▁here . ▁They ▁showed ▁up ▁in ▁\" The ▁Enterprise ▁Incident \" ▁next . \\x01'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([vocab_dict_rev[i.item()] for i in test_dataset[0][0].x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
