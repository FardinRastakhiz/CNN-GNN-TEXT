{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification Using Proposed CNN-GNN on IMDB binary dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Results:\n",
    "| metric | test 1 | test 2 | test 3 | test 4 | test 5 | Average |\n",
    "|:---|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| f1-score | 9039 | 9041 | 9015 | 9051 | 9050 | 9039 |\n",
    "| accuracy | 9038 | 9040 | 9015 | 9051 | 9042 | 9037 |\n",
    "| precision | 9040 | 9041 | 9015 | 9051 | 9058 | 9041 |\n",
    "| recall | 9038 | 9040 | 9015 | 9051 | 9042 | 9037 |\n",
    "| loss | 0.2738 | 0.2721 | 0.2597 | 0.2865 | 0.2947 | 0.2774 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_lg_reduced_embeddings = r'C:\\Users\\fardin\\Projects\\CGNet\\Data\\ReducedEmbeddings\\spacy_lg_reduced_embeddings.npy'\n",
    "imdb_data = r'C:\\Users\\fardin\\Projects\\CGNet\\Data\\TextClassification\\IMDB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch_scatter import scatter_max, scatter_mean, scatter_sum, scatter_std\n",
    "import torchmetrics\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from copy import copy\n",
    "import spacy\n",
    "from umap import UMAP\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import PyPDF2\n",
    "from bs4 import BeautifulSoup\n",
    "# import textract\n",
    "import json\n",
    "import gzip\n",
    "import re\n",
    "import collections\n",
    "import csv\n",
    "import string\n",
    "import textwrap\n",
    "import random\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "771064"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(spacy_lg_reduced_embeddings, 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "nlp = spacy.load('en_core_web_lg', disable=['tok2vec','tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
    "t_tokenizer = TweetTokenizer()\n",
    "nlp.max_length = len(' '.join(list(nlp.vocab.strings)))+1\n",
    "all_vocab_doc = nlp(' '.join(list(nlp.vocab.strings)))\n",
    "all_vocab_str = [f'{t}' for t in all_vocab_doc]\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "embeddings = (embeddings - torch.min(embeddings)) / (torch.max(embeddings)-torch.min(embeddings))\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))\n",
    "token_vocab_dict['<n>'] = token_vocab_dict['newline']\n",
    "len(token_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 128\n",
    "folder_path = imdb_data\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(fr'{imdb_data}\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I have seen this movie twice and it's theme is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I happened to catch this on community TV a few...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  I have seen this movie twice and it's theme is...\n",
       "1      1  I happened to catch this on community TV a few..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_ratio = 1.0\n",
    "test_df = pd.read_csv(fr'{imdb_data}\\test.csv')\n",
    "test_df['Topic'] = test_df['label']\n",
    "test_df['Content'] = test_df['text']\n",
    "test_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df = test_df.iloc[:int(keep_ratio*test_df.shape[0])]\n",
    "train_df = pd.read_csv(fr'{imdb_data}\\train.csv')\n",
    "train_df['Topic'] = train_df['label']\n",
    "train_df['Content'] = train_df['text']\n",
    "train_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df = train_df.iloc[:int(keep_ratio*train_df.shape[0])]\n",
    "sst_classes = [\"Negative\", \"Positive\"]\n",
    "df = pd.concat([train_df, test_df])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2901"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = np.array([len(t_tokenizer.tokenize(doc)) for doc in df['Content'].values])\n",
    "np.max(lengths)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = df.Topic.unique()\n",
    "class_id = {sst_classes[i]:i for i in class_list}\n",
    "id_class = {i:sst_classes[i] for i in class_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = set()\n",
    "for doc in df.Content.values:\n",
    "    char_set.update(set(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' '\n",
    "all_chars = set(allowed_chars).update(char_set)\n",
    "vocab_dict = {c:i for i, c in enumerate(allowed_chars)}\n",
    "if '\\x01' not in vocab_dict:\n",
    "    vocab_dict['\\x01'] = len(vocab_dict)\n",
    "char_Set = set(vocab_dict.keys())\n",
    "num_embedding = len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterandTokenLevelCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, num_classes, char_dict, token_dict, tokenizer) -> None:\n",
    "        super().__init__()\n",
    "        # y = y[indices].values\n",
    "        # y = torch.from_numpy(np.array([class_id[c] for c in y], dtype=np.longlong))\n",
    "        y = torch.from_numpy(y)\n",
    "        self.y = torch.nn.functional.one_hot(y, num_classes=num_classes).float()\n",
    "        \n",
    "        self.char_dict = char_dict\n",
    "        self.char_Set = set(char_dict.keys())\n",
    "        self.vocab_size = len(self.char_dict)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_dict = token_dict\n",
    "        self.max_token_count = 0\n",
    "        \n",
    "        self.all_data = []\n",
    "        \n",
    "        self.token_lengths = []\n",
    "        \n",
    "        self.token_embeddign_ids = []\n",
    "        for doc in tqdm(X):\n",
    "            tokens = self.tokenizer(''.join(c for c in doc if c in self.char_Set))\n",
    "            tokens = [t.text for t in tokens]\n",
    "            if len(tokens) == 0:\n",
    "                tokens = ['empty']\n",
    "                            \n",
    "            token_lengths = [len(t) for t in tokens]\n",
    "            tokens.append('\\x01')\n",
    "            \n",
    "            token_lengths.append(len(tokens[-1])-1)\n",
    "            token_lengths = torch.from_numpy(np.array(token_lengths, dtype=np.longlong))+1\n",
    "            token_embs = [self.token_dict[t] if t in self.token_dict else torch.zeros((64, ), dtype=torch.float32) for t in tokens]\n",
    "            token_embs = torch.from_numpy(np.array(token_embs, dtype=np.float32))\n",
    "            doc = ' '.join(tokens)\n",
    "            characters = torch.from_numpy(np.array([self.char_dict[t] for t in doc], dtype=np.longlong))\n",
    "            token_positions = torch.arange(len(token_lengths), dtype=torch.long)\n",
    "            token_indices = torch.repeat_interleave(token_positions, token_lengths)\n",
    "            num_tokens = len(token_lengths)\n",
    "            if num_tokens > self.max_token_count:\n",
    "                self.max_token_count = num_tokens\n",
    "            g_data = Data(x=characters,\n",
    "                            token_positions=token_positions,\n",
    "                            character_length = len(characters),\n",
    "                            num_tokens = num_tokens,\n",
    "                            token_indices=token_indices,\n",
    "                            token_lengths=token_lengths,\n",
    "                            token_embeddings=token_embs)\n",
    "            self.all_data.append(g_data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.all_data[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CharacterandTokenLevelDataLoader(DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        follow_batch: List[str] | None = None,\n",
    "        exclude_keys: List[str] | None = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CharacterandTokenLevelDataLoader, self).__init__(\n",
    "            dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        base_iterator = super(CharacterandTokenLevelDataLoader, self).__iter__()\n",
    "        for batch in base_iterator:\n",
    "            cumsum_vals = torch.cumsum(batch[0].num_tokens, dim=0).roll(1)\n",
    "            cumsum_vals[0] = 0\n",
    "            additions = torch.repeat_interleave(cumsum_vals, batch[0].character_length)\n",
    "            batch[0].cumulative_token_indices = batch[0].token_indices + additions\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 25000/25000 [03:12<00:00, 129.71it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 25000/25000 [02:40<00:00, 155.45it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CharacterandTokenLevelCustomDataset(train_df.Content.values, train_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, nlp)\n",
    "test_dataset = CharacterandTokenLevelCustomDataset(test_df.Content.values, test_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, nlp)\n",
    "max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[2958], token_positions=[626], character_length=2958, num_tokens=626, token_indices=[2958], token_lengths=[626], token_embeddings=[626, 64]),\n",
       " tensor([1., 0.]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv\n",
    "\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, *args, **kwargs):\n",
    "        super(GCNN, self).__init__(*args, **kwargs)\n",
    "        # self.hidden_dim = hidden_dim\n",
    "        self.gnn = GATv2Conv(hidden_dim, hidden_dim//8, heads=4)\n",
    "        # self.gnn = SimpleConv(aggr='mean')\n",
    "        self.conv = nn.Conv1d(hidden_dim, hidden_dim//2, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        # self.out_fc = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim//2)\n",
    "        # self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        # self.bn4 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, graph, total_token_count, return_attention_weights = False):\n",
    "        x1, edge_weights = self.gnn(x, graph.edge_index, return_attention_weights=return_attention_weights) \n",
    "        x2 = F.relu(self.conv(x[:total_token_count].T).T)#self.bn2(self.conv(x[:total_token_count].T).T))\n",
    "        x3 =  F.leaky_relu_(self.bn3(self.fc(x1[total_token_count:])))\n",
    "        x1 = F.leaky_relu_(self.bn1(x1[:total_token_count]))\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = torch.cat([x, x3], dim=0)\n",
    "        # x = self.bn4(x)\n",
    "        return x, edge_weights #F.leaky_relu_(self.bn4(self.out_fc(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, to_undirected\n",
    "\n",
    "class GenGraph(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, virtual_nodes, lattice_step, *args, **kwargs):\n",
    "        super(GenGraph, self).__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.lattice_step = lattice_step\n",
    "        self.virtual_node_embeddings = nn.Embedding(self.virtual_nodes, hidden_dim)\n",
    "        \n",
    "    def gen_graph(self, x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        edge_index = torch.empty((2, base_numel + v_n_e_counts*2), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "            \n",
    "        if self.virtual_nodes > 0:\n",
    "            virtual_nodes_range = torch.arange(self.virtual_nodes, device=x.device).view(1, -1)\n",
    "            virtual_nodes_ids = torch.repeat_interleave(virtual_nodes_range, len(token_counts), dim=0)\n",
    "            v_n_idx = (virtual_nodes_ids + torch.arange(0, len(token_counts)*self.virtual_nodes, self.virtual_nodes, device=x.device).view(-1, 1) + total_token_coutns )\n",
    "            virtual_edge_ids = torch.repeat_interleave(v_n_idx.view(-1), token_counts.view(-1, 1).expand(len(token_counts), self.virtual_nodes).reshape(-1), dim=0).view(1, -1)\n",
    "            \n",
    "            embs = self.virtual_node_embeddings(virtual_nodes_ids.T).view(-1, self.hidden_dim)\n",
    "            x_extended = torch.cat([x, embs], dim=0)\n",
    "            x_index = torch.arange(total_token_coutns, device=x.device).repeat(self.virtual_nodes).view(1, -1)\n",
    "            edge_index[:, base_numel:base_numel+v_n_e_counts] = torch.cat([x_index, virtual_edge_ids], dim=0)\n",
    "            edge_index[:, base_numel+v_n_e_counts:] = torch.cat([virtual_edge_ids, x_index], dim=0)\n",
    "            x = x_extended\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "        \n",
    "    def re_gen_graph(self, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        self.fill_lattice_and_random_edges(edge_index, random_links, lattice_links, tc_range)\n",
    "        # for i in range(base.shape[1]):\n",
    "        #     edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "            \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "    \n",
    "    def replace_unimportant_edges(self, edge_weights, x, edge_index, total_token_coutns, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2):\n",
    "        v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "        if v_n_e_counts>0:\n",
    "            important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        else:\n",
    "            important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "\n",
    "        important_indices = torch.arange(total_token_coutns, dtype=torch.int64, device=x.device) + important_indices*total_token_coutns\n",
    "        important_indices = important_indices.view(-1)\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "        new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_index[:, important_indices]\n",
    "        if(self.virtual_nodes>0):\n",
    "            new_edge_index[:, -2*v_n_e_counts:] = edge_index[:, -2*v_n_e_counts:]\n",
    "            \n",
    "        # for i in range(base.shape[1]):\n",
    "        #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "         \n",
    "    def calculate_graph(self, x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance):\n",
    "        tc_extended = torch.repeat_interleave(token_counts, token_counts, dim=0).view(-1,1)\n",
    "        tc_lower_bound = torch.empty((len(token_counts)+1), dtype=torch.long, device=x.device) #torch.cuda.IntTensor(len(token_counts)+1) #\n",
    "        tc_lower_bound[0] = 0\n",
    "        tc_lower_bound[1:] = torch.cumsum(token_counts, dim=0)\n",
    "        tc_lower_bound_extended = torch.repeat_interleave(tc_lower_bound[:-1], token_counts, dim=0).view(-1,1)\n",
    "        tc_range = torch.arange(tc_lower_bound[-1], device=x.device).view(-1,1)\n",
    "        # torch.arange(tc_lower_bound[-1], dtype=torch.int32, device=x.device).view(-1,1)\n",
    "        random_ints = torch.randint(0, 2*total_token_coutns, (total_token_coutns, random_edges), device=x.device) # torch.cuda.IntTensor(len(token_lengths), random_edges).random_()\n",
    "        lattice = torch.arange(lattice_start_distance, self.lattice_step*lattice_edges+1, self.lattice_step, device=x.device).view(1, -1)\n",
    "\n",
    "        # exponentials = torch.pow(2, torch.arange(1, self.exp_edges+1, device=x.device)).view(1, -1)\n",
    "        tc_local_range = tc_range - tc_lower_bound_extended\n",
    "        random_links = (((random_ints % (tc_extended - 1))+1 + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        lattice_links = ((lattice + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        # base = torch.cat([base1, base2], dim=1)\n",
    "        tc_range = tc_range.view(1,-1)\n",
    "        return random_links, lattice_links, tc_range\n",
    "    \n",
    "    def fill_lattice_and_random_edges(self, edge_index, random_links, lattice_links, tc_range):\n",
    "        for i in range(0, lattice_links.shape[1]*2, 2):\n",
    "            edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]] = torch.cat([lattice_links[:,i//2].view(1,-1), tc_range], dim=0)\n",
    "            edge_index[:, (i+1)*lattice_links.shape[0]:(i+2)*lattice_links.shape[0]] = edge_index[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]][[1, 0]]\n",
    "            \n",
    "        for i in range(random_links.shape[1]):\n",
    "            j = i + lattice_links.shape[1]*2\n",
    "            edge_index[:, j*random_links.shape[0]:(j+1)*random_links.shape[0]] = torch.cat([random_links[:,i].view(1,-1), tc_range], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv, summary\n",
    "\n",
    "class CNN_for_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embedding, pos_emb_size=8192, embedding_dim=64, hidden_dim=64, dropout=0.3, num_out_features=4, seed=-1, random_edges=4, lattice_edges=10, virtual_nodes=1, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64, *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text, self).__init__(*args, **kwargs)\n",
    "        self.pos_emb_size = pos_emb_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    " \n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.positional_encoding = nn.Embedding(pos_emb_size, embedding_dim)\n",
    "        self.positional_encoding.weight = self.create_positional_encoding()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(2*hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.gcnn2 = GCNN(hidden_dim + inject_embedding_dim)\n",
    "        self.graph_generator = GenGraph(hidden_dim, virtual_nodes, lattice_step)\n",
    "        \n",
    "        k = 4\n",
    "        self.fc0 = nn.Linear(hidden_dim , hidden_dim + inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim + inject_embedding_dim , hidden_dim * k)\n",
    "        self.fc2 = nn.Linear(hidden_dim * (2+virtual_nodes) * k , 32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, num_out_features)\n",
    "        self.max_length = 0\n",
    "    \n",
    "    def forward(self, g_data):\n",
    "        self.max_length = max(self.max_length, len(g_data.x))\n",
    "            \n",
    "        x = self.embedding(g_data.x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.T\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x1 = scatter_max(x, g_data.cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, g_data.cumulative_token_indices, dim=1)\n",
    "\n",
    "        x = torch.cat([x1, x2], dim=0)\n",
    "\n",
    "        x = F.relu(self.conv3(x)).T\n",
    "        \n",
    "        x = x + self.positional_encoding(g_data.token_positions)\n",
    "\n",
    "        rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "            \n",
    "        graph = self.graph_generator.gen_graph(x, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "        rand_edges = rand_edges-1\n",
    "        lattice_edges = lattice_edges-1\n",
    "        \n",
    "        x, edge_weights = self.gcnn1(graph.x, graph, len(g_data.token_lengths), return_attention_weights = True)\n",
    "        edge_weights = edge_weights[1][:graph.edge_index.shape[1], 0]\n",
    "        \n",
    "        graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, graph.edge_index, len(g_data.token_lengths), g_data.num_tokens, rand_edges, lattice_edges, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        \n",
    "        x = torch.cat([graph.x[:g_data.token_embeddings.shape[0]], g_data.token_embeddings], dim=1)\n",
    "        x1 = F.relu(self.fc0(graph.x[g_data.token_embeddings.shape[0]:]))\n",
    "        x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "        x, edge_weights = self.gcnn2(x, graph, len(g_data.token_lengths))\n",
    "\n",
    "        x = F.elu_(self.fc1(x))\n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(g_data.num_tokens), device=x.device), g_data.num_tokens)\n",
    "        x1 = scatter_max(x[:len(g_data.token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(g_data.token_lengths)], doc_token_index, dim=0)\n",
    "        vn_embs = x[len(g_data.token_lengths):]\n",
    "        x_for_cat = [x1, x2]\n",
    "        x_for_cat.extend([vn_embs[i*x1.shape[0]:(i+1)*x1.shape[0]] for i in range(self.virtual_nodes)])\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        \n",
    "        x = F.elu_(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def create_positional_encoding(self):\n",
    "        position = torch.arange(self.pos_emb_size).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.hidden_dim, 2) * (-math.log(10000.0) / self.hidden_dim))\n",
    "        pe = torch.zeros(self.pos_emb_size, self.hidden_dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return torch.nn.Parameter(pe, requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CnnGnnClassifierLightningModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        num_classes,\n",
    "        optimizer=None,\n",
    "        loss_func=None,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=64,\n",
    "        lr_scheduler=None,\n",
    "        user_lr_scheduler=False,\n",
    "        min_lr=0.0,\n",
    "    ):\n",
    "        super(CnnGnnClassifierLightningModel, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.min_lr = min_lr\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.save_hyperparameters(ignore=['loss_func'])\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        self.optimizer = self._get_optimizer(optimizer)\n",
    "        self.lr_scheduler = (\n",
    "            self._get_lr_scheduler(lr_scheduler) if user_lr_scheduler else None\n",
    "        )\n",
    "        self.loss_func = loss_func\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)\n",
    "\n",
    "    def on_train_epoch_start(self) -> None:\n",
    "        param_groups = next(iter(self.optimizer.param_groups))\n",
    "        if \"lr\" in param_groups and param_groups[\"lr\"] is not None:\n",
    "            current_learning_rate = float(param_groups[\"lr\"])\n",
    "            self.log(\n",
    "                \"lr\",\n",
    "                current_learning_rate,\n",
    "                batch_size=self.batch_size,\n",
    "                on_epoch=True,\n",
    "                on_step=False,\n",
    "            )\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.train()\n",
    "        y_out = self(X)\n",
    "\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.train_losses.append(loss.detach().item())\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        self.train_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        y_out = self(X)\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.val_losses.append(loss.detach().item())\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.val_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.lr_scheduler is None:\n",
    "            return self.optimizer\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": self.lr_scheduler,\n",
    "                \"monitor\": \"train_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def update_learning_rate(self, learning_rate: float):\n",
    "        self.learning_rate = learning_rate\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g[\"lr\"] = learning_rate\n",
    "\n",
    "    def _get_optimizer(self, optimizer):\n",
    "        return (\n",
    "            optimizer\n",
    "            if optimizer is not None\n",
    "            else torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        )\n",
    "\n",
    "    def _get_lr_scheduler(self, lr_scheduler):\n",
    "        return (\n",
    "            lr_scheduler\n",
    "            if lr_scheduler is not None\n",
    "            else torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer, patience=5, factor=0.5, mode=\"min\", min_lr=self.min_lr\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 128\n",
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "label_size = 1\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import Logger, CSVLogger\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from typing import List\n",
    "from pytorch_lightning.core.saving import save_hparams_to_yaml\n",
    "\n",
    "class ModelManager(ABC):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 max_epochs = 100,\n",
    "                 ckpt_path: str|None=None,\n",
    "                 accumulate_grad_batches=1):\n",
    "        self.torch_model = torch_model\n",
    "        self.lightning_model = lightning_model\n",
    "        self.log_dir = log_dir\n",
    "        self.log_name = log_name\n",
    "        self.model_save_dir = model_save_dir\n",
    "        self.device = device\n",
    "        self.accelerator = 'cpu' if self.device=='cpu' else 'gpu'\n",
    "        self.max_epochs = max_epochs\n",
    "        self.ckpt_path = ckpt_path\n",
    "\n",
    "        self.logger = self._create_logger()\n",
    "        self.callbacks = self._create_callbacks()\n",
    "        self.trainer: L.Trainer = self._create_trainer(accumulate_grad_batches)\n",
    "        self.tuner = Tuner(self.trainer)\n",
    "        self.tuning_result = None\n",
    "\n",
    "    def tune(self, data_manager=None, train_dataloaders=None, val_dataloaders=None, datamodule=None, draw_result=True, min_lr=0.0000001, max_lr=0.1):\n",
    "        self.tuning_result = self.tuner.lr_find(self.lightning_model, datamodule=data_manager, train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders, min_lr=min_lr,max_lr=max_lr, num_training=150)\n",
    "        if draw_result:\n",
    "            fig = self.tuning_result.plot(suggest=True)\n",
    "            fig.show()\n",
    "        self.update_learning_rate(self.tuning_result.suggestion())\n",
    "        return self.tuning_result.suggestion()\n",
    "    \n",
    "    def update_learning_rate(self, lr):\n",
    "        self.lightning_model.update_learning_rate(lr)\n",
    "\n",
    "    def fit(self, train_dataloaders=None, val_dataloaders=None, datamodule=None, max_epochs = -1, ckpt_path=None):\n",
    "        if ckpt_path is not None and ckpt_path != '':\n",
    "            self.ckpt_path = ckpt_path\n",
    "        if max_epochs>0:\n",
    "            self.trainer.fit_loop.max_epochs = max_epochs\n",
    "            # self.max_epochs = max_epochs\n",
    "            # self.trainer = self._create_trainer()\n",
    "        self.trainer.fit(self.lightning_model,\n",
    "                         datamodule=datamodule,\n",
    "                         train_dataloaders=train_dataloaders,\n",
    "                         val_dataloaders=val_dataloaders,\n",
    "                         ckpt_path = self.ckpt_path\n",
    "                         )\n",
    "\n",
    "    def validate(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.validate(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def predict(self, dataloaders=None, datamodule=None):\n",
    "        return self.trainer.predict(self.lightning_model,\n",
    "                             datamodule=datamodule,\n",
    "                             dataloaders=dataloaders)\n",
    "\n",
    "    def _create_trainer(self, accumulate_grad_batches) -> L.Trainer:\n",
    "        return L.Trainer(\n",
    "            callbacks=self.callbacks,\n",
    "            max_epochs=self.max_epochs,\n",
    "            accelerator=self.accelerator,\n",
    "            logger=self.logger,\n",
    "            num_sanity_val_steps=0,\n",
    "            default_root_dir=self.model_save_dir,\n",
    "            accumulate_grad_batches=accumulate_grad_batches\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        pass\n",
    "\n",
    "    def _create_logger(self) -> Logger:\n",
    "        return CSVLogger(save_dir=self.log_dir, name=self.log_name)\n",
    "\n",
    "    @abstractmethod\n",
    "    def draw_summary(self, dataloader):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def plot_csv_logger(self, loss_names, eval_names):\n",
    "        pass\n",
    "    \n",
    "    def save_hyper_parameters(self):\n",
    "        mhparams = {\n",
    "            'start_lr': 0.045,\n",
    "            'ckpt_lrs' :  {51: 0.002, 65: 0.00058},\n",
    "            'last_lr' : 0.0003,\n",
    "            'ac_loss_factor': 0.0002,\n",
    "            'weight_decay': 0.0012\n",
    "        }\n",
    "        save_hparams_to_yaml(config_yaml=r'logs\\hetero_model_17_AG\\version_12\\hparams.yaml',\n",
    "                     hparams=mhparams)\n",
    "        \n",
    "    # def find_best_settings(data_manager,\n",
    "    #                        lrs: List[float]=[0.001], dropouts: List[float]=[0.2], \n",
    "    #                        weight_decays: List[float]=[0.00055], emb_factors: List[float]=[0.1], \n",
    "    #                        batch_sizes: List[int]=[128], log_name='find_best_settings'):\n",
    "    #     for lr in lrs:\n",
    "    #         for dropout in dropouts:\n",
    "    #             for wd in weight_decays:\n",
    "    #                 for emb_factor in emb_factors:\n",
    "    #                     for bs in batch_sizes:\n",
    "    #                         data_manager.update_batch_size(bs)\n",
    "    #                         torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 128, dropout=dropout)\n",
    "    #                         lightning_model = HeteroBinaryLightningModel(torch_model,\n",
    "    #                                         torch.optim.Adam(torch_model.parameters(), lr=lr, weight_decay=wd),\n",
    "    #                                             loss_func=HeteroLoss1(exception_keys='word', enc_factor=emb_factor),\n",
    "    #                                             learning_rate=lr,\n",
    "    #                                             batch_size=bs,\n",
    "    #                                             user_lr_scheduler=True\n",
    "    #                                             ).to(device)\n",
    "    #                         model_manager = ClassifierModelManager(torch_model, lightning_model, log_name=log_name, device=device, num_train_epoch=10)\n",
    "    #                         model_manager.fit(datamodule=data_manager)\n",
    "    #                         model_manager.save_plot_csv_logger(name_prepend=f'{lr}_{dropout}_{wd}_{emb_factor}_{bs}', loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "import torch\n",
    "# from scripts.managers.ModelManager import ModelManager\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from torch_geometric.nn import summary\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from os import path\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "class ClassifierModelManager(ModelManager):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 num_train_epoch = 100,\n",
    "                 accumulate_grad_batches=1):\n",
    "        super(ClassifierModelManager, self).__init__(torch_model, lightning_model, model_save_dir, log_dir, log_name, device, num_train_epoch, accumulate_grad_batches=accumulate_grad_batches)\n",
    "\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        return [\n",
    "            ModelCheckpoint(save_top_k=2, mode='max', monitor='val_acc', save_last=True),\n",
    "            # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "        ]\n",
    "\n",
    "    def draw_summary(self, dataloader):\n",
    "        X, y = next(iter(dataloader))\n",
    "        print(summary(self.torch_model, X.to(self.device)))\n",
    "\n",
    "    def plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    def save_plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc'], name_prepend: str=\"\"):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        \n",
    "        loss_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_loss_metric.png')\n",
    "        plt.savefig(loss_png)\n",
    "        \n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        \n",
    "        acc_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_acc_metric.png')\n",
    "        plt.savefig(acc_png)\n",
    "        \n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate(self, eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.lightning_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        # if(give_hinge_loss):\n",
    "        #     print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')\n",
    "                \n",
    "    def evaluate_best_models(self, lightning_type: L.LightningModule, eval_dataloader,\n",
    "                             give_confusion_matrix: bool=True, \n",
    "                             give_report: bool=True, \n",
    "                             give_f1_score: bool=False, \n",
    "                             give_accuracy_score: bool=False, \n",
    "                             give_precision_score: bool=False, \n",
    "                             give_recall_score: bool=False, \n",
    "                             give_hinge_loss: bool=False,\n",
    "                             multi_class: bool=False, **kwargs):\n",
    "        self.lightning_model = lightning_type.load_from_checkpoint(rf'{self.trainer.checkpoint_callback.best_model_path}', map_location=None, hparams_file=None, strict=True, **kwargs).eval()\n",
    "        self.save_evaluation(eval_dataloader, 'best_model', give_confusion_matrix, give_report,\n",
    "                             give_f1_score, give_accuracy_score, give_precision_score, give_recall_score, give_hinge_loss, multi_class)\n",
    "            \n",
    "    def save_evaluation(self, eval_dataloader, name_prepend: str='',\n",
    "                    give_confusion_matrix: bool=True, \n",
    "                    give_report: bool=True, \n",
    "                    give_f1_score: bool=False, \n",
    "                    give_accuracy_score: bool=False, \n",
    "                    give_precision_score: bool=False, \n",
    "                    give_recall_score: bool=False, \n",
    "                    give_hinge_loss: bool=False,\n",
    "                    multi_class: bool=False\n",
    "                    ):\n",
    "            \n",
    "            test_metrics_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_test_metrics.txt')\n",
    "            \n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            self.lightning_model.eval()\n",
    "            self.lightning_model.model.eval()\n",
    "            self.torch_model.eval()\n",
    "            self.trainer.model.eval()\n",
    "            for X, y in eval_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    y_p = self.lightning_model(X.to(self.device))\n",
    "                if type(y_p) is tuple:\n",
    "                    y_p = y_p[0]\n",
    "                \n",
    "                if multi_class:\n",
    "                    y_pred.append(y_p.detach().to(y.device))\n",
    "                    y_true.append(y)\n",
    "                else:\n",
    "                    y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "                    y_true.append(y.to(torch.int32))\n",
    "                    \n",
    "            y_true = torch.concat(y_true)\n",
    "            y_pred = torch.concat(y_pred)\n",
    "            print(y_true.shape)\n",
    "            print(y_pred.shape)\n",
    "            if multi_class:\n",
    "                y_true_num = torch.argmax(y_true, dim=1)\n",
    "                y_pred_num = torch.argmax(y_pred, dim=1)\n",
    "            else:\n",
    "                y_true_num = y_true\n",
    "                y_pred_num = y_pred\n",
    "                \n",
    "            print(y_true_num.shape)\n",
    "            print(y_pred_num.shape)\n",
    "            with open(test_metrics_path, 'at+') as f:\n",
    "                if(give_confusion_matrix):\n",
    "                    print(f'confusion_matrix: \\n{confusion_matrix(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_report):\n",
    "                    print(classification_report(y_true_num, y_pred_num), file=f)\n",
    "                if(give_f1_score):\n",
    "                    if multi_class:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_accuracy_score):\n",
    "                    print(f'accuracy_score: {accuracy_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_precision_score):\n",
    "                    if multi_class:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_recall_score):\n",
    "                    if multi_class:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num)}', file=f)\n",
    "                # if(give_hinge_loss):\n",
    "                #     print(f'hinge_loss: {hinge_loss(y_true_num, y_pred)}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "def train_model(epochs=30, dropout=0.2, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True):\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 38, 40,45,50],gamma=0.5)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name='CNN-GNN14_imdb',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.torch_model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(CnnGnnClassifierLightningModel, test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 844 ms\n",
      "Wall time: 840 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     time.sleep(60)\n",
    "#     torch.cuda.empty_cache()\n",
    "#     import gc\n",
    "#     gc.collect()\n",
    "#     time.sleep(60)\n",
    "#     train_model(70, 0.2, 0.000012, 0.0032, amsgrad=False, fused=True, long_limit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | CNN_for_Text       | 729 K  | train\n",
      "1 | loss_func | BCEWithLogitsLoss  | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "204 K     Trainable params\n",
      "524 K     Non-trainable params\n",
      "729 K     Total params\n",
      "2.916     Total estimated model params size (MB)\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfc3120429347249cd9c3aba18fed51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24960, 2])\n",
      "torch.Size([24960, 2])\n",
      "torch.Size([24960])\n",
      "torch.Size([24960])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/195 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▊                                                                                 | 2/195 [00:00<00:14, 13.16it/s]\u001b[A\n",
      "  2%|█▋                                                                                | 4/195 [00:00<00:14, 12.81it/s]\u001b[A\n",
      "  3%|██▌                                                                               | 6/195 [00:00<00:14, 12.85it/s]\u001b[A\n",
      "  4%|███▎                                                                              | 8/195 [00:00<00:14, 12.84it/s]\u001b[A\n",
      "  5%|████▏                                                                            | 10/195 [00:00<00:16, 11.53it/s]\u001b[A\n",
      "  6%|████▉                                                                            | 12/195 [00:01<00:16, 11.25it/s]\u001b[A\n",
      "  7%|█████▊                                                                           | 14/195 [00:01<00:16, 11.31it/s]\u001b[A\n",
      "  8%|██████▋                                                                          | 16/195 [00:01<00:16, 11.01it/s]\u001b[A\n",
      "  9%|███████▍                                                                         | 18/195 [00:01<00:15, 11.39it/s]\u001b[A\n",
      " 10%|████████▎                                                                        | 20/195 [00:01<00:14, 11.67it/s]\u001b[A\n",
      " 11%|█████████▏                                                                       | 22/195 [00:01<00:14, 12.07it/s]\u001b[A\n",
      " 12%|█████████▉                                                                       | 24/195 [00:02<00:13, 12.31it/s]\u001b[A\n",
      " 13%|██████████▊                                                                      | 26/195 [00:02<00:13, 12.10it/s]\u001b[A\n",
      " 14%|███████████▋                                                                     | 28/195 [00:02<00:13, 12.26it/s]\u001b[A\n",
      " 15%|████████████▍                                                                    | 30/195 [00:02<00:13, 12.11it/s]\u001b[A\n",
      " 16%|█████████████▎                                                                   | 32/195 [00:02<00:13, 12.20it/s]\u001b[A\n",
      " 17%|██████████████                                                                   | 34/195 [00:02<00:12, 12.66it/s]\u001b[A\n",
      " 18%|██████████████▉                                                                  | 36/195 [00:02<00:12, 12.83it/s]\u001b[A\n",
      " 19%|███████████████▊                                                                 | 38/195 [00:03<00:13, 11.85it/s]\u001b[A\n",
      " 21%|████████████████▌                                                                | 40/195 [00:03<00:13, 11.54it/s]\u001b[A\n",
      " 22%|█████████████████▍                                                               | 42/195 [00:03<00:13, 11.44it/s]\u001b[A\n",
      " 23%|██████████████████▎                                                              | 44/195 [00:03<00:13, 10.91it/s]\u001b[A\n",
      " 24%|███████████████████                                                              | 46/195 [00:03<00:13, 11.42it/s]\u001b[A\n",
      " 25%|███████████████████▉                                                             | 48/195 [00:04<00:12, 11.69it/s]\u001b[A\n",
      " 26%|████████████████████▊                                                            | 50/195 [00:04<00:13, 10.89it/s]\u001b[A\n",
      " 27%|█████████████████████▌                                                           | 52/195 [00:04<00:12, 11.10it/s]\u001b[A\n",
      " 28%|██████████████████████▍                                                          | 54/195 [00:04<00:12, 11.75it/s]\u001b[A\n",
      " 29%|███████████████████████▎                                                         | 56/195 [00:04<00:11, 12.25it/s]\u001b[A\n",
      " 30%|████████████████████████                                                         | 58/195 [00:04<00:10, 12.72it/s]\u001b[A\n",
      " 31%|████████████████████████▉                                                        | 60/195 [00:05<00:10, 13.00it/s]\u001b[A\n",
      " 32%|█████████████████████████▊                                                       | 62/195 [00:05<00:09, 13.31it/s]\u001b[A\n",
      " 33%|██████████████████████████▌                                                      | 64/195 [00:05<00:10, 13.00it/s]\u001b[A\n",
      " 34%|███████████████████████████▍                                                     | 66/195 [00:05<00:10, 12.68it/s]\u001b[A\n",
      " 35%|████████████████████████████▏                                                    | 68/195 [00:05<00:10, 12.16it/s]\u001b[A\n",
      " 36%|█████████████████████████████                                                    | 70/195 [00:05<00:11, 11.06it/s]\u001b[A\n",
      " 37%|█████████████████████████████▉                                                   | 72/195 [00:06<00:11, 10.93it/s]\u001b[A\n",
      " 38%|██████████████████████████████▋                                                  | 74/195 [00:06<00:10, 11.00it/s]\u001b[A\n",
      " 39%|███████████████████████████████▌                                                 | 76/195 [00:06<00:11, 10.37it/s]\u001b[A\n",
      " 40%|████████████████████████████████▍                                                | 78/195 [00:06<00:12,  9.11it/s]\u001b[A\n",
      " 41%|████████████████████████████████▊                                                | 79/195 [00:06<00:15,  7.71it/s]\u001b[A\n",
      " 41%|█████████████████████████████████▏                                               | 80/195 [00:07<00:15,  7.65it/s]\u001b[A\n",
      " 42%|█████████████████████████████████▋                                               | 81/195 [00:07<00:14,  7.82it/s]\u001b[A\n",
      " 42%|██████████████████████████████████                                               | 82/195 [00:07<00:14,  7.95it/s]\u001b[A\n",
      " 43%|██████████████████████████████████▍                                              | 83/195 [00:07<00:13,  8.25it/s]\u001b[A\n",
      " 43%|██████████████████████████████████▉                                              | 84/195 [00:07<00:13,  8.08it/s]\u001b[A\n",
      " 44%|███████████████████████████████████▎                                             | 85/195 [00:07<00:14,  7.58it/s]\u001b[A\n",
      " 44%|███████████████████████████████████▋                                             | 86/195 [00:07<00:13,  7.94it/s]\u001b[A\n",
      " 45%|████████████████████████████████████▏                                            | 87/195 [00:08<00:15,  7.17it/s]\u001b[A\n",
      " 45%|████████████████████████████████████▌                                            | 88/195 [00:08<00:17,  6.27it/s]\u001b[A\n",
      " 46%|████████████████████████████████████▉                                            | 89/195 [00:08<00:15,  6.78it/s]\u001b[A\n",
      " 46%|█████████████████████████████████████▍                                           | 90/195 [00:08<00:15,  6.99it/s]\u001b[A\n",
      " 47%|█████████████████████████████████████▊                                           | 91/195 [00:08<00:14,  7.16it/s]\u001b[A\n",
      " 47%|██████████████████████████████████████▏                                          | 92/195 [00:08<00:13,  7.39it/s]\u001b[A\n",
      " 48%|██████████████████████████████████████▋                                          | 93/195 [00:08<00:13,  7.77it/s]\u001b[A\n",
      " 49%|███████████████████████████████████████▍                                         | 95/195 [00:09<00:11,  8.54it/s]\u001b[A\n",
      " 49%|███████████████████████████████████████▉                                         | 96/195 [00:09<00:11,  8.47it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████▎                                        | 97/195 [00:09<00:11,  8.64it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████▋                                        | 98/195 [00:09<00:11,  8.56it/s]\u001b[A\n",
      " 51%|█████████████████████████████████████████                                        | 99/195 [00:09<00:11,  8.43it/s]\u001b[A\n",
      " 51%|█████████████████████████████████████████                                       | 100/195 [00:09<00:11,  8.47it/s]\u001b[A\n",
      " 52%|█████████████████████████████████████████▍                                      | 101/195 [00:09<00:16,  5.62it/s]\u001b[A\n",
      " 52%|█████████████████████████████████████████▊                                      | 102/195 [00:10<00:23,  4.04it/s]\u001b[A\n",
      " 53%|██████████████████████████████████████████▎                                     | 103/195 [00:10<00:22,  4.14it/s]\u001b[A\n",
      " 53%|██████████████████████████████████████████▋                                     | 104/195 [00:10<00:18,  4.96it/s]\u001b[A\n",
      " 54%|███████████████████████████████████████████                                     | 105/195 [00:10<00:15,  5.80it/s]\u001b[A\n",
      " 54%|███████████████████████████████████████████▍                                    | 106/195 [00:10<00:13,  6.63it/s]\u001b[A\n",
      " 55%|████████████████████████████████████████████▎                                   | 108/195 [00:11<00:10,  7.92it/s]\u001b[A\n",
      " 56%|████████████████████████████████████████████▋                                   | 109/195 [00:11<00:10,  7.83it/s]\u001b[A\n",
      " 56%|█████████████████████████████████████████████▏                                  | 110/195 [00:11<00:11,  7.68it/s]\u001b[A\n",
      " 57%|█████████████████████████████████████████████▉                                  | 112/195 [00:11<00:09,  8.64it/s]\u001b[A\n",
      " 58%|██████████████████████████████████████████████▊                                 | 114/195 [00:11<00:09,  8.94it/s]\u001b[A\n",
      " 59%|███████████████████████████████████████████████▏                                | 115/195 [00:11<00:09,  8.89it/s]\u001b[A\n",
      " 59%|███████████████████████████████████████████████▌                                | 116/195 [00:12<00:09,  8.61it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████                                | 117/195 [00:12<00:10,  7.37it/s]\u001b[A\n",
      " 61%|████████████████████████████████████████████████▍                               | 118/195 [00:12<00:11,  6.72it/s]\u001b[A\n",
      " 61%|████████████████████████████████████████████████▊                               | 119/195 [00:12<00:10,  7.28it/s]\u001b[A\n",
      " 62%|█████████████████████████████████████████████████▏                              | 120/195 [00:12<00:09,  7.83it/s]\u001b[A\n",
      " 62%|█████████████████████████████████████████████████▋                              | 121/195 [00:12<00:09,  7.88it/s]\u001b[A\n",
      " 63%|██████████████████████████████████████████████████                              | 122/195 [00:12<00:08,  8.17it/s]\u001b[A\n",
      " 63%|██████████████████████████████████████████████████▍                             | 123/195 [00:12<00:08,  8.64it/s]\u001b[A\n",
      " 64%|██████████████████████████████████████████████████▊                             | 124/195 [00:13<00:08,  8.72it/s]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████▎                            | 125/195 [00:13<00:07,  8.92it/s]\u001b[A\n",
      " 65%|███████████████████████████████████████████████████▋                            | 126/195 [00:13<00:07,  8.99it/s]\u001b[A\n",
      " 65%|████████████████████████████████████████████████████                            | 127/195 [00:13<00:07,  9.07it/s]\u001b[A\n",
      " 66%|████████████████████████████████████████████████████▌                           | 128/195 [00:13<00:07,  9.03it/s]\u001b[A\n",
      " 66%|████████████████████████████████████████████████████▉                           | 129/195 [00:13<00:07,  9.10it/s]\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████▎                          | 130/195 [00:13<00:07,  9.14it/s]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████▏                         | 132/195 [00:13<00:06, 10.05it/s]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████▌                         | 133/195 [00:14<00:06,  9.96it/s]\u001b[A\n",
      " 69%|██████████████████████████████████████████████████████▉                         | 134/195 [00:14<00:06,  9.95it/s]\u001b[A\n",
      " 69%|███████████████████████████████████████████████████████▍                        | 135/195 [00:14<00:06,  9.10it/s]\u001b[A\n",
      " 70%|███████████████████████████████████████████████████████▊                        | 136/195 [00:14<00:06,  8.68it/s]\u001b[A\n",
      " 70%|████████████████████████████████████████████████████████▏                       | 137/195 [00:14<00:06,  8.37it/s]\u001b[A\n",
      " 71%|████████████████████████████████████████████████████████▌                       | 138/195 [00:14<00:06,  8.24it/s]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████████                       | 139/195 [00:14<00:06,  8.56it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████▍                      | 140/195 [00:14<00:06,  8.69it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████▊                      | 141/195 [00:15<00:07,  7.68it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████▎                     | 142/195 [00:15<00:06,  7.79it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████▋                     | 143/195 [00:15<00:06,  8.06it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████                     | 144/195 [00:15<00:06,  8.22it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████▍                    | 145/195 [00:15<00:05,  8.36it/s]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████████▉                    | 146/195 [00:15<00:05,  8.37it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████████▎                   | 147/195 [00:15<00:06,  7.16it/s]\u001b[A\n",
      " 76%|████████████████████████████████████████████████████████████▋                   | 148/195 [00:15<00:06,  7.37it/s]\u001b[A\n",
      " 76%|█████████████████████████████████████████████████████████████▏                  | 149/195 [00:16<00:05,  7.85it/s]\u001b[A\n",
      " 77%|█████████████████████████████████████████████████████████████▌                  | 150/195 [00:16<00:05,  7.73it/s]\u001b[A\n",
      " 77%|█████████████████████████████████████████████████████████████▉                  | 151/195 [00:16<00:05,  7.67it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████▎                 | 152/195 [00:16<00:05,  7.76it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████▊                 | 153/195 [00:16<00:05,  8.08it/s]\u001b[A\n",
      " 79%|███████████████████████████████████████████████████████████████▏                | 154/195 [00:16<00:04,  8.26it/s]\u001b[A\n",
      " 79%|███████████████████████████████████████████████████████████████▌                | 155/195 [00:16<00:04,  8.69it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████                | 156/195 [00:16<00:04,  9.02it/s]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████▍               | 157/195 [00:16<00:04,  8.97it/s]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████▊               | 158/195 [00:17<00:04,  9.18it/s]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████▋              | 160/195 [00:17<00:03, 10.05it/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████              | 161/195 [00:17<00:03,  9.96it/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████▍             | 162/195 [00:17<00:03,  9.60it/s]\u001b[A\n",
      " 84%|██████████████████████████████████████████████████████████████████▊             | 163/195 [00:17<00:03,  9.19it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████████████▎            | 164/195 [00:17<00:03,  9.19it/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████████████            | 166/195 [00:17<00:02,  9.82it/s]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████▉           | 168/195 [00:18<00:02, 10.08it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████████▋          | 170/195 [00:18<00:02,  9.27it/s]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████████████▏         | 171/195 [00:18<00:02,  9.18it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████████████████████████████████████▉         | 173/195 [00:18<00:02,  9.35it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████████████▍        | 174/195 [00:18<00:02,  9.35it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████▊        | 175/195 [00:18<00:02,  9.27it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████████▏       | 176/195 [00:18<00:02,  9.44it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████▌       | 177/195 [00:19<00:01,  9.39it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████       | 178/195 [00:19<00:01,  9.38it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▍      | 179/195 [00:19<00:01,  9.40it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▊      | 180/195 [00:19<00:01,  9.33it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████████▋     | 182/195 [00:19<00:01, 10.31it/s]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 184/195 [00:19<00:01, 10.79it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████████▎   | 186/195 [00:19<00:00, 11.19it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████▏  | 188/195 [00:20<00:00, 10.87it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████████████████████████████████████████▉  | 190/195 [00:20<00:00,  9.97it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████▊ | 192/195 [00:20<00:00, 10.08it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 195/195 [00:20<00:00,  9.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9588    0.7510    0.8423     12473\n",
      "           1     0.7955    0.9678    0.8733     12487\n",
      "\n",
      "    accuracy                         0.8595     24960\n",
      "   macro avg     0.8772    0.8594    0.8578     24960\n",
      "weighted avg     0.8771    0.8595    0.8578     24960\n",
      "\n",
      "confusion matrix:\n",
      " tensor([[ 9367,  3106],\n",
      "        [  402, 12085]])\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24960, 2])\n",
      "torch.Size([24960, 2])\n",
      "torch.Size([24960])\n",
      "torch.Size([24960])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | CNN_for_Text       | 729 K  | train\n",
      "1 | loss_func | BCEWithLogitsLoss  | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "204 K     Trainable params\n",
      "524 K     Non-trainable params\n",
      "729 K     Total params\n",
      "2.916     Total estimated model params size (MB)\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcabc3b287114655bbd79d54822ac299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(5):\n",
    "    model_manager = train_model(25, 0.2, 0.000012, 0.0032, amsgrad=False, fused=True)\n",
    "    time.sleep(60)\n",
    "    torch.cuda.empty_cache()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoints_True = {'1': r'logs\\CNN-GNN14_imdb\\version_5\\checkpoints\\epoch=27-step=5460.ckpt',\n",
    "                    '2': r'logs\\CNN-GNN14_imdb\\version_6\\checkpoints\\epoch=23-step=4680.ckpt',\n",
    "                    '3': r'logs\\CNN-GNN14_imdb\\version_7\\checkpoints\\epoch=18-step=3705.ckpt',\n",
    "                    '4': r'logs\\CNN-GNN14_imdb\\version_8\\checkpoints\\epoch=20-step=4095.ckpt',\n",
    "                    '5': r'logs\\CNN-GNN14_imdb\\version_9\\checkpoints\\epoch=19-step=3900.ckpt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(5):\n",
    "    model_manager = train_model(25, 0.2, 0.000012, 0.0032, amsgrad=False, fused=False)\n",
    "    time.sleep(60)\n",
    "    torch.cuda.empty_cache()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoints_False = {'1': r'logs\\CNN-GNN14_imdb\\version_10\\checkpoints\\epoch=22-step=4485.ckpt',\n",
    "                    '2': r'logs\\CNN-GNN14_imdb\\version_11\\checkpoints\\epoch=23-step=4680.ckpt',\n",
    "                    '3': r'logs\\CNN-GNN14_imdb\\version_12\\checkpoints\\epoch=24-step=4875.ckpt',\n",
    "                    '5': r'logs\\CNN-GNN14_imdb\\version_13\\checkpoints\\epoch=23-step=4680.ckpt',\n",
    "                    '5': r'logs\\CNN-GNN14_imdb\\version_14\\checkpoints\\epoch=16-step=3315.ckpt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.lightning_model = lightning_type.load_from_checkpoint(rf'{self.trainer.checkpoint_callback.best_model_path}', map_location=None, hparams_file=None, strict=True, **kwargs).eval()\n",
    "self.save_evaluation(eval_dataloader, 'best_model', give_confusion_matrix, give_report,\n",
    "                             give_f1_score, give_accuracy_score, give_precision_score, give_recall_score, give_hinge_loss, multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/CNN-GNN14_imdb\\\\version_15\\\\checkpoints\\\\epoch=1-step=390.ckpt'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_manager.trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4: Wall time: 45min 29s\n",
    "k = 4: Wall time: 46min 12s 0.9037 0.9037    0.9037    0.9037\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8: CPU times: total: 1h 53min 43s\n",
    "Wall time: 44min 41s\n",
    "k = 8: CPU times: total: 1h 55min 2s\n",
    "Wall time: 45min 57s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def give_best_output_results(best_checkpoints):\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "    for k in best_checkpoints:\n",
    "        classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "        classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(best_checkpoints[k], model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "        mean_infer_acc = []\n",
    "        mean_infer_f1 = []\n",
    "        mean_infer_prec = []\n",
    "        mean_infer_rec = []\n",
    "        for i in range(5):\n",
    "            all_ys = []\n",
    "            all_y_preds = []\n",
    "            for X, y in test_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    y_pred = classfier_lightning_model(X.to(device))\n",
    "                all_ys.append(torch.argmax(y,dim=1))\n",
    "                all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "            all_ys = torch.concat(all_ys)\n",
    "            all_y_preds = torch.concat(all_y_preds)\n",
    "            \n",
    "            cm = confusion_matrix(all_ys, all_y_preds)\n",
    "            \n",
    "            accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "            precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
    "            recall = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "            f1_score = (2*precision*recall)/(precision + recall)\n",
    "            \n",
    "            mean_infer_acc.append(accuracy)\n",
    "            mean_infer_f1.append(f1_score)\n",
    "            mean_infer_prec.append(precision)\n",
    "            mean_infer_rec.append(recall)\n",
    "        mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "        mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "        mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "        mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "        \n",
    "        print(f'accuracy {k}: {mean_infer_acc}')\n",
    "        print(f'f1 {k}: {mean_infer_f1}')\n",
    "        print(f'prec {k}: {mean_infer_prec}')\n",
    "        print(f'rec {k}: {mean_infer_rec}')\n",
    "        total_accuracy.append(mean_infer_acc)\n",
    "        total_f1.append(mean_infer_f1)\n",
    "        total_prec.append(mean_infer_prec)\n",
    "        total_rec.append(mean_infer_rec)\n",
    "    \n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1: 0.904022435897436\n",
      "f1 1: 0.9040257208951598\n",
      "prec 1: 0.9040290059235738\n",
      "rec 1: 0.904022435897436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 2: 0.9047676282051281\n",
      "f1 2: 0.9048246287113042\n",
      "prec 2: 0.9048816364053032\n",
      "rec 2: 0.9047676282051281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 3: 0.9009535256410256\n",
      "f1 3: 0.9012742713936875\n",
      "prec 3: 0.9015952466068446\n",
      "rec 3: 0.9009535256410256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 4: 0.9013060897435899\n",
      "f1 4: 0.9015070873625494\n",
      "prec 4: 0.9017081751018046\n",
      "rec 4: 0.9013060897435896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 5: 0.8999759615384615\n",
      "f1 5: 0.9006826096624472\n",
      "prec 5: 0.9013903710493179\n",
      "rec 5: 0.8999759615384615\n",
      "total_accuracy: 0.9022051282051283\n",
      "total_f1: 0.9024628636050295\n",
      "total_prec: 0.9027208870173687\n",
      "total_rec: 0.9022051282051281\n"
     ]
    }
   ],
   "source": [
    "give_best_output_results(best_checkpoints_True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1: 0.9019551282051281\n",
      "f1 1: 0.9022304258252662\n",
      "prec 1: 0.902505891698896\n",
      "rec 1: 0.9019551282051281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 2: 0.9033573717948717\n",
      "f1 2: 0.9033593749118293\n",
      "prec 2: 0.9033613780444725\n",
      "rec 2: 0.9033573717948717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 3: 0.9041025641025641\n",
      "f1 3: 0.9041680841249153\n",
      "prec 3: 0.9042336137494426\n",
      "rec 3: 0.9041025641025641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 5: 0.9033814102564103\n",
      "f1 5: 0.9038783239285528\n",
      "prec 5: 0.9043757850919132\n",
      "rec 5: 0.9033814102564103\n",
      "total_accuracy: 0.9031991185897436\n",
      "total_f1: 0.903409052197641\n",
      "total_prec: 0.9036191671461811\n",
      "total_rec: 0.9031991185897436\n"
     ]
    }
   ],
   "source": [
    "give_best_output_results(best_checkpoints_False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoints = {'0': r'logs\\CNN-GNN14_imdb\\version_0\\checkpoints\\epoch=21-step=4312.ckpt',\n",
    "                    '1': r'logs\\CNN-GNN14_imdb\\version_1\\checkpoints\\epoch=16-step=3332.ckpt',\n",
    "                    '2': r'logs\\CNN-GNN14_imdb\\version_2\\checkpoints\\epoch=15-step=3136.ckpt',\n",
    "                    '3': r'logs\\CNN-GNN14_imdb\\version_3\\checkpoints\\epoch=21-step=4312.ckpt',\n",
    "                    '4': r'logs\\CNN-GNN14_imdb\\version_4\\checkpoints\\epoch=21-step=4312.ckpt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0: 0.9033974358974358\n",
      "f1 0: 0.9035064435254805\n",
      "prec 0: 0.9036141853536996\n",
      "rec 0: 0.9033987280164777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1: 0.903790064102564\n",
      "f1 1: 0.9038367718697391\n",
      "prec 1: 0.9038826411572842\n",
      "rec 1: 0.9037909074346764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 2: 0.9012660256410256\n",
      "f1 2: 0.901268346364156\n",
      "prec 2: 0.9012704902530799\n",
      "rec 2: 0.9012662024884375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 3: 0.9044391025641026\n",
      "f1 3: 0.9044397519063028\n",
      "prec 3: 0.9044405139228923\n",
      "rec 3: 0.9044389898919913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 4: 0.9043910256410257\n",
      "f1 4: 0.9051648417962352\n",
      "prec 4: 0.9059365058620049\n",
      "rec 4: 0.9043944936980092\n",
      "total_accuracy: 0.9034567307692308\n",
      "total_f1: 0.9036432310923826\n",
      "total_prec: 0.9038288673097922\n",
      "total_rec: 0.9034578643059185\n"
     ]
    }
   ],
   "source": [
    "total_accuracy = []\n",
    "total_f1 = []\n",
    "total_prec = []\n",
    "total_rec = []\n",
    "\n",
    "\n",
    "for k in best_checkpoints:\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(best_checkpoints[k], model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "    mean_infer_acc = []\n",
    "    mean_infer_f1 = []\n",
    "    mean_infer_prec = []\n",
    "    mean_infer_rec = []\n",
    "    for i in range(5):\n",
    "        all_ys = []\n",
    "        all_y_preds = []\n",
    "        for X, y in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                y_pred = classfier_lightning_model(X.to(device))\n",
    "            all_ys.append(torch.argmax(y,dim=1))\n",
    "            all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "        all_ys = torch.concat(all_ys)\n",
    "        all_y_preds = torch.concat(all_y_preds)\n",
    "        \n",
    "        cm = confusion_matrix(all_ys, all_y_preds)\n",
    "        \n",
    "        accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "        precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
    "        recall = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "        f1_score = (2*precision*recall)/(precision + recall)\n",
    "        \n",
    "        mean_infer_acc.append(accuracy)\n",
    "        mean_infer_f1.append(f1_score)\n",
    "        mean_infer_prec.append(precision)\n",
    "        mean_infer_rec.append(recall)\n",
    "    mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "    mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "    mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "    mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "    \n",
    "    print(f'accuracy {k}: {mean_infer_acc}')\n",
    "    print(f'f1 {k}: {mean_infer_f1}')\n",
    "    print(f'prec {k}: {mean_infer_prec}')\n",
    "    print(f'rec {k}: {mean_infer_rec}')\n",
    "    total_accuracy.append(mean_infer_acc)\n",
    "    total_f1.append(mean_infer_f1)\n",
    "    total_prec.append(mean_infer_prec)\n",
    "    total_rec.append(mean_infer_rec)\n",
    "\n",
    "total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "total_prec = torch.mean(torch.tensor(total_prec))\n",
    "total_rec = torch.mean(torch.tensor(total_rec))\n",
    "print(f'total_accuracy: {total_accuracy}')\n",
    "print(f'total_f1: {total_f1}')\n",
    "print(f'total_prec: {total_prec}')\n",
    "print(f'total_rec: {total_rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0: 0.9033974358974358\n",
      "f1 0: 0.9035064435254805\n",
      "prec 0: 0.9036141853536996\n",
      "rec 0: 0.9033987280164777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1: 0.903790064102564\n",
      "f1 1: 0.9038367718697391\n",
      "prec 1: 0.9038826411572842\n",
      "rec 1: 0.9037909074346764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 2: 0.9012660256410256\n",
      "f1 2: 0.901268346364156\n",
      "prec 2: 0.9012704902530799\n",
      "rec 2: 0.9012662024884375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\Form&ColorIntelligence\\notebooks\\Task1_X_3\\text_classification\\text_classification_test_1_imdb.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m test_dataloader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         y_pred \u001b[39m=\u001b[39m classfier_lightning_model(X\u001b[39m.\u001b[39;49mto(device))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     all_ys\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39margmax(y,dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     all_y_preds\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39margmax(y_pred\u001b[39m.\u001b[39mcpu(), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\Form&ColorIntelligence\\notebooks\\Task1_X_3\\text_classification\\text_classification_test_1_imdb.ipynb Cell 37\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\Form&ColorIntelligence\\notebooks\\Task1_X_3\\text_classification\\text_classification_test_1_imdb.ipynb Cell 37\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m x1 \u001b[39m=\u001b[39m scatter_max(x, g_data\u001b[39m.\u001b[39;49mcumulative_token_indices, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m x2 \u001b[39m=\u001b[39m scatter_mean(x, g_data\u001b[39m.\u001b[39mcumulative_token_indices, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Form%26ColorIntelligence/notebooks/Task1_X_3/text_classification/text_classification_test_1_imdb.ipynb#X45sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x1, x2], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_scatter\\scatter.py:72\u001b[0m, in \u001b[0;36mscatter_max\u001b[1;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter_max\u001b[39m(\n\u001b[0;32m     69\u001b[0m         src: torch\u001b[39m.\u001b[39mTensor, index: torch\u001b[39m.\u001b[39mTensor, dim: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     70\u001b[0m         out: Optional[torch\u001b[39m.\u001b[39mTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m         dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mtorch_scatter\u001b[39m.\u001b[39;49mscatter_max(src, index, dim, out, dim_size)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_ops.py:692\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    688\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    689\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    691\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_accuracy = []\n",
    "total_f1 = []\n",
    "total_prec = []\n",
    "total_rec = []\n",
    "\n",
    "\n",
    "for k in best_checkpoints:\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=8192, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel.load_from_checkpoint(best_checkpoints[k], model=classifier_torch_model, num_classes=len(class_id)).eval()\n",
    "    mean_infer_acc = []\n",
    "    mean_infer_f1 = []\n",
    "    mean_infer_prec = []\n",
    "    mean_infer_rec = []\n",
    "    for i in range(5):\n",
    "        all_ys = []\n",
    "        all_y_preds = []\n",
    "        for X, y in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                y_pred = classfier_lightning_model(X.to(device))\n",
    "            all_ys.append(torch.argmax(y,dim=1))\n",
    "            all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "        all_ys = torch.concat(all_ys)\n",
    "        all_y_preds = torch.concat(all_y_preds)\n",
    "        \n",
    "        cm = confusion_matrix(all_ys, all_y_preds)\n",
    "        \n",
    "        accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "        precision = np.mean(np.diag(cm) / np.sum(cm, axis=0))\n",
    "        recall = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n",
    "        f1_score = (2*precision*recall)/(precision + recall)\n",
    "        \n",
    "        mean_infer_acc.append(accuracy)\n",
    "        mean_infer_f1.append(f1_score)\n",
    "        mean_infer_prec.append(precision)\n",
    "        mean_infer_rec.append(recall)\n",
    "    mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "    mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "    mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "    mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "    \n",
    "    print(f'accuracy {k}: {mean_infer_acc}')\n",
    "    print(f'f1 {k}: {mean_infer_f1}')\n",
    "    print(f'prec {k}: {mean_infer_prec}')\n",
    "    print(f'rec {k}: {mean_infer_rec}')\n",
    "    total_accuracy.append(mean_infer_acc)\n",
    "    total_f1.append(mean_infer_f1)\n",
    "    total_prec.append(mean_infer_prec)\n",
    "    total_rec.append(mean_infer_rec)\n",
    "\n",
    "total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "total_prec = torch.mean(torch.tensor(total_prec))\n",
    "total_rec = torch.mean(torch.tensor(total_rec))\n",
    "print(f'total_accuracy: {total_accuracy}')\n",
    "print(f'total_f1: {total_f1}')\n",
    "print(f'total_prec: {total_prec}')\n",
    "print(f'total_rec: {total_rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "def train_model(epochs=30, dropout=0.2, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True):\n",
    "    classifier_torch_model = CNN_for_Text(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=14336, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 38, 40,45,50],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name='CNN-GNN13_large_models',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.torch_model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(CnnGnnClassifierLightningModel, test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
