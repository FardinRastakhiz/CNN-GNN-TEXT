{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Parameter, Module\n",
    "from torch_scatter.scatter import scatter_sum\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv, GATConv\n",
    "from torch.nn import Linear\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGraphAttention(Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, num_heads=1, *args, **kwargs) -> None:\n",
    "        super(MultiHeadGraphAttention, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.head_in_features = in_features//num_heads\n",
    "        self.head_out_features = out_features//num_heads\n",
    "        \n",
    "        self.query_w, self.key_w, self.agg_value_w, self.update_value_w = self.create_weights()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        if edge_index.shape[0] != self.num_heads:\n",
    "            raise RuntimeError(\"The first dimension of edge_index should be equal to the number of heads.\")\n",
    "        x1_h = x.view(self.num_heads, x.shape[0], self.in_features//self.num_heads)\n",
    "        \n",
    "        batch_indices = torch.arange(self.num_heads).unsqueeze(1).unsqueeze(2).repeat(1, edge_index.shape[1], edge_index.shape[2]) \n",
    "        source_target_features = x1_h[batch_indices, edge_index]\n",
    "        \n",
    "        query = torch.sum(torch.einsum('ijkl,ilm->ijkm', source_target_features, self.query_w), dim=1)\n",
    "        key = torch.sum(torch.einsum('ijkl,ilm->ijkm', source_target_features, self.key_w), dim=1)\n",
    "        a = torch.einsum('ijk,ijk->ij', query, key)\n",
    "        attention = torch.softmax(a, dim=1) / torch.sqrt(torch.tensor(self.head_out_features))\n",
    "        \n",
    "        value_update = torch.einsum('ikl,ilm->ikm', x1_h, self.update_value_w)\n",
    "        value_aggregate = torch.sum(torch.einsum('ijkl,ilm->ijkm', source_target_features, self.agg_value_w), dim=1)\n",
    "        value_aggregate = torch.einsum('ij, ijk->ijk', attention, value_aggregate)\n",
    "        agg_sum = torch.zeros_like(value_update, device=value_update.device)\n",
    "        scatter_sum(value_aggregate, index=edge_index.permute(0, 2, 1)[:, :, :1], dim=1, out=agg_sum)\n",
    "        scatter_sum(value_aggregate, index=edge_index.permute(0, 2, 1)[:, :, 1:], dim=1, out=agg_sum)\n",
    "        out = value_update + agg_sum\n",
    "        print(out.shape, x.shape[0])\n",
    "        return out.permute(1, 0, 2).reshape(x.shape[0], -1)\n",
    "        \n",
    "    def create_weights(self):\n",
    "        query_w = torch.randn((self.num_heads, self.head_in_features, self.head_out_features))\n",
    "        key_w = torch.randn((self.num_heads, self.head_in_features, self.head_out_features))\n",
    "        agg_value_w = torch.randn((self.num_heads, self.head_in_features, self.head_out_features))\n",
    "        update_value_w = torch.randn((self.num_heads, self.head_in_features, self.head_out_features))\n",
    "        return Parameter(query_w), Parameter(key_w), Parameter(agg_value_w), Parameter(update_value_w)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 4\n",
    "in_features = 64\n",
    "out_features = 128\n",
    "MHGAT = MultiHeadGraphAttention(in_features, out_features, num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([251, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((4, 251, 32)).permute(1, 0, 2).reshape(251,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([ 0.0000, -0.3529, -0.7422,  1.8477,  0.0000, -0.0184,  0.0000, -0.9262,\n",
      "         0.0000,  0.0000])\n",
      "tensor([ 0.0000, -0.7059, -1.4844,  3.6954,  0.0000, -0.0367,  0.0000, -1.8524,\n",
      "         0.0000,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.randint(0, 250, (100, ), dtype=torch.long)\n",
    "random_values = torch.randn((100,))\n",
    "base_tensor = torch.zeros((250, ))\n",
    "print(base_tensor[:10])\n",
    "scatter_sum(random_values, edge_index, out=base_tensor)\n",
    "print(base_tensor[:10])\n",
    "scatter_sum(random_values, edge_index, out=base_tensor)\n",
    "print(base_tensor[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 251, 32]) 251\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.randn((251, in_features))\n",
    "edge_index = torch.randint(0, 220, (num_heads, 2, 2600), dtype=torch.long)\n",
    "out_x = MHGAT(x1, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "x1_h = x1.view(num_heads, x1.shape[0], in_features//num_heads)\n",
    "# x1_h = x1_h.permute( 0, 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 2600, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_indices = torch.arange(num_heads).unsqueeze(1).unsqueeze(2).repeat(1, edge_index.shape[1], edge_index.shape[2]) \n",
    "source_target_features = x1_h[batch_indices, edge_index]\n",
    "source_target_features[0] = source_target_features[0]*0 + 1 \n",
    "source_target_features[1] = source_target_features[1]*0 + 2 \n",
    "source_target_features[2] = source_target_features[2]*0 + 3 \n",
    "source_target_features[3] = source_target_features[3]*0 + 4\n",
    "source_target_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights1 = torch.randn((num_heads, in_features//num_heads, out_features//num_heads))\n",
    "weights2 = torch.randn((num_heads, in_features//num_heads, out_features//num_heads))\n",
    "weights1[0] = weights1[0]*0 + 1 \n",
    "weights1[1] = weights1[1]*0 + 2 \n",
    "weights1[2] = weights1[2]*0 + 3 \n",
    "weights1[3] = weights1[3]*0 + 4\n",
    "weights1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 250, 16])\n",
      "torch.Size([4, 2, 2600, 16])\n"
     ]
    }
   ],
   "source": [
    "print(x1_h.shape)\n",
    "print(source_target_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2600])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = torch.sum(torch.einsum('ijkl,ilm->ijkm', source_target_features, weights1), dim=1)\n",
    "key = torch.sum(torch.einsum('ijkl,ilm->ijkm', source_target_features, weights2), dim=1)\n",
    "a = torch.einsum('ijk,ijk->ij', query, key)\n",
    "attention = torch.softmax(a, dim=1) / torch.sqrt(torch.tensor(out_features//num_heads))\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 250, 32]), torch.Size([4, 250, 32]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_aggregate = torch.sum(torch.einsum('ijkl,ilm->ijkm', source_target_features, weights2), dim=1)\n",
    "value_aggregate = torch.einsum('ij, ijk->ijk', attention, value_aggregate)\n",
    "value_aggregate = scatter_sum(value_aggregate, index=edge_index.permute(0, 2, 1)[:, :, :1], dim=1)+ scatter_sum(value_aggregate, index=edge_index.permute(0, 2, 1)[:, :, 1:], dim=1)\n",
    "value_update = torch.einsum('ikl,ilm->ikm', x1_h, weights2)\n",
    "value_update.shape, value_aggregate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 2600])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index[:, :1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 2600])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 250, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 250, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_aggregate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = torch.ones((4, 2600))\n",
    "attention[1]*=torch.linspace(1, 2, 2600)\n",
    "attention[2]*=3\n",
    "attention[3]*=4\n",
    "value_aggregate = torch.ones((4, 2600, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0008, 1.0008, 1.0008, 1.0008, 1.0008, 1.0008, 1.0008, 1.0008, 1.0008,\n",
       "        1.0008, 1.0008, 1.0008, 1.0008, 1.0008, 1.0008, 1.0008, 1.0008, 1.0008,\n",
       "        1.0008, 1.0008, 1.0008, 1.0008, 1.0008, 1.0008, 1.0008, 1.0008, 1.0008,\n",
       "        1.0008, 1.0008, 1.0008, 1.0008, 1.0008])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_aggregate[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 250, 32])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_update.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2600, 32])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_aggregate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 250, 16]), torch.Size([4, 2600, 1]))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_h.shape, edge_index[:, 0].unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 250, 32])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# x1_h.scatter_reduce(1, edge_index[:, 0].unsqueeze(2), value_update, reduce='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 2600])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 2600, 16])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_target_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 26, 32])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_aggregate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.einsum('ijkl,ijkl->ijkm', source_target_features, weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 26, 32])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.index_select(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 4, 4, 16])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = torch.einsum('ijkl,ilm->ijkm', source_target_features, weights1)\n",
    "messages = F.leaky_relu_(messages[0] + messages[1])\n",
    "messages = torch.exp(torch.einsum('', w_a, messages))\n",
    "alpha = messages/torch.sum(messages, dim=(1,2))\n",
    "\n",
    "x = torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 5])\n",
      "1: torch.Size([5, 2]), torch.Size([2, 2, 5])\n",
      "2: torch.Size([5, 2]), torch.Size([2, 2, 5])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 'edge_index' to be two-dimensional (got 3 dimensions)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\Articles\\CGNet\\FindBestModel\\8_ModifyGATV2Layer\\modification1.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/8_ModifyGATV2Layer/modification1.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(edge_index\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/8_ModifyGATV2Layer/modification1.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m edge_attr \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m0.3\u001b[39m, \u001b[39m0.4\u001b[39m, \u001b[39m0.5\u001b[39m],[\u001b[39m0.15\u001b[39m, \u001b[39m0.25\u001b[39m, \u001b[39m0.35\u001b[39m, \u001b[39m0.45\u001b[39m, \u001b[39m0.55\u001b[39m]])\u001b[39m.\u001b[39mT\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/8_ModifyGATV2Layer/modification1.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m sample_layer(x, edge_index, edge_attr\u001b[39m=\u001b[39;49medge_attr)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\Articles\\CGNet\\FindBestModel\\8_ModifyGATV2Layer\\modification1.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/8_ModifyGATV2Layer/modification1.ipynb#W1sZmlsZQ%3D%3D?line=200'>201</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2: \u001b[39m\u001b[39m{\u001b[39;00medge_attr\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00medge_index\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/8_ModifyGATV2Layer/modification1.ipynb#W1sZmlsZQ%3D%3D?line=201'>202</a>\u001b[0m \u001b[39m# edge_updater_type: (x: PairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/8_ModifyGATV2Layer/modification1.ipynb#W1sZmlsZQ%3D%3D?line=202'>203</a>\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_updater(edge_index, x\u001b[39m=\u001b[39;49m(x_l, x_r),\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/8_ModifyGATV2Layer/modification1.ipynb#W1sZmlsZQ%3D%3D?line=203'>204</a>\u001b[0m                           edge_attr\u001b[39m=\u001b[39;49medge_attr)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/8_ModifyGATV2Layer/modification1.ipynb#W1sZmlsZQ%3D%3D?line=205'>206</a>\u001b[0m \u001b[39m# propagate_type: (x: PairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/8_ModifyGATV2Layer/modification1.ipynb#W1sZmlsZQ%3D%3D?line=206'>207</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(edge_index, x\u001b[39m=\u001b[39m(x_l, x_r), alpha\u001b[39m=\u001b[39malpha)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:682\u001b[0m, in \u001b[0;36mMessagePassing.edge_updater\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    680\u001b[0m         edge_index, size, kwargs \u001b[39m=\u001b[39m res\n\u001b[1;32m--> 682\u001b[0m mutable_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_input(edge_index, size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    684\u001b[0m coll_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collect(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edge_user_args, edge_index,\n\u001b[0;32m    685\u001b[0m                           mutable_size, kwargs)\n\u001b[0;32m    687\u001b[0m edge_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minspector\u001b[39m.\u001b[39mcollect_param_data(\n\u001b[0;32m    688\u001b[0m     \u001b[39m'\u001b[39m\u001b[39medge_update\u001b[39m\u001b[39m'\u001b[39m, coll_dict)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:281\u001b[0m, in \u001b[0;36mMessagePassing._check_input\u001b[1;34m(self, edge_index, size)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to be of integer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype (got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00medge_index\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m \u001b[39mif\u001b[39;00m edge_index\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 281\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to be two-dimensional\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m{\u001b[39;00medge_index\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m dimensions)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_tracing() \u001b[39mand\u001b[39;00m edge_index\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    284\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to have size \u001b[39m\u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthe first dimension (got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00medge_index\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 'edge_index' to be two-dimensional (got 3 dimensions)"
     ]
    }
   ],
   "source": [
    "sample_layer = GATv2Conv(4, 3, edge_dim=2, heads=2, add_self_loops=False)\n",
    "x = torch.ones((6, 4))\n",
    "edge_index = torch.tensor([[0, 0, 1, 1, 2],[2, 3, 4, 5, 5]], dtype=torch.long).unsqueeze(1)\n",
    "edge_index = torch.cat([edge_index, edge_index], dim=1)\n",
    "print(edge_index.shape)\n",
    "edge_attr = torch.tensor([[0.1, 0.2, 0.3, 0.4, 0.5],[0.15, 0.25, 0.35, 0.45, 0.55]]).T\n",
    "sample_layer(x, edge_index, edge_attr=edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,  80,  80, 160],\n",
       "        [160, 240, 320, 400, 400]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
