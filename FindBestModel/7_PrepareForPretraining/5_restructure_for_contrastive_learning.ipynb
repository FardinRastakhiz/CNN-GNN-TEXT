{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch_scatter import scatter_max, scatter_mean\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from torch import nn\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 256\n",
    "folder_path = r'C:\\Users\\fardin\\Projects\\CGNet\\Data\\TextClassification\\IMDB'\n",
    "# t_tokenizer = TweetTokenizer()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085 tensor([0.7000, 0.6000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "id_vocab = {v:k for k,v in tokenizer.vocab.items()}\n",
    "all_vocab_indices = list(id_vocab.keys())\n",
    "\n",
    "with open(r'Data\\ReducedEmbeddings\\deberta_larg_reduced_embeddings_64.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "all_vocab_str = []\n",
    "for i in range(len(id_vocab)):\n",
    "    all_vocab_str.append(id_vocab[i])\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))\n",
    "\n",
    "with open(r'Data\\ReducedEmbeddings\\polarity_debertav3_tokens_gpt_mini_emb.npy', 'rb') as f:\n",
    "    polarities_subjectivities= np.load(f)\n",
    "polarities_subjectivities = torch.from_numpy(polarities_subjectivities)\n",
    "polarity_vocab_dict = dict(zip(all_vocab_str, polarities_subjectivities))\n",
    "polarity_vocab_dict['<n>'] = torch.tensor([0.0, 0.0])\n",
    "len(token_vocab_dict)\n",
    "polarities_subjectivities.shape\n",
    "for i in range(len(all_vocab_str)):\n",
    "    if 'nice' in all_vocab_str[i]:\n",
    "        print(i, polarities_subjectivities[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_ratio = 0.04\n",
    "test_df = pd.read_csv(r'data\\TextClassification\\IMDB\\test.csv')\n",
    "test_df['Topic'] = test_df['label']\n",
    "test_df['Content'] = test_df['text']\n",
    "test_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.iloc[:int(keep_ratio*test_df.shape[0])]\n",
    "train_df = pd.read_csv(r'data\\TextClassification\\IMDB\\train.csv')\n",
    "train_df['Topic'] = train_df['label']\n",
    "train_df['Content'] = train_df['text']\n",
    "train_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df = train_df.iloc[:int(keep_ratio*train_df.shape[0])]\n",
    "sst_classes = [\"Negative\", \"Positive\"]\n",
    "df = pd.DataFrame(np.concatenate([train_df.values, test_df.values]), columns=train_df.columns)\n",
    "class_id = {c:i for i, c in enumerate(sst_classes)}\n",
    "id_class = {i:c for i, c in enumerate(sst_classes)}\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "vocabs_lists = list(token_vocab_dict.keys())\n",
    "term_frequencies = {t:1 for t in vocabs_lists}\n",
    "temp_term_frequencies = {}\n",
    "\n",
    "for doc in train_df.Content.values:\n",
    "    tokens_list = tokenizer.tokenize(doc)\n",
    "    new_tokens = {t.strip('▁').lower() for t in tokens_list}\n",
    "    for t in new_tokens:\n",
    "        if t not in temp_term_frequencies:\n",
    "            temp_term_frequencies[t] = 0\n",
    "        temp_term_frequencies[t] += 1\n",
    "        \n",
    "for k, v in term_frequencies.items():\n",
    "    stripped_token = k.strip('▁').lower()\n",
    "    term_frequencies[k] = temp_term_frequencies[stripped_token] if stripped_token in temp_term_frequencies else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.00001\n",
    "total_token_count = np.array(list(term_frequencies.values())).sum()\n",
    "one_tensor = torch.tensor(1)\n",
    "def subsampling_equation_linear(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = torch.min(one_tensor, torch.sqrt_(threshold/f_x))\n",
    "    return x\n",
    "\n",
    "def subsampling_equation_sigmoid(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = 1-0.95*F.sigmoid(0.05*((f_x/threshold)-90))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utilities.data_manager.CharacterandTokenLevelCustomDataset import CharacterandTokenLevelCustomDataset\n",
    "from utilities.data_manager.CharacterandTokenLevelDataLoader import CharacterandTokenLevelDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['good']\n",
    "id_vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Batch, Data\n",
    "import random\n",
    "\n",
    "class CharacterandTokenLevelCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, num_classes, token_dict, sentiment_dict, tokenizer, vocab, token_frequencies, sampling_equation, id_class, shuffle=True, batch_size=128) -> None:\n",
    "        super().__init__()\n",
    "        if len(X) % batch_size != 0:\n",
    "            self.shortage = ((len(X) // batch_size)+1)*batch_size - len(X)\n",
    "            empty_labels = [i%2 for i in range(self.shortage)]\n",
    "            empty_strings = [id_class[l] for l in empty_labels]\n",
    "            X = np.concatenate([X, empty_strings])\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.X = X\n",
    "        self.vocab_size = 16384\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "        self.token_dict = token_dict\n",
    "        self.embedding_size = token_vocab_dict[next(iter(token_dict))].shape[0]\n",
    "        self.zero_emb = torch.zeros((self.embedding_size,), dtype=torch.float32)\n",
    "        self.sentiment_dict = sentiment_dict\n",
    "        self.token_frequencies = token_frequencies\n",
    "        self.max_token_count = 0\n",
    "        self.all_data = []\n",
    "        self.token_lengths = []\n",
    "        self.token_embeddign_ids = []\n",
    "        \n",
    "        self.sum_a = 0\n",
    "        \n",
    "        for doc in tqdm(self.X):\n",
    "            g_data = self.content_to_graph(doc, sampling_equation)\n",
    "            self.all_data.append(g_data)\n",
    "        \n",
    "        \n",
    "        self.num_sections = len(X) // batch_size\n",
    "        self.x_lengths = np.array([self.all_data[i].character_length for i in range(len(self.all_data))])\n",
    "        self.x_len_args = np.argsort(self.x_lengths)[::-1]\n",
    "        \n",
    "        self.section_ranges = np.linspace(0, len(self.x_len_args), self.num_sections+1)\n",
    "        self.section_ranges = [(int(self.section_ranges[i-1]), int(self.section_ranges[i])) for i in range(1, len(self.section_ranges))]\n",
    "        \n",
    "\n",
    "        self.position_j = 0\n",
    "        self.section_i = 0\n",
    "        self.epoch = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "        self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        index = self.get_section_index()\n",
    "        ds = self.all_data[index]\n",
    "        cs_pos = ds.cumulative_pos\n",
    "        random_token_id= max(1, random.randint(ds.num_tokens//2 - 1 , ds.num_tokens-2))\n",
    "        new_data = Data(\n",
    "            x=ds.x[:cs_pos[random_token_id-1]+1],\n",
    "            character_length=cs_pos[random_token_id-1]+1,\n",
    "            num_tokens = random_token_id+1,\n",
    "            token_indices = ds.token_indices[:cs_pos[random_token_id-1]+1],\n",
    "            token_lengths = torch.cat([ds.token_lengths[:random_token_id], ds.token_lengths[-1].unsqueeze(0)], dim=0),\n",
    "            token_embeddings = torch.cat([ds.token_embeddings[:random_token_id],ds.token_embeddings[-1].unsqueeze(0)], dim=0),\n",
    "            token_sentiments = torch.cat([ds.token_sentiments[:random_token_id],ds.token_sentiments[-1].unsqueeze(0)], dim=0),\n",
    "            token_subsampling_probabilities = torch.cat([ds.token_subsampling_probabilities[:random_token_id],ds.token_subsampling_probabilities[-1].unsqueeze(0)], dim=0)\n",
    "            ) \n",
    "        new_data.x[-1] = 16300\n",
    "        label = ds.token_ids[random_token_id]\n",
    "        return new_data, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def get_section_index(self):\n",
    "        target_index = self.sections[self.section_i, self.position_j]\n",
    "        \n",
    "        self.position_j = (self.position_j + 1) % self.section_size\n",
    "        if self.position_j == 0:\n",
    "            self.section_i = (self.section_i + 1) % self.num_sections\n",
    "            if self.shuffle and self.section_i == 0:\n",
    "                self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        return target_index\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.section_i = 0\n",
    "        self.position_j = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "    def split_into_k_groups(self, len_sorted_args, lengths:np.array, k):\n",
    "        if self.shuffle and self.epoch > 0:\n",
    "            randomize_sections = np.concatenate([np.random.choice(np.arange(r[0], r[1]), size=r[1]-r[0], replace=False) for r in self.section_ranges])\n",
    "            len_sorted_args = len_sorted_args[randomize_sections]\n",
    "        \n",
    "        nums = lengths[len_sorted_args]\n",
    "        groups_size = len(len_sorted_args) // k\n",
    "        \n",
    "        \n",
    "        groups = [[] for _ in range(k)]\n",
    "        group_sums = np.zeros(k, dtype=int)\n",
    "        group_sizes = np.zeros(k, dtype=int)\n",
    "        \n",
    "        for i, num in enumerate(nums):\n",
    "            candidate_indices = np.where(group_sizes<groups_size)[0]\n",
    "            min_group_idx = candidate_indices[np.argmin(group_sums[candidate_indices])]\n",
    "            groups[min_group_idx].append(len_sorted_args[i])\n",
    "            group_sums[min_group_idx] += num\n",
    "            group_sizes[min_group_idx] += 1\n",
    "        self.epoch += 1\n",
    "        \n",
    "        groups = np.array(groups)\n",
    "        group_sums_argsort = np.argsort(group_sums)[::-1]\n",
    "        groups = groups[group_sums_argsort]\n",
    "        return np.array(groups), groups_size\n",
    "        \n",
    "    def content_to_graph(self, doc, sampling_equation):\n",
    "        tokens = self.tokenizer(doc)\n",
    "        if len(tokens) == 0:\n",
    "            tokens = ['empty']\n",
    "        # while len(tokens) < 3:\n",
    "        #     tokens.append('[PAD]')\n",
    "            \n",
    "        token_lengths = [len(t) for t in tokens]\n",
    "        tokens.append('\\x01')\n",
    "        \n",
    "        token_lengths.append(len(tokens[-1])-1)\n",
    "        token_lengths = torch.from_numpy(np.array(token_lengths, dtype=np.longlong))+1\n",
    "        token_embs = [self.token_dict[t] if t in self.token_dict else self.zero_emb for t in tokens]\n",
    "        token_ids = torch.from_numpy(np.array([self.vocab[t] if t in self.vocab else 0 for t in tokens]))\n",
    "        token_sentiments = [self.sentiment_dict[t] if t in self.sentiment_dict else (0.0, 0.0) for t in tokens]\n",
    "        token_embs = torch.from_numpy(np.array(token_embs, dtype=np.float32))\n",
    "        token_sentiments = torch.from_numpy(np.array(token_sentiments, dtype=np.float32))\n",
    "        doc = ' '.join(tokens)\n",
    "        characters = torch.from_numpy(np.array([ord(t) if ord(t)<16383 else 16383 for t in doc], dtype=np.longlong))\n",
    "        token_positions = torch.arange(len(token_lengths), dtype=torch.long)\n",
    "        token_indices = torch.repeat_interleave(token_positions, token_lengths)\n",
    "        token_subsampling_probabilities = sampling_equation(torch.from_numpy(np.array([self.token_frequencies[t] if t in self.token_frequencies else 1 for t in tokens])))\n",
    "        num_tokens = len(token_lengths)\n",
    "        if num_tokens > self.max_token_count:\n",
    "            self.max_token_count = num_tokens\n",
    "        \n",
    "        cumulative_pos = torch.cumsum(token_lengths, dim=0)    \n",
    "        \n",
    "        g_data = Data(x=characters,\n",
    "                        # token_positions=token_positions,\n",
    "                        token_ids = token_ids,\n",
    "                        character_length = len(characters),\n",
    "                        num_tokens = num_tokens,\n",
    "                        token_indices=token_indices,\n",
    "                        token_lengths=token_lengths,\n",
    "                        token_embeddings=token_embs,\n",
    "                        token_sentiments=token_sentiments,\n",
    "                        cumulative_pos=cumulative_pos,\n",
    "                        token_subsampling_probabilities=token_subsampling_probabilities)\n",
    "        return g_data\n",
    " \n",
    "    def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "        cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "        cumsum_vals[0] = 0\n",
    "        additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "        cumulative_token_indices = token_indices + additions\n",
    "        return cumulative_token_indices       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:15, 64.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:20<00:00, 50.80it/s]\n",
      "100%|██████████| 1024/1024 [00:18<00:00, 55.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 15s\n",
      "Wall time: 39.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = CharacterandTokenLevelCustomDataset(train_df.Content.values, len(class_id), token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, tokenizer.vocab, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, id_class=id_class, batch_size=batch_size)\n",
    "test_dataset = CharacterandTokenLevelCustomDataset(test_df.Content.values, len(class_id), token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, tokenizer.vocab, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, id_class=id_class, batch_size=batch_size)\n",
    "max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = train_dataset[0][0]\n",
    "ds2 = train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1.num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1255, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1.token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'㿼'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(16380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9601,    73,   116,  ...,    62,    32, 16300])\n",
      "tensor([ 9601,    65,    32,  ...,   101,    32, 16380])\n"
     ]
    }
   ],
   "source": [
    "print(ds1.x)\n",
    "ds2.x[-1] = 16380\n",
    "print(ds2.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_token_id= 407 #random.randint(ds.num_tokens//2, ds.num_tokens-1)\n",
    "# cs_pos = torch.cumsum(ds.token_lengths, dim=0)\n",
    "# new_data = Data(\n",
    "#     x=ds.x[:cs_pos[random_token_id-1]],\n",
    "#     character_length=cs_pos[random_token_id-1],\n",
    "#     num_tokens = random_token_id,\n",
    "#     token_indices = ds.token_indices[:cs_pos[random_token_id-1]],\n",
    "#     token_lengths = ds.token_lengths[:random_token_id],\n",
    "#     token_embeddings = ds.token_embeddings[:random_token_id],\n",
    "#     token_sentiments = ds.token_sentiments[:random_token_id],\n",
    "#     token_subsampling_probabilities = ds.token_subsampling_probabilities[:random_token_id]\n",
    "#     ) \n",
    "# label = ds.x[cs_pos[random_token_id-1]:cs_pos[random_token_id-1]+ds.token_lengths[random_token_id]]\n",
    "# print(''.join([chr(id) for id in new_data.x[-new_data.token_lengths[-1]:]]))\n",
    "# print(''.join([chr(id) for id in label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lngths = np.array([len(dss.token_lengths) for dss in train_dataset2.all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lngths.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lngths = np.array([len(dss[0].token_lengths) for dss in train_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3 = X.to_data_list()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁Positive 㾬'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([chr(tid) for tid in ds3.x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.model_layers.GCNN import GCNN\n",
    "from utilities.model_layers.GenGraph2 import GenGraph\n",
    "from utilities.model_layers.SentimentInjection import SentimentInjection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5_restructure_for_contrastive_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGNetTokenLevelEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim=64, hidden_dim=64, dropout=0.2, seed=-1, random_edges=4, lattice_edges=10, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64, step_of_test = 0, head=1, *args, **kwargs):\n",
    "        super(CGNetTokenLevelEmbedding, self).__init__(*args, **kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        self.step_of_test = step_of_test\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    "        self.embedding = nn.Embedding(16384, embedding_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(2*embedding_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.sentiment1  = SentimentInjection(hidden_dim, embedding_dim)\n",
    "        self.sentiment2  = SentimentInjection(hidden_dim, embedding_dim)\n",
    "        self.p_layer_1 = nn.Linear(hidden_dim, head)\n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.p_layer_2 = nn.Linear(hidden_dim, head)\n",
    "        self.gcnn2 = GCNN(hidden_dim+inject_embedding_dim)\n",
    "        self.graph_generator = GenGraph(hidden_dim, 0, lattice_step, head=head)\n",
    "        self.fc0 = nn.Linear(hidden_dim , hidden_dim+inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim+inject_embedding_dim , hidden_dim * 4)\n",
    "    \n",
    "    def forward(self, x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings):\n",
    "        cumulative_token_indices = self.caluculate_batch_token_positions(num_tokens, character_length, token_indices)\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.T\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x1 = scatter_max(x, cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, cumulative_token_indices, dim=1)\n",
    "        x = torch.cat([x1, x2], dim=0)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.sentiment1(x.T, token_sentiments)\n",
    "        rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "        p = self.p_layer_1(x.T)\n",
    "        p = F.softmax(p, dim=1)\n",
    "        ids = torch.argmax(p, dim=1, keepdim=True)\n",
    "        p = torch.zeros_like(p).scatter_(1, ids, torch.ones_like(p)) * token_subsampling_probabilities.unsqueeze(1)\n",
    "        graph = self.graph_generator.gen_graph(x, p, len(token_lengths), num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "        x, edge_weights, edge_index = self.gcnn1(graph.x.T, graph.edge_index, return_attention_weights = True)\n",
    "        edge_weights = edge_weights[1].unsqueeze(-1)\n",
    "        edge_weights = edge_weights[:edge_weights.shape[0], 0]\n",
    "        \n",
    "        p = self.p_layer_2(x)\n",
    "        p = F.softmax(p, dim=1)\n",
    "        ids = torch.argmax(p, dim=1, keepdim=True)\n",
    "        p = torch.zeros_like(p).scatter_(1, ids, torch.ones_like(p)) * token_subsampling_probabilities.unsqueeze(1)\n",
    "        graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, edge_index, p, len(token_lengths), num_tokens, rand_edges-1, lattice_edges-1, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        x = self.sentiment2(x, token_sentiments)\n",
    "        xa = graph.x[:token_embeddings.shape[0]]\n",
    "        xb = token_embeddings\n",
    "        x = torch.cat([xa, xb], dim=1)\n",
    "        x1 = F.relu(self.fc0(graph.x[token_embeddings.shape[0]:]))\n",
    "        x = torch.cat([x, x1], dim=0)\n",
    "        x, edge_weights, edge_index = self.gcnn2(x, graph.edge_index)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "        cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "        cumsum_vals[0] = 0\n",
    "        additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "        cumulative_token_indices = token_indices + additions\n",
    "        return cumulative_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGNetEmbedding(nn.Module):\n",
    "    def __init__(self, token_embedding_model, hidden_dim=64, *args, **kwargs):\n",
    "        super(CGNetEmbedding, self).__init__(*args, **kwargs)\n",
    "        self.token_embedding_model = token_embedding_model\n",
    "        self.fc2 = nn.Linear(hidden_dim * 2 * 4 , hidden_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings):\n",
    "        x = self.token_embedding_model(x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings)\n",
    "        x = F.elu_(x)\n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(num_tokens), device=x.device), num_tokens)\n",
    "        x1 = scatter_max(x[:len(token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(token_lengths)], doc_token_index, dim=0)\n",
    "        x_for_cat = [x1, x2]\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CGNetEmbedding(nn.Module):\n",
    "#     def __init__(self, embedding_dim=64, hidden_dim=64, dropout=0.2, seed=-1, random_edges=4, lattice_edges=10, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64, step_of_test = 0, head=1, *args, **kwargs):\n",
    "#         super(CGNetEmbedding, self).__init__(*args, **kwargs)\n",
    "#         self.embedding_dim = embedding_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.base_random_edges = random_edges\n",
    "#         self.base_lattice_edges = lattice_edges\n",
    "#         self.lattice_start_distance = lattice_start_distance\n",
    "#         self.step_of_test = step_of_test\n",
    "#         if seed>-1:\n",
    "#             torch.manual_seed(seed)\n",
    "#         self.embedding = nn.Embedding(16384, embedding_dim)\n",
    "#         self.dropout = nn.Dropout(p=dropout)\n",
    "#         self.conv1 = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=5, padding=2)\n",
    "#         self.pool1 = nn.MaxPool1d(2)\n",
    "#         self.conv2 = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=5, padding=2)\n",
    "#         self.conv3 = nn.Conv1d(2*embedding_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "#         self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "#         self.sentiment1  = SentimentInjection(hidden_dim, embedding_dim)\n",
    "#         self.sentiment2  = SentimentInjection(hidden_dim, embedding_dim)\n",
    "#         self.p_layer_1 = nn.Linear(hidden_dim, head)\n",
    "#         self.gcnn1 = GCNN(hidden_dim)\n",
    "#         self.p_layer_2 = nn.Linear(hidden_dim, head)\n",
    "#         self.gcnn2 = GCNN(hidden_dim+inject_embedding_dim)\n",
    "#         self.graph_generator = GenGraph(hidden_dim, 0, lattice_step, head=head)\n",
    "#         self.fc0 = nn.Linear(hidden_dim , hidden_dim+inject_embedding_dim)\n",
    "#         self.fc1 = nn.Linear(hidden_dim+inject_embedding_dim , hidden_dim * 4)\n",
    "#         self.fc2 = nn.Linear(hidden_dim * 2 * 4 , hidden_dim)\n",
    "    \n",
    "#     def forward(self, x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings):\n",
    "#         cumulative_token_indices = self.caluculate_batch_token_positions(num_tokens, character_length, token_indices)\n",
    "#         x = self.embedding(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = x.T\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x1 = scatter_max(x, cumulative_token_indices, dim=1)[0]\n",
    "#         x2 = scatter_mean(x, cumulative_token_indices, dim=1)\n",
    "#         x = torch.cat([x1, x2], dim=0)\n",
    "#         x = F.relu(self.conv3(x))\n",
    "#         x = self.sentiment1(x.T, token_sentiments)\n",
    "#         rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "#         p = self.p_layer_1(x.T)\n",
    "#         p = F.softmax(p, dim=1)\n",
    "#         ids = torch.argmax(p, dim=1, keepdim=True)\n",
    "#         p = torch.zeros_like(p).scatter_(1, ids, torch.ones_like(p)) * token_subsampling_probabilities.unsqueeze(1)\n",
    "#         graph = self.graph_generator.gen_graph(x, p, len(token_lengths), num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "#         x, edge_weights, edge_index = self.gcnn1(graph.x.T, graph.edge_index, return_attention_weights = True)\n",
    "#         edge_weights = edge_weights[1].unsqueeze(-1)\n",
    "#         edge_weights = edge_weights[:edge_weights.shape[0], 0]\n",
    "        \n",
    "#         p = self.p_layer_2(x)\n",
    "#         p = F.softmax(p, dim=1)\n",
    "#         ids = torch.argmax(p, dim=1, keepdim=True)\n",
    "#         p = torch.zeros_like(p).scatter_(1, ids, torch.ones_like(p)) * token_subsampling_probabilities.unsqueeze(1)\n",
    "#         graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, edge_index, p, len(token_lengths), num_tokens, rand_edges-1, lattice_edges-1, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "#         x = self.sentiment2(x, token_sentiments)\n",
    "#         xa = graph.x[:token_embeddings.shape[0]]\n",
    "#         xb = token_embeddings\n",
    "#         x = torch.cat([xa, xb], dim=1)\n",
    "#         x1 = F.relu(self.fc0(graph.x[token_embeddings.shape[0]:]))\n",
    "#         x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "#         x, edge_weights, edge_index = self.gcnn2(x, graph.edge_index)\n",
    "        \n",
    "#         x = F.elu_(self.fc1(x))\n",
    "#         doc_token_index = torch.repeat_interleave(torch.arange(len(num_tokens), device=x.device), num_tokens)\n",
    "#         x1 = scatter_max(x[:len(token_lengths)], doc_token_index, dim=0)[0]\n",
    "#         x2 = scatter_mean(x[:len(token_lengths)], doc_token_index, dim=0)\n",
    "#         x_for_cat = [x1, x2]\n",
    "#         x = torch.cat(x_for_cat, dim=1)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "    \n",
    "#     def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "#         cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "#         cumsum_vals[0] = 0\n",
    "#         additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "#         cumulative_token_indices = token_indices + additions\n",
    "#         return cumulative_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_for_Text_No_Positional_Encoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_model: CGNetEmbedding, hidden_dim=64, dropout=0.3, num_out_features=4, *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text_No_Positional_Encoding, self).__init__(*args, **kwargs)\n",
    "        self.embedding_model = embedding_model\n",
    "        self.num_out_features= num_out_features\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, self.num_out_features)\n",
    "    \n",
    "    def forward(self, x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings):\n",
    "        x = F.elu_(self.embedding_model(x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths=token_lengths, num_tokens=num_tokens, character_length=character_length, token_embeddings=token_embeddings))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module                                    FLOP    % Total\n",
      "-------------------------------------  -------  ---------\n",
      " CGNetEmbedding.token_embedding_model  74.220B     99.91%\n",
      "  - aten.convolution                   56.879B     76.57%\n",
      "  - aten.addmm                         17.341B     23.34%\n",
      "CGNetEmbedding                         74.287B    100.00%\n",
      " - aten.convolution                    56.879B     76.57%\n",
      " - aten.addmm                          17.408B     23.43%\n",
      " CGNetEmbedding.fc2                     0.067B      0.09%\n",
      "  - aten.addmm                          0.067B      0.09%\n"
     ]
    }
   ],
   "source": [
    "# for p1 in [False, True]:\n",
    "#     for p2 in [False, True]:\n",
    "#         for p3 in [False, True]:\n",
    "# print(f'\\n{p1}, {p2}, {p3}: \\n')\n",
    "token_embedding_model = CGNetTokenLevelEmbedding(embedding_dim=64, hidden_dim=128, dropout=0.2,  seed=911, random_edges=4, lattice_edges=4, lattice_step=2, lattice_start_distance=2)\n",
    "embedding_model = CGNetEmbedding(token_embedding_model, hidden_dim=128).eval()\n",
    "\n",
    "# embedding_model = CGNetEmbedding(embedding_dim=64, hidden_dim=128, dropout=0.2,  seed=911, random_edges=4, lattice_edges=4, lattice_step=2, lattice_start_distance=2)\n",
    "classifier_torch_model = CNN_for_Text_No_Positional_Encoding(embedding_model, hidden_dim=64, dropout=0.2, num_out_features=len(class_id)).eval()\n",
    "flopt_counter = FlopCounterMode(embedding_model)\n",
    "with flopt_counter:\n",
    "    embedding_model(X.x, torch.zeros((2, 0)), X.token_subsampling_probabilities, X.token_indices, X.token_sentiments, token_lengths=X.token_lengths, num_tokens=X.num_tokens, character_length=X.character_length, token_embeddings=X.token_embeddings)\n",
    "    # classifier_torch_model(X.x, torch.zeros((2, 0)), X.token_subsampling_probabilities, X.token_indices, X.token_sentiments, X.token_lengths, X.num_tokens, X.character_length, X.token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "import torch\n",
    "# from scripts.managers.ModelManager import ModelManager\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from torch_geometric.nn import summary\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "from os import path\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "import lightning as L\n",
    "from utilities.managers.ModelManager import ModelManager\n",
    "from utilities.callbacks.CustomModelCheckpoint import CustomModelCheckpoint\n",
    "\n",
    "class ClassifierModelManager(ModelManager):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 num_train_epoch = 100,\n",
    "                 accumulate_grad_batches=1):\n",
    "        super(ClassifierModelManager, self).__init__(torch_model, lightning_model, model_save_dir, log_dir, log_name, device, num_train_epoch, accumulate_grad_batches=accumulate_grad_batches)\n",
    "\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        return [\n",
    "            CustomModelCheckpoint(save_top_k=2, mode='max', monitor='val_acc', save_last=True, save_weights_only=True),\n",
    "            # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "        ]\n",
    "\n",
    "    def draw_summary(self, dataloader):\n",
    "        X, y = next(iter(dataloader))\n",
    "        print(summary(self.torch_model, X.to(self.device)))\n",
    "\n",
    "    def plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    def save_plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc'], name_prepend: str=\"\"):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        \n",
    "        loss_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_loss_metric.png')\n",
    "        plt.savefig(loss_png)\n",
    "        \n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        \n",
    "        acc_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_acc_metric.png')\n",
    "        plt.savefig(acc_png)\n",
    "        \n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate(self, eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.lightning_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        # if(give_hinge_loss):\n",
    "        #     print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')\n",
    "                \n",
    "    def evaluate_best_models(self, eval_dataloader,\n",
    "                             give_confusion_matrix: bool=True, \n",
    "                             give_report: bool=True, \n",
    "                             give_f1_score: bool=False, \n",
    "                             give_accuracy_score: bool=False, \n",
    "                             give_precision_score: bool=False, \n",
    "                             give_recall_score: bool=False, \n",
    "                             give_hinge_loss: bool=False,\n",
    "                             multi_class: bool=False, **kwargs):\n",
    "        \n",
    "        model = self.trainer.model.model\n",
    "        # self.lightning_model = lightning_type.load_from_checkpoint(rf'{self.trainer.checkpoint_callback.best_model_path}', map_location=None, hparams_file=None, strict=True, **kwargs).eval()\n",
    "        self.lightning_model.model.load_state_dict(torch.load(rf'{self.trainer.checkpoint_callback.best_model_path}', weights_only=True, map_location=None))\n",
    "        self.save_evaluation(self.lightning_model, eval_dataloader, 'best_model', give_confusion_matrix, give_report,\n",
    "                             give_f1_score, give_accuracy_score, give_precision_score, give_recall_score, give_hinge_loss, multi_class)\n",
    "            \n",
    "    def save_evaluation(self, model, eval_dataloader, name_prepend: str='',\n",
    "                    give_confusion_matrix: bool=True, \n",
    "                    give_report: bool=True, \n",
    "                    give_f1_score: bool=False, \n",
    "                    give_accuracy_score: bool=False, \n",
    "                    give_precision_score: bool=False, \n",
    "                    give_recall_score: bool=False, \n",
    "                    give_hinge_loss: bool=False,\n",
    "                    multi_class: bool=False\n",
    "                    ):\n",
    "            \n",
    "            test_metrics_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_test_metrics.txt')\n",
    "            \n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            model = model.eval()\n",
    "            for X, y in eval_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    y_p = model(X.to(self.device))\n",
    "                if type(y_p) is tuple:\n",
    "                    y_p = y_p[0]\n",
    "                \n",
    "                if multi_class:\n",
    "                    y_pred.append(y_p.detach().to(y.device))\n",
    "                    y_true.append(y)\n",
    "                else:\n",
    "                    y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "                    y_true.append(y.to(torch.int32))\n",
    "                    \n",
    "            y_true = torch.concat(y_true)\n",
    "            y_pred = torch.concat(y_pred)\n",
    "            print(y_true.shape)\n",
    "            print(y_pred.shape)\n",
    "            if multi_class:\n",
    "                y_true_num = torch.argmax(y_true, dim=1)\n",
    "                y_pred_num = torch.argmax(y_pred, dim=1)\n",
    "            else:\n",
    "                y_true_num = y_true\n",
    "                y_pred_num = y_pred\n",
    "                \n",
    "            print(y_true_num.shape)\n",
    "            print(y_pred_num.shape)\n",
    "            with open(test_metrics_path, 'at+') as f:\n",
    "                if(give_confusion_matrix):\n",
    "                    print(f'confusion_matrix: \\n{confusion_matrix(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_report):\n",
    "                    print(classification_report(y_true_num, y_pred_num), file=f)\n",
    "                if(give_f1_score):\n",
    "                    if multi_class:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_accuracy_score):\n",
    "                    print(f'accuracy_score: {accuracy_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_precision_score):\n",
    "                    if multi_class:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_recall_score):\n",
    "                    if multi_class:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num)}', file=f)\n",
    "                # if(give_hinge_loss):\n",
    "                #     print(f'hinge_loss: {hinge_loss(y_true_num, y_pred)}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.managers.ModelManager import ModelManager\n",
    "from utilities.managers.ClassifierModelManager import ClassifierModelManager\n",
    "from utilities.lightning_models.CGNetEmbeddingLightningModel import CGNetEmbeddingLightningModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 64\n",
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning as L\n",
    "import torchmetrics\n",
    "\n",
    "class CGNetEmbeddingLightningModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        num_classes,\n",
    "        optimizer=None,\n",
    "        loss_func=None,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=64,\n",
    "        lr_scheduler=None,\n",
    "        user_lr_scheduler=False,\n",
    "        min_lr=0.0,\n",
    "    ):\n",
    "        super(CGNetEmbeddingLightningModel, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.min_lr = min_lr\n",
    "        # self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        self.optimizer = self._get_optimizer(optimizer)\n",
    "        self.lr_scheduler = (\n",
    "            self._get_lr_scheduler(lr_scheduler) if user_lr_scheduler else None\n",
    "        )\n",
    "        self.loss_func = loss_func\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x.x, torch.zeros((2, 0)), x.token_subsampling_probabilities, x.token_indices, x.token_sentiments, x.token_lengths, x.num_tokens, x.character_length, x.token_embeddings)\n",
    "\n",
    "    def on_train_epoch_start(self) -> None:\n",
    "        param_groups = next(iter(self.optimizer.param_groups))\n",
    "        if \"lr\" in param_groups and param_groups[\"lr\"] is not None:\n",
    "            current_learning_rate = float(param_groups[\"lr\"])\n",
    "            self.log(\n",
    "                \"lr\",\n",
    "                current_learning_rate,\n",
    "                batch_size=self.batch_size,\n",
    "                on_epoch=True,\n",
    "                on_step=False,\n",
    "            )\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.train()\n",
    "        y_out = self(X)\n",
    "\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.train_losses.append(loss.detach().item())\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        self.train_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        y_out = self(X)\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.val_losses.append(loss.detach().item())\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.val_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.lr_scheduler is None:\n",
    "            return self.optimizer\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": self.lr_scheduler,\n",
    "                \"monitor\": \"train_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def update_learning_rate(self, learning_rate: float):\n",
    "        self.learning_rate = learning_rate\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g[\"lr\"] = learning_rate\n",
    "\n",
    "    def _get_optimizer(self, optimizer):\n",
    "        return (\n",
    "            optimizer\n",
    "            if optimizer is not None\n",
    "            else torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        )\n",
    "\n",
    "    def _get_lr_scheduler(self, lr_scheduler):\n",
    "        return (\n",
    "            lr_scheduler\n",
    "            if lr_scheduler is not None\n",
    "            else torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer, patience=5, factor=0.5, mode=\"min\", min_lr=self.min_lr\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, dropout=0.25, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True, use_positional_encoder=[False, False, False]):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    embedding_model = CGNetEmbedding(embedding_dim=embedding_dim, hidden_dim=hidden_dim, dropout=dropout,  seed=seed, random_edges=6, lattice_edges=10, lattice_step=2, lattice_start_distance=2).to(device)\n",
    "    classifier_torch_model = CNN_for_Text_No_Positional_Encoding(embedding_model, hidden_dim=hidden_dim, dropout=dropout, num_out_features=len(class_id)).to(device)\n",
    "    \n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 40, 45,50,55],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CGNetEmbeddingLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name=f'CNN-GNN_{use_positional_encoder[0]}_{use_positional_encoder[1]}_{use_positional_encoder[2]}',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    train_dataset.reset_params()\n",
    "    train_dataset.position_j = 0\n",
    "    test_dataset.reset_params()\n",
    "    test_dataset.position_j = 0\n",
    "    \n",
    "    # train_dataset.section_i = 0\n",
    "    # train_dataset.each_section_i = np.zeros((train_dataset.num_sections, ), dtype=int)\n",
    "    # test_dataset.section_i = 0\n",
    "    # test_dataset.each_section_i = np.zeros((test_dataset.num_sections, ), dtype=int)\n",
    "    \n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.lightning_model.model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(model_manager.lightning_model, test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                                | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0 | model     | CNN_for_Text_No_Positional_Encoding | 1.3 M  | train\n",
      "1 | loss_func | BCEWithLogitsLoss                   | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy                  | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy                  | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy                  | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.255     Total estimated model params size (MB)\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1afc52a4d344c4963e5263682e3d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad227a98e10c4cdaad1cda01401d4cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19dd924764f04da285c746587cc54bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddc8274a4144fc495c47a818d3399be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a7bbaa733349a5921d4bce1ed68355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a6f831b0d84d06818976e972dd8c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f83bccfc4094d11bd8c8bf3cc704bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7094f9caad74d1186957f0b1e578dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8cee56550d412a9518aedf6258fd52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15a7a4d250a47a3a0d29efb0ea6c09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cc695a8fd74bdda94035b8c924da50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e86a4bf22b4879b96332dfc6707dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14c442803fe41deaffc195494e0b29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfde88dbb3f4e96b5cd06adcca5902d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a724eb36f74d21b00642a2aeb3d5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f840d5cad1d943349f5835eef52c2488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9129f0ffe6b34431bc1617b6e2c4e4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d210b8bb08e94db7b6bd48fce4b660a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bf5a9dce714890a376312a468b08da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18685109067c48c6b7cf02c7ace2852a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b55fd0ce2549f1ae5245b0f2ce11e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c6eb7de7614fcb998536bbee893552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15540a8f3b2c4716945097d99eeff946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e207fe1bc89f4191b97bdf70cfd15edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e40da4b121a4118ad2ae03c7db25265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389d1a466961455f8a520bba5c6c6f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad8e7fe7b7644ef9cda0435b5a0a540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb7667fe7514d0988594b3b5ba85e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2425eb45d65480c83b737e014269bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1385942addc5447e93e75db63e6ee99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6278e07750a4de9954bda9805529824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62abb4f0f35348ea8e5f22f670a5e414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1fd5b0ce0b4cafa035a6590e3d3269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115fa32ff4fd4937b7fa4f9b82262336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff0b9ec4dc44dc9aa97422bb8a8e11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e06287dbba24894aae45c08bd685bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611cefb1e76e4c6d83324dd7f3e65e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25739dc0b1e4b4b8e360928a264ec1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcce9a148e04e349fdb6418364e6f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9bee5d0c8c4d9c97159b4a62a1433f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ad010576fc4915a1c7f94628357ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a98dac09464f9aa6db9518373c6659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62466221a549462eb27183dc8c572c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9349c9cac764cd6ae7e0133a4568c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ea6d03113549fc85abe3de09e3f622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b247dac8fbc4b11b17c82592ab0b49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111bd52fa4984e1881ceab2850884d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98ef79452f44eeb8f17275b340ec15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe07147eeaee4f1f9af93d19965b0006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04db34e6e534881858756d721889465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65290dd12fd4152a0084e54bb015326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adb0a0ab07843c697ee9234921b5f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d230f5a119594aa49b412cc3f251d61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf7e0e75da44c70a1101c3d036f025a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0935728e75644f3b94cc947816c5803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662389549f134e82b0da1ac9eace9696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b516e6c7ba24e619b797ad5f814c78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1eeb5e974f44ce9ac798b8eb75c6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439d7132d9ae4e00910053b1e7fd1ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6722696371394642858f08785c5fc531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c129bb89a94ba9961a66c26bf55403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fd5ea036cd4e319547e916f654e568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2175fb32a2af4a9981e8201fb9322566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05f78bbc81e4c67a147b5042a182e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34568fc79e414718b79336c2d2f06ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a745e942a38d4091ac16cc795e467084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761fbcfdc94e4dbdb77164fde003f778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7c058705de4e5f95157e7ef4775140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1862aaf9763455ea8dd7e0dae831d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac951bcad0d413d9a78249c15636b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6738e88e83e44b89dc85e31cf6436bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=70` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25088, 2])\n",
      "torch.Size([25088, 2])\n",
      "torch.Size([25088])\n",
      "torch.Size([25088])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:15<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9499    0.8418    0.8926     12544\n",
      "           1     0.8580    0.9556    0.9042     12544\n",
      "\n",
      "    accuracy                         0.8987     25088\n",
      "   macro avg     0.9039    0.8987    0.8984     25088\n",
      "weighted avg     0.9039    0.8987    0.8984     25088\n",
      "\n",
      "confusion matrix:\n",
      " tensor([[10560,  1984],\n",
      "        [  557, 11987]])\n",
      "================================\n",
      "torch.Size([25088, 2])\n",
      "torch.Size([25088, 2])\n",
      "torch.Size([25088])\n",
      "torch.Size([25088])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_manager = train_model(70, 0.2, 0.000012, 0.0032, use_positional_encoder=[False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "def calculatge_metrics(chpt_path, target_data_loader):\n",
    "    \n",
    "    embedding_model = CGNetEmbedding(embedding_dim=embedding_dim, hidden_dim=hidden_dim, dropout=0.2,  seed=seed, random_edges=6, lattice_edges=10, lattice_step=2, lattice_start_distance=2)\n",
    "    classifier_torch_model = CNN_for_Text_No_Positional_Encoding(embedding_model, hidden_dim=hidden_dim, dropout=0.2, num_out_features=len(class_id))\n",
    "    \n",
    "    classifier_torch_model.load_state_dict(torch.load(chpt_path, weights_only=True, map_location=\"cuda:0\"))\n",
    "    classfier_lightning_model = CGNetEmbeddingLightningModel(classifier_torch_model, \n",
    "                                                    num_classes=len(class_id),\n",
    "                                            batch_size=batch_size,\n",
    "                                            user_lr_scheduler=True\n",
    "                                            ).to(device).eval()\n",
    "    \n",
    "    mean_infer_acc = []\n",
    "    mean_infer_f1 = []\n",
    "    mean_infer_prec = []\n",
    "    mean_infer_rec = []\n",
    "    for i in range(5):\n",
    "        all_ys = []\n",
    "        all_y_preds = []\n",
    "        for X, y in target_data_loader:\n",
    "            with torch.no_grad():\n",
    "                y_pred = classfier_lightning_model(X.to(device))\n",
    "            all_ys.append(torch.argmax(y,dim=1))\n",
    "            all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "        all_ys = torch.concat(all_ys)\n",
    "        all_y_preds = torch.concat(all_y_preds)\n",
    "        \n",
    "        cm = confusion_matrix(all_ys, all_y_preds, labels=list(id_class.keys()))\n",
    "        \n",
    "        accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "        precision = np.mean(np.diag(cm) / (np.sum(cm, axis=0)+0.000001))\n",
    "        recall = np.mean(np.diag(cm) / (np.sum(cm, axis=1)+0.000001))\n",
    "        f1_score = (2*precision*recall)/(precision + recall+0.000001)\n",
    "        \n",
    "        mean_infer_acc.append(accuracy)\n",
    "        mean_infer_f1.append(f1_score)\n",
    "        mean_infer_prec.append(precision)\n",
    "        mean_infer_rec.append(recall)\n",
    "    mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "    mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "    mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "    mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "    return mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "def get_best_chpt(metrics_path, epoch_numbers):\n",
    "    epoch_data = pd.read_csv(metrics_path)\n",
    "    if 'val_acc_epoch' in epoch_data.columns and epoch_data['val_acc_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_acc_epoch'].idxmax()]\n",
    "    elif 'val_loss_epoch' in epoch_data.columns and epoch_data['val_loss_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_loss_epoch'].idxmin()]\n",
    "    else:\n",
    "        raise ValueError(f\"No valid validation metrics available for epoch {epoch_numbers}.\")\n",
    "    return np.argwhere(np.array(epoch_numbers)==best_chpt['epoch']).item(), best_chpt['val_loss_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_metrics_mean(base_path = 'logs\\CNN-GNN18_mr2k_seeds', start=0, interval=1):\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "    total_loss = []\n",
    "    \n",
    "    for i in range(start, start + interval):\n",
    "        version_path = join(base_path, f'version_{i}')\n",
    "        checkpoint_path = join(version_path, f'checkpoints')\n",
    "        onlyfiles  = [f for f in listdir(checkpoint_path) if (isfile(join(checkpoint_path, f)) and 'epoch' in f) ]\n",
    "        epoch_numbers = [int(re.search(r'\\d+', f).group()) for f in onlyfiles]\n",
    "        best_chpt_id, loss = get_best_chpt(join(version_path, 'metrics.csv'), epoch_numbers)\n",
    "        print(onlyfiles[best_chpt_id])\n",
    "        mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model = calculatge_metrics(join(checkpoint_path, f'{onlyfiles[best_chpt_id]}'), test_dataloader)\n",
    "            \n",
    "        total_accuracy.append(mean_infer_acc)\n",
    "        total_f1.append(mean_infer_f1)\n",
    "        total_prec.append(mean_infer_prec)\n",
    "        total_rec.append(mean_infer_rec)\n",
    "        total_loss.append(loss)\n",
    "\n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    total_loss = torch.mean(torch.tensor(total_loss))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')\n",
    "    print(f'total_loss: {total_loss}')\n",
    "    return classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=26-step=2646.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.9081951530612244\n",
      "total_f1: 0.9082070482356379\n",
      "total_prec: 0.9082199438493459\n",
      "total_rec: 0.9081951529888237\n",
      "total_loss: 0.2710480690002441\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(r'logs\\CNN-GNN_False_False_False', start=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=52-step=20723.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.9022218670076727\n",
      "total_f1: 0.9022369648498394\n",
      "total_prec: 0.9022530633260486\n",
      "total_rec: 0.9022218669355642\n",
      "total_loss: 0.250955730676651\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(r'logs\\CNN-GNN_False_False_False', start=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
