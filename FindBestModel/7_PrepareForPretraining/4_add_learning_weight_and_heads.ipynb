{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch_scatter import scatter_max, scatter_mean\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from torch import nn\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "folder_path = r'C:\\Users\\fardin\\Projects\\CGNet\\Data\\TextClassification\\IMDB'\n",
    "# t_tokenizer = TweetTokenizer()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085 tensor([0.7000, 0.6000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "id_vocab = {v:k for k,v in tokenizer.vocab.items()}\n",
    "all_vocab_indices = list(id_vocab.keys())\n",
    "\n",
    "with open(r'Data\\ReducedEmbeddings\\deberta_larg_reduced_embeddings_64.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "all_vocab_str = []\n",
    "for i in range(len(id_vocab)):\n",
    "    all_vocab_str.append(id_vocab[i])\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))\n",
    "\n",
    "with open(r'Data\\ReducedEmbeddings\\polarity_debertav3_tokens_gpt_mini_emb.npy', 'rb') as f:\n",
    "    polarities_subjectivities= np.load(f)\n",
    "polarities_subjectivities = torch.from_numpy(polarities_subjectivities)\n",
    "polarity_vocab_dict = dict(zip(all_vocab_str, polarities_subjectivities))\n",
    "polarity_vocab_dict['<n>'] = torch.tensor([0.0, 0.0])\n",
    "len(token_vocab_dict)\n",
    "polarities_subjectivities.shape\n",
    "for i in range(len(all_vocab_str)):\n",
    "    if 'nice' in all_vocab_str[i]:\n",
    "        print(i, polarities_subjectivities[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_ratio = 0.1\n",
    "test_df = pd.read_csv(r'data\\TextClassification\\IMDB\\test.csv')\n",
    "test_df['Topic'] = test_df['label']\n",
    "test_df['Content'] = test_df['text']\n",
    "test_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.iloc[:int(keep_ratio*test_df.shape[0])]\n",
    "train_df = pd.read_csv(r'data\\TextClassification\\IMDB\\train.csv')\n",
    "train_df['Topic'] = train_df['label']\n",
    "train_df['Content'] = train_df['text']\n",
    "train_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df = train_df.iloc[:int(keep_ratio*train_df.shape[0])]\n",
    "sst_classes = [\"Negative\", \"Positive\"]\n",
    "df = pd.DataFrame(np.concatenate([train_df.values, test_df.values]), columns=train_df.columns)\n",
    "class_id = {c:i for i, c in enumerate(sst_classes)}\n",
    "id_class = {i:c for i, c in enumerate(sst_classes)}\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "vocabs_lists = list(token_vocab_dict.keys())\n",
    "term_frequencies = {t:1 for t in vocabs_lists}\n",
    "temp_term_frequencies = {}\n",
    "\n",
    "for doc in train_df.Content.values:\n",
    "    tokens_list = tokenizer.tokenize(doc)\n",
    "    new_tokens = {t.strip('▁').lower() for t in tokens_list}\n",
    "    for t in new_tokens:\n",
    "        if t not in temp_term_frequencies:\n",
    "            temp_term_frequencies[t] = 0\n",
    "        temp_term_frequencies[t] += 1\n",
    "        \n",
    "for k, v in term_frequencies.items():\n",
    "    stripped_token = k.strip('▁').lower()\n",
    "    term_frequencies[k] = temp_term_frequencies[stripped_token] if stripped_token in temp_term_frequencies else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.00001\n",
    "total_token_count = np.array(list(term_frequencies.values())).sum()\n",
    "one_tensor = torch.tensor(1)\n",
    "def subsampling_equation_linear(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = torch.min(one_tensor, torch.sqrt_(threshold/f_x))\n",
    "    return x\n",
    "\n",
    "def subsampling_equation_sigmoid(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = 1-0.95*F.sigmoid(0.05*((f_x/threshold)-90))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.data_manager.CharacterandTokenLevelCustomDataset import CharacterandTokenLevelCustomDataset\n",
    "from utilities.data_manager.CharacterandTokenLevelDataLoader import CharacterandTokenLevelDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2560/2560 [00:35<00:00, 72.94it/s] \n",
      "100%|██████████| 2560/2560 [00:34<00:00, 74.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 34s\n",
      "Wall time: 1min 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = CharacterandTokenLevelCustomDataset(train_df.Content.values, train_df.Topic.values, len(class_id), token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, id_class=id_class, batch_size=batch_size)\n",
    "test_dataset = CharacterandTokenLevelCustomDataset(test_df.Content.values, test_df.Topic.values, len(class_id), token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, id_class=id_class, batch_size=batch_size)\n",
    "max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.model_layers.GCNN import GCNN\n",
    "# from utilities.model_layers.GenGraph import GenGraph\n",
    "from utilities.model_layers.SentimentInjection import SentimentInjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch_geometric.data import Batch, Data\n",
    "\n",
    "class GenGraph(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, virtual_nodes, lattice_step, lattice_pattern=None, head=4, *args, **kwargs):\n",
    "        super(GenGraph, self).__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.head = head\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.lattice_step = lattice_step\n",
    "        self.lp = lattice_pattern if lattice_pattern is None else torch.tensor(lattice_pattern)\n",
    "        self.virtual_node_embeddings = nn.Embedding(self.virtual_nodes, hidden_dim)\n",
    "        \n",
    "    def gen_graph(self, x, token_subsampling_probabilities, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        v_n_e_counts = total_token_counts*self.virtual_nodes\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        edge_indices = torch.empty((2, base_numel + v_n_e_counts*2), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(edge_indices, random_links, lattice_links, tc_range)\n",
    "            \n",
    "        if self.virtual_nodes > 0:\n",
    "            virtual_nodes_range = torch.arange(self.virtual_nodes, device=x.device).view(1, -1)\n",
    "            virtual_nodes_ids = torch.repeat_interleave(virtual_nodes_range, len(token_counts), dim=0)\n",
    "            v_n_idx = (virtual_nodes_ids + torch.arange(0, len(token_counts)*self.virtual_nodes, self.virtual_nodes, device=x.device).view(-1, 1) + total_token_counts )\n",
    "            virtual_edge_ids = torch.repeat_interleave(v_n_idx.view(-1), token_counts.view(-1, 1).expand(len(token_counts), self.virtual_nodes).reshape(-1), dim=0).view(1, -1)\n",
    "            \n",
    "            embs = self.virtual_node_embeddings(virtual_nodes_ids.T).view(-1, self.hidden_dim)\n",
    "            x_extended = torch.cat([x, embs], dim=0)\n",
    "            x_index = torch.arange(total_token_counts, device=x.device).repeat(self.virtual_nodes).view(1, -1)\n",
    "            edge_indices[:, base_numel:base_numel+v_n_e_counts] = torch.cat([x_index, virtual_edge_ids], dim=0)\n",
    "            edge_indices[:, base_numel+v_n_e_counts:] = torch.cat([virtual_edge_ids, x_index], dim=0)\n",
    "            x = x_extended\n",
    "        \n",
    "        edge_indices = self.subsample_edges(edge_indices, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_indices)])\n",
    "        \n",
    "    def re_gen_graph(self, x, edge_indices, token_subsampling_probabilities, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        self.fill_lattice_and_random_edges(edge_indices, random_links, lattice_links, tc_range)\n",
    "        # for i in range(base.shape[1]):\n",
    "        #     edge_indices[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        edge_indices = self.subsample_edges(edge_indices, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_indices)])\n",
    "    \n",
    "    def replace_unimportant_edges(self, edge_weights, x, edge_indices, token_subsampling_probabilities, total_token_counts, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2):\n",
    "        v_n_e_counts = total_token_counts*self.virtual_nodes\n",
    "        # if v_n_e_counts>0:\n",
    "        #     important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # else:\n",
    "        #     print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "        #     print(f'total_token_coutns: {total_token_coutns}')\n",
    "        #     print(f'p_keep: {p_keep}')\n",
    "        #     important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "        # print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "        # print(f'edge_indices.shape: {edge_indices.shape}')\n",
    "        # print(f'1: edge_weights: {edge_weights.shape}')\n",
    "        important_indices = torch.topk(edge_weights.squeeze(), p_keep*total_token_counts, dim=0).indices\n",
    "        # print(f'2: important_indices: {important_indices.shape}')\n",
    "        # print(f'2.5: \\n {edge_weights} \\n\\n {important_indices}')\n",
    "\n",
    "        # important_indices = torch.arange(total_token_counts, dtype=torch.int64, device=x.device)\n",
    "        # important_indices = important_indices.view(-1)\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        # print(f'3: random_links: {random_links.shape}, lattice_links: {lattice_links.shape}, tc_range: {tc_range.shape},')\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        # print(f'4: base_numel: {base_numel}')\n",
    "        \n",
    "        new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "        # print(f'5: new_edge_index: {new_edge_index.shape}')\n",
    "        # print(f'new_edge_index.shape 1: {new_edge_index.shape}, base_numel + important_indices.shape[0] + 2*v_n_e_counts: {base_numel + important_indices.shape[0] + 2*v_n_e_counts}')\n",
    "        self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "        # print(f'6: new_edge_index: {new_edge_index.shape}, random_links: {random_links.shape}, lattice_links: {lattice_links.shape}, tc_range: {tc_range.shape}')\n",
    "        # print(f'new_edge_index.shape 2: {new_edge_index.shape}, edge_indices: {edge_indices.shape}, important_indices shape: {important_indices.shape}, important_indices max: {important_indices.max()}')\n",
    "        new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_indices[:, important_indices]\n",
    "        # print(f'7: new_edge_index: {new_edge_index.shape}')\n",
    "\n",
    "        if(self.virtual_nodes>0):\n",
    "            new_edge_index[:, -2*v_n_e_counts:] = edge_indices[:, -2*v_n_e_counts:]\n",
    "            \n",
    "        # for i in range(base.shape[1]):\n",
    "        #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        # print(f'7.5: \\n {new_edge_index} \\n\\n {token_subsampling_probabilities}')\n",
    "        new_edge_index = self.subsample_edges(new_edge_index, token_subsampling_probabilities)\n",
    "        \n",
    "        return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "    \n",
    "        \n",
    "    def calculate_graph(self, x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance):\n",
    "\n",
    "        tc_extended = torch.repeat_interleave(token_counts, token_counts, dim=0).view(-1,1)\n",
    "        tc_lower_bound = torch.empty((len(token_counts)+1), dtype=torch.long, device=x.device) #torch.cuda.IntTensor(len(token_counts)+1) #\n",
    "        tc_lower_bound[0] = 0\n",
    "        tc_lower_bound[1:] = torch.cumsum(token_counts, dim=0)\n",
    "        tc_lower_bound_extended = torch.repeat_interleave(tc_lower_bound[:-1], token_counts, dim=0).view(-1,1)\n",
    "        tc_range = torch.arange(tc_lower_bound[-1], device=x.device).view(-1,1)\n",
    "        # torch.arange(tc_lower_bound[-1], dtype=torch.int32, device=x.device).view(-1,1)\n",
    "        \n",
    "        random_ints = torch.randint(0, 2*total_token_counts, (total_token_counts, random_edges), device=x.device) # torch.cuda.IntTensor(len(token_lengths), random_edges).random_()\n",
    "        lattice = self.lp.to(x.device) if self.lp is not None else torch.arange(lattice_start_distance, max(lattice_start_distance, self.lattice_step*lattice_edges+1), self.lattice_step, device=x.device).view(1, -1)\n",
    "        \n",
    "\n",
    "        # exponentials = torch.pow(2, torch.arange(1, self.exp_edges+1, device=x.device)).view(1, -1)\n",
    "        tc_local_range = tc_range - tc_lower_bound_extended\n",
    "        random_links = (((random_ints % (tc_extended - 1))+1 + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        lattice_links = ((lattice + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        \n",
    "        # base = torch.cat([base1, base2], dim=1)\n",
    "        tc_range = tc_range.view(1,-1)\n",
    "        return random_links, lattice_links, tc_range\n",
    "    \n",
    "    def fill_lattice_and_random_edges(self, edge_indices, random_links, lattice_links, tc_range):\n",
    "        for i in range(0, lattice_links.shape[1]*2, 2):\n",
    "            edge_indices[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]] = torch.cat([lattice_links[:,i//2].view(1,-1), tc_range], dim=0)\n",
    "            edge_indices[:, (i+1)*lattice_links.shape[0]:(i+2)*lattice_links.shape[0]] = edge_indices[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]][[1, 0]]\n",
    "            \n",
    "        for i in range(random_links.shape[1]):\n",
    "            j = i + lattice_links.shape[1]*2\n",
    "            edge_indices[:, j*random_links.shape[0]:(j+1)*random_links.shape[0]] = torch.cat([random_links[:,i].view(1,-1), tc_range], dim=0)\n",
    "            \n",
    "    def subsample_edges(self, edge_indices, token_subsampling_probabilities, keep_ratio=0.5):\n",
    "        top_k_indices = torch.topk(torch.sum(token_subsampling_probabilities[edge_indices], dim=0), int(keep_ratio*edge_indices.shape[1]/self.head), dim=0).indices\n",
    "        edge_indices = edge_indices[:, top_k_indices].reshape(2, -1)\n",
    "        return edge_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGNetEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim=64, hidden_dim=64, dropout=0.2, seed=-1, random_edges=4, lattice_edges=10, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64, step_of_test = 0, head=4, *args, **kwargs):\n",
    "        super(CGNetEmbedding, self).__init__(*args, **kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        self.step_of_test = step_of_test\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    "        self.embedding = nn.Embedding(16384, embedding_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(2*hidden_dim + 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.sentiment1  = SentimentInjection(hidden_dim)\n",
    "        self.sentiment2  = SentimentInjection(hidden_dim)\n",
    "        self.p_layer_1 = nn.Linear(hidden_dim, head)\n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.p_layer_2 = nn.Linear(hidden_dim, head)\n",
    "        self.gcnn2 = GCNN(hidden_dim+inject_embedding_dim)\n",
    "        self.graph_generator = GenGraph(hidden_dim, 0, lattice_step, head=head)\n",
    "        self.fc0 = nn.Linear(hidden_dim , hidden_dim+inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim+inject_embedding_dim , hidden_dim * 4)\n",
    "        self.fc2 = nn.Linear(hidden_dim * 2 * 4 , hidden_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings):\n",
    "        cumulative_token_indices = self.caluculate_batch_token_positions(num_tokens, character_length, token_indices)\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.T\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x1 = scatter_max(x, cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, cumulative_token_indices, dim=1)\n",
    "        x = torch.cat([x1, x2, token_sentiments.T], dim=0)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.sentiment1(x.T, token_sentiments)\n",
    "        rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "        p = self.p_layer_1(x.T)\n",
    "        p = F.softmax(p, dim=1)\n",
    "        ids = torch.argmax(p, dim=1, keepdim=True)\n",
    "        p = torch.zeros_like(p).scatter_(1, ids, torch.ones_like(p)) * token_subsampling_probabilities.unsqueeze(1)\n",
    "        graph = self.graph_generator.gen_graph(x, p, len(token_lengths), num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "        x, edge_weights, edge_index = self.gcnn1(graph.x.T, graph.edge_index, return_attention_weights = True)\n",
    "        edge_weights = edge_weights[1].unsqueeze(-1)\n",
    "        edge_weights = edge_weights[:edge_weights.shape[0], 0]\n",
    "        \n",
    "        p = self.p_layer_2(x)\n",
    "        p = F.softmax(p, dim=1)\n",
    "        ids = torch.argmax(p, dim=1, keepdim=True)\n",
    "        p = torch.zeros_like(p).scatter_(1, ids, torch.ones_like(p)) * token_subsampling_probabilities.unsqueeze(1)\n",
    "        graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, edge_index, p, len(token_lengths), num_tokens, rand_edges-1, lattice_edges-1, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        x = self.sentiment2(x, token_sentiments)\n",
    "        xa = graph.x[:token_embeddings.shape[0]]\n",
    "        xb = token_embeddings\n",
    "        x = torch.cat([xa, xb], dim=1)\n",
    "        x1 = F.relu(self.fc0(graph.x[token_embeddings.shape[0]:]))\n",
    "        x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "        x, edge_weights, edge_index = self.gcnn2(x, graph.edge_index)\n",
    "        \n",
    "        x = F.elu_(self.fc1(x))\n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(num_tokens), device=x.device), num_tokens)\n",
    "        x1 = scatter_max(x[:len(token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(token_lengths)], doc_token_index, dim=0)\n",
    "        x_for_cat = [x1, x2]\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "        cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "        cumsum_vals[0] = 0\n",
    "        additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "        cumulative_token_indices = token_indices + additions\n",
    "        return cumulative_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_for_Text_No_Positional_Encoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_model: CGNetEmbedding, hidden_dim=64, dropout=0.3, num_out_features=4, *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text_No_Positional_Encoding, self).__init__(*args, **kwargs)\n",
    "        self.embedding_model = embedding_model\n",
    "        self.num_out_features= num_out_features\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, self.num_out_features)\n",
    "    \n",
    "    def forward(self, x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings):\n",
    "        x = F.elu_(self.embedding_model(x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module                                                   FLOP    % Total\n",
      "----------------------------------------------------  -------  ---------\n",
      " CNN_for_Text_No_Positional_Encoding.embedding_model  14.260B    100.00%\n",
      "  - aten.convolution                                  12.228B     85.75%\n",
      "  - aten.addmm                                         2.032B     14.25%\n",
      "CNN_for_Text_No_Positional_Encoding                   14.260B    100.00%\n",
      " - aten.convolution                                   12.228B     85.75%\n",
      " - aten.addmm                                          2.032B     14.25%\n",
      " CNN_for_Text_No_Positional_Encoding.fc_out            0.000B      0.00%\n",
      "  - aten.addmm                                         0.000B      0.00%\n"
     ]
    }
   ],
   "source": [
    "# for p1 in [False, True]:\n",
    "#     for p2 in [False, True]:\n",
    "#         for p3 in [False, True]:\n",
    "# print(f'\\n{p1}, {p2}, {p3}: \\n')\n",
    "embedding_model = CGNetEmbedding(embedding_dim=64, hidden_dim=64, dropout=0.2,  seed=911, random_edges=4, lattice_edges=4, lattice_step=2, lattice_start_distance=2).eval()\n",
    "classifier_torch_model = CNN_for_Text_No_Positional_Encoding(embedding_model, hidden_dim=64, dropout=0.2, num_out_features=len(class_id)).eval()\n",
    "flopt_counter = FlopCounterMode(classifier_torch_model)\n",
    "with flopt_counter:\n",
    "    classifier_torch_model(X.x, torch.zeros((2, 0)), X.token_subsampling_probabilities, X.token_indices, X.token_sentiments, X.token_lengths, X.num_tokens, X.character_length, X.token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.managers.ModelManager import ModelManager\n",
    "from utilities.managers.ClassifierModelManager import ClassifierModelManager\n",
    "from utilities.lightning_models.CGNetEmbeddingLightningModel import CGNetEmbeddingLightningModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 128\n",
    "hidden_dim = 128\n",
    "embedding_dim = 128\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning as L\n",
    "import torchmetrics\n",
    "\n",
    "class CGNetEmbeddingLightningModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        num_classes,\n",
    "        optimizer=None,\n",
    "        loss_func=None,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=64,\n",
    "        lr_scheduler=None,\n",
    "        user_lr_scheduler=False,\n",
    "        min_lr=0.0,\n",
    "    ):\n",
    "        super(CGNetEmbeddingLightningModel, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.min_lr = min_lr\n",
    "        # self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        self.optimizer = self._get_optimizer(optimizer)\n",
    "        self.lr_scheduler = (\n",
    "            self._get_lr_scheduler(lr_scheduler) if user_lr_scheduler else None\n",
    "        )\n",
    "        self.loss_func = loss_func\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x.x, torch.zeros((2, 0)), x.token_subsampling_probabilities, x.token_indices, x.token_sentiments, x.token_lengths, x.num_tokens, x.character_length, x.token_embeddings)\n",
    "\n",
    "    def on_train_epoch_start(self) -> None:\n",
    "        param_groups = next(iter(self.optimizer.param_groups))\n",
    "        if \"lr\" in param_groups and param_groups[\"lr\"] is not None:\n",
    "            current_learning_rate = float(param_groups[\"lr\"])\n",
    "            self.log(\n",
    "                \"lr\",\n",
    "                current_learning_rate,\n",
    "                batch_size=self.batch_size,\n",
    "                on_epoch=True,\n",
    "                on_step=False,\n",
    "            )\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.train()\n",
    "        y_out = self(X)\n",
    "\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.train_losses.append(loss.detach().item())\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        self.train_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        y_out = self(X)\n",
    "        loss = self.loss_func(y_out.view(y.shape), y )\n",
    "        self.val_losses.append(loss.detach().item())\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.val_acc(torch.argmax(y_out, dim=1), torch.argmax(y, dim=1))\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.lr_scheduler is None:\n",
    "            return self.optimizer\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": self.lr_scheduler,\n",
    "                \"monitor\": \"train_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def update_learning_rate(self, learning_rate: float):\n",
    "        self.learning_rate = learning_rate\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g[\"lr\"] = learning_rate\n",
    "\n",
    "    def _get_optimizer(self, optimizer):\n",
    "        return (\n",
    "            optimizer\n",
    "            if optimizer is not None\n",
    "            else torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        )\n",
    "\n",
    "    def _get_lr_scheduler(self, lr_scheduler):\n",
    "        return (\n",
    "            lr_scheduler\n",
    "            if lr_scheduler is not None\n",
    "            else torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer, patience=5, factor=0.5, mode=\"min\", min_lr=self.min_lr\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, dropout=0.25, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True, use_positional_encoder=[False, False, False]):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    embedding_model = CGNetEmbedding(embedding_dim=embedding_dim, hidden_dim=hidden_dim, dropout=dropout,  seed=seed, random_edges=6, lattice_edges=10, lattice_step=2, lattice_start_distance=2).to(device)\n",
    "    classifier_torch_model = CNN_for_Text_No_Positional_Encoding(embedding_model, hidden_dim=hidden_dim, dropout=dropout, num_out_features=len(class_id)).to(device)\n",
    "    \n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 40, 45,50,55],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CGNetEmbeddingLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name=f'CNN-GNN_{use_positional_encoder[0]}_{use_positional_encoder[1]}_{use_positional_encoder[2]}',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    train_dataset.reset_params()\n",
    "    train_dataset.position_j = 0\n",
    "    test_dataset.reset_params()\n",
    "    test_dataset.position_j = 0\n",
    "    \n",
    "    # train_dataset.section_i = 0\n",
    "    # train_dataset.each_section_i = np.zeros((train_dataset.num_sections, ), dtype=int)\n",
    "    # test_dataset.section_i = 0\n",
    "    # test_dataset.each_section_i = np.zeros((test_dataset.num_sections, ), dtype=int)\n",
    "    \n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.lightning_model.model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(model_manager.lightning_model, test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                                | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0 | model     | CNN_for_Text_No_Positional_Encoding | 3.0 M  | train\n",
      "1 | loss_func | BCEWithLogitsLoss                   | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy                  | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy                  | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy                  | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "3.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 M     Total params\n",
      "12.105    Total estimated model params size (MB)\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:298: The number of training batches (40) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7971918fd3e940a4a07a0dbe17a046dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42723d20389b4258a076e74bf9032fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea318db80054dcc86b0a6e3b7c1a414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c905f151634f6299626ef0461a54a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c23c0f5b2346d7a5d5a00f2e6a861e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81be76169c6b4612a92073c2779bbc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6304dd13467d49f2acb65475f0e17f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1085ad9ca75d4330988cb0c59969f8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71e9133de1240629228641382df3376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54478f9949d142f4b46fef3f095848cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6cfce85e5549eabf36739d096f580c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697d677774654b6eae98bb80adabb612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ce5efcf3ba4e88bcaa3b3ea525e7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94aabf3a112d419c820731586bb78592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d36353d5594dde92cc87353feddb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efff789a5dd4f08be6aeab612112d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1272741aca734d888f4e56868898e38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392780af37bb4d09a1ac3ffd62b9473b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdab2f564b8b477d871d962d00877995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd515f7324641b785641db14f9d1f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61bad4676664a128fe3917e72d46f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975675dbf4a0440684dceda442660dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf63d4aeae9947fd8894b6ca2076c319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef70dc588c1a4049b1ad8a0f826be6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac3fbf96dca444fbbf61afe0d690410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c9d58edd1942fc954e53fd70262dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5851d7a56e543fc96bf64c2676283fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e48269db2e94aedbc3db7a66bcc4405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d191f78acb48dfb27d56c6ac11cfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa337e5e9e14b988183f1384c9af4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471cc62a2a484b63bf05ad328d68eada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185628263bbe434889b6a1c489c619aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c06e8dff8342269be6c487a047e314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6a59ff06324eeeb2154a63a2c09c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d881d908773c4225811b074831ba2750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626a6d5231ef4702b2079cefa7bdda9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e839ad5b8ca4f009e26a86bd2fc624c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2766e30d048d4dffb5b30f61d969d61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c47fc814394e5ab66c7055df707cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e494b99a249e4cd389003ff6806348da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83abb2d1bae143bea7886fee65d59a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e45b5af46a4d738c4092d588e1af52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd43d04dcc846a4937dd0f38648e6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67614f77f267402eb851fa66efa2d7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860a59bf43204080be9c0218ae5c22c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fde19a63864926b409c5dcfd630fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b61aeb6c54b4857ae2fd782968d260a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bcc08775064d4ab2148686d6e81e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26d0b0dfb5c401193b6a39e5b10f2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101fceef2be7473782cd84e3195e95d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354e4ff3d6a442af868b2306ef84c02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f4809ae657435289759fd2d7d6e61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f03c8c1f8e249c3b109383362c9a9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d141e762a5f54d55bf0fb2351335cd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f08e2a77a9a4bd9aae333ce97352f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74567294192649659f01538cf783d802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597d28f682764e309a582a5cc761f7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b251e59db0924b2ba49ad190d396933a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d89b3a5da2437aa0919f74766089c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411418b381a34f50970ed28bfe9e1b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d3c964cd7c4d1d87efa235d605b6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55fe923195e4599966933ee3d08790f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bc66e9c9744a86a2617feb25af11cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdab48b1a4134e12a7e305c05edd5acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f656f5a2964e01b6d02dc6c57e0d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d400bf73f099408bb831ad3d9281231e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53406caa40584bee8f86b8470fcc9362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2626b1426bae4738aa7fd33be4953eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f07472bce1547e59ebb3e806424767c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595c89f7029442b695d4fc28881907eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52cfb4f1d3940a5816cc12c26636c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=70` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2560, 2])\n",
      "torch.Size([2560, 2])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:04<00:00,  9.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8361    0.8563    0.8461      1287\n",
      "           1     0.8510    0.8303    0.8406      1273\n",
      "\n",
      "    accuracy                         0.8434      2560\n",
      "   macro avg     0.8436    0.8433    0.8433      2560\n",
      "weighted avg     0.8435    0.8434    0.8433      2560\n",
      "\n",
      "confusion matrix:\n",
      " tensor([[1102,  185],\n",
      "        [ 216, 1057]])\n",
      "================================\n",
      "torch.Size([2560, 2])\n",
      "torch.Size([2560, 2])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_manager = train_model(70, 0.2, 0.000012, 0.0032, use_positional_encoder=[False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "def calculatge_metrics(chpt_path, target_data_loader):\n",
    "    \n",
    "    embedding_model = CGNetEmbedding(embedding_dim=embedding_dim, hidden_dim=hidden_dim, dropout=0.2,  seed=seed, random_edges=6, lattice_edges=10, lattice_step=2, lattice_start_distance=2)\n",
    "    classifier_torch_model = CNN_for_Text_No_Positional_Encoding(embedding_model, hidden_dim=hidden_dim, dropout=0.2, num_out_features=len(class_id))\n",
    "    \n",
    "    classifier_torch_model.load_state_dict(torch.load(chpt_path, weights_only=True, map_location=\"cuda:0\"))\n",
    "    classfier_lightning_model = CGNetEmbeddingLightningModel(classifier_torch_model, \n",
    "                                                    num_classes=len(class_id),\n",
    "                                            batch_size=batch_size,\n",
    "                                            user_lr_scheduler=True\n",
    "                                            ).to(device).eval()\n",
    "    \n",
    "    mean_infer_acc = []\n",
    "    mean_infer_f1 = []\n",
    "    mean_infer_prec = []\n",
    "    mean_infer_rec = []\n",
    "    for i in range(5):\n",
    "        all_ys = []\n",
    "        all_y_preds = []\n",
    "        for X, y in target_data_loader:\n",
    "            with torch.no_grad():\n",
    "                y_pred = classfier_lightning_model(X.to(device))\n",
    "            all_ys.append(torch.argmax(y,dim=1))\n",
    "            all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "        all_ys = torch.concat(all_ys)\n",
    "        all_y_preds = torch.concat(all_y_preds)\n",
    "        \n",
    "        cm = confusion_matrix(all_ys, all_y_preds, labels=list(id_class.keys()))\n",
    "        \n",
    "        accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "        precision = np.mean(np.diag(cm) / (np.sum(cm, axis=0)+0.000001))\n",
    "        recall = np.mean(np.diag(cm) / (np.sum(cm, axis=1)+0.000001))\n",
    "        f1_score = (2*precision*recall)/(precision + recall+0.000001)\n",
    "        \n",
    "        mean_infer_acc.append(accuracy)\n",
    "        mean_infer_f1.append(f1_score)\n",
    "        mean_infer_prec.append(precision)\n",
    "        mean_infer_rec.append(recall)\n",
    "    mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "    mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "    mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "    mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "    return mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "def get_best_chpt(metrics_path, epoch_numbers):\n",
    "    epoch_data = pd.read_csv(metrics_path)\n",
    "    if 'val_acc_epoch' in epoch_data.columns and epoch_data['val_acc_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_acc_epoch'].idxmax()]\n",
    "    elif 'val_loss_epoch' in epoch_data.columns and epoch_data['val_loss_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_loss_epoch'].idxmin()]\n",
    "    else:\n",
    "        raise ValueError(f\"No valid validation metrics available for epoch {epoch_numbers}.\")\n",
    "    return np.argwhere(np.array(epoch_numbers)==best_chpt['epoch']).item(), best_chpt['val_loss_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_metrics_mean(base_path = 'logs\\CNN-GNN18_mr2k_seeds', start=0, interval=1):\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "    total_loss = []\n",
    "    \n",
    "    for i in range(start, start + interval):\n",
    "        version_path = join(base_path, f'version_{i}')\n",
    "        checkpoint_path = join(version_path, f'checkpoints')\n",
    "        onlyfiles  = [f for f in listdir(checkpoint_path) if (isfile(join(checkpoint_path, f)) and 'epoch' in f) ]\n",
    "        epoch_numbers = [int(re.search(r'\\d+', f).group()) for f in onlyfiles]\n",
    "        best_chpt_id, loss = get_best_chpt(join(version_path, 'metrics.csv'), epoch_numbers)\n",
    "        print(onlyfiles[best_chpt_id])\n",
    "        mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model = calculatge_metrics(join(checkpoint_path, f'{onlyfiles[best_chpt_id]}'), test_dataloader)\n",
    "            \n",
    "        total_accuracy.append(mean_infer_acc)\n",
    "        total_f1.append(mean_infer_f1)\n",
    "        total_prec.append(mean_infer_prec)\n",
    "        total_rec.append(mean_infer_rec)\n",
    "        total_loss.append(loss)\n",
    "\n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    total_loss = torch.mean(torch.tensor(total_loss))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')\n",
    "    print(f'total_loss: {total_loss}')\n",
    "    return classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=27-step=1120.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.844375\n",
      "total_f1: 0.8443766098241637\n",
      "total_prec: 0.8443736205825403\n",
      "total_rec: 0.844380599101893\n",
      "total_loss: 0.8474971652030945\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(r'logs\\CNN-GNN_False_False_False', start=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[100642], token_positions=[18859], character_length=[64], num_tokens=[64], token_indices=[100642], token_lengths=[18859], token_embeddings=[18859, 64], token_sentiments=[18859, 2], token_subsampling_probabilities=[18859], batch=[100642], ptr=[65], cumulative_token_indices=[100642])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier_lightning_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
