{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch_scatter import scatter_max, scatter_mean\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from torch import nn\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vocab = {v:k for k,v in tokenizer.vocab.items()}\n",
    "all_vocab_indices = list(id_vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation\n",
    "all_chars = set(allowed_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Data\\ReducedEmbeddings\\deberta_larg_reduced_embeddings_64.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "all_vocab_str = []\n",
    "for i in range(len(id_vocab)):\n",
    "    all_vocab_str.append(id_vocab[i])\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'Data\\ReducedEmbeddings\\polarity_debertav3_tokens_gpt_mini_emb.npy', 'rb') as f:\n",
    "    polarities_subjectivities= np.load(f)\n",
    "polarities_subjectivities = torch.from_numpy(polarities_subjectivities)\n",
    "polarity_vocab_dict = dict(zip(all_vocab_str, polarities_subjectivities))\n",
    "polarity_vocab_dict['<n>'] = torch.tensor([0.0, 0.0])\n",
    "len(token_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' \\t'\n",
    "all_chars = set(allowed_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 256\n",
    "folder_path = r'C:\\Users\\fardin\\Projects\\CGNet\\Data\\TextClassification\\IMDB'\n",
    "# t_tokenizer = TweetTokenizer()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_ratio = 0.1\n",
    "test_df = pd.read_csv(r'data\\TextClassification\\IMDB\\test.csv')\n",
    "test_df['Topic'] = test_df['label']\n",
    "test_df['Content'] = test_df['text']\n",
    "test_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.iloc[:int(keep_ratio*test_df.shape[0])]\n",
    "train_df = pd.read_csv(r'data\\TextClassification\\IMDB\\train.csv')\n",
    "train_df['Topic'] = train_df['label']\n",
    "train_df['Content'] = train_df['text']\n",
    "train_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df = train_df.iloc[:int(keep_ratio*train_df.shape[0])]\n",
    "sst_classes = [\"Negative\", \"Positive\"]\n",
    "df = pd.DataFrame(np.concatenate([train_df.values, test_df.values]), columns=train_df.columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = {c:i for i, c in enumerate(sst_classes)}\n",
    "id_class = {i:c for i, c in enumerate(sst_classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "vocabs_lists = list(token_vocab_dict.keys())\n",
    "term_frequencies = {t:1 for t in vocabs_lists}\n",
    "temp_term_frequencies = {}\n",
    "\n",
    "char_set = set()\n",
    "for doc in train_df.Content.values:\n",
    "    tokens_list = tokenizer.tokenize(doc)\n",
    "    char_set.update(set(' '.join(tokens_list)))\n",
    "    char_set.update(set(doc))\n",
    "    new_tokens = {t.strip('▁').lower() for t in tokens_list}\n",
    "    for t in new_tokens:\n",
    "        if t not in temp_term_frequencies:\n",
    "            temp_term_frequencies[t] = 0\n",
    "        temp_term_frequencies[t] += 1\n",
    "        \n",
    "for k, v in term_frequencies.items():\n",
    "    stripped_token = k.strip('▁').lower()\n",
    "    term_frequencies[k] = temp_term_frequencies[stripped_token] if stripped_token in temp_term_frequencies else 1\n",
    "\n",
    "# del temp_term_frequencies\n",
    "    \n",
    "for doc in test_df.Content.values:\n",
    "    char_set.update(set(' '.join(tokenizer.tokenize(doc))))\n",
    "    char_set.update(set(doc))\n",
    "len(char_set)\n",
    "\n",
    "allowed_chars = string.ascii_letters + string.digits + string.punctuation + ' '\n",
    "all_chars = sorted(list(set(''.join(char_set).join(allowed_chars))))\n",
    "vocab_dict = {c:i for i, c in enumerate(all_chars)}  # [Problems]\n",
    "if '\\x01' not in vocab_dict:\n",
    "    vocab_dict['\\x01'] = len(vocab_dict)\n",
    "char_Set = set(vocab_dict.keys())\n",
    "num_embedding = len(vocab_dict)\n",
    "vocab_dict_rev = dict(zip(list(vocab_dict.values()), list(vocab_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.00001\n",
    "total_token_count = np.array(list(term_frequencies.values())).sum()\n",
    "one_tensor = torch.tensor(1)\n",
    "def subsampling_equation_linear(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = torch.min(one_tensor, torch.sqrt_(threshold/f_x))\n",
    "    return x\n",
    "\n",
    "def subsampling_equation_sigmoid(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = 1-0.95*F.sigmoid(0.05*((f_x/threshold)-90))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterandTokenLevelCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, num_classes, char_dict, token_dict, sentiment_dict, tokenizer, token_frequencies, sampling_equation, shuffle=True, batch_size=128) -> None:\n",
    "        super().__init__()\n",
    "        if len(y) % batch_size != 0:\n",
    "            self.shortage = ((len(y) // batch_size)+1)*batch_size - len(y)\n",
    "            empty_labels = [i%2 for i in range(self.shortage)]\n",
    "            empty_strings = [id_class[l] for l in empty_labels]\n",
    "            y = np.concatenate([y, empty_labels])\n",
    "            X = np.concatenate([X, empty_strings])\n",
    "        \n",
    "        y = torch.from_numpy(y)\n",
    "        self.shuffle = shuffle\n",
    "        self.y = torch.nn.functional.one_hot(y, num_classes=num_classes).float()\n",
    "        self.X = X\n",
    "        self.char_dict = char_dict\n",
    "        self.char_Set = set(char_dict.keys())\n",
    "        self.vocab_size = len(self.char_dict)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_dict = token_dict\n",
    "        self.sentiment_dict = sentiment_dict\n",
    "        self.token_frequencies = token_frequencies\n",
    "        self.max_token_count = 0\n",
    "        self.all_data = []\n",
    "        self.token_lengths = []\n",
    "        self.token_embeddign_ids = []\n",
    "        \n",
    "        self.sum_a = 0\n",
    "        \n",
    "        for doc in tqdm(self.X):\n",
    "            g_data = self.content_to_graph(doc, sampling_equation)\n",
    "            self.all_data.append(g_data)\n",
    "        \n",
    "        \n",
    "        self.num_sections = len(y) // batch_size\n",
    "        self.x_lengths = np.array([self.all_data[i].character_length for i in range(len(self.all_data))])\n",
    "        self.x_len_args = np.argsort(self.x_lengths)[::-1]\n",
    "        \n",
    "        self.section_ranges = np.linspace(0, len(self.x_len_args), self.num_sections+1)\n",
    "        self.section_ranges = [(int(self.section_ranges[i-1]), int(self.section_ranges[i])) for i in range(1, len(self.section_ranges))]\n",
    "\n",
    "        self.position_j = 0\n",
    "        self.section_i = 0\n",
    "        self.epoch = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "        self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        index = self.get_section_index()\n",
    "        return self.all_data[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def get_section_index(self):\n",
    "        target_index = self.sections[self.section_i, self.position_j]\n",
    "        \n",
    "        self.position_j = (self.position_j + 1) % self.section_size\n",
    "        if self.position_j == 0:\n",
    "            self.section_i = (self.section_i + 1) % self.num_sections\n",
    "            if self.shuffle and self.section_i == 0:\n",
    "                self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        return target_index\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.section_i = 0\n",
    "        self.position_j = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "    def split_into_k_groups(self, len_sorted_args, lengths:np.array, k):\n",
    "        if self.shuffle and self.epoch > 0:\n",
    "            randomize_sections = np.concatenate([np.random.choice(np.arange(r[0], r[1]), size=r[1]-r[0], replace=False) for r in self.section_ranges])\n",
    "            len_sorted_args = len_sorted_args[randomize_sections]\n",
    "        \n",
    "        nums = lengths[len_sorted_args]\n",
    "        groups_size = len(len_sorted_args) // k\n",
    "        \n",
    "        \n",
    "        groups = [[] for _ in range(k)]\n",
    "        group_sums = np.zeros(k, dtype=int)\n",
    "        group_sizes = np.zeros(k, dtype=int)\n",
    "        \n",
    "        for i, num in enumerate(nums):\n",
    "            candidate_indices = np.where(group_sizes<groups_size)[0]\n",
    "            min_group_idx = candidate_indices[np.argmin(group_sums[candidate_indices])]\n",
    "            groups[min_group_idx].append(len_sorted_args[i])\n",
    "            group_sums[min_group_idx] += num\n",
    "            group_sizes[min_group_idx] += 1\n",
    "        self.epoch += 1\n",
    "        \n",
    "        groups = np.array(groups)\n",
    "        group_sums_argsort = np.argsort(group_sums)[::-1]\n",
    "        groups = groups[group_sums_argsort]\n",
    "        return np.array(groups), groups_size\n",
    "        \n",
    "    def content_to_graph(self, doc, sampling_equation):\n",
    "        tokens = self.tokenizer(doc)\n",
    "        if len(tokens) == 0:\n",
    "            tokens = ['empty']\n",
    "                        \n",
    "        token_lengths = [len(t) for t in tokens]\n",
    "        tokens.append('\\x01')\n",
    "        \n",
    "        token_lengths.append(len(tokens[-1])-1)\n",
    "        token_lengths = torch.from_numpy(np.array(token_lengths, dtype=np.longlong))+1\n",
    "        token_embs = [self.token_dict[t] if t in self.token_dict else torch.zeros((64, ), dtype=torch.float32) for t in tokens]\n",
    "        token_sentiments = [self.sentiment_dict[t] if t in self.sentiment_dict else (0.0, 0.0) for t in tokens]\n",
    "        token_embs = torch.from_numpy(np.array(token_embs, dtype=np.float32))\n",
    "        token_sentiments = torch.from_numpy(np.array(token_sentiments, dtype=np.float32))\n",
    "        doc = ' '.join(tokens)\n",
    "        characters = torch.from_numpy(np.array([self.char_dict[t] for t in doc], dtype=np.longlong))\n",
    "        token_positions = torch.arange(len(token_lengths), dtype=torch.long)\n",
    "        token_indices = torch.repeat_interleave(token_positions, token_lengths)\n",
    "        token_subsampling_probabilities = sampling_equation(torch.from_numpy(np.array([self.token_frequencies[t] if t in self.token_frequencies else 1 for t in tokens])))\n",
    "        num_tokens = len(token_lengths)\n",
    "        if num_tokens > self.max_token_count:\n",
    "            self.max_token_count = num_tokens\n",
    "        g_data = Data(x=characters,\n",
    "                        token_positions=token_positions,\n",
    "                        character_length = len(characters),\n",
    "                        num_tokens = num_tokens,\n",
    "                        token_indices=token_indices,\n",
    "                        token_lengths=token_lengths,\n",
    "                        token_embeddings=token_embs,\n",
    "                        token_sentiments=token_sentiments,\n",
    "                        token_subsampling_probabilities=token_subsampling_probabilities)\n",
    "        return g_data\n",
    " \n",
    "    def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "        cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "        cumsum_vals[0] = 0\n",
    "        additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "        cumulative_token_indices = token_indices + additions\n",
    "        return cumulative_token_indices       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CharacterandTokenLevelDataLoader(DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        follow_batch: List[str] | None = None,\n",
    "        exclude_keys: List[str] | None = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CharacterandTokenLevelDataLoader, self).__init__(\n",
    "            dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        base_iterator = super(CharacterandTokenLevelDataLoader, self).__iter__()\n",
    "        for batch in base_iterator:\n",
    "            cumsum_vals = torch.cumsum(batch[0].num_tokens, dim=0).roll(1)\n",
    "            cumsum_vals[0] = 0\n",
    "            additions = torch.repeat_interleave(cumsum_vals, batch[0].character_length)\n",
    "            batch[0].cumulative_token_indices = batch[0].token_indices + additions\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2560 [00:00<00:41, 61.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2560/2560 [00:42<00:00, 60.69it/s]\n",
      "100%|██████████| 2560/2560 [00:42<00:00, 60.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 8s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = CharacterandTokenLevelCustomDataset(train_df.Content.values, train_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, batch_size=batch_size)\n",
    "test_dataset = CharacterandTokenLevelCustomDataset(test_df.Content.values, test_df.Topic.values, len(class_id), vocab_dict, token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, batch_size=batch_size)\n",
    "max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv\n",
    "\n",
    "# Normalization on each feature of all tokens, for this we used batch norm class but with tokens at batch dimention\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, *args, **kwargs):\n",
    "        super(GCNN, self).__init__(*args, **kwargs)\n",
    "        self.gnn = GATv2Conv(hidden_dim, hidden_dim//8, heads=4, add_self_loops=False)\n",
    "        self.conv = nn.Conv1d(hidden_dim, hidden_dim//2, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim//2)\n",
    "        \n",
    "    def forward(self, x, edge_data, return_attention_weights = False):\n",
    "        x1, edge_weights = self.gnn(x, edge_data, return_attention_weights=return_attention_weights) \n",
    "        x2 = F.relu(self.conv(x.T).T)\n",
    "        x1 = F.leaky_relu_(self.bn1(x1))\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        return x, edge_weights, edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, to_undirected\n",
    "\n",
    "class GenGraph(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, virtual_nodes, lattice_step, lattice_pattern=None, *args, **kwargs):\n",
    "        super(GenGraph, self).__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.lattice_step = lattice_step\n",
    "        self.lp = lattice_pattern if lattice_pattern is None else torch.tensor(lattice_pattern)\n",
    "        self.virtual_node_embeddings = nn.Embedding(self.virtual_nodes, hidden_dim)\n",
    "        \n",
    "    def gen_graph(self, x, token_subsampling_probabilities, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        v_n_e_counts = total_token_counts*self.virtual_nodes\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        edge_indices = torch.empty((2, base_numel + v_n_e_counts*2), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(edge_indices, random_links, lattice_links, tc_range)\n",
    "            \n",
    "        if self.virtual_nodes > 0:\n",
    "            virtual_nodes_range = torch.arange(self.virtual_nodes, device=x.device).view(1, -1)\n",
    "            virtual_nodes_ids = torch.repeat_interleave(virtual_nodes_range, len(token_counts), dim=0)\n",
    "            v_n_idx = (virtual_nodes_ids + torch.arange(0, len(token_counts)*self.virtual_nodes, self.virtual_nodes, device=x.device).view(-1, 1) + total_token_counts )\n",
    "            virtual_edge_ids = torch.repeat_interleave(v_n_idx.view(-1), token_counts.view(-1, 1).expand(len(token_counts), self.virtual_nodes).reshape(-1), dim=0).view(1, -1)\n",
    "            \n",
    "            embs = self.virtual_node_embeddings(virtual_nodes_ids.T).view(-1, self.hidden_dim)\n",
    "            x_extended = torch.cat([x, embs], dim=0)\n",
    "            x_index = torch.arange(total_token_counts, device=x.device).repeat(self.virtual_nodes).view(1, -1)\n",
    "            edge_indices[:, base_numel:base_numel+v_n_e_counts] = torch.cat([x_index, virtual_edge_ids], dim=0)\n",
    "            edge_indices[:, base_numel+v_n_e_counts:] = torch.cat([virtual_edge_ids, x_index], dim=0)\n",
    "            x = x_extended\n",
    "        \n",
    "        edge_indices = self.subsample_edges(edge_indices, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_indices)])\n",
    "        \n",
    "    def re_gen_graph(self, x, edge_indices, token_subsampling_probabilities, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        self.fill_lattice_and_random_edges(edge_indices, random_links, lattice_links, tc_range)\n",
    "        # for i in range(base.shape[1]):\n",
    "        #     edge_indices[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        edge_indices = self.subsample_edges(edge_indices, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_indices)])\n",
    "    \n",
    "    def replace_unimportant_edges(self, edge_weights, x, edge_indices, token_subsampling_probabilities, total_token_counts, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2):\n",
    "        v_n_e_counts = total_token_counts*self.virtual_nodes\n",
    "        # if v_n_e_counts>0:\n",
    "        #     important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # else:\n",
    "        #     print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "        #     print(f'total_token_coutns: {total_token_coutns}')\n",
    "        #     print(f'p_keep: {p_keep}')\n",
    "        #     important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "        # print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "        # print(f'edge_indices.shape: {edge_indices.shape}')\n",
    "        # print(f'1: edge_weights: {edge_weights.shape}')\n",
    "        important_indices = torch.topk(edge_weights.squeeze(), p_keep*total_token_counts, dim=0).indices\n",
    "        # print(f'2: important_indices: {important_indices.shape}')\n",
    "        # print(f'2.5: \\n {edge_weights} \\n\\n {important_indices}')\n",
    "\n",
    "        # important_indices = torch.arange(total_token_counts, dtype=torch.int64, device=x.device)\n",
    "        # important_indices = important_indices.view(-1)\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        # print(f'3: random_links: {random_links.shape}, lattice_links: {lattice_links.shape}, tc_range: {tc_range.shape},')\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        # print(f'4: base_numel: {base_numel}')\n",
    "        \n",
    "        new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "        # print(f'5: new_edge_index: {new_edge_index.shape}')\n",
    "        # print(f'new_edge_index.shape 1: {new_edge_index.shape}, base_numel + important_indices.shape[0] + 2*v_n_e_counts: {base_numel + important_indices.shape[0] + 2*v_n_e_counts}')\n",
    "        self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "        # print(f'6: new_edge_index: {new_edge_index.shape}, random_links: {random_links.shape}, lattice_links: {lattice_links.shape}, tc_range: {tc_range.shape}')\n",
    "        # print(f'new_edge_index.shape 2: {new_edge_index.shape}, edge_indices: {edge_indices.shape}, important_indices shape: {important_indices.shape}, important_indices max: {important_indices.max()}')\n",
    "        new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_indices[:, important_indices]\n",
    "        # print(f'7: new_edge_index: {new_edge_index.shape}')\n",
    "\n",
    "        if(self.virtual_nodes>0):\n",
    "            new_edge_index[:, -2*v_n_e_counts:] = edge_indices[:, -2*v_n_e_counts:]\n",
    "            \n",
    "        # for i in range(base.shape[1]):\n",
    "        #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        # print(f'7.5: \\n {new_edge_index} \\n\\n {token_subsampling_probabilities}')\n",
    "        new_edge_index = self.subsample_edges(new_edge_index, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "    \n",
    "    # def replace_unimportant_edges(self, edge_weights, x, edge_index, token_subsampling_probabilities, total_token_coutns, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2, seed=-1):\n",
    "    #     v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "    #     if v_n_e_counts>0:\n",
    "    #         important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "    #     else:\n",
    "    #         print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "    #         print(f'total_token_coutns: {total_token_coutns}')\n",
    "    #         print(f'p_keep: {p_keep}')\n",
    "    #         important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "    #     # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "\n",
    "    #     important_indices = torch.arange(total_token_coutns, dtype=torch.int64, device=x.device) + important_indices*total_token_coutns\n",
    "    #     important_indices = important_indices.view(-1)\n",
    "    #     random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance, seed)\n",
    "    #     base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "    #     new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "    #     self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "    #     new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_index[:, important_indices]\n",
    "    #     if(self.virtual_nodes>0):\n",
    "    #         new_edge_index[:, -2*v_n_e_counts:] = edge_index[:, -2*v_n_e_counts:]\n",
    "            \n",
    "    #     # for i in range(base.shape[1]):\n",
    "    #     #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "    #     new_edge_index = self.subsample_edges(new_edge_index, token_subsampling_probabilities)\n",
    "    #     return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "    \n",
    "    \n",
    "         \n",
    "    def calculate_graph(self, x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance):\n",
    "\n",
    "        tc_extended = torch.repeat_interleave(token_counts, token_counts, dim=0).view(-1,1)\n",
    "        tc_lower_bound = torch.empty((len(token_counts)+1), dtype=torch.long, device=x.device) #torch.cuda.IntTensor(len(token_counts)+1) #\n",
    "        tc_lower_bound[0] = 0\n",
    "        tc_lower_bound[1:] = torch.cumsum(token_counts, dim=0)\n",
    "        tc_lower_bound_extended = torch.repeat_interleave(tc_lower_bound[:-1], token_counts, dim=0).view(-1,1)\n",
    "        tc_range = torch.arange(tc_lower_bound[-1], device=x.device).view(-1,1)\n",
    "        # torch.arange(tc_lower_bound[-1], dtype=torch.int32, device=x.device).view(-1,1)\n",
    "        \n",
    "        random_ints = torch.randint(0, 2*total_token_counts, (total_token_counts, random_edges), device=x.device) # torch.cuda.IntTensor(len(token_lengths), random_edges).random_()\n",
    "        lattice = self.lp.to(x.device) if self.lp is not None else torch.arange(lattice_start_distance, max(lattice_start_distance, self.lattice_step*lattice_edges+1), self.lattice_step, device=x.device).view(1, -1)\n",
    "        \n",
    "\n",
    "        # exponentials = torch.pow(2, torch.arange(1, self.exp_edges+1, device=x.device)).view(1, -1)\n",
    "        tc_local_range = tc_range - tc_lower_bound_extended\n",
    "        random_links = (((random_ints % (tc_extended - 1))+1 + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        lattice_links = ((lattice + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        # base = torch.cat([base1, base2], dim=1)\n",
    "        tc_range = tc_range.view(1,-1)\n",
    "        return random_links, lattice_links, tc_range\n",
    "    \n",
    "    def fill_lattice_and_random_edges(self, edge_indices, random_links, lattice_links, tc_range):\n",
    "        for i in range(0, lattice_links.shape[1]*2, 2):\n",
    "            edge_indices[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]] = torch.cat([lattice_links[:,i//2].view(1,-1), tc_range], dim=0)\n",
    "            edge_indices[:, (i+1)*lattice_links.shape[0]:(i+2)*lattice_links.shape[0]] = edge_indices[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]][[1, 0]]\n",
    "            \n",
    "        for i in range(random_links.shape[1]):\n",
    "            j = i + lattice_links.shape[1]*2\n",
    "            edge_indices[:, j*random_links.shape[0]:(j+1)*random_links.shape[0]] = torch.cat([random_links[:,i].view(1,-1), tc_range], dim=0)\n",
    "            \n",
    "    def subsample_edges(self, edge_indices, token_subsampling_probabilities, keep_ratio=0.65):\n",
    "        \n",
    "        p = torch.rand(edge_indices.shape, dtype=torch.float, device=edge_indices.device)\n",
    "        to_keep = (p<token_subsampling_probabilities[edge_indices]).float()\n",
    "        to_keep = torch.topk(to_keep[0] + to_keep[1], (int)(edge_indices.shape[1]*keep_ratio), dim=0).indices\n",
    "        edge_indices = edge_indices[:, to_keep]\n",
    "        return edge_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment_Injection(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)        \n",
    "        self.conv1 = nn.Conv1d(2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim*2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, token_sentiments):\n",
    "        x1 = F.relu_(self.bn1(self.conv1(token_sentiments.T).T))\n",
    "        x = F.relu_(self.conv2(torch.cat([x, x1], dim=1).T))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv, summary\n",
    "import math\n",
    "\n",
    "class CNN_for_Text_No_Positional_Encoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embedding, pos_emb_size=8192, embedding_dim=64, hidden_dim=64, dropout=0.3, num_out_features=4, seed=-1, random_edges=4, lattice_edges=10, virtual_nodes=1, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64, isXaiTests=False, step_of_test = 0, num_tests=50, *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text_No_Positional_Encoding, self).__init__(*args, **kwargs)\n",
    "        self.pos_emb_size = pos_emb_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        self.num_out_features = num_out_features\n",
    "        self.isXaiTests = int(isXaiTests)\n",
    "        self.num_tests = num_tests\n",
    "        self.step_of_test = step_of_test\n",
    "\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # self.positional_encoding = nn.Embedding(pos_emb_size, embedding_dim)\n",
    "        # self.positional_encoding.weight = self.create_positional_encoding()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        \n",
    "        # if self.use_token_polarity[0]:\n",
    "        # self.conv3 = nn.Conv1d(2*hidden_dim + 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        # else:\n",
    "        self.conv3 = nn.Conv1d(2*hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        # if self.use_token_polarity[1]:\n",
    "        self.sentiment1  = Sentiment_Injection(hidden_dim)\n",
    "        # if self.use_token_polarity[2]:\n",
    "        self.sentiment2  = Sentiment_Injection(hidden_dim)\n",
    "            \n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.gcnn2 = GCNN(hidden_dim+inject_embedding_dim)\n",
    "        self.graph_generator = GenGraph(hidden_dim, virtual_nodes, lattice_step)\n",
    "        \n",
    "        k = 4\n",
    "        self.fc0 = nn.Linear(hidden_dim , hidden_dim+inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim+inject_embedding_dim , hidden_dim * k)\n",
    "        self.fc2 = nn.Linear(hidden_dim * (2+virtual_nodes) * k , 32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, self.num_out_features)\n",
    "        self.max_length = 0\n",
    "    \n",
    "    def forward(self, x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings, token_positions):\n",
    "        # cumulative_token_indices = token_indices if not self.isXaiTests else self.caluculate_batch_token_positions(num_tokens, character_length, token_indices)\n",
    "        cumulative_token_indices = self.caluculate_batch_token_positions(num_tokens, character_length, token_indices)\n",
    "        \n",
    "        # print(f'2: {x.shape}')\n",
    "        x = self.embedding(x)\n",
    "        # print(f'2.5: {x.shape}')\n",
    "        x = self.dropout(x)\n",
    "        # print(f'2.6: {x.shape}')\n",
    "        x = x.T\n",
    "        # print(f'2.7: {x.shape}')\n",
    "        # x = self.refine_shape(1, x, 0)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # print(f'2.8: {x.shape}')\n",
    "        x = self.refine_shape(1, x, self.hidden_dim, 0)\n",
    "        # print(f'2.8 refined: {x.shape}')\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.refine_shape(2, x, self.hidden_dim, 0)\n",
    "        # print(f'2.9: {x.shape}')\n",
    "        x = self.dropout(x)\n",
    "        # x = self.refine_shape(4, x, 0)\n",
    "        # print(f'3: {x.shape}')\n",
    "        x1 = scatter_max(x, cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, cumulative_token_indices, dim=1)\n",
    "\n",
    "        # if self.use_token_polarity[0]:\n",
    "        # x = torch.cat([x1, x2, token_sentiments.T], dim=0)\n",
    "        # else:\n",
    "        x = torch.cat([x1, x2], dim=0)\n",
    "            \n",
    "        # print(f'4: {x.shape}')\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # x = x + self.positional_encoding(token_positions).T\n",
    "        \n",
    "        # print(f'4: {x.shape}')\n",
    "        \n",
    "        # print(f'4.5: {x.shape}, self.hidden_dim: {self.hidden_dim}, self.is_tests_token_level: {self.step_of_test}')\n",
    "        # if self.isXaiTests and x.shape[0] != self.hidden_dim:\n",
    "        # x = torch.chunk(x, self.num_tests ** (1 - self.isXaiTests), dim=0)\n",
    "        x = self.refine_shape(3, x, self.hidden_dim, 0)\n",
    "        \n",
    "        # x = torch.chunk(x, (x.shape[0] // self.hidden_dim)**self.is_tests_token_level, dim=0)\n",
    "        # x = torch.cat(x, dim=1)\n",
    "        \n",
    "        # if self.isXaiTests and x.shape[0] != self.hidden_dim:\n",
    "        #     x = torch.chunk(x, self.num_tests, dim=0)\n",
    "        #     x = torch.cat(x, dim=1)\n",
    "        # x = x.reshape(self.hidden_dim, -1)\n",
    "        # print(\"abababdadasd\")\n",
    "        # print(f'5: {x.shape}, {edge_index.shape}, {cumulative_token_indices.shape}, {token_sentiments.shape}, {token_lengths.shape}, {num_tokens.shape}, {character_length.shape}, {token_embeddings.shape}')\n",
    "        # if self.use_token_polarity[1]:\n",
    "        x = self.sentiment1(x.T, token_sentiments)\n",
    "\n",
    "        # print(f'6: {x.shape}')\n",
    "        x = self.refine_shape(4, x.T, self.hidden_dim, 1)\n",
    "        # print(f'6 refined: {x.shape}')\n",
    "        rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "            \n",
    "        graph = self.graph_generator.gen_graph(x, token_subsampling_probabilities, len(token_lengths), num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "        rand_edges = rand_edges-1\n",
    "        lattice_edges = lattice_edges-1\n",
    "        \n",
    "        # print(f'7: {graph.x.shape}')\n",
    "        \n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(num_tokens), device=x.device), num_tokens)\n",
    "        x, edge_weights, edge_index = self.gcnn1(graph.x, graph.edge_index, return_attention_weights = True)\n",
    "        # print(f'7.1: {x.shape}')\n",
    "        x = self.refine_shape(5, x, self.hidden_dim, 1)\n",
    "        # print(f'7.1 2 : {len(torch.cat(edge_weights[1::2], dim=0))}')\n",
    "        edge_weights = self.refine_edge_weights(edge_weights)\n",
    "        edge_index = self.refine_edge_index(edge_index)\n",
    "        \n",
    "        # edge_weights = edge_weights[1].unsqueeze(-1)\n",
    "        # print(f'7.5 edge_weights: {edge_weights.shape}, - {graph.edge_index.shape[1]}, {edge_weights.shape[0]}')\n",
    "        # edge_weights = edge_weights[:min(graph.edge_index.shape[1], edge_weights.shape[0]), 0]\n",
    "        # edge_weights = edge_weights.squeeze()\n",
    "        \n",
    "        edge_weights = edge_weights.unsqueeze(-1)\n",
    "        # print(f'7.5 edge_weights: {edge_weights.shape}, - {edge_weights.shape[0]}')\n",
    "        edge_weights = edge_weights[:edge_weights.shape[0], 0]\n",
    "        \n",
    "        # print(f'7.6 edge_weights: {edge_weights.shape}')\n",
    "        # print(f'7.7: {x.shape}')\n",
    "        x = self.refine_shape(5, x, self.hidden_dim, 1)\n",
    "        # print(f'7.8 refined: {x.shape}')\n",
    "        \n",
    "        graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, edge_index, token_subsampling_probabilities, len(token_lengths), num_tokens, rand_edges, lattice_edges, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        \n",
    "        # print(f'8: {graph.x.shape}')\n",
    "        \n",
    "        # if self.use_token_polarity[2]:\n",
    "        x = self.sentiment2(x, token_sentiments)\n",
    "          \n",
    "        # print(f'8.1: {x.shape}')\n",
    "        x = self.refine_shape(6, x.T, self.hidden_dim, 1)\n",
    "        # print(f'8.2 refined: {x.shape}')\n",
    "        \n",
    "        # print(f'9: {x.shape}')  \n",
    "        xa = graph.x[:token_embeddings.shape[0]]\n",
    "        xb = token_embeddings\n",
    "        x = torch.cat([xa, xb], dim=1)\n",
    "        # x = torch.cat([graph.x[:g_data.token_embeddings.shape[0]], g_data.token_embeddings], dim=1)\n",
    "        \n",
    "        # print(f'10: {x.shape}')  \n",
    "        x1 = F.relu(self.fc0(graph.x[token_embeddings.shape[0]:]))\n",
    "        x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "        # print(f'11: {x.shape}')  \n",
    "        sum1 = torch.sum(edge_weights) + torch.sum(edge_index)\n",
    "        x, edge_weights, edge_index = self.gcnn2(x, graph.edge_index)\n",
    "        edge_weights = self.refine_edge_weights(edge_weights)\n",
    "        sum1 = sum1 + torch.sum(edge_weights) + torch.sum(edge_index) \n",
    "        \n",
    "        # print(f'12: {x.shape}')  \n",
    "        x = F.elu_(self.fc1(x))\n",
    "        x1 = scatter_max(x[:len(token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(token_lengths)], doc_token_index, dim=0)\n",
    "        vn_embs = x[len(token_lengths):]\n",
    "        x_for_cat = [x1, x2]\n",
    "        x_for_cat.extend([vn_embs[i*x1.shape[0]:(i+1)*x1.shape[0]] for i in range(self.virtual_nodes)])\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        \n",
    "        # print(f'13: {x.shape}')  \n",
    "        x = F.elu_(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        # print(f'14: {x.shape}')  \n",
    "        return x + sum1 * 0.0\n",
    "    \n",
    "    def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "        cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "        cumsum_vals[0] = 0\n",
    "        additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "        cumulative_token_indices = token_indices + additions\n",
    "        return cumulative_token_indices\n",
    "    \n",
    "    def create_positional_encoding(self):\n",
    "        position = torch.arange(self.pos_emb_size).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.hidden_dim, 2) * (-math.log(10000.0) / self.hidden_dim))\n",
    "        pe = torch.zeros(self.pos_emb_size, self.hidden_dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return torch.nn.Parameter(pe, requires_grad=False)\n",
    "    \n",
    "    def refine_shape(self, test_step, x, num_chunks, section=0):\n",
    "        x = torch.chunk(x, (x.shape[section] // num_chunks)**(self.step_of_test==test_step), dim=0)\n",
    "        x = torch.cat(x, dim=1-section)\n",
    "        return x\n",
    "        \n",
    "    def refine_edge_weights(self, edge_weights):\n",
    "        edge_weights = edge_weights[1::2] + edge_weights[0::2] * 0\n",
    "        edge_weights = [edge_weights[i] for i in range(len(edge_weights))]\n",
    "        edge_weights = torch.cat(edge_weights, dim=0)\n",
    "        return edge_weights\n",
    "        \n",
    "    def refine_edge_index(self, edge_index):\n",
    "        edge_index = torch.cat([edge_index[::2].reshape(1, -1), edge_index[1::2].reshape(1, -1)], dim=0)\n",
    "        return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module                                              FLOP    % Total\n",
      "-----------------------------------------------  -------  ---------\n",
      " CNN_for_Text_No_Positional_Encoding.conv1       16.467B     29.05%\n",
      "  - aten.convolution                             16.467B     29.05%\n",
      "CNN_for_Text_No_Positional_Encoding              56.695B    100.00%\n",
      " - aten.convolution                              48.705B     85.91%\n",
      " - aten.addmm                                     7.990B     14.09%\n",
      " CNN_for_Text_No_Positional_Encoding.conv2       16.467B     29.05%\n",
      "  - aten.convolution                             16.467B     29.05%\n",
      " CNN_for_Text_No_Positional_Encoding.conv3        3.684B      6.50%\n",
      "  - aten.convolution                              3.684B      6.50%\n",
      " CNN_for_Text_No_Positional_Encoding.sentiment1   3.741B      6.60%\n",
      "  - aten.convolution                              3.741B      6.60%\n",
      " CNN_for_Text_No_Positional_Encoding.gcnn1        1.535B      2.71%\n",
      "  - aten.addmm                                    0.614B      1.08%\n",
      "  - aten.convolution                              0.921B      1.62%\n",
      " CNN_for_Text_No_Positional_Encoding.sentiment2   3.741B      6.60%\n",
      "  - aten.convolution                              3.741B      6.60%\n",
      " CNN_for_Text_No_Positional_Encoding.fc0          0.000B      0.00%\n",
      "  - aten.addmm                                    0.000B      0.00%\n",
      " CNN_for_Text_No_Positional_Encoding.gcnn2        6.139B     10.83%\n",
      "  - aten.addmm                                    2.456B      4.33%\n",
      "  - aten.convolution                              3.684B      6.50%\n",
      " CNN_for_Text_No_Positional_Encoding.fc1          4.912B      8.66%\n",
      "  - aten.addmm                                    4.912B      8.66%\n",
      " CNN_for_Text_No_Positional_Encoding.fc2          0.008B      0.01%\n",
      "  - aten.addmm                                    0.008B      0.01%\n",
      " CNN_for_Text_No_Positional_Encoding.fc_out       0.000B      0.00%\n",
      "  - aten.addmm                                    0.000B      0.00%\n"
     ]
    }
   ],
   "source": [
    "# for p1 in [False, True]:\n",
    "#     for p2 in [False, True]:\n",
    "#         for p3 in [False, True]:\n",
    "# print(f'\\n{p1}, {p2}, {p3}: \\n')\n",
    "classifier_torch_model = CNN_for_Text_No_Positional_Encoding(num_embedding=num_embedding, hidden_dim=64, embedding_dim=64, pos_emb_size=3080, dropout=0.2, num_out_features=len(class_id), seed=911, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2, isXaiTests=True, num_tests=len(X.num_tokens)).eval()\n",
    "flopt_counter = FlopCounterMode(classifier_torch_model)\n",
    "with flopt_counter:\n",
    "    classifier_torch_model(X.x, torch.zeros((2, 0)), X.token_subsampling_probabilities, X.token_indices, X.token_sentiments, X.token_lengths, X.num_tokens, X.character_length, X.token_embeddings, X.token_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.managers.ModelManager import ModelManager\n",
    "from utilities.managers.ClassifierModelManager import ClassifierModelManager\n",
    "from utilities.lightning_models.CnnGnnClassifierLightningModel import CnnGnnClassifierLightningModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 128\n",
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "label_size = 1\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, dropout=0.25, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True, use_positional_encoder=[False, False, False]):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    classifier_torch_model = CNN_for_Text_No_Positional_Encoding(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=4096, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=6, lattice_edges=10, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 40, 45,50,55],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name=f'CNN-GNN_{use_positional_encoder[0]}_{use_positional_encoder[1]}_{use_positional_encoder[2]}',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    train_dataset.reset_params()\n",
    "    train_dataset.position_j = 0\n",
    "    test_dataset.reset_params()\n",
    "    test_dataset.position_j = 0\n",
    "    \n",
    "    # train_dataset.section_i = 0\n",
    "    # train_dataset.each_section_i = np.zeros((train_dataset.num_sections, ), dtype=int)\n",
    "    # test_dataset.section_i = 0\n",
    "    # test_dataset.each_section_i = np.zeros((test_dataset.num_sections, ), dtype=int)\n",
    "    \n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.lightning_model.model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(model_manager.lightning_model, test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                                | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0 | model     | CNN_for_Text_No_Positional_Encoding | 258 K  | train\n",
      "1 | loss_func | BCEWithLogitsLoss                   | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy                  | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy                  | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy                  | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "258 K     Trainable params\n",
      "0         Non-trainable params\n",
      "258 K     Total params\n",
      "1.033     Total estimated model params size (MB)\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba1745e187049e997aa0d829148ecaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e86dee01c54b2aa8ee582f4a43f022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0deb95cc8e4d3a8aad6e8c7e2454c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f526382e6e948a29ab7310d2da47d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d58ba8d71894b8f89bb9b46b6ad381f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66173cdfc8f4e49a346e037a0d6958a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d789fbefdb904561a81ca3522e4dfee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bfe7fc89854bdf849814860fa49c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7800d422967d4f79b6df23afe3936933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d53ede94954b9abfc053314b2db00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed2624f415144a09bc2d685668d9981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2059b473244c44e98c46b6a83d3ce0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c832578dc7f4130a298f83ab366f0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a044836e3844f197f126df98289a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354a296eb1cb48118f90bfd148993558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942bf887cf6947ac909d82b0c8e31db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631ba97959964a6398b6918c03c6a553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef46abecfe44bae9e6b9b7cee072036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b516e36c9b6142deadc0808a8676c142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a92ba8942c423189867181e07d05b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87eab70bbe7442e2bb5d18ce2a35f015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3aca16176c44284961da0e86b34cb4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38826e469b3b42a19fe2854e2d266dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db55819cdc84082b31e5fc5d4c8c5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d7cf8e41fb4414a72580b51db4d949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958bcb14e3a846b79109d56bd3039404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b1c329d4ad4d56884bae80532e34d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17391b60f294fc5a099930973b6c579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3f84f26c454011a6d37bf3e3068f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0466fc65e09a455796f86229878cbfbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb06f727493140eba7f0cf23da72df0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5b4148ae764b4fa0dbcf18909a74b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21d0472d8f8464ba879fcbf79dc30ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431488b28a4941a68d337de3ef192400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4638d7bf794d1d99ad8e0395ddb9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77b035ae80e4a1a985ff56ff75f7fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3da95b20c4849bf8a25a8be57a01258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446b86a3f5184a2c9f14457af1d7f93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c268da7754a42118c77e89a516d0a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321d020b238e437e9da439d3145e5383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb99405babd42b89ab975f3f8ee3267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a67b980d1240b7813ad953cf550619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b90560df2d48479f430502351756b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eecd65431a24c5eac7da7b61b4053ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23d135e889e402fb2226faf0ec72097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6df78d347e4ad7b54cbd43334d9ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8716b0c7d27478b95e16c195a2dc48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec8c493b48e4765bbc15ce2d221045f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ee130e3405444f9ee95cd805412113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bb8c13aec4489aa87bc9442c15b17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a522c3f6ec4f1797d25db7d274b061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde0136443644d738cd34fa069374458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a135e99296472ca6ad5215a94a85e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd6aa1935dc4e47994b59325d17dae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b301235da7429da2ab139769abcf59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b463b025bbf94da0bdff36707b935b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6039a641fc04847bcfae0823a3006b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02072216ee6640f38b9d87134a9ea6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b377c1fa39ae4bd0b4edd4689f453968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b129fa02e2248b49ca23c12050650cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79947a0393a8430d99a6912440006b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158e733dd70d42dd84fdf4b1512ec712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b52b4df396848c4af72e05d527de291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab5b4d67db74ec0816caa0693f7d079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd01be841f14598969f3da64c588cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6034b881c4f945469f06542ced939508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a886d7c317425699663160e15b5fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de28b0174c8b4538a37832e3ac06fb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9261bb29ea4c57bc0e5a5812cfe081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f66b152c408413e85aac187a208e506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8918fe4fb2744b3f855be01928799bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=70` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2560, 2])\n",
      "torch.Size([2560, 2])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8588    0.8127    0.8351      1287\n",
      "           1     0.8204    0.8649    0.8421      1273\n",
      "\n",
      "    accuracy                         0.8387      2560\n",
      "   macro avg     0.8396    0.8388    0.8386      2560\n",
      "weighted avg     0.8397    0.8387    0.8386      2560\n",
      "\n",
      "confusion matrix:\n",
      " tensor([[1046,  241],\n",
      "        [ 172, 1101]])\n",
      "================================\n",
      "torch.Size([2560, 2])\n",
      "torch.Size([2560, 2])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_manager = train_model(70, 0.2, 0.000012, 0.0032, use_positional_encoder=[False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "p = Path(r'logs/CNN-GNN_False_False_False\\version_0\\checkpoints\\epoch=0-step=4.ckpt.pth')\n",
    "not p.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "def calculatge_metrics(chpt_path, target_data_loader, num_embedding):\n",
    "        classifier_torch_model = CNN_for_Text_No_Positional_Encoding(num_embedding=num_embedding, hidden_dim=hidden_dim, embedding_dim=embedding_dim, pos_emb_size=4096, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=8, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "        classifier_torch_model.load_state_dict(torch.load(chpt_path, weights_only=True, map_location=\"cuda:0\"))\n",
    "        classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                batch_size=batch_size,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device).eval()\n",
    "        \n",
    "        mean_infer_acc = []\n",
    "        mean_infer_f1 = []\n",
    "        mean_infer_prec = []\n",
    "        mean_infer_rec = []\n",
    "        for i in range(5):\n",
    "            all_ys = []\n",
    "            all_y_preds = []\n",
    "            for X, y in target_data_loader:\n",
    "                with torch.no_grad():\n",
    "                    y_pred = classfier_lightning_model(X.to(device))\n",
    "                all_ys.append(torch.argmax(y,dim=1))\n",
    "                all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "            all_ys = torch.concat(all_ys)\n",
    "            all_y_preds = torch.concat(all_y_preds)\n",
    "            \n",
    "            cm = confusion_matrix(all_ys, all_y_preds, labels=list(id_class.keys()))\n",
    "            \n",
    "            accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "            precision = np.mean(np.diag(cm) / (np.sum(cm, axis=0)+0.000001))\n",
    "            recall = np.mean(np.diag(cm) / (np.sum(cm, axis=1)+0.000001))\n",
    "            f1_score = (2*precision*recall)/(precision + recall+0.000001)\n",
    "            \n",
    "            mean_infer_acc.append(accuracy)\n",
    "            mean_infer_f1.append(f1_score)\n",
    "            mean_infer_prec.append(precision)\n",
    "            mean_infer_rec.append(recall)\n",
    "        mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "        mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "        mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "        mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "        return mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "def get_best_chpt(metrics_path, epoch_numbers):\n",
    "    epoch_data = pd.read_csv(metrics_path)\n",
    "    if 'val_acc_epoch' in epoch_data.columns and epoch_data['val_acc_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_acc_epoch'].idxmax()]\n",
    "    elif 'val_loss_epoch' in epoch_data.columns and epoch_data['val_loss_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_loss_epoch'].idxmin()]\n",
    "    else:\n",
    "        raise ValueError(f\"No valid validation metrics available for epoch {epoch_numbers}.\")\n",
    "    return np.argwhere(np.array(epoch_numbers)==best_chpt['epoch']).item(), best_chpt['val_loss_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_metrics_mean(num_embedding, base_path = 'logs\\CNN-GNN18_mr2k_seeds', start=0, interval=1):\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "    total_loss = []\n",
    "    \n",
    "    for i in range(start, start + interval):\n",
    "        version_path = join(base_path, f'version_{i}')\n",
    "        checkpoint_path = join(version_path, f'checkpoints')\n",
    "        onlyfiles  = [f for f in listdir(checkpoint_path) if (isfile(join(checkpoint_path, f)) and 'epoch' in f) ]\n",
    "        epoch_numbers = [int(re.search(r'\\d+', f).group()) for f in onlyfiles]\n",
    "        best_chpt_id, loss = get_best_chpt(join(version_path, 'metrics.csv'), epoch_numbers)\n",
    "        print(onlyfiles[best_chpt_id])\n",
    "        mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model = calculatge_metrics(join(checkpoint_path, f'{onlyfiles[best_chpt_id]}'), test_dataloader, num_embedding)\n",
    "            \n",
    "        total_accuracy.append(mean_infer_acc)\n",
    "        total_f1.append(mean_infer_f1)\n",
    "        total_prec.append(mean_infer_prec)\n",
    "        total_rec.append(mean_infer_rec)\n",
    "        total_loss.append(loss)\n",
    "\n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    total_loss = torch.mean(torch.tensor(total_loss))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')\n",
    "    print(f'total_loss: {total_loss}')\n",
    "    return classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=39-step=400.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.8413281250000001\n",
      "total_f1: 0.8417059309388965\n",
      "total_prec: 0.8419670224686655\n",
      "total_rec: 0.8414460020610957\n",
      "total_loss: 0.8299449682235718\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18-step=190.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.811875\n",
      "total_f1: 0.8151318115687147\n",
      "total_prec: 0.8180321615364052\n",
      "total_rec: 0.8122530513667903\n",
      "total_loss: 0.5731271505355835\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=46-step=470.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.8373437500000002\n",
      "total_f1: 0.837505119123956\n",
      "total_prec: 0.8375937584124117\n",
      "total_rec: 0.8374175002353044\n",
      "total_loss: 0.7775648832321167\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18-step=190.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.8114062500000001\n",
      "total_f1: 0.8145425615031335\n",
      "total_prec: 0.817327601474538\n",
      "total_rec: 0.8117774512057855\n",
      "total_loss: 0.5731271505355835\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'logs\\\\CNN-GNN_False_False_False\\\\version_3\\\\checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\Articles\\CGNet\\FindBestModel\\6.1_ReduceAttentionToStopWordsNoSentiment\\with_positional_encoding copy.ipynb Cell 37\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/6.1_ReduceAttentionToStopWordsNoSentiment/with_positional_encoding%20copy.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m classfier_lightning_model1 \u001b[39m=\u001b[39m calculate_average_metrics_mean(\u001b[39mlen\u001b[39m(vocab_dict), \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlogs\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mCNN-GNN_False_False_False\u001b[39m\u001b[39m'\u001b[39m, start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/6.1_ReduceAttentionToStopWordsNoSentiment/with_positional_encoding%20copy.ipynb#X52sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m classfier_lightning_model3 \u001b[39m=\u001b[39m calculate_average_metrics_mean(\u001b[39mlen\u001b[39;49m(vocab_dict), \u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlogs\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mCNN-GNN_False_False_False\u001b[39;49m\u001b[39m'\u001b[39;49m, start\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\Articles\\CGNet\\FindBestModel\\6.1_ReduceAttentionToStopWordsNoSentiment\\with_positional_encoding copy.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/6.1_ReduceAttentionToStopWordsNoSentiment/with_positional_encoding%20copy.ipynb#X52sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m version_path \u001b[39m=\u001b[39m join(base_path, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mversion_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/6.1_ReduceAttentionToStopWordsNoSentiment/with_positional_encoding%20copy.ipynb#X52sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m checkpoint_path \u001b[39m=\u001b[39m join(version_path, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcheckpoints\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/6.1_ReduceAttentionToStopWordsNoSentiment/with_positional_encoding%20copy.ipynb#X52sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m onlyfiles  \u001b[39m=\u001b[39m [f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m listdir(checkpoint_path) \u001b[39mif\u001b[39;00m (isfile(join(checkpoint_path, f)) \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m f) ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/6.1_ReduceAttentionToStopWordsNoSentiment/with_positional_encoding%20copy.ipynb#X52sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m epoch_numbers \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m'\u001b[39m, f)\u001b[39m.\u001b[39mgroup()) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m onlyfiles]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/6.1_ReduceAttentionToStopWordsNoSentiment/with_positional_encoding%20copy.ipynb#X52sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m best_chpt_id, loss \u001b[39m=\u001b[39m get_best_chpt(join(version_path, \u001b[39m'\u001b[39m\u001b[39mmetrics.csv\u001b[39m\u001b[39m'\u001b[39m), epoch_numbers)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'logs\\\\CNN-GNN_False_False_False\\\\version_3\\\\checkpoints'"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model1 = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=1)\n",
    "classfier_lightning_model3 = calculate_average_metrics_mean(len(vocab_dict), r'logs\\CNN-GNN_False_False_False', start=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2.1667, -1.0284, -0.3112,  ...,  0.8440,  0.4139, -1.3559],\n",
       "        [ 0.4477,  0.4483, -1.6092,  ...,  0.6777,  0.5552, -0.0789],\n",
       "        [-0.1111, -1.1905, -1.0991,  ...,  0.0750,  0.3222,  0.2924],\n",
       "        ...,\n",
       "        [-0.2027, -0.7937,  0.0352,  ..., -0.7527,  0.2331,  0.1826],\n",
       "        [ 0.3098,  0.4349, -0.3574,  ...,  0.1672,  0.1886, -0.9232],\n",
       "        [-1.0632, -0.6390,  1.7161,  ...,  1.0442,  0.9414, -0.1757]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier_lightning_model1.model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2.1667e+00, -1.0284e+00, -3.1116e-01,  ...,  8.4399e-01,\n",
       "          4.1394e-01, -1.3559e+00],\n",
       "        [ 5.2677e-01,  6.3853e-01, -1.5004e+00,  ...,  4.7975e-01,\n",
       "          5.7680e-01, -1.4392e-01],\n",
       "        [-1.2900e-01, -1.2595e+00, -1.1261e+00,  ...,  2.0922e-03,\n",
       "          3.4685e-01,  1.9804e-01],\n",
       "        ...,\n",
       "        [-2.5178e-01, -7.1559e-01, -1.1819e-01,  ..., -5.6713e-01,\n",
       "          4.9578e-01,  1.1270e-01],\n",
       "        [ 2.5813e-01,  3.8796e-01, -3.1091e-01,  ...,  1.9647e-01,\n",
       "          2.2127e-01, -9.7274e-01],\n",
       "        [-1.0966e+00, -6.0523e-01,  1.5983e+00,  ...,  1.0477e+00,\n",
       "          9.0805e-01, -8.9105e-02]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier_lightning_model3.model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([145,  77,  37,  ...,   1,  37, 148])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][0].x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
