{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch_scatter import scatter_max, scatter_mean\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from torch import nn\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 256\n",
    "folder_path = r'C:\\Users\\fardin\\Projects\\CGNet\\Data\\TextClassification\\IMDB'\n",
    "# t_tokenizer = TweetTokenizer()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085 tensor([0.7000, 0.6000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "id_vocab = {v:k for k,v in tokenizer.vocab.items()}\n",
    "all_vocab_indices = list(id_vocab.keys())\n",
    "\n",
    "with open(r'Data\\ReducedEmbeddings\\deberta_larg_reduced_embeddings_64.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "all_vocab_str = []\n",
    "for i in range(len(id_vocab)):\n",
    "    all_vocab_str.append(id_vocab[i])\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))\n",
    "\n",
    "with open(r'Data\\ReducedEmbeddings\\polarity_debertav3_tokens_gpt_mini_emb.npy', 'rb') as f:\n",
    "    polarities_subjectivities= np.load(f)\n",
    "polarities_subjectivities = torch.from_numpy(polarities_subjectivities)\n",
    "polarity_vocab_dict = dict(zip(all_vocab_str, polarities_subjectivities))\n",
    "polarity_vocab_dict['<n>'] = torch.tensor([0.0, 0.0])\n",
    "len(token_vocab_dict)\n",
    "polarities_subjectivities.shape\n",
    "for i in range(len(all_vocab_str)):\n",
    "    if 'nice' in all_vocab_str[i]:\n",
    "        print(i, polarities_subjectivities[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_ratio = 0.1\n",
    "test_df = pd.read_csv(r'data\\TextClassification\\IMDB\\test.csv')\n",
    "test_df['Topic'] = test_df['label']\n",
    "test_df['Content'] = test_df['text']\n",
    "test_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.iloc[:int(keep_ratio*test_df.shape[0])]\n",
    "train_df = pd.read_csv(r'data\\TextClassification\\IMDB\\train.csv')\n",
    "train_df['Topic'] = train_df['label']\n",
    "train_df['Content'] = train_df['text']\n",
    "train_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df = train_df.iloc[:int(keep_ratio*train_df.shape[0])]\n",
    "sst_classes = [\"Negative\", \"Positive\"]\n",
    "df = pd.DataFrame(np.concatenate([train_df.values, test_df.values]), columns=train_df.columns)\n",
    "class_id = {c:i for i, c in enumerate(sst_classes)}\n",
    "id_class = {i:c for i, c in enumerate(sst_classes)}\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "vocabs_lists = list(token_vocab_dict.keys())\n",
    "term_frequencies = {t:1 for t in vocabs_lists}\n",
    "temp_term_frequencies = {}\n",
    "\n",
    "for doc in train_df.Content.values:\n",
    "    tokens_list = tokenizer.tokenize(doc)\n",
    "    new_tokens = {t.strip('▁').lower() for t in tokens_list}\n",
    "    for t in new_tokens:\n",
    "        if t not in temp_term_frequencies:\n",
    "            temp_term_frequencies[t] = 0\n",
    "        temp_term_frequencies[t] += 1\n",
    "        \n",
    "for k, v in term_frequencies.items():\n",
    "    stripped_token = k.strip('▁').lower()\n",
    "    term_frequencies[k] = temp_term_frequencies[stripped_token] if stripped_token in temp_term_frequencies else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.00001\n",
    "total_token_count = np.array(list(term_frequencies.values())).sum()\n",
    "one_tensor = torch.tensor(1)\n",
    "def subsampling_equation_linear(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = torch.min(one_tensor, torch.sqrt_(threshold/f_x))\n",
    "    return x\n",
    "\n",
    "def subsampling_equation_sigmoid(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = 1-0.95*F.sigmoid(0.05*((f_x/threshold)-90))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterandTokenLevelCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, num_classes, token_dict, sentiment_dict, tokenizer, token_frequencies, sampling_equation, shuffle=True, batch_size=128) -> None:\n",
    "        super().__init__()\n",
    "        if len(y) % batch_size != 0:\n",
    "            self.shortage = ((len(y) // batch_size)+1)*batch_size - len(y)\n",
    "            empty_labels = [i%2 for i in range(self.shortage)]\n",
    "            empty_strings = [id_class[l] for l in empty_labels]\n",
    "            y = np.concatenate([y, empty_labels])\n",
    "            X = np.concatenate([X, empty_strings])\n",
    "        \n",
    "        y = torch.from_numpy(y)\n",
    "        self.shuffle = shuffle\n",
    "        self.y = torch.nn.functional.one_hot(y, num_classes=num_classes).float()\n",
    "        self.X = X\n",
    "        self.vocab_size = 16384\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_dict = token_dict\n",
    "        self.sentiment_dict = sentiment_dict\n",
    "        self.token_frequencies = token_frequencies\n",
    "        self.max_token_count = 0\n",
    "        self.all_data = []\n",
    "        self.token_lengths = []\n",
    "        self.token_embeddign_ids = []\n",
    "        \n",
    "        self.sum_a = 0\n",
    "        \n",
    "        for doc in tqdm(self.X):\n",
    "            g_data = self.content_to_graph(doc, sampling_equation)\n",
    "            self.all_data.append(g_data)\n",
    "        \n",
    "        \n",
    "        self.num_sections = len(y) // batch_size\n",
    "        self.x_lengths = np.array([self.all_data[i].character_length for i in range(len(self.all_data))])\n",
    "        self.x_len_args = np.argsort(self.x_lengths)[::-1]\n",
    "        \n",
    "        self.section_ranges = np.linspace(0, len(self.x_len_args), self.num_sections+1)\n",
    "        self.section_ranges = [(int(self.section_ranges[i-1]), int(self.section_ranges[i])) for i in range(1, len(self.section_ranges))]\n",
    "\n",
    "        self.position_j = 0\n",
    "        self.section_i = 0\n",
    "        self.epoch = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "        self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        index = self.get_section_index()\n",
    "        return self.all_data[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def get_section_index(self):\n",
    "        target_index = self.sections[self.section_i, self.position_j]\n",
    "        \n",
    "        self.position_j = (self.position_j + 1) % self.section_size\n",
    "        if self.position_j == 0:\n",
    "            self.section_i = (self.section_i + 1) % self.num_sections\n",
    "            if self.shuffle and self.section_i == 0:\n",
    "                self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        return target_index\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.section_i = 0\n",
    "        self.position_j = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "    def split_into_k_groups(self, len_sorted_args, lengths:np.array, k):\n",
    "        if self.shuffle and self.epoch > 0:\n",
    "            randomize_sections = np.concatenate([np.random.choice(np.arange(r[0], r[1]), size=r[1]-r[0], replace=False) for r in self.section_ranges])\n",
    "            len_sorted_args = len_sorted_args[randomize_sections]\n",
    "        \n",
    "        nums = lengths[len_sorted_args]\n",
    "        groups_size = len(len_sorted_args) // k\n",
    "        \n",
    "        \n",
    "        groups = [[] for _ in range(k)]\n",
    "        group_sums = np.zeros(k, dtype=int)\n",
    "        group_sizes = np.zeros(k, dtype=int)\n",
    "        \n",
    "        for i, num in enumerate(nums):\n",
    "            candidate_indices = np.where(group_sizes<groups_size)[0]\n",
    "            min_group_idx = candidate_indices[np.argmin(group_sums[candidate_indices])]\n",
    "            groups[min_group_idx].append(len_sorted_args[i])\n",
    "            group_sums[min_group_idx] += num\n",
    "            group_sizes[min_group_idx] += 1\n",
    "        self.epoch += 1\n",
    "        \n",
    "        groups = np.array(groups)\n",
    "        group_sums_argsort = np.argsort(group_sums)[::-1]\n",
    "        groups = groups[group_sums_argsort]\n",
    "        return np.array(groups), groups_size\n",
    "        \n",
    "    def content_to_graph(self, doc, sampling_equation):\n",
    "        tokens = self.tokenizer(doc)\n",
    "        if len(tokens) == 0:\n",
    "            tokens = ['empty']\n",
    "                        \n",
    "        token_lengths = [len(t) for t in tokens]\n",
    "        tokens.append('\\x01')\n",
    "        \n",
    "        token_lengths.append(len(tokens[-1])-1)\n",
    "        token_lengths = torch.from_numpy(np.array(token_lengths, dtype=np.longlong))+1\n",
    "        token_embs = [self.token_dict[t] if t in self.token_dict else torch.zeros((64, ), dtype=torch.float32) for t in tokens]\n",
    "        token_sentiments = [self.sentiment_dict[t] if t in self.sentiment_dict else (0.0, 0.0) for t in tokens]\n",
    "        token_embs = torch.from_numpy(np.array(token_embs, dtype=np.float32))\n",
    "        token_sentiments = torch.from_numpy(np.array(token_sentiments, dtype=np.float32))\n",
    "        doc = ' '.join(tokens)\n",
    "        characters = torch.from_numpy(np.array([ord(t) if ord(t)<16383 else 16383 for t in doc], dtype=np.longlong))\n",
    "        token_positions = torch.arange(len(token_lengths), dtype=torch.long)\n",
    "        token_indices = torch.repeat_interleave(token_positions, token_lengths)\n",
    "        token_subsampling_probabilities = sampling_equation(torch.from_numpy(np.array([self.token_frequencies[t] if t in self.token_frequencies else 1 for t in tokens])))\n",
    "        num_tokens = len(token_lengths)\n",
    "        if num_tokens > self.max_token_count:\n",
    "            self.max_token_count = num_tokens\n",
    "        g_data = Data(x=characters,\n",
    "                        token_positions=token_positions,\n",
    "                        character_length = len(characters),\n",
    "                        num_tokens = num_tokens,\n",
    "                        token_indices=token_indices,\n",
    "                        token_lengths=token_lengths,\n",
    "                        token_embeddings=token_embs,\n",
    "                        token_sentiments=token_sentiments,\n",
    "                        token_subsampling_probabilities=token_subsampling_probabilities)\n",
    "        return g_data\n",
    " \n",
    "    def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "        cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "        cumsum_vals[0] = 0\n",
    "        additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "        cumulative_token_indices = token_indices + additions\n",
    "        return cumulative_token_indices       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class CharacterandTokenLevelDataLoader(DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        follow_batch: List[str] | None = None,\n",
    "        exclude_keys: List[str] | None = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CharacterandTokenLevelDataLoader, self).__init__(\n",
    "            dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        base_iterator = super(CharacterandTokenLevelDataLoader, self).__iter__()\n",
    "        for batch in base_iterator:\n",
    "            cumsum_vals = torch.cumsum(batch[0].num_tokens, dim=0).roll(1)\n",
    "            cumsum_vals[0] = 0\n",
    "            additions = torch.repeat_interleave(cumsum_vals, batch[0].character_length)\n",
    "            batch[0].cumulative_token_indices = batch[0].token_indices + additions\n",
    "            yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2560 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2560/2560 [00:41<00:00, 60.99it/s]\n",
      "100%|██████████| 2560/2560 [00:43<00:00, 59.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 17s\n",
      "Wall time: 1min 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = CharacterandTokenLevelCustomDataset(train_df.Content.values, train_df.Topic.values, len(class_id), token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, batch_size=batch_size)\n",
    "test_dataset = CharacterandTokenLevelCustomDataset(test_df.Content.values, test_df.Topic.values, len(class_id), token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, batch_size=batch_size)\n",
    "max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv\n",
    "\n",
    "# Normalization on each feature of all tokens, for this we used batch norm class but with tokens at batch dimention\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, *args, **kwargs):\n",
    "        super(GCNN, self).__init__(*args, **kwargs)\n",
    "        self.gnn = GATv2Conv(hidden_dim, hidden_dim//8, heads=4, add_self_loops=False)\n",
    "        self.conv = nn.Conv1d(hidden_dim, hidden_dim//2, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim//2)\n",
    "        \n",
    "    def forward(self, x, edge_data, return_attention_weights = False):\n",
    "        x1, edge_weights = self.gnn(x, edge_data, return_attention_weights=return_attention_weights) \n",
    "        x2 = F.relu(self.conv(x.T).T)\n",
    "        x1 = F.leaky_relu_(self.bn1(x1))\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        return x, edge_weights, edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, to_undirected\n",
    "\n",
    "class GenGraph(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, virtual_nodes, lattice_step, lattice_pattern=None, *args, **kwargs):\n",
    "        super(GenGraph, self).__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.lattice_step = lattice_step\n",
    "        self.lp = lattice_pattern if lattice_pattern is None else torch.tensor(lattice_pattern)\n",
    "        self.virtual_node_embeddings = nn.Embedding(self.virtual_nodes, hidden_dim)\n",
    "        \n",
    "    def gen_graph(self, x, token_subsampling_probabilities, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        v_n_e_counts = total_token_counts*self.virtual_nodes\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        edge_indices = torch.empty((2, base_numel + v_n_e_counts*2), dtype=torch.int64, device=x.device)\n",
    "        self.fill_lattice_and_random_edges(edge_indices, random_links, lattice_links, tc_range)\n",
    "            \n",
    "        if self.virtual_nodes > 0:\n",
    "            virtual_nodes_range = torch.arange(self.virtual_nodes, device=x.device).view(1, -1)\n",
    "            virtual_nodes_ids = torch.repeat_interleave(virtual_nodes_range, len(token_counts), dim=0)\n",
    "            v_n_idx = (virtual_nodes_ids + torch.arange(0, len(token_counts)*self.virtual_nodes, self.virtual_nodes, device=x.device).view(-1, 1) + total_token_counts )\n",
    "            virtual_edge_ids = torch.repeat_interleave(v_n_idx.view(-1), token_counts.view(-1, 1).expand(len(token_counts), self.virtual_nodes).reshape(-1), dim=0).view(1, -1)\n",
    "            \n",
    "            embs = self.virtual_node_embeddings(virtual_nodes_ids.T).view(-1, self.hidden_dim)\n",
    "            x_extended = torch.cat([x, embs], dim=0)\n",
    "            x_index = torch.arange(total_token_counts, device=x.device).repeat(self.virtual_nodes).view(1, -1)\n",
    "            edge_indices[:, base_numel:base_numel+v_n_e_counts] = torch.cat([x_index, virtual_edge_ids], dim=0)\n",
    "            edge_indices[:, base_numel+v_n_e_counts:] = torch.cat([virtual_edge_ids, x_index], dim=0)\n",
    "            x = x_extended\n",
    "        \n",
    "        edge_indices = self.subsample_edges(edge_indices, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_indices)])\n",
    "        \n",
    "    def re_gen_graph(self, x, edge_indices, token_subsampling_probabilities, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance=2):\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "        self.fill_lattice_and_random_edges(edge_indices, random_links, lattice_links, tc_range)\n",
    "        # for i in range(base.shape[1]):\n",
    "        #     edge_indices[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        edge_indices = self.subsample_edges(edge_indices, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=edge_indices)])\n",
    "    \n",
    "    def replace_unimportant_edges(self, edge_weights, x, edge_indices, token_subsampling_probabilities, total_token_counts, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2):\n",
    "        v_n_e_counts = total_token_counts*self.virtual_nodes\n",
    "        # if v_n_e_counts>0:\n",
    "        #     important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # else:\n",
    "        #     print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "        #     print(f'total_token_coutns: {total_token_coutns}')\n",
    "        #     print(f'p_keep: {p_keep}')\n",
    "        #     important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "        # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "        # print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "        # print(f'edge_indices.shape: {edge_indices.shape}')\n",
    "        # print(f'1: edge_weights: {edge_weights.shape}')\n",
    "        important_indices = torch.topk(edge_weights.squeeze(), p_keep*total_token_counts, dim=0).indices\n",
    "        # print(f'2: important_indices: {important_indices.shape}')\n",
    "        # print(f'2.5: \\n {edge_weights} \\n\\n {important_indices}')\n",
    "\n",
    "        # important_indices = torch.arange(total_token_counts, dtype=torch.int64, device=x.device)\n",
    "        # important_indices = important_indices.view(-1)\n",
    "        random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance)\n",
    "        # print(f'3: random_links: {random_links.shape}, lattice_links: {lattice_links.shape}, tc_range: {tc_range.shape},')\n",
    "        base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        # print(f'4: base_numel: {base_numel}')\n",
    "        \n",
    "        new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "        # print(f'5: new_edge_index: {new_edge_index.shape}')\n",
    "        # print(f'new_edge_index.shape 1: {new_edge_index.shape}, base_numel + important_indices.shape[0] + 2*v_n_e_counts: {base_numel + important_indices.shape[0] + 2*v_n_e_counts}')\n",
    "        self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "        # print(f'6: new_edge_index: {new_edge_index.shape}, random_links: {random_links.shape}, lattice_links: {lattice_links.shape}, tc_range: {tc_range.shape}')\n",
    "        # print(f'new_edge_index.shape 2: {new_edge_index.shape}, edge_indices: {edge_indices.shape}, important_indices shape: {important_indices.shape}, important_indices max: {important_indices.max()}')\n",
    "        new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_indices[:, important_indices]\n",
    "        # print(f'7: new_edge_index: {new_edge_index.shape}')\n",
    "\n",
    "        if(self.virtual_nodes>0):\n",
    "            new_edge_index[:, -2*v_n_e_counts:] = edge_indices[:, -2*v_n_e_counts:]\n",
    "            \n",
    "        # for i in range(base.shape[1]):\n",
    "        #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "        # print(f'7.5: \\n {new_edge_index} \\n\\n {token_subsampling_probabilities}')\n",
    "        new_edge_index = self.subsample_edges(new_edge_index, token_subsampling_probabilities)\n",
    "        return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "    \n",
    "    # def replace_unimportant_edges(self, edge_weights, x, edge_index, token_subsampling_probabilities, total_token_coutns, token_counts, random_edges, lattice_edges, p_keep=1, lattice_start_distance=2, seed=-1):\n",
    "    #     v_n_e_counts = total_token_coutns*self.virtual_nodes\n",
    "    #     if v_n_e_counts>0:\n",
    "    #         important_indices = torch.topk(edge_weights[:-2*v_n_e_counts].view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "    #     else:\n",
    "    #         print(f'edge_weights.shape: {edge_weights.shape}')\n",
    "    #         print(f'total_token_coutns: {total_token_coutns}')\n",
    "    #         print(f'p_keep: {p_keep}')\n",
    "    #         important_indices = torch.topk(edge_weights.view(-1, total_token_coutns), p_keep, dim=0).indices\n",
    "    #     # important_indices = torch.topk(edge_weights[:-1*total_token_coutns].view(-1, total_token_coutns), 1, dim=0).indices.squeeze()\n",
    "\n",
    "    #     important_indices = torch.arange(total_token_coutns, dtype=torch.int64, device=x.device) + important_indices*total_token_coutns\n",
    "    #     important_indices = important_indices.view(-1)\n",
    "    #     random_links, lattice_links, tc_range = self.calculate_graph(x, total_token_coutns, token_counts, random_edges, lattice_edges, lattice_start_distance, seed)\n",
    "    #     base_numel = random_links.numel() + lattice_links.numel()*2\n",
    "        \n",
    "    #     new_edge_index = torch.empty((2, base_numel + important_indices.shape[0] + 2*v_n_e_counts), dtype=torch.int64, device=x.device)\n",
    "    #     self.fill_lattice_and_random_edges(new_edge_index, random_links, lattice_links, tc_range)\n",
    "    #     new_edge_index[:, base_numel:base_numel+important_indices.shape[0]] = edge_index[:, important_indices]\n",
    "    #     if(self.virtual_nodes>0):\n",
    "    #         new_edge_index[:, -2*v_n_e_counts:] = edge_index[:, -2*v_n_e_counts:]\n",
    "            \n",
    "    #     # for i in range(base.shape[1]):\n",
    "    #     #     new_edge_index[:, i*base.shape[0]:(i+1)*base.shape[0]] = torch.cat([tc_range, base[:,i].view(1,-1)], dim=0)\n",
    "    #     new_edge_index = self.subsample_edges(new_edge_index, token_subsampling_probabilities)\n",
    "    #     return Batch.from_data_list([Data(x=x, edge_index=new_edge_index)])\n",
    "    \n",
    "    \n",
    "         \n",
    "    def calculate_graph(self, x, total_token_counts, token_counts, random_edges, lattice_edges, lattice_start_distance):\n",
    "\n",
    "        tc_extended = torch.repeat_interleave(token_counts, token_counts, dim=0).view(-1,1)\n",
    "        tc_lower_bound = torch.empty((len(token_counts)+1), dtype=torch.long, device=x.device) #torch.cuda.IntTensor(len(token_counts)+1) #\n",
    "        tc_lower_bound[0] = 0\n",
    "        tc_lower_bound[1:] = torch.cumsum(token_counts, dim=0)\n",
    "        tc_lower_bound_extended = torch.repeat_interleave(tc_lower_bound[:-1], token_counts, dim=0).view(-1,1)\n",
    "        tc_range = torch.arange(tc_lower_bound[-1], device=x.device).view(-1,1)\n",
    "        # torch.arange(tc_lower_bound[-1], dtype=torch.int32, device=x.device).view(-1,1)\n",
    "        \n",
    "        random_ints = torch.randint(0, 2*total_token_counts, (total_token_counts, random_edges), device=x.device) # torch.cuda.IntTensor(len(token_lengths), random_edges).random_()\n",
    "        lattice = self.lp.to(x.device) if self.lp is not None else torch.arange(lattice_start_distance, max(lattice_start_distance, self.lattice_step*lattice_edges+1), self.lattice_step, device=x.device).view(1, -1)\n",
    "        \n",
    "\n",
    "        # exponentials = torch.pow(2, torch.arange(1, self.exp_edges+1, device=x.device)).view(1, -1)\n",
    "        tc_local_range = tc_range - tc_lower_bound_extended\n",
    "        random_links = (((random_ints % (tc_extended - 1))+1 + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        lattice_links = ((lattice + tc_local_range) % tc_extended)+tc_lower_bound_extended\n",
    "        # base = torch.cat([base1, base2], dim=1)\n",
    "        tc_range = tc_range.view(1,-1)\n",
    "        return random_links, lattice_links, tc_range\n",
    "    \n",
    "    def fill_lattice_and_random_edges(self, edge_indices, random_links, lattice_links, tc_range):\n",
    "        for i in range(0, lattice_links.shape[1]*2, 2):\n",
    "            edge_indices[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]] = torch.cat([lattice_links[:,i//2].view(1,-1), tc_range], dim=0)\n",
    "            edge_indices[:, (i+1)*lattice_links.shape[0]:(i+2)*lattice_links.shape[0]] = edge_indices[:, i*lattice_links.shape[0]:(i+1)*lattice_links.shape[0]][[1, 0]]\n",
    "            \n",
    "        for i in range(random_links.shape[1]):\n",
    "            j = i + lattice_links.shape[1]*2\n",
    "            edge_indices[:, j*random_links.shape[0]:(j+1)*random_links.shape[0]] = torch.cat([random_links[:,i].view(1,-1), tc_range], dim=0)\n",
    "            \n",
    "    def subsample_edges(self, edge_indices, token_subsampling_probabilities, keep_ratio=0.65):\n",
    "        \n",
    "        p = torch.rand(edge_indices.shape, dtype=torch.float, device=edge_indices.device)\n",
    "        to_keep = (p<token_subsampling_probabilities[edge_indices]).float()\n",
    "        to_keep = torch.topk(to_keep[0] + to_keep[1], (int)(edge_indices.shape[1]*keep_ratio), dim=0).indices\n",
    "        edge_indices = edge_indices[:, to_keep]\n",
    "        return edge_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment_Injection(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)        \n",
    "        self.conv1 = nn.Conv1d(2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim*2, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, token_sentiments):\n",
    "        x1 = F.relu_(self.bn1(self.conv1(token_sentiments.T).T))\n",
    "        x = F.relu_(self.conv2(torch.cat([x, x1], dim=1).T))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, SimpleConv, summary\n",
    "import math\n",
    "\n",
    "class CNN_for_Text_No_Positional_Encoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim=64, hidden_dim=64, dropout=0.3, num_out_features=4, seed=-1, random_edges=4, lattice_edges=10, virtual_nodes=1, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64, isXaiTests=False, step_of_test = 0, num_tests=50, *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text_No_Positional_Encoding, self).__init__(*args, **kwargs)\n",
    "        # self.pos_emb_size = pos_emb_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        self.num_out_features = num_out_features\n",
    "        self.isXaiTests = int(isXaiTests)\n",
    "        self.num_tests = num_tests\n",
    "        self.step_of_test = step_of_test\n",
    "\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    "        \n",
    "        self.embedding = nn.Embedding(16384, embedding_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # self.positional_encoding = nn.Embedding(pos_emb_size, embedding_dim)\n",
    "        # self.positional_encoding.weight = self.create_positional_encoding()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        \n",
    "        # if self.use_token_polarity[0]:\n",
    "        self.conv3 = nn.Conv1d(2*hidden_dim + 2, hidden_dim, kernel_size=3, padding=1)\n",
    "        # else:\n",
    "        # self.conv3 = nn.Conv1d(2*hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        # if self.use_token_polarity[1]:\n",
    "        # self.sentiment1  = Sentiment_Injection(hidden_dim)\n",
    "        # if self.use_token_polarity[2]:\n",
    "        # self.sentiment2  = Sentiment_Injection(hidden_dim)\n",
    "            \n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.gcnn2 = GCNN(hidden_dim+inject_embedding_dim)\n",
    "        self.graph_generator = GenGraph(hidden_dim, virtual_nodes, lattice_step)\n",
    "        \n",
    "        k = 4\n",
    "        self.fc0 = nn.Linear(hidden_dim , hidden_dim+inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim+inject_embedding_dim , hidden_dim * k)\n",
    "        self.fc2 = nn.Linear(hidden_dim * (2+virtual_nodes) * k , 32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, self.num_out_features)\n",
    "        self.max_length = 0\n",
    "    \n",
    "    def forward(self, x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings, token_positions):\n",
    "        # cumulative_token_indices = token_indices if not self.isXaiTests else self.caluculate_batch_token_positions(num_tokens, character_length, token_indices)\n",
    "        cumulative_token_indices = self.caluculate_batch_token_positions(num_tokens, character_length, token_indices)\n",
    "        \n",
    "        # print(f'2: {x.shape}')\n",
    "        x = self.embedding(x)\n",
    "        # print(f'2.5: {x.shape}')\n",
    "        x = self.dropout(x)\n",
    "        # print(f'2.6: {x.shape}')\n",
    "        x = x.T\n",
    "        # print(f'2.7: {x.shape}')\n",
    "        # x = self.refine_shape(1, x, 0)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # print(f'2.8: {x.shape}')\n",
    "        x = self.refine_shape(1, x, self.hidden_dim, 0)\n",
    "        # print(f'2.8 refined: {x.shape}')\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.refine_shape(2, x, self.hidden_dim, 0)\n",
    "        # print(f'2.9: {x.shape}')\n",
    "        x = self.dropout(x)\n",
    "        # x = self.refine_shape(4, x, 0)\n",
    "        # print(f'3: {x.shape}')\n",
    "        x1 = scatter_max(x, cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, cumulative_token_indices, dim=1)\n",
    "\n",
    "        # if self.use_token_polarity[0]:\n",
    "        x = torch.cat([x1, x2, token_sentiments.T], dim=0)\n",
    "        # else:\n",
    "        # x = torch.cat([x1, x2], dim=0)\n",
    "            \n",
    "        # print(f'4: {x.shape}')\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # x = x + self.positional_encoding(token_positions).T\n",
    "        \n",
    "        # print(f'4: {x.shape}')\n",
    "        \n",
    "        # print(f'4.5: {x.shape}, self.hidden_dim: {self.hidden_dim}, self.is_tests_token_level: {self.step_of_test}')\n",
    "        # if self.isXaiTests and x.shape[0] != self.hidden_dim:\n",
    "        # x = torch.chunk(x, self.num_tests ** (1 - self.isXaiTests), dim=0)\n",
    "        x = self.refine_shape(3, x, self.hidden_dim, 0)\n",
    "        \n",
    "        # x = torch.chunk(x, (x.shape[0] // self.hidden_dim)**self.is_tests_token_level, dim=0)\n",
    "        # x = torch.cat(x, dim=1)\n",
    "        \n",
    "        # if self.isXaiTests and x.shape[0] != self.hidden_dim:\n",
    "        #     x = torch.chunk(x, self.num_tests, dim=0)\n",
    "        #     x = torch.cat(x, dim=1)\n",
    "        # x = x.reshape(self.hidden_dim, -1)\n",
    "        # print(\"abababdadasd\")\n",
    "        # print(f'5: {x.shape}, {edge_index.shape}, {cumulative_token_indices.shape}, {token_sentiments.shape}, {token_lengths.shape}, {num_tokens.shape}, {character_length.shape}, {token_embeddings.shape}')\n",
    "        # if self.use_token_polarity[1]:\n",
    "        # x = self.sentiment1(x.T, token_sentiments)\n",
    "\n",
    "        # print(f'6: {x.shape}')\n",
    "        x = self.refine_shape(4, x.T, self.hidden_dim, 1)\n",
    "        # print(f'6 refined: {x.shape}')\n",
    "        rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "            \n",
    "        graph = self.graph_generator.gen_graph(x, token_subsampling_probabilities, len(token_lengths), num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "        rand_edges = rand_edges-1\n",
    "        lattice_edges = lattice_edges-1\n",
    "        \n",
    "        # print(f'7: {graph.x.shape}')\n",
    "        \n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(num_tokens), device=x.device), num_tokens)\n",
    "        x, edge_weights, edge_index = self.gcnn1(graph.x, graph.edge_index, return_attention_weights = True)\n",
    "        # print(f'7.1: {x.shape}')\n",
    "        x = self.refine_shape(5, x, self.hidden_dim, 1)\n",
    "        # print(f'7.1 2 : {len(torch.cat(edge_weights[1::2], dim=0))}')\n",
    "        edge_weights = self.refine_edge_weights(edge_weights)\n",
    "        edge_index = self.refine_edge_index(edge_index)\n",
    "        \n",
    "        # edge_weights = edge_weights[1].unsqueeze(-1)\n",
    "        # print(f'7.5 edge_weights: {edge_weights.shape}, - {graph.edge_index.shape[1]}, {edge_weights.shape[0]}')\n",
    "        # edge_weights = edge_weights[:min(graph.edge_index.shape[1], edge_weights.shape[0]), 0]\n",
    "        # edge_weights = edge_weights.squeeze()\n",
    "        \n",
    "        edge_weights = edge_weights.unsqueeze(-1)\n",
    "        # print(f'7.5 edge_weights: {edge_weights.shape}, - {edge_weights.shape[0]}')\n",
    "        edge_weights = edge_weights[:edge_weights.shape[0], 0]\n",
    "        \n",
    "        # print(f'7.6 edge_weights: {edge_weights.shape}')\n",
    "        # print(f'7.7: {x.shape}')\n",
    "        x = self.refine_shape(5, x, self.hidden_dim, 1)\n",
    "        # print(f'7.8 refined: {x.shape}')\n",
    "        \n",
    "        graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, edge_index, token_subsampling_probabilities, len(token_lengths), num_tokens, rand_edges, lattice_edges, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        \n",
    "        # print(f'8: {graph.x.shape}')\n",
    "        \n",
    "        # if self.use_token_polarity[2]:\n",
    "        # x = self.sentiment2(x, token_sentiments)\n",
    "          \n",
    "        # print(f'8.1: {x.shape}')\n",
    "        x = self.refine_shape(6, x.T, self.hidden_dim, 1)\n",
    "        # print(f'8.2 refined: {x.shape}')\n",
    "        \n",
    "        # print(f'9: {x.shape}')  \n",
    "        xa = graph.x[:token_embeddings.shape[0]]\n",
    "        xb = token_embeddings\n",
    "        x = torch.cat([xa, xb], dim=1)\n",
    "        # x = torch.cat([graph.x[:g_data.token_embeddings.shape[0]], g_data.token_embeddings], dim=1)\n",
    "        \n",
    "        # print(f'10: {x.shape}')  \n",
    "        x1 = F.relu(self.fc0(graph.x[token_embeddings.shape[0]:]))\n",
    "        x = torch.cat([x, x1], dim=0)\n",
    "        \n",
    "        # print(f'11: {x.shape}')  \n",
    "        sum1 = torch.sum(edge_weights) + torch.sum(edge_index)\n",
    "        x, edge_weights, edge_index = self.gcnn2(x, graph.edge_index)\n",
    "        edge_weights = self.refine_edge_weights(edge_weights)\n",
    "        sum1 = sum1 + torch.sum(edge_weights) + torch.sum(edge_index) \n",
    "        \n",
    "        # print(f'12: {x.shape}')  \n",
    "        x = F.elu_(self.fc1(x))\n",
    "        x1 = scatter_max(x[:len(token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(token_lengths)], doc_token_index, dim=0)\n",
    "        vn_embs = x[len(token_lengths):]\n",
    "        x_for_cat = [x1, x2]\n",
    "        x_for_cat.extend([vn_embs[i*x1.shape[0]:(i+1)*x1.shape[0]] for i in range(self.virtual_nodes)])\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        \n",
    "        # print(f'13: {x.shape}')  \n",
    "        x = F.elu_(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        # print(f'14: {x.shape}')  \n",
    "        return x + sum1 * 0.0\n",
    "    \n",
    "    def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "        cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "        cumsum_vals[0] = 0\n",
    "        additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "        cumulative_token_indices = token_indices + additions\n",
    "        return cumulative_token_indices\n",
    "    \n",
    "    # def create_positional_encoding(self):\n",
    "    #     position = torch.arange(self.pos_emb_size).unsqueeze(1)\n",
    "    #     div_term = torch.exp(torch.arange(0, self.hidden_dim, 2) * (-math.log(10000.0) / self.hidden_dim))\n",
    "    #     pe = torch.zeros(self.pos_emb_size, self.hidden_dim)\n",
    "    #     pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    #     pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    #     return torch.nn.Parameter(pe, requires_grad=False)\n",
    "    \n",
    "    def refine_shape(self, test_step, x, num_chunks, section=0):\n",
    "        x = torch.chunk(x, (x.shape[section] // num_chunks)**(self.step_of_test==test_step), dim=0)\n",
    "        x = torch.cat(x, dim=1-section)\n",
    "        return x\n",
    "        \n",
    "    def refine_edge_weights(self, edge_weights):\n",
    "        edge_weights = edge_weights[1::2] + edge_weights[0::2] * 0\n",
    "        edge_weights = [edge_weights[i] for i in range(len(edge_weights))]\n",
    "        edge_weights = torch.cat(edge_weights, dim=0)\n",
    "        return edge_weights\n",
    "        \n",
    "    def refine_edge_index(self, edge_index):\n",
    "        edge_index = torch.cat([edge_index[::2].reshape(1, -1), edge_index[1::2].reshape(1, -1)], dim=0)\n",
    "        return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module                                          FLOP    % Total\n",
      "-------------------------------------------  -------  ---------\n",
      "CNN_for_Text_No_Positional_Encoding          49.270B    100.00%\n",
      " - aten.convolution                          41.281B     83.78%\n",
      " - aten.addmm                                 7.990B     16.22%\n",
      " CNN_for_Text_No_Positional_Encoding.conv1   16.467B     33.42%\n",
      "  - aten.convolution                         16.467B     33.42%\n",
      " CNN_for_Text_No_Positional_Encoding.conv2   16.467B     33.42%\n",
      "  - aten.convolution                         16.467B     33.42%\n",
      " CNN_for_Text_No_Positional_Encoding.conv3    3.741B      7.59%\n",
      "  - aten.convolution                          3.741B      7.59%\n",
      " CNN_for_Text_No_Positional_Encoding.gcnn1    1.535B      3.12%\n",
      "  - aten.addmm                                0.614B      1.25%\n",
      "  - aten.convolution                          0.921B      1.87%\n",
      " CNN_for_Text_No_Positional_Encoding.fc0      0.000B      0.00%\n",
      "  - aten.addmm                                0.000B      0.00%\n",
      " CNN_for_Text_No_Positional_Encoding.gcnn2    6.139B     12.46%\n",
      "  - aten.addmm                                2.456B      4.98%\n",
      "  - aten.convolution                          3.684B      7.48%\n",
      " CNN_for_Text_No_Positional_Encoding.fc1      4.912B      9.97%\n",
      "  - aten.addmm                                4.912B      9.97%\n",
      " CNN_for_Text_No_Positional_Encoding.fc2      0.008B      0.02%\n",
      "  - aten.addmm                                0.008B      0.02%\n",
      " CNN_for_Text_No_Positional_Encoding.fc_out   0.000B      0.00%\n",
      "  - aten.addmm                                0.000B      0.00%\n"
     ]
    }
   ],
   "source": [
    "# for p1 in [False, True]:\n",
    "#     for p2 in [False, True]:\n",
    "#         for p3 in [False, True]:\n",
    "# print(f'\\n{p1}, {p2}, {p3}: \\n')\n",
    "classifier_torch_model = CNN_for_Text_No_Positional_Encoding(hidden_dim=64, embedding_dim=64, dropout=0.2, num_out_features=len(class_id), seed=911, random_edges=4, lattice_edges=4, lattice_step=2, virtual_nodes=0, lattice_start_distance=2, isXaiTests=True, num_tests=len(X.num_tokens)).eval()\n",
    "flopt_counter = FlopCounterMode(classifier_torch_model)\n",
    "with flopt_counter:\n",
    "    classifier_torch_model(X.x, torch.zeros((2, 0)), X.token_subsampling_probabilities, X.token_indices, X.token_sentiments, X.token_lengths, X.num_tokens, X.character_length, X.token_embeddings, X.token_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.managers.ModelManager import ModelManager\n",
    "from utilities.managers.ClassifierModelManager import ClassifierModelManager\n",
    "from utilities.lightning_models.CnnGnnClassifierLightningModel import CnnGnnClassifierLightningModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 128\n",
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "label_size = 1\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, dropout=0.25, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True, use_positional_encoder=[False, False, False]):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    classifier_torch_model = CNN_for_Text_No_Positional_Encoding(hidden_dim=hidden_dim, embedding_dim=embedding_dim, dropout=dropout, num_out_features=len(class_id), seed=seed, random_edges=6, lattice_edges=10, lattice_step=2, virtual_nodes=0, lattice_start_distance=2).to(device)\n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 40, 45,50,55],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name=f'CNN-GNN_{use_positional_encoder[0]}_{use_positional_encoder[1]}_{use_positional_encoder[2]}',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    train_dataset.reset_params()\n",
    "    train_dataset.position_j = 0\n",
    "    test_dataset.reset_params()\n",
    "    test_dataset.position_j = 0\n",
    "    \n",
    "    # train_dataset.section_i = 0\n",
    "    # train_dataset.each_section_i = np.zeros((train_dataset.num_sections, ), dtype=int)\n",
    "    # test_dataset.section_i = 0\n",
    "    # test_dataset.each_section_i = np.zeros((test_dataset.num_sections, ), dtype=int)\n",
    "    \n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.lightning_model.model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(model_manager.lightning_model, test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                                | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0 | model     | CNN_for_Text_No_Positional_Encoding | 1.2 M  | train\n",
      "1 | loss_func | BCEWithLogitsLoss                   | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy                  | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy                  | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy                  | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.989     Total estimated model params size (MB)\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1804c7b0b01045aca1ff212591fb1f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb7ac2594bc4ba8a812eefa9a56bf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3201a50e161408caab708934a4ec23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af38bc2217549869642faa5da224db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c72ca7800f49c99acf7f489d255e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2f5f9392544ce1a9db6d54153b3b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde5ad621f3b43b7a9dde7253e1c4fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a085fcfce14cc5981f023db1f2e536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae3cb1f8f9144dda1e6b54056219a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc9ded5647f4ced8b24bb59a8bbac34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3199c1f5f3524f7884c68a846d301b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482ec14a21c8463a8ad26ff4ebaff983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66af7b26e0114975bf7e92e0c499316a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae33b2537cc34ae2a1424b38e5ca10d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e12ba8d5d8343b98d8999ae03a9428a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99b6756287a4167990a9c46fba8daf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9cf6a417c64705bf823c92fbc2c340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d84cfed53b48dba9a7e23baced791c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1249b8bbc2ec4df1817907b8c05be73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a0b1455d0e49ce86e150d5760ae46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b5307e76504d3187765620e64fade4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ca6f587c4a42a7a4f15f5b058da498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92db8e42138b42a3a948ebf1b18e2b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660e198cc0a34c46991ebbe17f377006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cdfb12dae24298a6f23f1ce4a3792a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58db1f57eb164d6eb911bf0bd3b1b970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4369b140e7459ba6f6dead32b24b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe9e4530d5b41d5ab8de768d89b7e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dada4be7778454295e95803959c3358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbf7196159b455ab227fe1088c6a5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d98d599a4a4d069a0db84068902d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f665b365ca042bdb2b7082c401ee3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7ccd1f1fd04829820807afc01c49c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c37b2c5c7f048b08626a1a6ebdc7e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb75a6325c64fdd9c399308c81184c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f90ae6e69845f1a4a5b4589ea9f818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baffb8bb9434571bcf23469bf3c045d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81265db87da4dc98375593aa6a74225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783a01ffa89e4dd2bed83b7ba746cfe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5026c79429d4666a2af1248a860d730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b3dd3ced414cf4b2dd7fd37c560652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ba9a89d17040f68b38e0ee0ef9ec16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0694014e16154d33bc6d00e9fffe64fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5095248ac8a46e3ab61898bd39f9d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e0d8863e2642fb949eea2054f33555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c473fd5ce0450cba48a7b869ceb6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cffe15d6774c5b93ecd03121e93ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5550c29020564772936839ea81aeb66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8551769ed757463a82bcfb84f6a31c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af81a932b08471885e5962ff7c74b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11b1638c3c04ce386020e7aab0a30be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f13e10487248e0aae2a788c679e0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9974a983269c4a0b9f10f5249fa8f236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01256faaff474e58a046a93c266f5f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c53c96cddd741318ad16d4dd5c5fa45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d94ba9e9cb1472897e0c917a56c23eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2971cff65b5436391617f691090fb4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96deb680d254e8ca4d5ecf05d033f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fae10dd00ef4714ae6b89acc2a87c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51950054cb9e423784b6be31f77ae553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33db01b340e41599ea9f59ede93ee4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ecaa5d50dc42488876f0e6afd33d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cf85120b8d47fc9806471a58640194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060a82a605784a86abf1b22626d32f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a3776220384cfba637e71ef8a804d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f983103dfc2d453ab410251fc0d01e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368f0307e40944779daf0c8d7c4e7c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9276f553e5460f93dbd0047ded7d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2242cbd62f74957be491c128fe42b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7deba72f19ef4635b1a4aaee3b585d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65144fc47dd74f96b9ecab129bd8bd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=70` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2560, 2])\n",
      "torch.Size([2560, 2])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9255    0.6566    0.7682      1287\n",
      "           1     0.7316    0.9466    0.8253      1273\n",
      "\n",
      "    accuracy                         0.8008      2560\n",
      "   macro avg     0.8286    0.8016    0.7968      2560\n",
      "weighted avg     0.8291    0.8008    0.7966      2560\n",
      "\n",
      "confusion matrix:\n",
      " tensor([[ 845,  442],\n",
      "        [  68, 1205]])\n",
      "================================\n",
      "torch.Size([2560, 2])\n",
      "torch.Size([2560, 2])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_manager = train_model(70, 0.2, 0.000012, 0.0032, use_positional_encoder=[False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "p = Path(r'logs/CNN-GNN_False_False_False\\version_0\\checkpoints\\epoch=0-step=4.ckpt.pth')\n",
    "not p.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "def calculatge_metrics(chpt_path, target_data_loader):\n",
    "        classifier_torch_model = CNN_for_Text_No_Positional_Encoding(hidden_dim=hidden_dim, embedding_dim=embedding_dim, dropout=0.2, num_out_features=len(class_id), seed=seed, random_edges=4, lattice_edges=8, lattice_step=2, virtual_nodes=0, lattice_start_distance=2)\n",
    "        classifier_torch_model.load_state_dict(torch.load(chpt_path, weights_only=True, map_location=\"cuda:0\"))\n",
    "        classfier_lightning_model = CnnGnnClassifierLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(class_id),\n",
    "                                                batch_size=batch_size,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device).eval()\n",
    "        \n",
    "        mean_infer_acc = []\n",
    "        mean_infer_f1 = []\n",
    "        mean_infer_prec = []\n",
    "        mean_infer_rec = []\n",
    "        for i in range(5):\n",
    "            all_ys = []\n",
    "            all_y_preds = []\n",
    "            for X, y in target_data_loader:\n",
    "                with torch.no_grad():\n",
    "                    y_pred = classfier_lightning_model(X.to(device))\n",
    "                all_ys.append(torch.argmax(y,dim=1))\n",
    "                all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "            all_ys = torch.concat(all_ys)\n",
    "            all_y_preds = torch.concat(all_y_preds)\n",
    "            \n",
    "            cm = confusion_matrix(all_ys, all_y_preds, labels=list(id_class.keys()))\n",
    "            \n",
    "            accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "            precision = np.mean(np.diag(cm) / (np.sum(cm, axis=0)+0.000001))\n",
    "            recall = np.mean(np.diag(cm) / (np.sum(cm, axis=1)+0.000001))\n",
    "            f1_score = (2*precision*recall)/(precision + recall+0.000001)\n",
    "            \n",
    "            mean_infer_acc.append(accuracy)\n",
    "            mean_infer_f1.append(f1_score)\n",
    "            mean_infer_prec.append(precision)\n",
    "            mean_infer_rec.append(recall)\n",
    "        mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "        mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "        mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "        mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "        return mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "def get_best_chpt(metrics_path, epoch_numbers):\n",
    "    epoch_data = pd.read_csv(metrics_path)\n",
    "    if 'val_acc_epoch' in epoch_data.columns and epoch_data['val_acc_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_acc_epoch'].idxmax()]\n",
    "    elif 'val_loss_epoch' in epoch_data.columns and epoch_data['val_loss_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_loss_epoch'].idxmin()]\n",
    "    else:\n",
    "        raise ValueError(f\"No valid validation metrics available for epoch {epoch_numbers}.\")\n",
    "    return np.argwhere(np.array(epoch_numbers)==best_chpt['epoch']).item(), best_chpt['val_loss_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_metrics_mean(base_path = 'logs\\CNN-GNN18_mr2k_seeds', start=0, interval=1):\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "    total_loss = []\n",
    "    \n",
    "    for i in range(start, start + interval):\n",
    "        version_path = join(base_path, f'version_{i}')\n",
    "        checkpoint_path = join(version_path, f'checkpoints')\n",
    "        onlyfiles  = [f for f in listdir(checkpoint_path) if (isfile(join(checkpoint_path, f)) and 'epoch' in f) ]\n",
    "        epoch_numbers = [int(re.search(r'\\d+', f).group()) for f in onlyfiles]\n",
    "        best_chpt_id, loss = get_best_chpt(join(version_path, 'metrics.csv'), epoch_numbers)\n",
    "        print(onlyfiles[best_chpt_id])\n",
    "        mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model = calculatge_metrics(join(checkpoint_path, f'{onlyfiles[best_chpt_id]}'), test_dataloader)\n",
    "            \n",
    "        total_accuracy.append(mean_infer_acc)\n",
    "        total_f1.append(mean_infer_f1)\n",
    "        total_prec.append(mean_infer_prec)\n",
    "        total_rec.append(mean_infer_rec)\n",
    "        total_loss.append(loss)\n",
    "\n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    total_loss = torch.mean(torch.tensor(total_loss))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')\n",
    "    print(f'total_loss: {total_loss}')\n",
    "    return classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17-step=180.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.845\n",
      "total_f1: 0.8451441359274157\n",
      "total_prec: 0.8452204347863965\n",
      "total_rec: 0.8450688521069194\n",
      "total_loss: 0.5068789720535278\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(r'logs\\CNN-GNN_False_False_False', start=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
