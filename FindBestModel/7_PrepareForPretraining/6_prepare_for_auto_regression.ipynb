{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch_scatter import scatter_max, scatter_mean\n",
    "import lightning as L\n",
    "from torch_geometric.data import Batch, Data\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from torch import nn\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 256\n",
    "folder_path = r'C:\\Users\\fardin\\Projects\\CGNet\\Data\\TextClassification\\IMDB'\n",
    "# t_tokenizer = TweetTokenizer()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085 tensor([0.7000, 0.6000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "id_vocab = {v:k for k,v in tokenizer.vocab.items()}\n",
    "all_vocab_indices = list(id_vocab.keys())\n",
    "\n",
    "with open(r'Data\\ReducedEmbeddings\\deberta_larg_reduced_embeddings_64.npy', 'rb') as f:\n",
    "    embeddings = np.load(f)\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "all_vocab_str = []\n",
    "for i in range(len(id_vocab)):\n",
    "    all_vocab_str.append(id_vocab[i])\n",
    "token_vocab_dict = dict(zip(all_vocab_str, embeddings))\n",
    "\n",
    "with open(r'Data\\ReducedEmbeddings\\polarity_debertav3_tokens_gpt_mini_emb.npy', 'rb') as f:\n",
    "    polarities_subjectivities= np.load(f)\n",
    "polarities_subjectivities = torch.from_numpy(polarities_subjectivities)\n",
    "polarity_vocab_dict = dict(zip(all_vocab_str, polarities_subjectivities))\n",
    "polarity_vocab_dict['<n>'] = torch.tensor([0.0, 0.0])\n",
    "len(token_vocab_dict)\n",
    "polarities_subjectivities.shape\n",
    "for i in range(len(all_vocab_str)):\n",
    "    if 'nice' in all_vocab_str[i]:\n",
    "        print(i, polarities_subjectivities[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_ratio = 0.04\n",
    "test_df = pd.read_csv(r'data\\TextClassification\\IMDB\\test.csv')\n",
    "test_df['Topic'] = test_df['label']\n",
    "test_df['Content'] = test_df['text']\n",
    "test_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.iloc[:int(keep_ratio*test_df.shape[0])]\n",
    "train_df = pd.read_csv(r'data\\TextClassification\\IMDB\\train.csv')\n",
    "train_df['Topic'] = train_df['label']\n",
    "train_df['Content'] = train_df['text']\n",
    "train_df.drop(['label', 'text'], axis=1, inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df = train_df.iloc[:int(keep_ratio*train_df.shape[0])]\n",
    "sst_classes = [\"Negative\", \"Positive\"]\n",
    "df = pd.DataFrame(np.concatenate([train_df.values, test_df.values]), columns=train_df.columns)\n",
    "class_id = {c:i for i, c in enumerate(sst_classes)}\n",
    "id_class = {i:c for i, c in enumerate(sst_classes)}\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "vocabs_lists = list(token_vocab_dict.keys())\n",
    "term_frequencies = {t:1 for t in vocabs_lists}\n",
    "temp_term_frequencies = {}\n",
    "\n",
    "for doc in train_df.Content.values:\n",
    "    tokens_list = tokenizer.tokenize(doc)\n",
    "    new_tokens = {t.strip('▁').lower() for t in tokens_list}\n",
    "    for t in new_tokens:\n",
    "        if t not in temp_term_frequencies:\n",
    "            temp_term_frequencies[t] = 0\n",
    "        temp_term_frequencies[t] += 1\n",
    "        \n",
    "for k, v in term_frequencies.items():\n",
    "    stripped_token = k.strip('▁').lower()\n",
    "    term_frequencies[k] = temp_term_frequencies[stripped_token] if stripped_token in temp_term_frequencies else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.00001\n",
    "total_token_count = np.array(list(term_frequencies.values())).sum()\n",
    "one_tensor = torch.tensor(1)\n",
    "def subsampling_equation_linear(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = torch.min(one_tensor, torch.sqrt_(threshold/f_x))\n",
    "    return x\n",
    "\n",
    "def subsampling_equation_sigmoid(x: torch.Tensor):\n",
    "    f_x = x/total_token_count\n",
    "    x = 1-0.95*F.sigmoid(0.05*((f_x/threshold)-90))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utilities.data_manager.CharacterandTokenLevelCustomDataset import CharacterandTokenLevelCustomDataset\n",
    "from utilities.data_manager.CharacterandTokenLevelDataLoader import CharacterandTokenLevelDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['good']\n",
    "id_vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Batch, Data\n",
    "import random\n",
    "\n",
    "class CharacterandTokenLevelCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, num_classes, token_dict, sentiment_dict, tokenizer, vocab, token_frequencies, sampling_equation, id_class, shuffle=True, batch_size=128) -> None:\n",
    "        super().__init__()\n",
    "        if len(X) % batch_size != 0:\n",
    "            self.shortage = ((len(X) // batch_size)+1)*batch_size - len(X)\n",
    "            empty_labels = [i%2 for i in range(self.shortage)]\n",
    "            empty_strings = [id_class[l] for l in empty_labels]\n",
    "            X = np.concatenate([X, empty_strings])\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.X = X\n",
    "        self.vocab_size = 16384\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "        self.token_dict = token_dict\n",
    "        self.embedding_size = token_vocab_dict[next(iter(token_dict))].shape[0]\n",
    "        self.zero_emb = torch.zeros((self.embedding_size,), dtype=torch.float32)\n",
    "        self.sentiment_dict = sentiment_dict\n",
    "        self.token_frequencies = token_frequencies\n",
    "        self.max_token_count = 0\n",
    "        self.all_data = []\n",
    "        self.token_lengths = []\n",
    "        self.token_embeddign_ids = []\n",
    "        \n",
    "        self.sum_a = 0\n",
    "        \n",
    "        for doc in tqdm(self.X):\n",
    "            g_data = self.content_to_graph(doc, sampling_equation)\n",
    "            self.all_data.append(g_data)\n",
    "        \n",
    "        \n",
    "        self.num_sections = len(X) // batch_size\n",
    "        self.x_lengths = np.array([self.all_data[i].character_length for i in range(len(self.all_data))])\n",
    "        self.x_len_args = np.argsort(self.x_lengths)[::-1]\n",
    "        \n",
    "        self.section_ranges = np.linspace(0, len(self.x_len_args), self.num_sections+1)\n",
    "        self.section_ranges = [(int(self.section_ranges[i-1]), int(self.section_ranges[i])) for i in range(1, len(self.section_ranges))]\n",
    "        \n",
    "\n",
    "        self.position_j = 0\n",
    "        self.section_i = 0\n",
    "        self.epoch = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "        self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        index = self.get_section_index()\n",
    "        ds = self.all_data[index]\n",
    "        cs_pos = ds.cumulative_pos\n",
    "        random_token_id= max(1, random.randint(ds.num_tokens//2 - 1 , ds.num_tokens-2))\n",
    "        new_data = Data(\n",
    "            x=ds.x[:cs_pos[random_token_id-1]+1],\n",
    "            character_length=cs_pos[random_token_id-1]+1,\n",
    "            num_tokens = random_token_id+1,\n",
    "            token_indices = ds.token_indices[:cs_pos[random_token_id-1]+1],\n",
    "            token_lengths = torch.cat([ds.token_lengths[:random_token_id], ds.token_lengths[-1].unsqueeze(0)], dim=0),\n",
    "            token_embeddings = torch.cat([ds.token_embeddings[:random_token_id],ds.token_embeddings[-1].unsqueeze(0)], dim=0),\n",
    "            token_sentiments = torch.cat([ds.token_sentiments[:random_token_id],ds.token_sentiments[-1].unsqueeze(0)], dim=0),\n",
    "            token_subsampling_probabilities = torch.cat([ds.token_subsampling_probabilities[:random_token_id],ds.token_subsampling_probabilities[-1].unsqueeze(0)], dim=0)\n",
    "            ) \n",
    "        new_data.x[-1] = 16300\n",
    "        label = ds.token_ids[random_token_id]\n",
    "        return new_data, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def get_section_index(self):\n",
    "        target_index = self.sections[self.section_i, self.position_j]\n",
    "        \n",
    "        self.position_j = (self.position_j + 1) % self.section_size\n",
    "        if self.position_j == 0:\n",
    "            self.section_i = (self.section_i + 1) % self.num_sections\n",
    "            if self.shuffle and self.section_i == 0:\n",
    "                self.sections, self.section_size = self.split_into_k_groups(self.x_len_args, self.x_lengths, self.num_sections)\n",
    "        return target_index\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.section_i = 0\n",
    "        self.position_j = 0\n",
    "        self.each_section_i = np.zeros((self.num_sections, ), dtype=int)\n",
    "        \n",
    "    def split_into_k_groups(self, len_sorted_args, lengths:np.array, k):\n",
    "        if self.shuffle and self.epoch > 0:\n",
    "            randomize_sections = np.concatenate([np.random.choice(np.arange(r[0], r[1]), size=r[1]-r[0], replace=False) for r in self.section_ranges])\n",
    "            len_sorted_args = len_sorted_args[randomize_sections]\n",
    "        \n",
    "        nums = lengths[len_sorted_args]\n",
    "        groups_size = len(len_sorted_args) // k\n",
    "        \n",
    "        \n",
    "        groups = [[] for _ in range(k)]\n",
    "        group_sums = np.zeros(k, dtype=int)\n",
    "        group_sizes = np.zeros(k, dtype=int)\n",
    "        \n",
    "        for i, num in enumerate(nums):\n",
    "            candidate_indices = np.where(group_sizes<groups_size)[0]\n",
    "            min_group_idx = candidate_indices[np.argmin(group_sums[candidate_indices])]\n",
    "            groups[min_group_idx].append(len_sorted_args[i])\n",
    "            group_sums[min_group_idx] += num\n",
    "            group_sizes[min_group_idx] += 1\n",
    "        self.epoch += 1\n",
    "        \n",
    "        groups = np.array(groups)\n",
    "        group_sums_argsort = np.argsort(group_sums)[::-1]\n",
    "        groups = groups[group_sums_argsort]\n",
    "        return np.array(groups), groups_size\n",
    "        \n",
    "    def content_to_graph(self, doc, sampling_equation):\n",
    "        tokens = self.tokenizer(doc)\n",
    "        if len(tokens) == 0:\n",
    "            tokens = ['empty']\n",
    "        # while len(tokens) < 3:\n",
    "        #     tokens.append('[PAD]')\n",
    "            \n",
    "        token_lengths = [len(t) for t in tokens]\n",
    "        tokens.append('\\x01')\n",
    "        \n",
    "        token_lengths.append(len(tokens[-1])-1)\n",
    "        token_lengths = torch.from_numpy(np.array(token_lengths, dtype=np.longlong))+1\n",
    "        token_embs = [self.token_dict[t] if t in self.token_dict else self.zero_emb for t in tokens]\n",
    "        token_ids = torch.from_numpy(np.array([self.vocab[t] if t in self.vocab else 0 for t in tokens], dtype=np.longlong))\n",
    "        token_sentiments = [self.sentiment_dict[t] if t in self.sentiment_dict else (0.0, 0.0) for t in tokens]\n",
    "        token_embs = torch.from_numpy(np.array(token_embs, dtype=np.float32))\n",
    "        token_sentiments = torch.from_numpy(np.array(token_sentiments, dtype=np.float32))\n",
    "        doc = ' '.join(tokens)\n",
    "        characters = torch.from_numpy(np.array([ord(t) if ord(t)<16383 else 16383 for t in doc], dtype=np.longlong))\n",
    "        token_positions = torch.arange(len(token_lengths), dtype=torch.long)\n",
    "        token_indices = torch.repeat_interleave(token_positions, token_lengths)\n",
    "        token_subsampling_probabilities = sampling_equation(torch.from_numpy(np.array([self.token_frequencies[t] if t in self.token_frequencies else 1 for t in tokens])))\n",
    "        num_tokens = len(token_lengths)\n",
    "        if num_tokens > self.max_token_count:\n",
    "            self.max_token_count = num_tokens\n",
    "        \n",
    "        cumulative_pos = torch.cumsum(token_lengths, dim=0)    \n",
    "        \n",
    "        g_data = Data(x=characters,\n",
    "                        # token_positions=token_positions,\n",
    "                        token_ids = token_ids,\n",
    "                        character_length = len(characters),\n",
    "                        num_tokens = num_tokens,\n",
    "                        token_indices=token_indices,\n",
    "                        token_lengths=token_lengths,\n",
    "                        token_embeddings=token_embs,\n",
    "                        token_sentiments=token_sentiments,\n",
    "                        cumulative_pos=cumulative_pos,\n",
    "                        token_subsampling_probabilities=token_subsampling_probabilities)\n",
    "        return g_data\n",
    " \n",
    "    def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "        cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "        cumsum_vals[0] = 0\n",
    "        additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "        cumulative_token_indices = token_indices + additions\n",
    "        return cumulative_token_indices       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:15<00:00, 64.87it/s]\n",
      "100%|██████████| 1024/1024 [00:15<00:00, 65.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min\n",
      "Wall time: 31.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = CharacterandTokenLevelCustomDataset(train_df.Content.values, len(class_id), token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, tokenizer.vocab, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, id_class=id_class, batch_size=batch_size)\n",
    "test_dataset = CharacterandTokenLevelCustomDataset(test_df.Content.values, len(class_id), token_vocab_dict, polarity_vocab_dict, tokenizer.tokenize, tokenizer.vocab, token_frequencies=term_frequencies, sampling_equation=subsampling_equation_sigmoid, id_class=id_class, batch_size=batch_size)\n",
    "max_token_count = max(train_dataset.max_token_count, test_dataset.max_token_count)\n",
    "train_dataloader = CharacterandTokenLevelDataLoader(train_dataset, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "test_dataloader = CharacterandTokenLevelDataLoader(test_dataset, batch_size=batch_size, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = train_dataset[0][0]\n",
    "ds2 = train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "963"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1.num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([963, 64])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1.token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'㿼'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(16380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9601,    73,   116,  ...,   115,    32, 16300])\n",
      "tensor([ 9601,    65,    32,  ...,   102,    32, 16380])\n"
     ]
    }
   ],
   "source": [
    "print(ds1.x)\n",
    "ds2.x[-1] = 16380\n",
    "print(ds2.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_token_id= 407 #random.randint(ds.num_tokens//2, ds.num_tokens-1)\n",
    "# cs_pos = torch.cumsum(ds.token_lengths, dim=0)\n",
    "# new_data = Data(\n",
    "#     x=ds.x[:cs_pos[random_token_id-1]],\n",
    "#     character_length=cs_pos[random_token_id-1],\n",
    "#     num_tokens = random_token_id,\n",
    "#     token_indices = ds.token_indices[:cs_pos[random_token_id-1]],\n",
    "#     token_lengths = ds.token_lengths[:random_token_id],\n",
    "#     token_embeddings = ds.token_embeddings[:random_token_id],\n",
    "#     token_sentiments = ds.token_sentiments[:random_token_id],\n",
    "#     token_subsampling_probabilities = ds.token_subsampling_probabilities[:random_token_id]\n",
    "#     ) \n",
    "# label = ds.x[cs_pos[random_token_id-1]:cs_pos[random_token_id-1]+ds.token_lengths[random_token_id]]\n",
    "# print(''.join([chr(id) for id in new_data.x[-new_data.token_lengths[-1]:]]))\n",
    "# print(''.join([chr(id) for id in label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lngths = np.array([len(dss.token_lengths) for dss in train_dataset2.all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lngths.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lngths = np.array([len(dss[0].token_lengths) for dss in train_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3 = X.to_data_list()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁Positive 㾬'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([chr(tid) for tid in ds3.x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.model_layers.GCNN import GCNN\n",
    "from utilities.model_layers.GenGraph2 import GenGraph\n",
    "from utilities.model_layers.SentimentInjection import SentimentInjection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5_restructure_for_contrastive_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGNetTokenLevelEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim=64, hidden_dim=64, dropout=0.2, seed=-1, random_edges=4, lattice_edges=10, lattice_step=2, lattice_start_distance=2, inject_embedding_dim=64, step_of_test = 0, head=1, *args, **kwargs):\n",
    "        super(CGNetTokenLevelEmbedding, self).__init__(*args, **kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.base_random_edges = random_edges\n",
    "        self.base_lattice_edges = lattice_edges\n",
    "        self.lattice_start_distance = lattice_start_distance\n",
    "        self.step_of_test = step_of_test\n",
    "        if seed>-1:\n",
    "            torch.manual_seed(seed)\n",
    "        self.embedding = nn.Embedding(16384, embedding_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(2*embedding_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.sentiment1  = SentimentInjection(hidden_dim, embedding_dim)\n",
    "        self.sentiment2  = SentimentInjection(hidden_dim, embedding_dim)\n",
    "        self.p_layer_1 = nn.Linear(hidden_dim, head)\n",
    "        self.gcnn1 = GCNN(hidden_dim)\n",
    "        self.p_layer_2 = nn.Linear(hidden_dim, head)\n",
    "        self.gcnn2 = GCNN(hidden_dim+inject_embedding_dim)\n",
    "        self.graph_generator = GenGraph(hidden_dim, 0, lattice_step, head=head)\n",
    "        self.fc0 = nn.Linear(hidden_dim , hidden_dim+inject_embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim+inject_embedding_dim , hidden_dim * 4)\n",
    "    \n",
    "    def forward(self, x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings):\n",
    "        cumulative_token_indices = self.caluculate_batch_token_positions(num_tokens, character_length, token_indices)\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.T\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x1 = scatter_max(x, cumulative_token_indices, dim=1)[0]\n",
    "        x2 = scatter_mean(x, cumulative_token_indices, dim=1)\n",
    "        x = torch.cat([x1, x2], dim=0)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.sentiment1(x.T, token_sentiments)\n",
    "        rand_edges, lattice_edges = self.base_random_edges, self.base_lattice_edges\n",
    "        p = self.p_layer_1(x.T)\n",
    "        p = F.softmax(p, dim=1)\n",
    "        ids = torch.argmax(p, dim=1, keepdim=True)\n",
    "        p = torch.zeros_like(p).scatter_(1, ids, torch.ones_like(p)) * token_subsampling_probabilities.unsqueeze(1)\n",
    "        graph = self.graph_generator.gen_graph(x, p, len(token_lengths), num_tokens, rand_edges, lattice_edges, lattice_start_distance=self.lattice_start_distance)\n",
    "        x, edge_weights, edge_index = self.gcnn1(graph.x.T, graph.edge_index, return_attention_weights = True)\n",
    "        edge_weights = edge_weights[1].unsqueeze(-1)\n",
    "        edge_weights = edge_weights[:edge_weights.shape[0], 0]\n",
    "        \n",
    "        p = self.p_layer_2(x)\n",
    "        p = F.softmax(p, dim=1)\n",
    "        ids = torch.argmax(p, dim=1, keepdim=True)\n",
    "        p = torch.zeros_like(p).scatter_(1, ids, torch.ones_like(p)) * token_subsampling_probabilities.unsqueeze(1)\n",
    "        graph = self.graph_generator.replace_unimportant_edges(edge_weights, x, edge_index, p, len(token_lengths), num_tokens, rand_edges-1, lattice_edges-1, p_keep=2, lattice_start_distance=self.lattice_start_distance+1)\n",
    "        x = self.sentiment2(x, token_sentiments)\n",
    "        xa = graph.x[:token_embeddings.shape[0]]\n",
    "        xb = token_embeddings\n",
    "        x = torch.cat([xa, xb], dim=1)\n",
    "        x1 = F.relu(self.fc0(graph.x[token_embeddings.shape[0]:]))\n",
    "        x = torch.cat([x, x1], dim=0)\n",
    "        x, edge_weights, edge_index = self.gcnn2(x, graph.edge_index)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    def caluculate_batch_token_positions(self, num_tokens, character_length, token_indices):\n",
    "        cumsum_vals = torch.cumsum(num_tokens, dim=0).roll(1)\n",
    "        cumsum_vals[0] = 0\n",
    "        additions = torch.repeat_interleave(cumsum_vals, character_length)\n",
    "        cumulative_token_indices = token_indices + additions\n",
    "        return cumulative_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGNetEmbedding(nn.Module):\n",
    "    def __init__(self, token_embedding_model, hidden_dim=64, output_dim=512, *args, **kwargs):\n",
    "        super(CGNetEmbedding, self).__init__(*args, **kwargs)\n",
    "        self.token_embedding_model = token_embedding_model\n",
    "        self.fc2 = nn.Linear(hidden_dim * 8 , output_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings):\n",
    "        x = self.token_embedding_model(x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings)\n",
    "        x = F.elu_(x)\n",
    "        doc_token_index = torch.repeat_interleave(torch.arange(len(num_tokens), device=x.device), num_tokens)\n",
    "        x1 = scatter_max(x[:len(token_lengths)], doc_token_index, dim=0)[0]\n",
    "        x2 = scatter_mean(x[:len(token_lengths)], doc_token_index, dim=0)\n",
    "        x_for_cat = [x1, x2]\n",
    "        x = torch.cat(x_for_cat, dim=1)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128001"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_for_Text_No_Positional_Encoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_model: CGNetEmbedding, hidden_dim=64, dropout=0.3, num_out_features=len(id_vocab), *args, **kwargs) -> None:\n",
    "        super(CNN_for_Text_No_Positional_Encoding, self).__init__(*args, **kwargs)\n",
    "        self.embedding_model = embedding_model\n",
    "        self.num_out_features= num_out_features\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, self.num_out_features)\n",
    "    \n",
    "    def forward(self, x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths, num_tokens, character_length, token_embeddings):\n",
    "        x = F.elu_(self.embedding_model(x, edge_index, token_subsampling_probabilities, token_indices, token_sentiments, token_lengths=token_lengths, num_tokens=num_tokens, character_length=character_length, token_embeddings=token_embeddings))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module                                                   FLOP    % Total\n",
      "----------------------------------------------------  -------  ---------\n",
      "CNN_for_Text_No_Positional_Encoding                   88.229B    100.00%\n",
      " - aten.convolution                                   54.649B     61.94%\n",
      " - aten.addmm                                         33.580B     38.06%\n",
      " CNN_for_Text_No_Positional_Encoding.embedding_model  71.452B     80.98%\n",
      "  - aten.convolution                                  54.649B     61.94%\n",
      "  - aten.addmm                                        16.802B     19.04%\n",
      " CNN_for_Text_No_Positional_Encoding.fc_out           16.777B     19.02%\n",
      "  - aten.addmm                                        16.777B     19.02%\n"
     ]
    }
   ],
   "source": [
    "# for p1 in [False, True]:\n",
    "#     for p2 in [False, True]:\n",
    "#         for p3 in [False, True]:\n",
    "# print(f'\\n{p1}, {p2}, {p3}: \\n')\n",
    "token_embedding_model = CGNetTokenLevelEmbedding(embedding_dim=64, hidden_dim=128, dropout=0.2,  seed=911, random_edges=4, lattice_edges=4, lattice_step=2, lattice_start_distance=2)\n",
    "embedding_model = CGNetEmbedding(token_embedding_model, hidden_dim=128, output_dim=256).eval()\n",
    "\n",
    "# embedding_model = CGNetEmbedding(embedding_dim=64, hidden_dim=128, dropout=0.2,  seed=911, random_edges=4, lattice_edges=4, lattice_step=2, lattice_start_distance=2)\n",
    "classifier_torch_model = CNN_for_Text_No_Positional_Encoding(embedding_model, hidden_dim=256, dropout=0.2, num_out_features=len(id_vocab)).eval()\n",
    "flopt_counter = FlopCounterMode(classifier_torch_model)\n",
    "with flopt_counter:\n",
    "    # embedding_model(X.x, torch.zeros((2, 0)), X.token_subsampling_probabilities, X.token_indices, X.token_sentiments, token_lengths=X.token_lengths, num_tokens=X.num_tokens, character_length=X.character_length, token_embeddings=X.token_embeddings)\n",
    "    classifier_torch_model(X.x, torch.zeros((2, 0)), X.token_subsampling_probabilities, X.token_indices, X.token_sentiments, X.token_lengths, X.num_tokens, X.character_length, X.token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "def calculate_metrics(cl_model, dataloader):\n",
    "    cm = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_id))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    cl_model = cl_model.eval()\n",
    "    cl_model.to(device)\n",
    "    for X, y in tqdm(dataloader):\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_p = cl_model(X)\n",
    "            y_p = y_p.cpu()\n",
    "        y_pred.append(y_p)\n",
    "        y_true.append(y)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred2 = torch.argmax(y_pred, dim=1)\n",
    "    y_true2 = torch.argmax(y_true, dim=1)\n",
    "    print(f'classification report: \\n {classification_report(y_true2, y_pred2, digits=4)}')\n",
    "    print(f'confusion matrix:\\n {cm(y_pred2, y_true2)}')\n",
    "    print('================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "import torch\n",
    "# from scripts.managers.ModelManager import ModelManager\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from torch_geometric.nn import summary\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "from os import path\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "import lightning as L\n",
    "from utilities.managers.ModelManager import ModelManager\n",
    "from utilities.callbacks.CustomModelCheckpoint import CustomModelCheckpoint\n",
    "\n",
    "class ClassifierModelManager(ModelManager):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 num_train_epoch = 100,\n",
    "                 accumulate_grad_batches=1):\n",
    "        super(ClassifierModelManager, self).__init__(torch_model, lightning_model, model_save_dir, log_dir, log_name, device, num_train_epoch, accumulate_grad_batches=accumulate_grad_batches)\n",
    "\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        return [\n",
    "            CustomModelCheckpoint(save_top_k=2, mode='max', monitor='val_acc', save_last=True, save_weights_only=True),\n",
    "            # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "        ]\n",
    "\n",
    "    def draw_summary(self, dataloader):\n",
    "        X, y = next(iter(dataloader))\n",
    "        print(summary(self.torch_model, X.to(self.device)))\n",
    "\n",
    "    def plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    def save_plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc'], name_prepend: str=\"\"):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        \n",
    "        loss_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_loss_metric.png')\n",
    "        plt.savefig(loss_png)\n",
    "        \n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        \n",
    "        acc_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_acc_metric.png')\n",
    "        plt.savefig(acc_png)\n",
    "        \n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate(self, eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.lightning_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        # if(give_hinge_loss):\n",
    "        #     print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')\n",
    "                \n",
    "    def evaluate_best_models(self, eval_dataloader,\n",
    "                             give_confusion_matrix: bool=True, \n",
    "                             give_report: bool=True, \n",
    "                             give_f1_score: bool=False, \n",
    "                             give_accuracy_score: bool=False, \n",
    "                             give_precision_score: bool=False, \n",
    "                             give_recall_score: bool=False, \n",
    "                             give_hinge_loss: bool=False,\n",
    "                             multi_class: bool=False, **kwargs):\n",
    "        \n",
    "        model = self.trainer.model.model\n",
    "        # self.lightning_model = lightning_type.load_from_checkpoint(rf'{self.trainer.checkpoint_callback.best_model_path}', map_location=None, hparams_file=None, strict=True, **kwargs).eval()\n",
    "        self.lightning_model.model.load_state_dict(torch.load(rf'{self.trainer.checkpoint_callback.best_model_path}', weights_only=True, map_location=None))\n",
    "        self.save_evaluation(self.lightning_model, eval_dataloader, 'best_model', give_confusion_matrix, give_report,\n",
    "                             give_f1_score, give_accuracy_score, give_precision_score, give_recall_score, give_hinge_loss, multi_class)\n",
    "            \n",
    "    def save_evaluation(self, model, eval_dataloader, name_prepend: str='',\n",
    "                    give_confusion_matrix: bool=True, \n",
    "                    give_report: bool=True, \n",
    "                    give_f1_score: bool=False, \n",
    "                    give_accuracy_score: bool=False, \n",
    "                    give_precision_score: bool=False, \n",
    "                    give_recall_score: bool=False, \n",
    "                    give_hinge_loss: bool=False,\n",
    "                    multi_class: bool=False\n",
    "                    ):\n",
    "            \n",
    "            test_metrics_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_test_metrics.txt')\n",
    "            \n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            model = model.eval()\n",
    "            for X, y in eval_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    y_p = model(X.to(self.device))\n",
    "                if type(y_p) is tuple:\n",
    "                    y_p = y_p[0]\n",
    "                \n",
    "                if multi_class:\n",
    "                    y_pred.append(y_p.detach().to(y.device))\n",
    "                    y_true.append(y)\n",
    "                else:\n",
    "                    y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "                    y_true.append(y.to(torch.int32))\n",
    "                    \n",
    "            y_true = torch.concat(y_true)\n",
    "            y_pred = torch.concat(y_pred)\n",
    "            print(y_true.shape)\n",
    "            print(y_pred.shape)\n",
    "            if multi_class:\n",
    "                y_true_num = torch.argmax(y_true, dim=1)\n",
    "                y_pred_num = torch.argmax(y_pred, dim=1)\n",
    "            else:\n",
    "                y_true_num = y_true\n",
    "                y_pred_num = y_pred\n",
    "                \n",
    "            print(y_true_num.shape)\n",
    "            print(y_pred_num.shape)\n",
    "            with open(test_metrics_path, 'at+') as f:\n",
    "                if(give_confusion_matrix):\n",
    "                    print(f'confusion_matrix: \\n{confusion_matrix(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_report):\n",
    "                    print(classification_report(y_true_num, y_pred_num), file=f)\n",
    "                if(give_f1_score):\n",
    "                    if multi_class:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_accuracy_score):\n",
    "                    print(f'accuracy_score: {accuracy_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_precision_score):\n",
    "                    if multi_class:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'precision: {precision_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_recall_score):\n",
    "                    if multi_class:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'recall: {recall_score(y_true_num, y_pred_num)}', file=f)\n",
    "                # if(give_hinge_loss):\n",
    "                #     print(f'hinge_loss: {hinge_loss(y_true_num, y_pred)}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.managers.ModelManager import ModelManager\n",
    "from utilities.managers.ClassifierModelManager import ClassifierModelManager\n",
    "from utilities.lightning_models.CGNetEmbeddingLightningModel import CGNetEmbeddingLightningModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 64\n",
    "hidden_dim = 64\n",
    "embedding_dim = 64\n",
    "seed = 911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning as L\n",
    "import torchmetrics\n",
    "\n",
    "class CGNetEmbeddingLightningModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        num_classes,\n",
    "        optimizer=None,\n",
    "        loss_func=None,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=64,\n",
    "        lr_scheduler=None,\n",
    "        user_lr_scheduler=False,\n",
    "        min_lr=0.0,\n",
    "    ):\n",
    "        super(CGNetEmbeddingLightningModel, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.min_lr = min_lr\n",
    "        # self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        self.optimizer = self._get_optimizer(optimizer)\n",
    "        self.lr_scheduler = (\n",
    "            self._get_lr_scheduler(lr_scheduler) if user_lr_scheduler else None\n",
    "        )\n",
    "        self.loss_func = loss_func\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x.x, torch.zeros((2, 0)), x.token_subsampling_probabilities, x.token_indices, x.token_sentiments, x.token_lengths, x.num_tokens, x.character_length, x.token_embeddings)\n",
    "\n",
    "    def on_train_epoch_start(self) -> None:\n",
    "        param_groups = next(iter(self.optimizer.param_groups))\n",
    "        if \"lr\" in param_groups and param_groups[\"lr\"] is not None:\n",
    "            current_learning_rate = float(param_groups[\"lr\"])\n",
    "            self.log(\n",
    "                \"lr\",\n",
    "                current_learning_rate,\n",
    "                batch_size=self.batch_size,\n",
    "                on_epoch=True,\n",
    "                on_step=False,\n",
    "            )\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.train()\n",
    "        y_out = self(X)\n",
    "        \n",
    "        loss = self.loss_func(y_out, F.one_hot(y, y_out.shape[1]).float())\n",
    "        self.train_losses.append(loss.detach().item())\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        self.train_acc(torch.argmax(y_out, dim=1), y)\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        X, y = batch\n",
    "        X.to(self.device)\n",
    "        y.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        y_out = self(X)\n",
    "        loss = self.loss_func(y_out, F.one_hot(y, y_out.shape[1]).float())\n",
    "        self.val_losses.append(loss.detach().item())\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=self.batch_size,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.val_acc(torch.argmax(y_out, dim=1), y)\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.lr_scheduler is None:\n",
    "            return self.optimizer\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": self.lr_scheduler,\n",
    "                \"monitor\": \"train_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def update_learning_rate(self, learning_rate: float):\n",
    "        self.learning_rate = learning_rate\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g[\"lr\"] = learning_rate\n",
    "\n",
    "    def _get_optimizer(self, optimizer):\n",
    "        return (\n",
    "            optimizer\n",
    "            if optimizer is not None\n",
    "            else torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        )\n",
    "\n",
    "    def _get_lr_scheduler(self, lr_scheduler):\n",
    "        return (\n",
    "            lr_scheduler\n",
    "            if lr_scheduler is not None\n",
    "            else torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer, patience=5, factor=0.5, mode=\"min\", min_lr=self.min_lr\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, dropout=0.25, weight_decay=0.000012, lr=0.0002, amsgrad=False, fused=True, use_positional_encoder=[False, False, False]):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    \n",
    "    token_embedding_model = CGNetTokenLevelEmbedding(embedding_dim=embedding_dim, hidden_dim=hidden_dim, dropout=dropout,  seed=seed, random_edges=6, lattice_edges=10, lattice_step=2, lattice_start_distance=2).to(device)\n",
    "    embedding_model = CGNetEmbedding(token_embedding_model, hidden_dim=hidden_dim, output_dim=256).to(device)\n",
    "    classifier_torch_model = CNN_for_Text_No_Positional_Encoding(embedding_model, hidden_dim=256, dropout=dropout, num_out_features=len(id_vocab)).to(device)\n",
    "        \n",
    "    # optimizer = torch.optim.Adam(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    optimizer = torch.optim.AdamW(classifier_torch_model.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=amsgrad, fused=fused)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100, 150, 200, 250, 300, 350],gamma=0.5, verbose=False)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 20, 30, 40, 45,50,55],gamma=0.5, verbose=False)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    classfier_lightning_model = CGNetEmbeddingLightningModel(classifier_torch_model, \n",
    "                                                        num_classes=len(id_vocab),\n",
    "                                                learning_rate=lr,\n",
    "                                                batch_size=batch_size,\n",
    "                                                optimizer=optimizer,\n",
    "                                                loss_func=loss_func,\n",
    "                                                lr_scheduler=lr_scheduler,\n",
    "                                                user_lr_scheduler=True\n",
    "                                                ).to(device)\n",
    "\n",
    "\n",
    "    model_manager = ClassifierModelManager(classifier_torch_model, classfier_lightning_model, log_name=f'CNN-GNN_{use_positional_encoder[0]}_{use_positional_encoder[1]}_{use_positional_encoder[2]}',device=device, num_train_epoch=epochs, accumulate_grad_batches=1)\n",
    "    # trainer = L.Trainer(\n",
    "    #             # callbacks=callbacks,\n",
    "    #             max_epochs=epochs,\n",
    "    #             accelerator= 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    #             logger=CSVLogger(save_dir='logs/', name='log2'), \n",
    "    #             num_sanity_val_steps=0,\n",
    "    #         #     default_root_dir='models\\model2_word_embedding-256-2'\n",
    "    #         )\n",
    "\n",
    "    train_dataset.reset_params()\n",
    "    train_dataset.position_j = 0\n",
    "    test_dataset.reset_params()\n",
    "    test_dataset.position_j = 0\n",
    "    \n",
    "    # train_dataset.section_i = 0\n",
    "    # train_dataset.each_section_i = np.zeros((train_dataset.num_sections, ), dtype=int)\n",
    "    # test_dataset.section_i = 0\n",
    "    # test_dataset.each_section_i = np.zeros((test_dataset.num_sections, ), dtype=int)\n",
    "    \n",
    "    model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss_epoch'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{dropout}_{weight_decay}_{lr}_{amsgrad}_{fused}')\n",
    "    model_manager.lightning_model.model = model_manager.torch_model.to(device)\n",
    "    model_manager.save_evaluation(model_manager.lightning_model, test_dataloader, f'{dropout}_{weight_decay}_{lr}]',True, True, True, True, True, True, True, multi_class=True)\n",
    "    # trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\n",
    "    classfier_lightning_model.model = classfier_lightning_model.model.eval()\n",
    "    classfier_lightning_model = classfier_lightning_model.eval()\n",
    "    calculate_metrics(classfier_lightning_model, test_dataloader)\n",
    "    model_manager.evaluate_best_models(test_dataloader,True, True, True, True, True, True, True, multi_class=True, model=classifier_torch_model, num_classes=len(class_id))\n",
    "    return model_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4238"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                                | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0 | model     | CNN_for_Text_No_Positional_Encoding | 34.3 M | train\n",
      "1 | loss_func | BCEWithLogitsLoss                   | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy                  | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy                  | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy                  | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "34.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "34.3 M    Total params\n",
      "137.234   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4ad69c750c43f3ba61aef740fe5fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd4c17fe967491b9c0bcf85f9bb7dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d073ca5e24484a9be72f9e74b14626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89dd9ba71e3546db98759285c21d5f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95754300a4b4be492e707444c28b757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fba843955a949a198ff89dbd5542139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd1e0d5e4e2424e98f51f91c3e3ce58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1c6744b9e94ac980afa0ef032d0d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e643ef3952454e5b8514aa440255f397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642ed77be2ff4380872e9bd56fd83206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71806df78e7458490e681fba7eb52ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff01564ecdb24c0a9196f4f494e09f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31ad7d53ae041e196cb3d7603a8bc62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dedcbc5232b4a76a28a5be7918eb990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b20ed6ec83d46d0a01f56f9689e956d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7ea7aad2e84c62b3da012820cc92b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc9ca6ce868416fa11fead74cd379b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56cb91c5b02f430aa283711ab9eea2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6cc4a746fa4421a005ff0d50addba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n",
      "torch.Size([1024, 128001])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\Articles\\CGNet\\FindBestModel\\7_PrepareForPretraining\\6_prepare_for_auto_regression.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/7_PrepareForPretraining/6_prepare_for_auto_regression.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_manager \u001b[39m=\u001b[39m train_model(\u001b[39m70\u001b[39;49m, \u001b[39m0.2\u001b[39;49m, \u001b[39m0.000012\u001b[39;49m, \u001b[39m0.0032\u001b[39;49m, use_positional_encoder\u001b[39m=\u001b[39;49m[\u001b[39mFalse\u001b[39;49;00m, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mFalse\u001b[39;49;00m])\n",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\Articles\\CGNet\\FindBestModel\\7_PrepareForPretraining\\6_prepare_for_auto_regression.ipynb Cell 36\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/7_PrepareForPretraining/6_prepare_for_auto_regression.ipynb#X50sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m model_manager\u001b[39m.\u001b[39msave_plot_csv_logger(loss_names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtrain_loss_epoch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval_loss_epoch\u001b[39m\u001b[39m'\u001b[39m], eval_names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtrain_acc_epoch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval_acc_epoch\u001b[39m\u001b[39m'\u001b[39m], name_prepend\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtests_\u001b[39m\u001b[39m{\u001b[39;00mdropout\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mweight_decay\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mlr\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mamsgrad\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mfused\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/7_PrepareForPretraining/6_prepare_for_auto_regression.ipynb#X50sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m model_manager\u001b[39m.\u001b[39mlightning_model\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model_manager\u001b[39m.\u001b[39mtorch_model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/7_PrepareForPretraining/6_prepare_for_auto_regression.ipynb#X50sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m model_manager\u001b[39m.\u001b[39;49msave_evaluation(model_manager\u001b[39m.\u001b[39;49mlightning_model, test_dataloader, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mdropout\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mweight_decay\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mlr\u001b[39m}\u001b[39;49;00m\u001b[39m]\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39mTrue\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, multi_class\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/7_PrepareForPretraining/6_prepare_for_auto_regression.ipynb#X50sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# trainer.fit(classfier_lightning_model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/Articles/CGNet/FindBestModel/7_PrepareForPretraining/6_prepare_for_auto_regression.ipynb#X50sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m classfier_lightning_model\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m classfier_lightning_model\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\fardin\\Projects\\Articles\\CGNet\\utilities\\managers\\ClassifierModelManager.py:163\u001b[0m, in \u001b[0;36mClassifierModelManager.save_evaluation\u001b[1;34m(self, model, eval_dataloader, name_prepend, give_confusion_matrix, give_report, give_f1_score, give_accuracy_score, give_precision_score, give_recall_score, give_hinge_loss, multi_class)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mprint\u001b[39m(y_pred\u001b[39m.\u001b[39mshape)\n\u001b[0;32m    162\u001b[0m \u001b[39mif\u001b[39;00m multi_class:\n\u001b[1;32m--> 163\u001b[0m     y_true_num \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49margmax(y_true, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    164\u001b[0m     y_pred_num \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(y_pred, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    165\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_manager = train_model(70, 0.2, 0.000012, 0.0032, use_positional_encoder=[False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "def calculatge_metrics(chpt_path, target_data_loader):\n",
    "    \n",
    "    embedding_model = CGNetEmbedding(embedding_dim=embedding_dim, hidden_dim=hidden_dim, dropout=0.2,  seed=seed, random_edges=6, lattice_edges=10, lattice_step=2, lattice_start_distance=2)\n",
    "    classifier_torch_model = CNN_for_Text_No_Positional_Encoding(embedding_model, hidden_dim=hidden_dim, dropout=0.2, num_out_features=len(class_id))\n",
    "    \n",
    "    classifier_torch_model.load_state_dict(torch.load(chpt_path, weights_only=True, map_location=\"cuda:0\"))\n",
    "    classfier_lightning_model = CGNetEmbeddingLightningModel(classifier_torch_model, \n",
    "                                                    num_classes=len(class_id),\n",
    "                                            batch_size=batch_size,\n",
    "                                            user_lr_scheduler=True\n",
    "                                            ).to(device).eval()\n",
    "    \n",
    "    mean_infer_acc = []\n",
    "    mean_infer_f1 = []\n",
    "    mean_infer_prec = []\n",
    "    mean_infer_rec = []\n",
    "    for i in range(5):\n",
    "        all_ys = []\n",
    "        all_y_preds = []\n",
    "        for X, y in target_data_loader:\n",
    "            with torch.no_grad():\n",
    "                y_pred = classfier_lightning_model(X.to(device))\n",
    "            all_ys.append(torch.argmax(y,dim=1))\n",
    "            all_y_preds.append(torch.argmax(y_pred.cpu(), dim=1))\n",
    "        all_ys = torch.concat(all_ys)\n",
    "        all_y_preds = torch.concat(all_y_preds)\n",
    "        \n",
    "        cm = confusion_matrix(all_ys, all_y_preds, labels=list(id_class.keys()))\n",
    "        \n",
    "        accuracy = np.sum(np.diag(cm))/ np.sum(cm)\n",
    "        precision = np.mean(np.diag(cm) / (np.sum(cm, axis=0)+0.000001))\n",
    "        recall = np.mean(np.diag(cm) / (np.sum(cm, axis=1)+0.000001))\n",
    "        f1_score = (2*precision*recall)/(precision + recall+0.000001)\n",
    "        \n",
    "        mean_infer_acc.append(accuracy)\n",
    "        mean_infer_f1.append(f1_score)\n",
    "        mean_infer_prec.append(precision)\n",
    "        mean_infer_rec.append(recall)\n",
    "    mean_infer_acc = torch.mean(torch.tensor(mean_infer_acc))\n",
    "    mean_infer_f1 = torch.mean(torch.tensor(mean_infer_f1))\n",
    "    mean_infer_prec = torch.mean(torch.tensor(mean_infer_prec))\n",
    "    mean_infer_rec = torch.mean(torch.tensor(mean_infer_rec))\n",
    "    return mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "def get_best_chpt(metrics_path, epoch_numbers):\n",
    "    epoch_data = pd.read_csv(metrics_path)\n",
    "    if 'val_acc_epoch' in epoch_data.columns and epoch_data['val_acc_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_acc_epoch'].idxmax()]\n",
    "    elif 'val_loss_epoch' in epoch_data.columns and epoch_data['val_loss_epoch'].notna().any():\n",
    "        best_chpt = epoch_data.loc[epoch_data['val_loss_epoch'].idxmin()]\n",
    "    else:\n",
    "        raise ValueError(f\"No valid validation metrics available for epoch {epoch_numbers}.\")\n",
    "    return np.argwhere(np.array(epoch_numbers)==best_chpt['epoch']).item(), best_chpt['val_loss_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_metrics_mean(base_path = 'logs\\CNN-GNN18_mr2k_seeds', start=0, interval=1):\n",
    "    total_accuracy = []\n",
    "    total_f1 = []\n",
    "    total_prec = []\n",
    "    total_rec = []\n",
    "    total_loss = []\n",
    "    \n",
    "    for i in range(start, start + interval):\n",
    "        version_path = join(base_path, f'version_{i}')\n",
    "        checkpoint_path = join(version_path, f'checkpoints')\n",
    "        onlyfiles  = [f for f in listdir(checkpoint_path) if (isfile(join(checkpoint_path, f)) and 'epoch' in f) ]\n",
    "        epoch_numbers = [int(re.search(r'\\d+', f).group()) for f in onlyfiles]\n",
    "        best_chpt_id, loss = get_best_chpt(join(version_path, 'metrics.csv'), epoch_numbers)\n",
    "        print(onlyfiles[best_chpt_id])\n",
    "        mean_infer_acc, mean_infer_f1, mean_infer_prec, mean_infer_rec, classfier_lightning_model = calculatge_metrics(join(checkpoint_path, f'{onlyfiles[best_chpt_id]}'), test_dataloader)\n",
    "            \n",
    "        total_accuracy.append(mean_infer_acc)\n",
    "        total_f1.append(mean_infer_f1)\n",
    "        total_prec.append(mean_infer_prec)\n",
    "        total_rec.append(mean_infer_rec)\n",
    "        total_loss.append(loss)\n",
    "\n",
    "    total_accuracy = torch.mean(torch.tensor(total_accuracy))\n",
    "    total_f1 = torch.mean(torch.tensor(total_f1))\n",
    "    total_prec = torch.mean(torch.tensor(total_prec))\n",
    "    total_rec = torch.mean(torch.tensor(total_rec))\n",
    "    total_loss = torch.mean(torch.tensor(total_loss))\n",
    "    print(f'total_accuracy: {total_accuracy}')\n",
    "    print(f'total_f1: {total_f1}')\n",
    "    print(f'total_prec: {total_prec}')\n",
    "    print(f'total_rec: {total_rec}')\n",
    "    print(f'total_loss: {total_loss}')\n",
    "    return classfier_lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=26-step=2646.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.9081951530612244\n",
      "total_f1: 0.9082070482356379\n",
      "total_prec: 0.9082199438493459\n",
      "total_rec: 0.9081951529888237\n",
      "total_loss: 0.2710480690002441\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(r'logs\\CNN-GNN_False_False_False', start=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=52-step=20723.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_accuracy: 0.9022218670076727\n",
      "total_f1: 0.9022369648498394\n",
      "total_prec: 0.9022530633260486\n",
      "total_rec: 0.9022218669355642\n",
      "total_loss: 0.250955730676651\n"
     ]
    }
   ],
   "source": [
    "classfier_lightning_model = calculate_average_metrics_mean(r'logs\\CNN-GNN_False_False_False', start=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
